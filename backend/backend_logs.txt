
> xob-cat-backend@1.0.0 dev
> tsx watch src/index.ts

ğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T02:11:23.316Z",
  "dateTo": "2025-08-12T02:12:23.316Z",
  "skip": 0,
  "limit": 1
}
[fetchContainmentTypeMetadata] API Response: 0 agent sessions received
[getSessionsMetadataForConnectionTest] Single API call succeeded with 0 sessions
::1 - - [12/Aug/2025:02:12:26 +0000] "GET /api/kore/test HTTP/1.1" 200 299 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[Direct API] Fetching real Kore.ai sessions from 2025-08-05T02:12:26.813Z to 2025-08-12T02:12:26.813Z for User Bot st-90549... (limit=50)
Retrieving sessions from 2025-08-05T02:12:26.813Z to 2025-08-12T02:12:26.813Z (limit=50), populateMessages=true...
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T02:12:26.813Z",
  "dateTo": "2025-08-12T02:12:26.813Z",
  "limit": 50
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T02:12:26.813Z",
  "dateTo": "2025-08-12T02:12:26.813Z",
  "skip": 0,
  "limit": 50
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T02:12:26.813Z",
  "dateTo": "2025-08-12T02:12:26.813Z",
  "skip": 0,
  "limit": 50
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T02:12:26.813Z",
  "dateTo": "2025-08-12T02:12:26.813Z",
  "skip": 0,
  "limit": 50
}
::1 - - [12/Aug/2025:02:12:27 +0000] "GET /api/analysis/sessions?limit=50 HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[Direct API] Fetching real Kore.ai sessions from 2025-08-05T02:12:27.656Z to 2025-08-12T02:12:27.656Z for User Bot st-90549... (limit=50)
Retrieving sessions from 2025-08-05T02:12:27.656Z to 2025-08-12T02:12:27.656Z (limit=50), populateMessages=true...
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T02:12:27.656Z",
  "dateTo": "2025-08-12T02:12:27.656Z",
  "limit": 50
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T02:12:27.656Z",
  "dateTo": "2025-08-12T02:12:27.656Z",
  "skip": 0,
  "limit": 50
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T02:12:27.656Z",
  "dateTo": "2025-08-12T02:12:27.656Z",
  "skip": 0,
  "limit": 50
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T02:12:27.656Z",
  "dateTo": "2025-08-12T02:12:27.656Z",
  "skip": 0,
  "limit": 50
}
::1 - - [12/Aug/2025:02:12:27 +0000] "GET /api/analysis/sessions?limit=50 HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 50 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689aa18d0a261bd44366dc1f',
  '689a9ddbb110c33d6977a4d7',
  '689a9b5d995362de8de21eda'
]
[fetchContainmentTypeMetadata] API Response: 50 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689a9a761fa10dad3e907bab',
  '689a97b5144f8feea17188cf',
  '689a96f3f54cdbf3dee324a0'
]
[fetchContainmentTypeMetadata] API Response: 50 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689a9fe1296df1d830c05e55',
  '689a9f815ed4804abeac9597',
  '689a9f7f886ba2d0d23d0c98'
]
[getSessionsMetadata] agent API call succeeded with 50 sessions
[getSessionsMetadata] selfService API call succeeded with 50 sessions
[getSessionsMetadata] dropOff API call succeeded with 50 sessions
Total session metadata retrieved: 150 (parallel execution)
Retrieved 150 session metadata objects
Creating 150 SWTs from metadata (no messages)
Created 150 SWT objects from metadata
Populating messages for all sessions (legacy behavior)
Populating messages for 150 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 150 sessions from 2025-08-11T21:55:29.466Z to 2025-08-12T02:07:53.656Z at 2025-08-12T02:12:30.268Z
ğŸš€ [ConcurrentBatch] Split 150 sessions into 8 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/8] Starting: 20 sessions
[Batch 2/8] Starting: 20 sessions
[Batch 3/8] Starting: 20 sessions
[Batch 4/8] Starting: 20 sessions
[Batch 5/8] Starting: 20 sessions
[Batch 6/8] Starting: 20 sessions
[Batch 7/8] Starting: 20 sessions
[Batch 8/8] Starting: 10 sessions
[fetchContainmentTypeMetadata] API Response: 50 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689aa18d0a261bd44366dc1f',
  '689a9ddbb110c33d6977a4d7',
  '689a9b5d995362de8de21eda'
]
[fetchContainmentTypeMetadata] API Response: 50 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689a9a761fa10dad3e907bab',
  '689a97b5144f8feea17188cf',
  '689a96f3f54cdbf3dee324a0'
]
[fetchContainmentTypeMetadata] API Response: 50 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689a9fe1296df1d830c05e55',
  '689a9f815ed4804abeac9597',
  '689a9f7f886ba2d0d23d0c98'
]
[getSessionsMetadata] agent API call succeeded with 50 sessions
[getSessionsMetadata] selfService API call succeeded with 50 sessions
[getSessionsMetadata] dropOff API call succeeded with 50 sessions
Total session metadata retrieved: 150 (parallel execution)
Retrieved 150 session metadata objects
Creating 150 SWTs from metadata (no messages)
Created 150 SWT objects from metadata
Populating messages for all sessions (legacy behavior)
Populating messages for 150 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 150 sessions from 2025-08-11T21:55:29.466Z to 2025-08-12T02:07:53.656Z at 2025-08-12T02:12:30.457Z
ğŸš€ [ConcurrentBatch] Split 150 sessions into 8 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/8] Starting: 20 sessions
[Batch 2/8] Starting: 20 sessions
[Batch 3/8] Starting: 20 sessions
[Batch 4/8] Starting: 20 sessions
[Batch 5/8] Starting: 20 sessions
[Batch 6/8] Starting: 20 sessions
[Batch 7/8] Starting: 20 sessions
[Batch 8/8] Starting: 10 sessions
[Batch 2/8] Completed in 198ms: 213 messages retrieved (1/8 done)
[Batch 1/8] Completed in 313ms: 262 messages retrieved (2/8 done)
[Batch 3/8] Completed in 321ms: 495 messages retrieved (3/8 done)
[Batch 7/8] Completed in 359ms: 187 messages retrieved (4/8 done)
[Batch 1/8] Completed in 200ms: 262 messages retrieved (1/8 done)
[Batch 2/8] Completed in 219ms: 213 messages retrieved (2/8 done)
[Batch 5/8] Completed in 479ms: 505 messages retrieved (5/8 done)
[Batch 8/8] Completed in 486ms: 110 messages retrieved (6/8 done)
[Batch 4/8] Completed in 341ms: 568 messages retrieved (3/8 done)
[Batch 4/8] Completed in 622ms: 568 messages retrieved (7/8 done)
[Batch 6/8] Completed in 476ms: 385 messages retrieved (4/8 done)
[Batch 6/8] Completed in 693ms: 385 messages retrieved (8/8 done)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 693ms (0.69s)
â±ï¸  Batch Processing: 693ms (0.69s)
ğŸ“¦ Total batches: 8 (max 10 concurrent)
âœ… Successful batches: 8/8
ğŸ’¬ Total messages: 2725
ğŸ“ˆ Avg time per batch: 87ms
ğŸš€ Time per session: 5ms
ğŸ’ª Performance: 216.5 sessions/second
=======================================================

Retrieved 2725 messages for 150 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
Populated messages for 150 SWT objects
Generated 150 SWT objects in 4173ms using layered architecture
[Batch 3/8] Completed in 540ms: 495 messages retrieved (5/8 done)
[Batch 5/8] Completed in 543ms: 505 messages retrieved (6/8 done)
[Batch 7/8] Completed in 558ms: 187 messages retrieved (7/8 done)
[Batch 8/8] Completed in 723ms: 110 messages retrieved (8/8 done)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 724ms (0.72s)
â±ï¸  Batch Processing: 724ms (0.72s)
ğŸ“¦ Total batches: 8 (max 10 concurrent)
âœ… Successful batches: 8/8
ğŸ’¬ Total messages: 2725
ğŸ“ˆ Avg time per batch: 91ms
ğŸš€ Time per session: 5ms
ğŸ’ª Performance: 207.2 sessions/second
=======================================================

Retrieved 2725 messages for 150 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
Populated messages for 150 SWT objects
Generated 150 SWT objects in 3537ms using layered architecture
ğŸš€ [AutoAnalyzeRoute] Starting analysis for bot ***REMOVED*** with real credentials
ğŸš€ AutoAnalyzeService: Creating services for bot ***REMOVED***
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
ğŸ­ ServiceFactory: Creating OpenAI service (type: real)
ğŸš€ [AutoAnalyzeService] Starting analysis f20d18bc-a519-4e47-a314-08eeb56e4436 with bot ***REMOVED***
ğŸš€ [AutoAnalyzeService] Using credentials: real
ğŸš€ [AutoAnalyzeRoute] Analysis started: f20d18bc-a519-4e47-a314-08eeb56e4436
::1 - - [12/Aug/2025:02:12:45 +0000] "POST /api/analysis/auto-analyze/start HTTP/1.1" 200 205 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:02:12:45 +0000] "GET /api/analysis/auto-analyze/progress/f20d18bc-a519-4e47-a314-08eeb56e4436 HTTP/1.1" 200 478 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:02:12:45 +0000] "GET /api/analysis/auto-analyze/progress/f20d18bc-a519-4e47-a314-08eeb56e4436 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[BackgroundJobQueue] Starting job processing after delay for job f20d18bc-a519-4e47-a314-08eeb56e4436-sampling
[BackgroundJobQueue] Starting processing for job f20d18bc-a519-4e47-a314-08eeb56e4436-sampling, phase: sampling
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing sampling phase for job f20d18bc-a519-4e47-a314-08eeb56e4436-sampling
[BackgroundJobQueue] Processing sampling phase for bot: ***REMOVED***
[BackgroundJobQueue] Creating real service for bot: ***REMOVED***
[BackgroundJobQueue] Full config: {
  "botId": "***REMOVED***",
  "clientId": "***REMOVED***",
  "clientSecret": "***REMOVED***",
  "baseUrl": "https://bots.kore.ai"
}
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[BackgroundJobQueue] Created service type: RealKoreApiService

ğŸ• ============ SESSION SAMPLING STARTED ============
ğŸ• [SessionSampling] Starting session sampling at 2025-08-12T02:12:46.477Z
ğŸ” [SessionDiscovery] Starting window 1/4: Initial 3-hour window
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
::1 - - [12/Aug/2025:02:12:47 +0000] "GET /api/analysis/auto-analyze/progress/f20d18bc-a519-4e47-a314-08eeb56e4436 HTTP/1.1" 200 533 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 80 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a1287849680ad9fe59e',
  '689229f9583056c6108e38fb',
  '68922914f8bee7ba6c3e67b8'
]
[fetchContainmentTypeMetadata] API Response: 139 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6a14dd27c3112087cd',
  '68922a22ef03d8ad2ec7b4ba',
  '68922a1278c1fe09a079719c'
]
::1 - - [12/Aug/2025:02:12:49 +0000] "GET /api/analysis/auto-analyze/progress/f20d18bc-a519-4e47-a314-08eeb56e4436 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 1338 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6d14dd27c31120888b',
  '68922a62e3804084741191d5',
  '68922a523a3160d25de144c8'
]
[getSessionsMetadata] agent API call succeeded with 1338 sessions
[getSessionsMetadata] selfService API call succeeded with 80 sessions
[getSessionsMetadata] dropOff API call succeeded with 139 sessions
Total session metadata retrieved: 1557 (parallel execution)
Creating 1557 SWTs from metadata (no messages)
Created 1557 SWT objects from metadata
âœ… [SessionDiscovery] Window 1 completed in 4934ms: found 1557 new sessions (total: 1557)
â±ï¸  TIMING: Window 1 took 4934ms (4.93s)
ğŸ¯ [SessionDiscovery] Target reached! Found 1557 sessions in 4934ms
ğŸ² [SessionSampling] Random sampling from 1557 sessions to 10 sessions

ğŸ“¬ ============ MESSAGE RETRIEVAL STARTED ============
ğŸ“¬ [MessageRetrieval] Starting message retrieval for 10 sampled sessions at 2025-08-12T02:12:51.412Z
Using new lazy loading approach to populate messages for 10 sampled sessions
Populating messages for 10 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 10 sessions from 2025-08-05T13:06:58.777Z to 2025-08-05T15:35:04.671Z at 2025-08-12T02:12:51.412Z
ğŸ”„ [KoreAPI] Using single API call for 10 sessions (â‰¤20)
::1 - - [12/Aug/2025:02:12:51 +0000] "GET /api/analysis/auto-analyze/progress/f20d18bc-a519-4e47-a314-08eeb56e4436 HTTP/1.1" 200 553 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… [KoreAPI] Single call completed in 240ms: 119 messages
Retrieved 119 messages for 10 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
Populated messages for 10 SWT objects
Successfully populated messages for 10 sessions using lazy loading
Applying final filtering to 10 sessions with populated messages
Final result: 10 sessions passed filtering with populated messages

ğŸ‰ ============ SESSION SAMPLING COMPLETED ============
â±ï¸  TOTAL TIME: 5176ms (5.18s)
â±ï¸  Session Discovery: 4934ms (4.93s) - 95.3% of total
â±ï¸  Message Retrieval: 241ms (0.24s) - 4.7% of total
â±ï¸  Performance: 1.9 sessions/second
ğŸ¯ Final result: 10 sessions with messages retrieved
====================================================

[BackgroundJobQueue] Found 10 sessions for job f20d18bc-a519-4e47-a314-08eeb56e4436-sampling
[BackgroundJobQueue] Starting job processing after delay for job f20d18bc-a519-4e47-a314-08eeb56e4436-sampling-analysis
[BackgroundJobQueue] Starting processing for job f20d18bc-a519-4e47-a314-08eeb56e4436-sampling-analysis, phase: analyzing
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing analysis phase for job f20d18bc-a519-4e47-a314-08eeb56e4436-sampling-analysis with 10 sessions
ğŸ­ ServiceFactory: Creating OpenAI service (type: real)

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T02:12:52.656Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6724,
  existingClassifications: { intents: 0, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.



For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and another intent, classify the intent as the other i...
::1 - - [12/Aug/2025:02:12:53 +0000] "GET /api/analysis/auto-analyze/progress/f20d18bc-a519-4e47-a314-08eeb56e4436 HTTP/1.1" 200 521 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:02:12:55 +0000] "GET /api/analysis/auto-analyze/progress/f20d18bc-a519-4e47-a314-08eeb56e4436 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T02:12:55.742Z',
  duration: '3086ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1956,
    completion_tokens: 335,
    total_tokens: 2291,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Claim Status', 'Unknown' ],
  transferCount: 3,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-8126563b-e494-55d5-9511-40288ef17b49",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User needed help with a claim, session was handled by bot."
    },
    {
      "user_id": "u-0166205d-0c7a-55b3-9e07-111b6dae59d7",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested customer service and was transferred to an agent."
    },
    {
      "user_id": "u-86a4c1e1-bbf4-5386-9a53-90c0714b79f5",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent and was transferred."
    },
    {
      "user_id": "u-9c8b9970-d345-5240-b8f0-91f54acc7469",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User provided claim details and received a status update."
    },
    {
      "user_id": "u-3f48cbe1-1f8f-5e2a-8a85-c22b43e243de",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked about doctor sending FMLA paperwork and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1956,
  completionTokens: 335,
  totalTokens: 2291,
  cost: '$0.000330',
  modelUsedForCost: 'gpt-4.1-nano'
}
::1 - - [12/Aug/2025:02:12:57 +0000] "GET /api/analysis/auto-analyze/progress/f20d18bc-a519-4e47-a314-08eeb56e4436 HTTP/1.1" 200 532 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T02:12:57.745Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7316,
  existingClassifications: { intents: 2, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live A...
::1 - - [12/Aug/2025:02:12:59 +0000] "GET /api/analysis/auto-analyze/progress/f20d18bc-a519-4e47-a314-08eeb56e4436 HTTP/1.1" 200 532 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T02:13:00.047Z',
  duration: '2301ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2092,
    completion_tokens: 323,
    total_tokens: 2415,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Claim Status', 'Live Agent' ],
  transferCount: 2,
  containedCount: 3
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-f3ba59dd-762d-5bf3-ae72-fa82b8026e56",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User was unable to provide leave request number and the session was closed without transfer."
    },
    {
      "user_id": "u-30f50bcc-b24c-519d-987e-df1b5803c392",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User was silent; no transfer occurred."
    },
    {
      "user_id": "u-1e335903-d482-5092-aebf-1c3765fca936",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an operator; session was transferred to an agent."
    },
    {
      "user_id": "u-336964cc-89d8-5f7d-8752-594032bb16c8",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User provided claim and personal details but did not complete the request; session ended without transfer."
    },
    {
      "user_id": "u-f49ff565-7e3b-5d8a-afb5-6f2318aa26b7",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent; session was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2092,
  completionTokens: 323,
  totalTokens: 2415,
  cost: '$0.000338',
  modelUsedForCost: 'gpt-4.1-nano'
}
[BackgroundJobQueue] Session analysis completed for job f20d18bc-a519-4e47-a314-08eeb56e4436-sampling-analysis, processed 10 sessions
::1 - - [12/Aug/2025:02:13:01 +0000] "GET /api/analysis/auto-analyze/progress/f20d18bc-a519-4e47-a314-08eeb56e4436 HTTP/1.1" 200 548 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:02:13:03 +0000] "GET /api/analysis/auto-analyze/progress/f20d18bc-a519-4e47-a314-08eeb56e4436 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:02:13:05 +0000] "GET /api/analysis/auto-analyze/progress/f20d18bc-a519-4e47-a314-08eeb56e4436 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:02:13:07 +0000] "GET /api/analysis/auto-analyze/progress/f20d18bc-a519-4e47-a314-08eeb56e4436 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:02:13:09 +0000] "GET /api/analysis/auto-analyze/progress/f20d18bc-a519-4e47-a314-08eeb56e4436 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:02:13:11 +0000] "GET /api/analysis/auto-analyze/progress/f20d18bc-a519-4e47-a314-08eeb56e4436 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:02:13:13 +0000] "GET /api/analysis/auto-analyze/progress/f20d18bc-a519-4e47-a314-08eeb56e4436 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:02:13:15 +0000] "GET /api/analysis/auto-analyze/progress/f20d18bc-a519-4e47-a314-08eeb56e4436 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:02:13:17 +0000] "GET /api/analysis/auto-analyze/progress/f20d18bc-a519-4e47-a314-08eeb56e4436 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:02:13:19 +0000] "GET /api/analysis/auto-analyze/progress/f20d18bc-a519-4e47-a314-08eeb56e4436 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[BackgroundJobQueue] Analysis summary generated for job f20d18bc-a519-4e47-a314-08eeb56e4436-sampling-analysis
[BackgroundJobQueue] Analysis completed for job f20d18bc-a519-4e47-a314-08eeb56e4436-sampling-analysis, processed 10 sessions
[BackgroundJobQueue] Results successfully stored in AutoAnalyzeService for analysis f20d18bc-a519-4e47-a314-08eeb56e4436
[BackgroundJobQueue] Analysis f20d18bc-a519-4e47-a314-08eeb56e4436 completed with 10 sessions
::1 - - [12/Aug/2025:02:13:21 +0000] "GET /api/analysis/auto-analyze/progress/f20d18bc-a519-4e47-a314-08eeb56e4436 HTTP/1.1" 200 564 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:02:13:21 +0000] "GET /api/analysis/auto-analyze/results/f20d18bc-a519-4e47-a314-08eeb56e4436 HTTP/1.1" 200 71375 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
10:24:47 PM [tsx] change in ./src/services/parallelProcessingOrchestratorService.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
10:25:36 PM [tsx] change in ./src/services/streamProcessingService.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
10:25:52 PM [tsx] change in ./src/services/streamProcessingService.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
10:26:54 PM [tsx] change in ./src/services/tokenManagementService.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
10:28:07 PM [tsx] change in ./src/services/batchAnalysisService.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T02:27:33.074Z",
  "dateTo": "2025-08-12T02:28:33.074Z",
  "skip": 0,
  "limit": 1
}
[fetchContainmentTypeMetadata] API Response: 0 agent sessions received
[getSessionsMetadataForConnectionTest] Single API call succeeded with 0 sessions
::1 - - [12/Aug/2025:02:28:36 +0000] "GET /api/kore/test HTTP/1.1" 200 299 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[Direct API] Fetching real Kore.ai sessions from 2025-08-05T02:28:36.646Z to 2025-08-12T02:28:36.646Z for User Bot st-90549... (limit=50)
Retrieving sessions from 2025-08-05T02:28:36.646Z to 2025-08-12T02:28:36.646Z (limit=50), populateMessages=true...
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T02:28:36.646Z",
  "dateTo": "2025-08-12T02:28:36.646Z",
  "limit": 50
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T02:28:36.646Z",
  "dateTo": "2025-08-12T02:28:36.646Z",
  "skip": 0,
  "limit": 50
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T02:28:36.646Z",
  "dateTo": "2025-08-12T02:28:36.646Z",
  "skip": 0,
  "limit": 50
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T02:28:36.646Z",
  "dateTo": "2025-08-12T02:28:36.646Z",
  "skip": 0,
  "limit": 50
}
::1 - - [12/Aug/2025:02:28:37 +0000] "GET /api/analysis/sessions?limit=50 HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 50 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689aa5b8cc9c7f5ad059a7df',
  '689aa4ae995362de8de2f0c9',
  '689aa485144f8feea172bb79'
]
[fetchContainmentTypeMetadata] API Response: 50 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689a9a761fa10dad3e907bab',
  '689a97b5144f8feea17188cf',
  '689a96f3f54cdbf3dee324a0'
]
[fetchContainmentTypeMetadata] API Response: 50 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689aa6c0fca75d8282009498',
  '689aa691695380b63c3ade9b',
  '689aa567144f8feea172d668'
]
[getSessionsMetadata] agent API call succeeded with 50 sessions
[getSessionsMetadata] selfService API call succeeded with 50 sessions
[getSessionsMetadata] dropOff API call succeeded with 50 sessions
Total session metadata retrieved: 150 (parallel execution)
Retrieved 150 session metadata objects
Creating 150 SWTs from metadata (no messages)
Created 150 SWT objects from metadata
Populating messages for all sessions (legacy behavior)
Populating messages for 150 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 150 sessions from 2025-08-11T22:30:16.664Z to 2025-08-12T02:28:32.001Z at 2025-08-12T02:28:39.520Z
ğŸš€ [ConcurrentBatch] Split 150 sessions into 8 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/8] Starting: 20 sessions
[Batch 2/8] Starting: 20 sessions
[Batch 3/8] Starting: 20 sessions
[Batch 4/8] Starting: 20 sessions
[Batch 5/8] Starting: 20 sessions
[Batch 6/8] Starting: 20 sessions
[Batch 7/8] Starting: 20 sessions
[Batch 8/8] Starting: 10 sessions
[Batch 2/8] Completed in 267ms: 255 messages retrieved (1/8 done)
[Batch 1/8] Completed in 271ms: 253 messages retrieved (2/8 done)
[Batch 3/8] Completed in 299ms: 336 messages retrieved (3/8 done)
[Batch 8/8] Completed in 363ms: 110 messages retrieved (4/8 done)
[Batch 7/8] Completed in 444ms: 187 messages retrieved (5/8 done)
[Batch 6/8] Completed in 538ms: 385 messages retrieved (6/8 done)
[Batch 5/8] Completed in 708ms: 528 messages retrieved (7/8 done)
[Batch 4/8] Completed in 725ms: 652 messages retrieved (8/8 done)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 726ms (0.73s)
â±ï¸  Batch Processing: 725ms (0.72s)
ğŸ“¦ Total batches: 8 (max 10 concurrent)
âœ… Successful batches: 8/8
ğŸ’¬ Total messages: 2706
ğŸ“ˆ Avg time per batch: 91ms
ğŸš€ Time per session: 5ms
ğŸ’ª Performance: 206.6 sessions/second
=======================================================

Retrieved 2706 messages for 150 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
Populated messages for 150 SWT objects
Generated 150 SWT objects in 3624ms using layered architecture
ğŸš€ [AutoAnalyzeRoute] Starting analysis for bot ***REMOVED*** with real credentials
ğŸš€ AutoAnalyzeService: Creating services for bot ***REMOVED***
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
ğŸ­ ServiceFactory: Creating OpenAI service (type: real)
ğŸš€ [AutoAnalyzeService] Starting analysis ccd0cac5-2349-4aec-bb06-3c5737e77e08 with bot ***REMOVED***
ğŸš€ [AutoAnalyzeService] Using credentials: real
ğŸš€ [AutoAnalyzeRoute] Analysis started: ccd0cac5-2349-4aec-bb06-3c5737e77e08
::1 - - [12/Aug/2025:02:28:55 +0000] "POST /api/analysis/auto-analyze/start HTTP/1.1" 200 205 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:02:28:55 +0000] "GET /api/analysis/auto-analyze/progress/ccd0cac5-2349-4aec-bb06-3c5737e77e08 HTTP/1.1" 200 478 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:02:28:55 +0000] "GET /api/analysis/auto-analyze/progress/ccd0cac5-2349-4aec-bb06-3c5737e77e08 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[BackgroundJobQueue] Starting job processing after delay for job ccd0cac5-2349-4aec-bb06-3c5737e77e08-sampling
[BackgroundJobQueue] Starting processing for job ccd0cac5-2349-4aec-bb06-3c5737e77e08-sampling, phase: sampling
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing sampling phase for job ccd0cac5-2349-4aec-bb06-3c5737e77e08-sampling
[BackgroundJobQueue] Processing sampling phase for bot: ***REMOVED***
[BackgroundJobQueue] Creating real service for bot: ***REMOVED***
[BackgroundJobQueue] Full config: {
  "botId": "***REMOVED***",
  "clientId": "***REMOVED***",
  "clientSecret": "***REMOVED***",
  "baseUrl": "https://bots.kore.ai"
}
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[BackgroundJobQueue] Created service type: RealKoreApiService

ğŸ• ============ SESSION SAMPLING STARTED ============
ğŸ• [SessionSampling] Starting session sampling at 2025-08-12T02:28:56.476Z
ğŸ” [SessionDiscovery] Starting window 1/4: Initial 3-hour window
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
::1 - - [12/Aug/2025:02:28:57 +0000] "GET /api/analysis/auto-analyze/progress/ccd0cac5-2349-4aec-bb06-3c5737e77e08 HTTP/1.1" 200 533 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 80 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a1287849680ad9fe59e',
  '689229f9583056c6108e38fb',
  '68922914f8bee7ba6c3e67b8'
]
::1 - - [12/Aug/2025:02:28:59 +0000] "GET /api/analysis/auto-analyze/progress/ccd0cac5-2349-4aec-bb06-3c5737e77e08 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 139 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6a14dd27c3112087cd',
  '68922a22ef03d8ad2ec7b4ba',
  '68922a1278c1fe09a079719c'
]
[fetchContainmentTypeMetadata] API Response: 1338 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6d14dd27c31120888b',
  '68922a62e3804084741191d5',
  '68922a523a3160d25de144c8'
]
[getSessionsMetadata] agent API call succeeded with 1338 sessions
[getSessionsMetadata] selfService API call succeeded with 80 sessions
[getSessionsMetadata] dropOff API call succeeded with 139 sessions
Total session metadata retrieved: 1557 (parallel execution)
Creating 1557 SWTs from metadata (no messages)
Created 1557 SWT objects from metadata
âœ… [SessionDiscovery] Window 1 completed in 4868ms: found 1557 new sessions (total: 1557)
â±ï¸  TIMING: Window 1 took 4868ms (4.87s)
ğŸ¯ [SessionDiscovery] Target reached! Found 1557 sessions in 4868ms
ğŸ² [SessionSampling] Random sampling from 1557 sessions to 10 sessions

ğŸ“¬ ============ MESSAGE RETRIEVAL STARTED ============
ğŸ“¬ [MessageRetrieval] Starting message retrieval for 10 sampled sessions at 2025-08-12T02:29:01.345Z
Using new lazy loading approach to populate messages for 10 sampled sessions
Populating messages for 10 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 10 sessions from 2025-08-05T13:01:51.804Z to 2025-08-05T15:51:51.680Z at 2025-08-12T02:29:01.345Z
ğŸ”„ [KoreAPI] Using single API call for 10 sessions (â‰¤20)
::1 - - [12/Aug/2025:02:29:01 +0000] "GET /api/analysis/auto-analyze/progress/ccd0cac5-2349-4aec-bb06-3c5737e77e08 HTTP/1.1" 200 553 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… [KoreAPI] Single call completed in 292ms: 166 messages
Retrieved 166 messages for 10 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
Populated messages for 10 SWT objects
Successfully populated messages for 10 sessions using lazy loading
Applying final filtering to 10 sessions with populated messages
Final result: 10 sessions passed filtering with populated messages

ğŸ‰ ============ SESSION SAMPLING COMPLETED ============
â±ï¸  TOTAL TIME: 5162ms (5.16s)
â±ï¸  Session Discovery: 4868ms (4.87s) - 94.3% of total
â±ï¸  Message Retrieval: 293ms (0.29s) - 5.7% of total
â±ï¸  Performance: 1.9 sessions/second
ğŸ¯ Final result: 10 sessions with messages retrieved
====================================================

[BackgroundJobQueue] Found 10 sessions for job ccd0cac5-2349-4aec-bb06-3c5737e77e08-sampling
[BackgroundJobQueue] Starting job processing after delay for job ccd0cac5-2349-4aec-bb06-3c5737e77e08-sampling-analysis
[BackgroundJobQueue] Starting processing for job ccd0cac5-2349-4aec-bb06-3c5737e77e08-sampling-analysis, phase: analyzing
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing analysis phase for job ccd0cac5-2349-4aec-bb06-3c5737e77e08-sampling-analysis with 10 sessions
ğŸ­ ServiceFactory: Creating OpenAI service (type: real)

ğŸ“¦ ===== BATCH 1 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T02:29:02.642Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 0
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 1ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T02:29:02.643Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T02:29:02.645Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 8252,
  existingClassifications: { intents: 0, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.



For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and another intent, classify the intent as the other i...
::1 - - [12/Aug/2025:02:29:03 +0000] "GET /api/analysis/auto-analyze/progress/ccd0cac5-2349-4aec-bb06-3c5737e77e08 HTTP/1.1" 200 521 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:02:29:05 +0000] "GET /api/analysis/auto-analyze/progress/ccd0cac5-2349-4aec-bb06-3c5737e77e08 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T02:29:05.853Z',
  duration: '3207ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2361,
    completion_tokens: 363,
    total_tokens: 2724,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Live Agent', 'Authorization', 'Claim Status', 'Time Entry' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-48551807-4d52-50e3-a209-f49923052de5",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent but did not provide input before session ended."
    },
    {
      "user_id": "u-e6cb457c-5356-50ad-9582-22092e1a1a86",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and did not respond, leading to transfer to an agent."
    },
    {
      "user_id": "u-5b34c616-2859-5f6d-868f-d9f67a3fc5e5",
      "general_intent": "Authorization",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative, session transferred."
    },
    {
      "user_id": "u-655a83a2-22f0-57c6-8fa5-4ce279aa16bc",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted a representative; session transferred."
    },
    {
      "user_id": "u-2db0e173-29c3-55da-b67c-75eb37670165",
      "general_intent": "Time Entry",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was unable to verify details and transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2361,
  completionTokens: 363,
  totalTokens: 2724,
  cost: '$0.000381',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 3211ms (3.21s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2724 ($0.0004)
âš¡ Performance: 848.3 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 3211ms (3.21s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2724

âœ… ===== BATCH 1 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 3212ms (3.21s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2724 ($0.0004)
âš¡ Performance: 1.6 sessions/sec
âš¡ Avg Time Per Session: 642.40ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:02:29:07 +0000] "GET /api/analysis/auto-analyze/progress/ccd0cac5-2349-4aec-bb06-3c5737e77e08 HTTP/1.1" 200 532 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"

ğŸ“¦ ===== BATCH 2 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T02:29:07.856Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 1ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T02:29:07.857Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T02:29:07.857Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6907,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Authorization, Claim Status, Live Agent, Time Entry
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Bi...
::1 - - [12/Aug/2025:02:29:09 +0000] "GET /api/analysis/auto-analyze/progress/ccd0cac5-2349-4aec-bb06-3c5737e77e08 HTTP/1.1" 200 532 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:02:29:11 +0000] "GET /api/analysis/auto-analyze/progress/ccd0cac5-2349-4aec-bb06-3c5737e77e08 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:02:29:13 +0000] "GET /api/analysis/auto-analyze/progress/ccd0cac5-2349-4aec-bb06-3c5737e77e08 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T02:29:13.605Z',
  duration: '5748ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1971,
    completion_tokens: 365,
    total_tokens: 2336,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Time Entry', 'Claim Status', 'Live Agent', 'Leave Form' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-1da68389-6b58-5f96-99b0-f293cdb6d560",
      "general_intent": "Time Entry",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to report time but was transferred to a live agent."
    },
    {
      "user_id": "u-21585c58-f3fa-50f8-a3b5-ec99852a5b2b",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User inquired about claim status and was transferred to a live agent."
    },
    {
      "user_id": "u-046312a9-e331-5d87-91bf-18f55f78202e",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent and was transferred."
    },
    {
      "user_id": "u-5f863a17-1021-58ee-97ce-915f05a4e656",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to check claim status and was transferred to a live agent."
    },
    {
      "user_id": "u-075e6782-6eaa-5775-bfce-a929ed78e103",
      "general_intent": "Leave Form",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a leave form and was transferred to a live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1971,
  completionTokens: 365,
  totalTokens: 2336,
  cost: '$0.000343',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 5749ms (5.75s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2336 ($0.0003)
âš¡ Performance: 406.3 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 5749ms (5.75s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2336

âœ… ===== BATCH 2 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 5750ms (5.75s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2336 ($0.0003)
âš¡ Performance: 0.9 sessions/sec
âš¡ Avg Time Per Session: 1150.00ms
â±ï¸  Metadata Processing: 0ms
[BackgroundJobQueue] Session analysis completed for job ccd0cac5-2349-4aec-bb06-3c5737e77e08-sampling-analysis, processed 10 sessions
::1 - - [12/Aug/2025:02:29:15 +0000] "GET /api/analysis/auto-analyze/progress/ccd0cac5-2349-4aec-bb06-3c5737e77e08 HTTP/1.1" 200 549 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:02:29:17 +0000] "GET /api/analysis/auto-analyze/progress/ccd0cac5-2349-4aec-bb06-3c5737e77e08 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:02:29:19 +0000] "GET /api/analysis/auto-analyze/progress/ccd0cac5-2349-4aec-bb06-3c5737e77e08 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:02:29:21 +0000] "GET /api/analysis/auto-analyze/progress/ccd0cac5-2349-4aec-bb06-3c5737e77e08 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:02:29:23 +0000] "GET /api/analysis/auto-analyze/progress/ccd0cac5-2349-4aec-bb06-3c5737e77e08 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:02:29:25 +0000] "GET /api/analysis/auto-analyze/progress/ccd0cac5-2349-4aec-bb06-3c5737e77e08 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[BackgroundJobQueue] Analysis summary generated for job ccd0cac5-2349-4aec-bb06-3c5737e77e08-sampling-analysis
[BackgroundJobQueue] Analysis completed for job ccd0cac5-2349-4aec-bb06-3c5737e77e08-sampling-analysis, processed 10 sessions
[BackgroundJobQueue] Results successfully stored in AutoAnalyzeService for analysis ccd0cac5-2349-4aec-bb06-3c5737e77e08
[BackgroundJobQueue] Analysis ccd0cac5-2349-4aec-bb06-3c5737e77e08 completed with 10 sessions
::1 - - [12/Aug/2025:02:29:27 +0000] "GET /api/analysis/auto-analyze/progress/ccd0cac5-2349-4aec-bb06-3c5737e77e08 HTTP/1.1" 200 565 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:02:29:27 +0000] "GET /api/analysis/auto-analyze/results/ccd0cac5-2349-4aec-bb06-3c5737e77e08 HTTP/1.1" 200 87223 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
10:30:41 PM [tsx] change in ./src/routes/analysis.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
10:30:57 PM [tsx] change in ./src/routes/analysis.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
ğŸš€ [ParallelAutoAnalyzeRoute] Starting parallel analysis for bot test-bot with mock credentials
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=real
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: test-bot
ğŸ­ ServiceFactory: Creating OpenAI service (type: real)
ğŸš€ [ParallelAutoAnalyzeService] Starting parallel analysis 4595690f-e8ad-4d0a-99fb-46a42d4e4889 with bot test-bot
ğŸš€ [ParallelAutoAnalyzeService] Using credentials: mock
ğŸš€ [ParallelAutoAnalyzeRoute] Parallel analysis started: 4595690f-e8ad-4d0a-99fb-46a42d4e4889
::1 - - [12/Aug/2025:02:31:07 +0000] "POST /api/analysis/auto-analyze/parallel/start HTTP/1.1" 200 214 "-" "curl/8.7.1"
[BackgroundJobQueue] Starting job processing after delay for job 4595690f-e8ad-4d0a-99fb-46a42d4e4889-parallel
[BackgroundJobQueue] Starting processing for job 4595690f-e8ad-4d0a-99fb-46a42d4e4889-parallel, phase: sampling
[BackgroundJobQueue] Job credentials available: false
[BackgroundJobQueue] Processing parallel analysis job 4595690f-e8ad-4d0a-99fb-46a42d4e4889-parallel
[BackgroundJobQueue] Processing parallel analysis for bot mock-bot-id
[BackgroundJobQueue] Creating new ParallelAutoAnalyzeService instance for bot mock-bot-id (ServiceFactory: real)
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=real
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: mock-bot-id
ğŸ­ ServiceFactory: Creating OpenAI service (type: real)
[BackgroundJobQueue] Session recreated for 4595690f-e8ad-4d0a-99fb-46a42d4e4889
[ParallelAutoAnalyzeService] Running parallel analysis for 4595690f-e8ad-4d0a-99fb-46a42d4e4889
[ParallelAutoAnalyzeService] Phase 0: Starting session sampling for 4595690f-e8ad-4d0a-99fb-46a42d4e4889

ğŸ• ============ SESSION SAMPLING STARTED ============
ğŸ• [SessionSampling] Starting session sampling at 2025-08-12T02:31:08.224Z
ğŸ” [SessionDiscovery] Starting window 1/4: Initial 3-hour window
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-01T16:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-01T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-01T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-01T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
[getSessionsMetadata] agent API call failed: AxiosError: Request failed with status code 401
    at settle (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/settle.js:19:12)
    at IncomingMessage.handleStreamEnd (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:599:11)
    at IncomingMessage.emit (node:events:519:35)
    at endReadableNT (node:internal/streams/readable:1701:12)
    at process.processTicksAndRejections (node:internal/process/task_queues:90:21)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async Promise.allSettled (index 0)
    at async KoreApiService.getSessionsMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:342:23)
    at async SessionSamplingService.getSessionsInTimeWindow (/Users/kengrafals/workspace/xobcat/backend/src/services/sessionSamplingService.ts:233:31)
    at async SessionSamplingService.sampleSessions (/Users/kengrafals/workspace/xobcat/backend/src/services/sessionSamplingService.ts:64:34)
    at async ParallelAutoAnalyzeService.runSamplingPhase (/Users/kengrafals/workspace/xobcat/backend/src/services/parallelAutoAnalyzeService.ts:313:30)
    at async ParallelAutoAnalyzeService.runParallelAnalysis (/Users/kengrafals/workspace/xobcat/backend/src/services/parallelAutoAnalyzeService.ts:260:30) {
  code: 'ERR_BAD_REQUEST',
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU0OTY1ODY4LCJleHAiOjE3NTQ5Njk0NjgsImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.T04rk7dxK6DoXWdJFO2TODfb0utJ8UAJsZiyQMFiSVs',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '98',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
    data: '{"dateFrom":"2025-08-01T13:00:00.000Z","dateTo":"2025-08-01T16:00:00.000Z","skip":0,"limit":10000}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> ClientRequest {
    _events: [Object: null prototype] {
      abort: [Function (anonymous)],
      aborted: [Function (anonymous)],
      connect: [Function (anonymous)],
      error: [Function (anonymous)],
      socket: [Function (anonymous)],
      timeout: [Function (anonymous)],
      finish: [Function: requestOnFinish]
    },
    _eventsCount: 7,
    _maxListeners: undefined,
    outputData: [],
    outputSize: 0,
    writable: true,
    destroyed: true,
    _last: false,
    chunkedEncoding: false,
    shouldKeepAlive: true,
    maxRequestsOnConnectionReached: false,
    _defaultKeepAlive: true,
    useChunkedEncodingByDefault: true,
    sendDate: false,
    _removedConnection: false,
    _removedContLen: false,
    _removedTE: false,
    strictContentLength: false,
    _contentLength: 98,
    _hasBody: true,
    _trailer: '',
    finished: true,
    _headerSent: true,
    _closed: true,
    _header: 'POST /api/public/bot/mock-bot-id/getSessions?containmentType=agent HTTP/1.1\r\n' +
      'Accept: application/json, text/plain, */*\r\n' +
      'Content-Type: application/json\r\n' +
      'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU0OTY1ODY4LCJleHAiOjE3NTQ5Njk0NjgsImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.T04rk7dxK6DoXWdJFO2TODfb0utJ8UAJsZiyQMFiSVs\r\n' +
      'User-Agent: axios/1.11.0\r\n' +
      'Content-Length: 98\r\n' +
      'Accept-Encoding: gzip, compress, deflate, br\r\n' +
      'Host: bots.kore.ai\r\n' +
      'Connection: keep-alive\r\n' +
      '\r\n',
    _keepAliveTimeout: 0,
    _onPendingData: [Function: nop],
    agent: Agent {
      _events: [Object: null prototype],
      _eventsCount: 2,
      _maxListeners: undefined,
      defaultPort: 443,
      protocol: 'https:',
      options: [Object: null prototype],
      requests: [Object: null prototype] {},
      sockets: [Object: null prototype] {},
      freeSockets: [Object: null prototype],
      keepAliveMsecs: 1000,
      keepAlive: true,
      maxSockets: Infinity,
      maxFreeSockets: 256,
      scheduling: 'lifo',
      maxTotalSockets: Infinity,
      totalSocketCount: 3,
      maxCachedSessions: 100,
      _sessionCache: [Object],
      Symbol(shapeMode): false,
      Symbol(kCapture): false
    },
    socketPath: undefined,
    method: 'POST',
    maxHeaderSize: undefined,
    insecureHTTPParser: undefined,
    joinDuplicateHeaders: undefined,
    path: '/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
    _ended: true,
    res: IncomingMessage {
      _events: [Object],
      _readableState: [ReadableState],
      _maxListeners: undefined,
      socket: null,
      httpVersionMajor: 1,
      httpVersionMinor: 1,
      httpVersion: '1.1',
      complete: true,
      rawHeaders: [Array],
      rawTrailers: [],
      joinDuplicateHeaders: undefined,
      aborted: false,
      upgrade: false,
      url: '',
      method: null,
      statusCode: 401,
      statusMessage: 'Unauthorized',
      client: [TLSSocket],
      _consuming: false,
      _dumped: false,
      req: [Circular *1],
      _eventsCount: 4,
      responseUrl: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      redirects: [],
      Symbol(shapeMode): true,
      Symbol(kCapture): false,
      Symbol(kHeaders): [Object],
      Symbol(kHeadersCount): 36,
      Symbol(kTrailers): null,
      Symbol(kTrailersCount): 0
    },
    aborted: false,
    timeoutCb: null,
    upgradeOrConnect: false,
    parser: null,
    maxHeadersCount: null,
    reusedSocket: false,
    host: 'bots.kore.ai',
    protocol: 'https:',
    _redirectable: Writable {
      _events: [Object],
      _writableState: [WritableState],
      _maxListeners: undefined,
      _options: [Object],
      _ended: true,
      _ending: true,
      _redirectCount: 0,
      _redirects: [],
      _requestBodyLength: 98,
      _requestBodyBuffers: [],
      _eventsCount: 3,
      _onNativeResponse: [Function (anonymous)],
      _currentRequest: [Circular *1],
      _currentUrl: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      _timeout: null,
      Symbol(shapeMode): true,
      Symbol(kCapture): false
    },
    Symbol(shapeMode): false,
    Symbol(kCapture): false,
    Symbol(kBytesWritten): 0,
    Symbol(kNeedDrain): false,
    Symbol(corked): 0,
    Symbol(kChunkedBuffer): [],
    Symbol(kChunkedLength): 0,
    Symbol(kSocket): TLSSocket {
      _tlsOptions: [Object],
      _secureEstablished: true,
      _securePending: false,
      _newSessionPending: false,
      _controlReleased: true,
      secureConnecting: false,
      _SNICallback: null,
      servername: 'bots.kore.ai',
      alpnProtocol: false,
      authorized: true,
      authorizationError: null,
      encrypted: true,
      _events: [Object: null prototype],
      _eventsCount: 9,
      connecting: false,
      _hadError: false,
      _parent: null,
      _host: 'bots.kore.ai',
      _closeAfterHandlingError: false,
      _readableState: [ReadableState],
      _writableState: [WritableState],
      allowHalfOpen: false,
      _maxListeners: undefined,
      _sockname: null,
      _pendingData: null,
      _pendingEncoding: '',
      server: undefined,
      _server: null,
      ssl: [TLSWrap],
      _requestCert: true,
      _rejectUnauthorized: true,
      timeout: 5000,
      parser: null,
      _httpMessage: null,
      autoSelectFamilyAttemptedAddresses: [Array],
      Symbol(alpncallback): null,
      Symbol(res): [TLSWrap],
      Symbol(verified): true,
      Symbol(pendingSession): null,
      Symbol(async_id_symbol): -1,
      Symbol(kHandle): [TLSWrap],
      Symbol(lastWriteQueueSize): 0,
      Symbol(timeout): Timeout {
        _idleTimeout: 5000,
        _idlePrev: [TimersList],
        _idleNext: [Timeout],
        _idleStart: 10818,
        _onTimeout: [Function: bound ],
        _timerArgs: undefined,
        _repeat: null,
        _destroyed: false,
        Symbol(refed): false,
        Symbol(kHasPrimitive): false,
        Symbol(asyncId): 155,
        Symbol(triggerId): 153,
        Symbol(kAsyncContextFrame): undefined
      },
      Symbol(kBuffer): null,
      Symbol(kBufferCb): null,
      Symbol(kBufferGen): null,
      Symbol(shapeMode): true,
      Symbol(kCapture): false,
      Symbol(kSetNoDelay): false,
      Symbol(kSetKeepAlive): true,
      Symbol(kSetKeepAliveInitialDelay): 1,
      Symbol(kBytesRead): 0,
      Symbol(kBytesWritten): 0,
      Symbol(connect-options): [Object]
    },
    Symbol(kOutHeaders): [Object: null prototype] {
      accept: [Array],
      'content-type': [Array],
      auth: [Array],
      'user-agent': [Array],
      'content-length': [Array],
      'accept-encoding': [Array],
      host: [Array]
    },
    Symbol(errored): null,
    Symbol(kHighWaterMark): 65536,
    Symbol(kRejectNonStandardBodyWrites): false,
    Symbol(kUniqueHeaders): null
  },
  response: {
    status: 401,
    statusText: 'Unauthorized',
    headers: Object [AxiosHeaders] {
      date: 'Tue, 12 Aug 2025 02:31:08 GMT',
      'content-type': 'application/json; charset=utf-8',
      'content-length': '58',
      connection: 'keep-alive',
      server: 'KoreServer/COMMITH',
      'access-control-allow-methods': 'GET,POST,PUT',
      'access-control-allow-headers': 'Authorization,Content-Type,X-Requested-With,X-HTTP-Method-Override,X-UserToken,X-Timezone-Offset,smartassist,state,X-Request-Id,bot-language,app-language,accountid,iId,x-timezone',
      'access-control-allow-credentials': 'true',
      'access-control-allow-origin': '*',
      'x-requesttime': '1754965868858',
      pid: '127147',
      'x-traceid': 'ca37b7e1-59ad-4997-92b3-dc9a15902df6',
      'response-error-description': '{"errors":[{"msg":"Invalid SDK credentials","code":4002}]}',
      'content-security-policy': "frame-ancestors https://*.smartassist.ai https://*.kore.ai https://*.korebots.com https://kore.ai https://*.force.com https://*.zendesk.com https://*.mypurecloud.com https://*.mypurecloud.jp https://*.usw2.pure.cloud https://*.onbmc.com https://*.workspace.ai https://*.niceincontact.com https://*.kore.ai https://*.kore.com; script-src 'self' 'unsafe-inline' 'unsafe-eval' https://*.kore.ai https://*.force.com https://*.zendesk.com https://*.mypurecloud.com https://*.mypurecloud.jp https://*.usw2.pure.cloud https://*.onbmc.com https://*.pendo.io https://*.appcues.com https://*.inlinemanual.com https://inlinemanual.com  https://cdn.mxpnl.com https://www.google-analytics.com  https://maps.googleapis.com https://canny.io https://js.hs-scripts.com https://www.googletagmanager.com https://*.grammarly.com https://*.grammarly.io https://unpkg.com/ https://*.niceincontact.com",
      'x-content-type-options': 'nosniff',
      'x-xss-protection': '1; mode=block',
      'strict-transport-security': 'max-age=31536000; includeSubdomains;',
      'referrer-policy': 'strict-origin-when-cross-origin'
    },
    config: {
      transitional: [Object],
      adapter: [Array],
      transformRequest: [Array],
      transformResponse: [Array],
      timeout: 30000,
      xsrfCookieName: 'XSRF-TOKEN',
      xsrfHeaderName: 'X-XSRF-TOKEN',
      maxContentLength: -1,
      maxBodyLength: -1,
      env: [Object],
      validateStatus: [Function: validateStatus],
      headers: [Object [AxiosHeaders]],
      method: 'post',
      url: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      data: '{"dateFrom":"2025-08-01T13:00:00.000Z","dateTo":"2025-08-01T16:00:00.000Z","skip":0,"limit":10000}',
      allowAbsoluteUrls: true
    },
    request: <ref *1> ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: true,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 98,
      _hasBody: true,
      _trailer: '',
      finished: true,
      _headerSent: true,
      _closed: true,
      _header: 'POST /api/public/bot/mock-bot-id/getSessions?containmentType=agent HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU0OTY1ODY4LCJleHAiOjE3NTQ5Njk0NjgsImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.T04rk7dxK6DoXWdJFO2TODfb0utJ8UAJsZiyQMFiSVs\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 98\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: bots.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      _ended: true,
      res: [IncomingMessage],
      aborted: false,
      timeoutCb: null,
      upgradeOrConnect: false,
      parser: null,
      maxHeadersCount: null,
      reusedSocket: false,
      host: 'bots.kore.ai',
      protocol: 'https:',
      _redirectable: [Writable],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    data: { errors: [Array] }
  },
  status: 401
}
Authentication failed - throwing error to caller
Authentication failed during parallel execution - throwing error to caller
Error fetching session metadata for window Initial 3-hour window: AxiosError: Request failed with status code 401
    at settle (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/settle.js:19:12)
    at IncomingMessage.handleStreamEnd (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:599:11)
    at IncomingMessage.emit (node:events:519:35)
    at endReadableNT (node:internal/streams/readable:1701:12)
    at process.processTicksAndRejections (node:internal/process/task_queues:90:21)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async Promise.allSettled (index 0)
    at async KoreApiService.getSessionsMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:342:23)
    at async SessionSamplingService.getSessionsInTimeWindow (/Users/kengrafals/workspace/xobcat/backend/src/services/sessionSamplingService.ts:233:31)
    at async SessionSamplingService.sampleSessions (/Users/kengrafals/workspace/xobcat/backend/src/services/sessionSamplingService.ts:64:34)
    at async ParallelAutoAnalyzeService.runSamplingPhase (/Users/kengrafals/workspace/xobcat/backend/src/services/parallelAutoAnalyzeService.ts:313:30)
    at async ParallelAutoAnalyzeService.runParallelAnalysis (/Users/kengrafals/workspace/xobcat/backend/src/services/parallelAutoAnalyzeService.ts:260:30) {
  code: 'ERR_BAD_REQUEST',
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU0OTY1ODY4LCJleHAiOjE3NTQ5Njk0NjgsImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.T04rk7dxK6DoXWdJFO2TODfb0utJ8UAJsZiyQMFiSVs',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '98',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
    data: '{"dateFrom":"2025-08-01T13:00:00.000Z","dateTo":"2025-08-01T16:00:00.000Z","skip":0,"limit":10000}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> ClientRequest {
    _events: [Object: null prototype] {
      abort: [Function (anonymous)],
      aborted: [Function (anonymous)],
      connect: [Function (anonymous)],
      error: [Function (anonymous)],
      socket: [Function (anonymous)],
      timeout: [Function (anonymous)],
      finish: [Function: requestOnFinish]
    },
    _eventsCount: 7,
    _maxListeners: undefined,
    outputData: [],
    outputSize: 0,
    writable: true,
    destroyed: true,
    _last: false,
    chunkedEncoding: false,
    shouldKeepAlive: true,
    maxRequestsOnConnectionReached: false,
    _defaultKeepAlive: true,
    useChunkedEncodingByDefault: true,
    sendDate: false,
    _removedConnection: false,
    _removedContLen: false,
    _removedTE: false,
    strictContentLength: false,
    _contentLength: 98,
    _hasBody: true,
    _trailer: '',
    finished: true,
    _headerSent: true,
    _closed: true,
    _header: 'POST /api/public/bot/mock-bot-id/getSessions?containmentType=agent HTTP/1.1\r\n' +
      'Accept: application/json, text/plain, */*\r\n' +
      'Content-Type: application/json\r\n' +
      'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU0OTY1ODY4LCJleHAiOjE3NTQ5Njk0NjgsImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.T04rk7dxK6DoXWdJFO2TODfb0utJ8UAJsZiyQMFiSVs\r\n' +
      'User-Agent: axios/1.11.0\r\n' +
      'Content-Length: 98\r\n' +
      'Accept-Encoding: gzip, compress, deflate, br\r\n' +
      'Host: bots.kore.ai\r\n' +
      'Connection: keep-alive\r\n' +
      '\r\n',
    _keepAliveTimeout: 0,
    _onPendingData: [Function: nop],
    agent: Agent {
      _events: [Object: null prototype],
      _eventsCount: 2,
      _maxListeners: undefined,
      defaultPort: 443,
      protocol: 'https:',
      options: [Object: null prototype],
      requests: [Object: null prototype] {},
      sockets: [Object: null prototype] {},
      freeSockets: [Object: null prototype],
      keepAliveMsecs: 1000,
      keepAlive: true,
      maxSockets: Infinity,
      maxFreeSockets: 256,
      scheduling: 'lifo',
      maxTotalSockets: Infinity,
      totalSocketCount: 3,
      maxCachedSessions: 100,
      _sessionCache: [Object],
      Symbol(shapeMode): false,
      Symbol(kCapture): false
    },
    socketPath: undefined,
    method: 'POST',
    maxHeaderSize: undefined,
    insecureHTTPParser: undefined,
    joinDuplicateHeaders: undefined,
    path: '/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
    _ended: true,
    res: IncomingMessage {
      _events: [Object],
      _readableState: [ReadableState],
      _maxListeners: undefined,
      socket: null,
      httpVersionMajor: 1,
      httpVersionMinor: 1,
      httpVersion: '1.1',
      complete: true,
      rawHeaders: [Array],
      rawTrailers: [],
      joinDuplicateHeaders: undefined,
      aborted: false,
      upgrade: false,
      url: '',
      method: null,
      statusCode: 401,
      statusMessage: 'Unauthorized',
      client: [TLSSocket],
      _consuming: false,
      _dumped: false,
      req: [Circular *1],
      _eventsCount: 4,
      responseUrl: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      redirects: [],
      Symbol(shapeMode): true,
      Symbol(kCapture): false,
      Symbol(kHeaders): [Object],
      Symbol(kHeadersCount): 36,
      Symbol(kTrailers): null,
      Symbol(kTrailersCount): 0
    },
    aborted: false,
    timeoutCb: null,
    upgradeOrConnect: false,
    parser: null,
    maxHeadersCount: null,
    reusedSocket: false,
    host: 'bots.kore.ai',
    protocol: 'https:',
    _redirectable: Writable {
      _events: [Object],
      _writableState: [WritableState],
      _maxListeners: undefined,
      _options: [Object],
      _ended: true,
      _ending: true,
      _redirectCount: 0,
      _redirects: [],
      _requestBodyLength: 98,
      _requestBodyBuffers: [],
      _eventsCount: 3,
      _onNativeResponse: [Function (anonymous)],
      _currentRequest: [Circular *1],
      _currentUrl: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      _timeout: null,
      Symbol(shapeMode): true,
      Symbol(kCapture): false
    },
    Symbol(shapeMode): false,
    Symbol(kCapture): false,
    Symbol(kBytesWritten): 0,
    Symbol(kNeedDrain): false,
    Symbol(corked): 0,
    Symbol(kChunkedBuffer): [],
    Symbol(kChunkedLength): 0,
    Symbol(kSocket): TLSSocket {
      _tlsOptions: [Object],
      _secureEstablished: true,
      _securePending: false,
      _newSessionPending: false,
      _controlReleased: true,
      secureConnecting: false,
      _SNICallback: null,
      servername: 'bots.kore.ai',
      alpnProtocol: false,
      authorized: true,
      authorizationError: null,
      encrypted: true,
      _events: [Object: null prototype],
      _eventsCount: 9,
      connecting: false,
      _hadError: false,
      _parent: null,
      _host: 'bots.kore.ai',
      _closeAfterHandlingError: false,
      _readableState: [ReadableState],
      _writableState: [WritableState],
      allowHalfOpen: false,
      _maxListeners: undefined,
      _sockname: null,
      _pendingData: null,
      _pendingEncoding: '',
      server: undefined,
      _server: null,
      ssl: [TLSWrap],
      _requestCert: true,
      _rejectUnauthorized: true,
      timeout: 5000,
      parser: null,
      _httpMessage: null,
      autoSelectFamilyAttemptedAddresses: [Array],
      Symbol(alpncallback): null,
      Symbol(res): [TLSWrap],
      Symbol(verified): true,
      Symbol(pendingSession): null,
      Symbol(async_id_symbol): -1,
      Symbol(kHandle): [TLSWrap],
      Symbol(lastWriteQueueSize): 0,
      Symbol(timeout): Timeout {
        _idleTimeout: 5000,
        _idlePrev: [TimersList],
        _idleNext: [Timeout],
        _idleStart: 10818,
        _onTimeout: [Function: bound ],
        _timerArgs: undefined,
        _repeat: null,
        _destroyed: false,
        Symbol(refed): false,
        Symbol(kHasPrimitive): false,
        Symbol(asyncId): 155,
        Symbol(triggerId): 153,
        Symbol(kAsyncContextFrame): undefined
      },
      Symbol(kBuffer): null,
      Symbol(kBufferCb): null,
      Symbol(kBufferGen): null,
      Symbol(shapeMode): true,
      Symbol(kCapture): false,
      Symbol(kSetNoDelay): false,
      Symbol(kSetKeepAlive): true,
      Symbol(kSetKeepAliveInitialDelay): 1,
      Symbol(kBytesRead): 0,
      Symbol(kBytesWritten): 0,
      Symbol(connect-options): [Object]
    },
    Symbol(kOutHeaders): [Object: null prototype] {
      accept: [Array],
      'content-type': [Array],
      auth: [Array],
      'user-agent': [Array],
      'content-length': [Array],
      'accept-encoding': [Array],
      host: [Array]
    },
    Symbol(errored): null,
    Symbol(kHighWaterMark): 65536,
    Symbol(kRejectNonStandardBodyWrites): false,
    Symbol(kUniqueHeaders): null
  },
  response: {
    status: 401,
    statusText: 'Unauthorized',
    headers: Object [AxiosHeaders] {
      date: 'Tue, 12 Aug 2025 02:31:08 GMT',
      'content-type': 'application/json; charset=utf-8',
      'content-length': '58',
      connection: 'keep-alive',
      server: 'KoreServer/COMMITH',
      'access-control-allow-methods': 'GET,POST,PUT',
      'access-control-allow-headers': 'Authorization,Content-Type,X-Requested-With,X-HTTP-Method-Override,X-UserToken,X-Timezone-Offset,smartassist,state,X-Request-Id,bot-language,app-language,accountid,iId,x-timezone',
      'access-control-allow-credentials': 'true',
      'access-control-allow-origin': '*',
      'x-requesttime': '1754965868858',
      pid: '127147',
      'x-traceid': 'ca37b7e1-59ad-4997-92b3-dc9a15902df6',
      'response-error-description': '{"errors":[{"msg":"Invalid SDK credentials","code":4002}]}',
      'content-security-policy': "frame-ancestors https://*.smartassist.ai https://*.kore.ai https://*.korebots.com https://kore.ai https://*.force.com https://*.zendesk.com https://*.mypurecloud.com https://*.mypurecloud.jp https://*.usw2.pure.cloud https://*.onbmc.com https://*.workspace.ai https://*.niceincontact.com https://*.kore.ai https://*.kore.com; script-src 'self' 'unsafe-inline' 'unsafe-eval' https://*.kore.ai https://*.force.com https://*.zendesk.com https://*.mypurecloud.com https://*.mypurecloud.jp https://*.usw2.pure.cloud https://*.onbmc.com https://*.pendo.io https://*.appcues.com https://*.inlinemanual.com https://inlinemanual.com  https://cdn.mxpnl.com https://www.google-analytics.com  https://maps.googleapis.com https://canny.io https://js.hs-scripts.com https://www.googletagmanager.com https://*.grammarly.com https://*.grammarly.io https://unpkg.com/ https://*.niceincontact.com",
      'x-content-type-options': 'nosniff',
      'x-xss-protection': '1; mode=block',
      'strict-transport-security': 'max-age=31536000; includeSubdomains;',
      'referrer-policy': 'strict-origin-when-cross-origin'
    },
    config: {
      transitional: [Object],
      adapter: [Array],
      transformRequest: [Array],
      transformResponse: [Array],
      timeout: 30000,
      xsrfCookieName: 'XSRF-TOKEN',
      xsrfHeaderName: 'X-XSRF-TOKEN',
      maxContentLength: -1,
      maxBodyLength: -1,
      env: [Object],
      validateStatus: [Function: validateStatus],
      headers: [Object [AxiosHeaders]],
      method: 'post',
      url: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      data: '{"dateFrom":"2025-08-01T13:00:00.000Z","dateTo":"2025-08-01T16:00:00.000Z","skip":0,"limit":10000}',
      allowAbsoluteUrls: true
    },
    request: <ref *1> ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: true,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 98,
      _hasBody: true,
      _trailer: '',
      finished: true,
      _headerSent: true,
      _closed: true,
      _header: 'POST /api/public/bot/mock-bot-id/getSessions?containmentType=agent HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU0OTY1ODY4LCJleHAiOjE3NTQ5Njk0NjgsImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.T04rk7dxK6DoXWdJFO2TODfb0utJ8UAJsZiyQMFiSVs\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 98\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: bots.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      _ended: true,
      res: [IncomingMessage],
      aborted: false,
      timeoutCb: null,
      upgradeOrConnect: false,
      parser: null,
      maxHeadersCount: null,
      reusedSocket: false,
      host: 'bots.kore.ai',
      protocol: 'https:',
      _redirectable: [Writable],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    data: { errors: [Array] }
  },
  status: 401
}
âœ… [SessionDiscovery] Window 1 completed in 582ms: found 0 new sessions (total: 0)
â±ï¸  TIMING: Window 1 took 582ms (0.58s)
ğŸ” [SessionDiscovery] Starting window 2/4: Extended to 6 hours
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-01T19:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-01T19:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-01T19:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-01T19:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
[getSessionsMetadata] agent API call failed: AxiosError: Request failed with status code 401
    at settle (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/settle.js:19:12)
    at IncomingMessage.handleStreamEnd (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:599:11)
    at IncomingMessage.emit (node:events:519:35)
    at endReadableNT (node:internal/streams/readable:1701:12)
    at process.processTicksAndRejections (node:internal/process/task_queues:90:21)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async Promise.allSettled (index 0)
    at async KoreApiService.getSessionsMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:342:23)
    at async SessionSamplingService.getSessionsInTimeWindow (/Users/kengrafals/workspace/xobcat/backend/src/services/sessionSamplingService.ts:233:31)
    at async SessionSamplingService.sampleSessions (/Users/kengrafals/workspace/xobcat/backend/src/services/sessionSamplingService.ts:64:34)
    at async ParallelAutoAnalyzeService.runSamplingPhase (/Users/kengrafals/workspace/xobcat/backend/src/services/parallelAutoAnalyzeService.ts:313:30)
    at async ParallelAutoAnalyzeService.runParallelAnalysis (/Users/kengrafals/workspace/xobcat/backend/src/services/parallelAutoAnalyzeService.ts:260:30) {
  code: 'ERR_BAD_REQUEST',
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU0OTY1ODY4LCJleHAiOjE3NTQ5Njk0NjgsImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.T04rk7dxK6DoXWdJFO2TODfb0utJ8UAJsZiyQMFiSVs',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '98',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
    data: '{"dateFrom":"2025-08-01T13:00:00.000Z","dateTo":"2025-08-01T19:00:00.000Z","skip":0,"limit":10000}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> ClientRequest {
    _events: [Object: null prototype] {
      abort: [Function (anonymous)],
      aborted: [Function (anonymous)],
      connect: [Function (anonymous)],
      error: [Function (anonymous)],
      socket: [Function (anonymous)],
      timeout: [Function (anonymous)],
      finish: [Function: requestOnFinish]
    },
    _eventsCount: 7,
    _maxListeners: undefined,
    outputData: [],
    outputSize: 0,
    writable: true,
    destroyed: true,
    _last: false,
    chunkedEncoding: false,
    shouldKeepAlive: true,
    maxRequestsOnConnectionReached: false,
    _defaultKeepAlive: true,
    useChunkedEncodingByDefault: true,
    sendDate: false,
    _removedConnection: false,
    _removedContLen: false,
    _removedTE: false,
    strictContentLength: false,
    _contentLength: 98,
    _hasBody: true,
    _trailer: '',
    finished: true,
    _headerSent: true,
    _closed: true,
    _header: 'POST /api/public/bot/mock-bot-id/getSessions?containmentType=agent HTTP/1.1\r\n' +
      'Accept: application/json, text/plain, */*\r\n' +
      'Content-Type: application/json\r\n' +
      'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU0OTY1ODY4LCJleHAiOjE3NTQ5Njk0NjgsImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.T04rk7dxK6DoXWdJFO2TODfb0utJ8UAJsZiyQMFiSVs\r\n' +
      'User-Agent: axios/1.11.0\r\n' +
      'Content-Length: 98\r\n' +
      'Accept-Encoding: gzip, compress, deflate, br\r\n' +
      'Host: bots.kore.ai\r\n' +
      'Connection: keep-alive\r\n' +
      '\r\n',
    _keepAliveTimeout: 0,
    _onPendingData: [Function: nop],
    agent: Agent {
      _events: [Object: null prototype],
      _eventsCount: 2,
      _maxListeners: undefined,
      defaultPort: 443,
      protocol: 'https:',
      options: [Object: null prototype],
      requests: [Object: null prototype] {},
      sockets: [Object: null prototype] {},
      freeSockets: [Object: null prototype],
      keepAliveMsecs: 1000,
      keepAlive: true,
      maxSockets: Infinity,
      maxFreeSockets: 256,
      scheduling: 'lifo',
      maxTotalSockets: Infinity,
      totalSocketCount: 3,
      maxCachedSessions: 100,
      _sessionCache: [Object],
      Symbol(shapeMode): false,
      Symbol(kCapture): false
    },
    socketPath: undefined,
    method: 'POST',
    maxHeaderSize: undefined,
    insecureHTTPParser: undefined,
    joinDuplicateHeaders: undefined,
    path: '/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
    _ended: true,
    res: IncomingMessage {
      _events: [Object],
      _readableState: [ReadableState],
      _maxListeners: undefined,
      socket: null,
      httpVersionMajor: 1,
      httpVersionMinor: 1,
      httpVersion: '1.1',
      complete: true,
      rawHeaders: [Array],
      rawTrailers: [],
      joinDuplicateHeaders: undefined,
      aborted: false,
      upgrade: false,
      url: '',
      method: null,
      statusCode: 401,
      statusMessage: 'Unauthorized',
      client: [TLSSocket],
      _consuming: false,
      _dumped: false,
      req: [Circular *1],
      _eventsCount: 4,
      responseUrl: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      redirects: [],
      Symbol(shapeMode): true,
      Symbol(kCapture): false,
      Symbol(kHeaders): [Object],
      Symbol(kHeadersCount): 36,
      Symbol(kTrailers): null,
      Symbol(kTrailersCount): 0
    },
    aborted: false,
    timeoutCb: null,
    upgradeOrConnect: false,
    parser: null,
    maxHeadersCount: null,
    reusedSocket: true,
    host: 'bots.kore.ai',
    protocol: 'https:',
    _redirectable: Writable {
      _events: [Object],
      _writableState: [WritableState],
      _maxListeners: undefined,
      _options: [Object],
      _ended: true,
      _ending: true,
      _redirectCount: 0,
      _redirects: [],
      _requestBodyLength: 98,
      _requestBodyBuffers: [],
      _eventsCount: 3,
      _onNativeResponse: [Function (anonymous)],
      _currentRequest: [Circular *1],
      _currentUrl: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      _timeout: null,
      Symbol(shapeMode): true,
      Symbol(kCapture): false
    },
    Symbol(shapeMode): false,
    Symbol(kCapture): false,
    Symbol(kBytesWritten): 0,
    Symbol(kNeedDrain): false,
    Symbol(corked): 0,
    Symbol(kChunkedBuffer): [],
    Symbol(kChunkedLength): 0,
    Symbol(kSocket): TLSSocket {
      _tlsOptions: [Object],
      _secureEstablished: true,
      _securePending: false,
      _newSessionPending: false,
      _controlReleased: true,
      secureConnecting: false,
      _SNICallback: null,
      servername: 'bots.kore.ai',
      alpnProtocol: false,
      authorized: true,
      authorizationError: null,
      encrypted: true,
      _events: [Object: null prototype],
      _eventsCount: 9,
      connecting: false,
      _hadError: false,
      _parent: null,
      _host: 'bots.kore.ai',
      _closeAfterHandlingError: false,
      _readableState: [ReadableState],
      _writableState: [WritableState],
      allowHalfOpen: false,
      _maxListeners: undefined,
      _sockname: null,
      _pendingData: null,
      _pendingEncoding: '',
      server: undefined,
      _server: null,
      ssl: [TLSWrap],
      _requestCert: true,
      _rejectUnauthorized: true,
      timeout: 5000,
      parser: null,
      _httpMessage: null,
      autoSelectFamilyAttemptedAddresses: [Array],
      Symbol(alpncallback): null,
      Symbol(res): [TLSWrap],
      Symbol(verified): true,
      Symbol(pendingSession): null,
      Symbol(async_id_symbol): -1,
      Symbol(kHandle): [TLSWrap],
      Symbol(lastWriteQueueSize): 0,
      Symbol(timeout): Timeout {
        _idleTimeout: 5000,
        _idlePrev: [TimersList],
        _idleNext: [Timeout],
        _idleStart: 10934,
        _onTimeout: [Function: bound ],
        _timerArgs: undefined,
        _repeat: null,
        _destroyed: false,
        Symbol(refed): false,
        Symbol(kHasPrimitive): false,
        Symbol(asyncId): 217,
        Symbol(triggerId): 215,
        Symbol(kAsyncContextFrame): undefined
      },
      Symbol(kBuffer): null,
      Symbol(kBufferCb): null,
      Symbol(kBufferGen): null,
      Symbol(shapeMode): true,
      Symbol(kCapture): false,
      Symbol(kSetNoDelay): false,
      Symbol(kSetKeepAlive): true,
      Symbol(kSetKeepAliveInitialDelay): 1,
      Symbol(kBytesRead): 0,
      Symbol(kBytesWritten): 0,
      Symbol(connect-options): [Object]
    },
    Symbol(kOutHeaders): [Object: null prototype] {
      accept: [Array],
      'content-type': [Array],
      auth: [Array],
      'user-agent': [Array],
      'content-length': [Array],
      'accept-encoding': [Array],
      host: [Array]
    },
    Symbol(errored): null,
    Symbol(kHighWaterMark): 65536,
    Symbol(kRejectNonStandardBodyWrites): false,
    Symbol(kUniqueHeaders): null
  },
  response: {
    status: 401,
    statusText: 'Unauthorized',
    headers: Object [AxiosHeaders] {
      date: 'Tue, 12 Aug 2025 02:31:08 GMT',
      'content-type': 'application/json; charset=utf-8',
      'content-length': '58',
      connection: 'keep-alive',
      server: 'KoreServer/COMMITH',
      'access-control-allow-methods': 'GET,POST,PUT',
      'access-control-allow-headers': 'Authorization,Content-Type,X-Requested-With,X-HTTP-Method-Override,X-UserToken,X-Timezone-Offset,smartassist,state,X-Request-Id,bot-language,app-language,accountid,iId,x-timezone',
      'access-control-allow-credentials': 'true',
      'access-control-allow-origin': '*',
      'x-requesttime': '1754965868993',
      pid: '126933',
      'x-traceid': 'b7576675-8bda-4748-be56-9caf521cd3dc',
      'response-error-description': '{"errors":[{"msg":"Invalid SDK credentials","code":4002}]}',
      'content-security-policy': "frame-ancestors https://*.smartassist.ai https://*.kore.ai https://*.korebots.com https://kore.ai https://*.force.com https://*.zendesk.com https://*.mypurecloud.com https://*.mypurecloud.jp https://*.usw2.pure.cloud https://*.onbmc.com https://*.workspace.ai https://*.niceincontact.com https://*.kore.ai https://*.kore.com; script-src 'self' 'unsafe-inline' 'unsafe-eval' https://*.kore.ai https://*.force.com https://*.zendesk.com https://*.mypurecloud.com https://*.mypurecloud.jp https://*.usw2.pure.cloud https://*.onbmc.com https://*.pendo.io https://*.appcues.com https://*.inlinemanual.com https://inlinemanual.com  https://cdn.mxpnl.com https://www.google-analytics.com  https://maps.googleapis.com https://canny.io https://js.hs-scripts.com https://www.googletagmanager.com https://*.grammarly.com https://*.grammarly.io https://unpkg.com/ https://*.niceincontact.com",
      'x-content-type-options': 'nosniff',
      'x-xss-protection': '1; mode=block',
      'strict-transport-security': 'max-age=31536000; includeSubdomains;',
      'referrer-policy': 'strict-origin-when-cross-origin'
    },
    config: {
      transitional: [Object],
      adapter: [Array],
      transformRequest: [Array],
      transformResponse: [Array],
      timeout: 30000,
      xsrfCookieName: 'XSRF-TOKEN',
      xsrfHeaderName: 'X-XSRF-TOKEN',
      maxContentLength: -1,
      maxBodyLength: -1,
      env: [Object],
      validateStatus: [Function: validateStatus],
      headers: [Object [AxiosHeaders]],
      method: 'post',
      url: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      data: '{"dateFrom":"2025-08-01T13:00:00.000Z","dateTo":"2025-08-01T19:00:00.000Z","skip":0,"limit":10000}',
      allowAbsoluteUrls: true
    },
    request: <ref *1> ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: true,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 98,
      _hasBody: true,
      _trailer: '',
      finished: true,
      _headerSent: true,
      _closed: true,
      _header: 'POST /api/public/bot/mock-bot-id/getSessions?containmentType=agent HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU0OTY1ODY4LCJleHAiOjE3NTQ5Njk0NjgsImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.T04rk7dxK6DoXWdJFO2TODfb0utJ8UAJsZiyQMFiSVs\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 98\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: bots.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      _ended: true,
      res: [IncomingMessage],
      aborted: false,
      timeoutCb: null,
      upgradeOrConnect: false,
      parser: null,
      maxHeadersCount: null,
      reusedSocket: true,
      host: 'bots.kore.ai',
      protocol: 'https:',
      _redirectable: [Writable],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    data: { errors: [Array] }
  },
  status: 401
}
Authentication failed - throwing error to caller
Authentication failed during parallel execution - throwing error to caller
Error fetching session metadata for window Extended to 6 hours: AxiosError: Request failed with status code 401
    at settle (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/settle.js:19:12)
    at IncomingMessage.handleStreamEnd (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:599:11)
    at IncomingMessage.emit (node:events:519:35)
    at endReadableNT (node:internal/streams/readable:1701:12)
    at process.processTicksAndRejections (node:internal/process/task_queues:90:21)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async Promise.allSettled (index 0)
    at async KoreApiService.getSessionsMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:342:23)
    at async SessionSamplingService.getSessionsInTimeWindow (/Users/kengrafals/workspace/xobcat/backend/src/services/sessionSamplingService.ts:233:31)
    at async SessionSamplingService.sampleSessions (/Users/kengrafals/workspace/xobcat/backend/src/services/sessionSamplingService.ts:64:34)
    at async ParallelAutoAnalyzeService.runSamplingPhase (/Users/kengrafals/workspace/xobcat/backend/src/services/parallelAutoAnalyzeService.ts:313:30)
    at async ParallelAutoAnalyzeService.runParallelAnalysis (/Users/kengrafals/workspace/xobcat/backend/src/services/parallelAutoAnalyzeService.ts:260:30) {
  code: 'ERR_BAD_REQUEST',
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU0OTY1ODY4LCJleHAiOjE3NTQ5Njk0NjgsImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.T04rk7dxK6DoXWdJFO2TODfb0utJ8UAJsZiyQMFiSVs',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '98',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
    data: '{"dateFrom":"2025-08-01T13:00:00.000Z","dateTo":"2025-08-01T19:00:00.000Z","skip":0,"limit":10000}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> ClientRequest {
    _events: [Object: null prototype] {
      abort: [Function (anonymous)],
      aborted: [Function (anonymous)],
      connect: [Function (anonymous)],
      error: [Function (anonymous)],
      socket: [Function (anonymous)],
      timeout: [Function (anonymous)],
      finish: [Function: requestOnFinish]
    },
    _eventsCount: 7,
    _maxListeners: undefined,
    outputData: [],
    outputSize: 0,
    writable: true,
    destroyed: true,
    _last: false,
    chunkedEncoding: false,
    shouldKeepAlive: true,
    maxRequestsOnConnectionReached: false,
    _defaultKeepAlive: true,
    useChunkedEncodingByDefault: true,
    sendDate: false,
    _removedConnection: false,
    _removedContLen: false,
    _removedTE: false,
    strictContentLength: false,
    _contentLength: 98,
    _hasBody: true,
    _trailer: '',
    finished: true,
    _headerSent: true,
    _closed: true,
    _header: 'POST /api/public/bot/mock-bot-id/getSessions?containmentType=agent HTTP/1.1\r\n' +
      'Accept: application/json, text/plain, */*\r\n' +
      'Content-Type: application/json\r\n' +
      'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU0OTY1ODY4LCJleHAiOjE3NTQ5Njk0NjgsImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.T04rk7dxK6DoXWdJFO2TODfb0utJ8UAJsZiyQMFiSVs\r\n' +
      'User-Agent: axios/1.11.0\r\n' +
      'Content-Length: 98\r\n' +
      'Accept-Encoding: gzip, compress, deflate, br\r\n' +
      'Host: bots.kore.ai\r\n' +
      'Connection: keep-alive\r\n' +
      '\r\n',
    _keepAliveTimeout: 0,
    _onPendingData: [Function: nop],
    agent: Agent {
      _events: [Object: null prototype],
      _eventsCount: 2,
      _maxListeners: undefined,
      defaultPort: 443,
      protocol: 'https:',
      options: [Object: null prototype],
      requests: [Object: null prototype] {},
      sockets: [Object: null prototype] {},
      freeSockets: [Object: null prototype],
      keepAliveMsecs: 1000,
      keepAlive: true,
      maxSockets: Infinity,
      maxFreeSockets: 256,
      scheduling: 'lifo',
      maxTotalSockets: Infinity,
      totalSocketCount: 3,
      maxCachedSessions: 100,
      _sessionCache: [Object],
      Symbol(shapeMode): false,
      Symbol(kCapture): false
    },
    socketPath: undefined,
    method: 'POST',
    maxHeaderSize: undefined,
    insecureHTTPParser: undefined,
    joinDuplicateHeaders: undefined,
    path: '/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
    _ended: true,
    res: IncomingMessage {
      _events: [Object],
      _readableState: [ReadableState],
      _maxListeners: undefined,
      socket: null,
      httpVersionMajor: 1,
      httpVersionMinor: 1,
      httpVersion: '1.1',
      complete: true,
      rawHeaders: [Array],
      rawTrailers: [],
      joinDuplicateHeaders: undefined,
      aborted: false,
      upgrade: false,
      url: '',
      method: null,
      statusCode: 401,
      statusMessage: 'Unauthorized',
      client: [TLSSocket],
      _consuming: false,
      _dumped: false,
      req: [Circular *1],
      _eventsCount: 4,
      responseUrl: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      redirects: [],
      Symbol(shapeMode): true,
      Symbol(kCapture): false,
      Symbol(kHeaders): [Object],
      Symbol(kHeadersCount): 36,
      Symbol(kTrailers): null,
      Symbol(kTrailersCount): 0
    },
    aborted: false,
    timeoutCb: null,
    upgradeOrConnect: false,
    parser: null,
    maxHeadersCount: null,
    reusedSocket: true,
    host: 'bots.kore.ai',
    protocol: 'https:',
    _redirectable: Writable {
      _events: [Object],
      _writableState: [WritableState],
      _maxListeners: undefined,
      _options: [Object],
      _ended: true,
      _ending: true,
      _redirectCount: 0,
      _redirects: [],
      _requestBodyLength: 98,
      _requestBodyBuffers: [],
      _eventsCount: 3,
      _onNativeResponse: [Function (anonymous)],
      _currentRequest: [Circular *1],
      _currentUrl: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      _timeout: null,
      Symbol(shapeMode): true,
      Symbol(kCapture): false
    },
    Symbol(shapeMode): false,
    Symbol(kCapture): false,
    Symbol(kBytesWritten): 0,
    Symbol(kNeedDrain): false,
    Symbol(corked): 0,
    Symbol(kChunkedBuffer): [],
    Symbol(kChunkedLength): 0,
    Symbol(kSocket): TLSSocket {
      _tlsOptions: [Object],
      _secureEstablished: true,
      _securePending: false,
      _newSessionPending: false,
      _controlReleased: true,
      secureConnecting: false,
      _SNICallback: null,
      servername: 'bots.kore.ai',
      alpnProtocol: false,
      authorized: true,
      authorizationError: null,
      encrypted: true,
      _events: [Object: null prototype],
      _eventsCount: 9,
      connecting: false,
      _hadError: false,
      _parent: null,
      _host: 'bots.kore.ai',
      _closeAfterHandlingError: false,
      _readableState: [ReadableState],
      _writableState: [WritableState],
      allowHalfOpen: false,
      _maxListeners: undefined,
      _sockname: null,
      _pendingData: null,
      _pendingEncoding: '',
      server: undefined,
      _server: null,
      ssl: [TLSWrap],
      _requestCert: true,
      _rejectUnauthorized: true,
      timeout: 5000,
      parser: null,
      _httpMessage: null,
      autoSelectFamilyAttemptedAddresses: [Array],
      Symbol(alpncallback): null,
      Symbol(res): [TLSWrap],
      Symbol(verified): true,
      Symbol(pendingSession): null,
      Symbol(async_id_symbol): -1,
      Symbol(kHandle): [TLSWrap],
      Symbol(lastWriteQueueSize): 0,
      Symbol(timeout): Timeout {
        _idleTimeout: 5000,
        _idlePrev: [TimersList],
        _idleNext: [Timeout],
        _idleStart: 10934,
        _onTimeout: [Function: bound ],
        _timerArgs: undefined,
        _repeat: null,
        _destroyed: false,
        Symbol(refed): false,
        Symbol(kHasPrimitive): false,
        Symbol(asyncId): 217,
        Symbol(triggerId): 215,
        Symbol(kAsyncContextFrame): undefined
      },
      Symbol(kBuffer): null,
      Symbol(kBufferCb): null,
      Symbol(kBufferGen): null,
      Symbol(shapeMode): true,
      Symbol(kCapture): false,
      Symbol(kSetNoDelay): false,
      Symbol(kSetKeepAlive): true,
      Symbol(kSetKeepAliveInitialDelay): 1,
      Symbol(kBytesRead): 0,
      Symbol(kBytesWritten): 0,
      Symbol(connect-options): [Object]
    },
    Symbol(kOutHeaders): [Object: null prototype] {
      accept: [Array],
      'content-type': [Array],
      auth: [Array],
      'user-agent': [Array],
      'content-length': [Array],
      'accept-encoding': [Array],
      host: [Array]
    },
    Symbol(errored): null,
    Symbol(kHighWaterMark): 65536,
    Symbol(kRejectNonStandardBodyWrites): false,
    Symbol(kUniqueHeaders): null
  },
  response: {
    status: 401,
    statusText: 'Unauthorized',
    headers: Object [AxiosHeaders] {
      date: 'Tue, 12 Aug 2025 02:31:08 GMT',
      'content-type': 'application/json; charset=utf-8',
      'content-length': '58',
      connection: 'keep-alive',
      server: 'KoreServer/COMMITH',
      'access-control-allow-methods': 'GET,POST,PUT',
      'access-control-allow-headers': 'Authorization,Content-Type,X-Requested-With,X-HTTP-Method-Override,X-UserToken,X-Timezone-Offset,smartassist,state,X-Request-Id,bot-language,app-language,accountid,iId,x-timezone',
      'access-control-allow-credentials': 'true',
      'access-control-allow-origin': '*',
      'x-requesttime': '1754965868993',
      pid: '126933',
      'x-traceid': 'b7576675-8bda-4748-be56-9caf521cd3dc',
      'response-error-description': '{"errors":[{"msg":"Invalid SDK credentials","code":4002}]}',
      'content-security-policy': "frame-ancestors https://*.smartassist.ai https://*.kore.ai https://*.korebots.com https://kore.ai https://*.force.com https://*.zendesk.com https://*.mypurecloud.com https://*.mypurecloud.jp https://*.usw2.pure.cloud https://*.onbmc.com https://*.workspace.ai https://*.niceincontact.com https://*.kore.ai https://*.kore.com; script-src 'self' 'unsafe-inline' 'unsafe-eval' https://*.kore.ai https://*.force.com https://*.zendesk.com https://*.mypurecloud.com https://*.mypurecloud.jp https://*.usw2.pure.cloud https://*.onbmc.com https://*.pendo.io https://*.appcues.com https://*.inlinemanual.com https://inlinemanual.com  https://cdn.mxpnl.com https://www.google-analytics.com  https://maps.googleapis.com https://canny.io https://js.hs-scripts.com https://www.googletagmanager.com https://*.grammarly.com https://*.grammarly.io https://unpkg.com/ https://*.niceincontact.com",
      'x-content-type-options': 'nosniff',
      'x-xss-protection': '1; mode=block',
      'strict-transport-security': 'max-age=31536000; includeSubdomains;',
      'referrer-policy': 'strict-origin-when-cross-origin'
    },
    config: {
      transitional: [Object],
      adapter: [Array],
      transformRequest: [Array],
      transformResponse: [Array],
      timeout: 30000,
      xsrfCookieName: 'XSRF-TOKEN',
      xsrfHeaderName: 'X-XSRF-TOKEN',
      maxContentLength: -1,
      maxBodyLength: -1,
      env: [Object],
      validateStatus: [Function: validateStatus],
      headers: [Object [AxiosHeaders]],
      method: 'post',
      url: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      data: '{"dateFrom":"2025-08-01T13:00:00.000Z","dateTo":"2025-08-01T19:00:00.000Z","skip":0,"limit":10000}',
      allowAbsoluteUrls: true
    },
    request: <ref *1> ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: true,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 98,
      _hasBody: true,
      _trailer: '',
      finished: true,
      _headerSent: true,
      _closed: true,
      _header: 'POST /api/public/bot/mock-bot-id/getSessions?containmentType=agent HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU0OTY1ODY4LCJleHAiOjE3NTQ5Njk0NjgsImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.T04rk7dxK6DoXWdJFO2TODfb0utJ8UAJsZiyQMFiSVs\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 98\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: bots.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      _ended: true,
      res: [IncomingMessage],
      aborted: false,
      timeoutCb: null,
      upgradeOrConnect: false,
      parser: null,
      maxHeadersCount: null,
      reusedSocket: true,
      host: 'bots.kore.ai',
      protocol: 'https:',
      _redirectable: [Writable],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    data: { errors: [Array] }
  },
  status: 401
}
âœ… [SessionDiscovery] Window 2 completed in 115ms: found 0 new sessions (total: 0)
â±ï¸  TIMING: Window 2 took 115ms (0.12s)
ğŸ” [SessionDiscovery] Starting window 3/4: Extended to 12 hours
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-02T01:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-02T01:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-02T01:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-02T01:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
[getSessionsMetadata] agent API call failed: AxiosError: Request failed with status code 401
    at settle (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/settle.js:19:12)
    at IncomingMessage.handleStreamEnd (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:599:11)
    at IncomingMessage.emit (node:events:519:35)
    at endReadableNT (node:internal/streams/readable:1701:12)
    at process.processTicksAndRejections (node:internal/process/task_queues:90:21)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async Promise.allSettled (index 0)
    at async KoreApiService.getSessionsMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:342:23)
    at async SessionSamplingService.getSessionsInTimeWindow (/Users/kengrafals/workspace/xobcat/backend/src/services/sessionSamplingService.ts:233:31)
    at async SessionSamplingService.sampleSessions (/Users/kengrafals/workspace/xobcat/backend/src/services/sessionSamplingService.ts:64:34)
    at async ParallelAutoAnalyzeService.runSamplingPhase (/Users/kengrafals/workspace/xobcat/backend/src/services/parallelAutoAnalyzeService.ts:313:30)
    at async ParallelAutoAnalyzeService.runParallelAnalysis (/Users/kengrafals/workspace/xobcat/backend/src/services/parallelAutoAnalyzeService.ts:260:30) {
  code: 'ERR_BAD_REQUEST',
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU0OTY1ODY4LCJleHAiOjE3NTQ5Njk0NjgsImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.T04rk7dxK6DoXWdJFO2TODfb0utJ8UAJsZiyQMFiSVs',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '98',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
    data: '{"dateFrom":"2025-08-01T13:00:00.000Z","dateTo":"2025-08-02T01:00:00.000Z","skip":0,"limit":10000}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> ClientRequest {
    _events: [Object: null prototype] {
      abort: [Function (anonymous)],
      aborted: [Function (anonymous)],
      connect: [Function (anonymous)],
      error: [Function (anonymous)],
      socket: [Function (anonymous)],
      timeout: [Function (anonymous)],
      finish: [Function: requestOnFinish]
    },
    _eventsCount: 7,
    _maxListeners: undefined,
    outputData: [],
    outputSize: 0,
    writable: true,
    destroyed: true,
    _last: false,
    chunkedEncoding: false,
    shouldKeepAlive: true,
    maxRequestsOnConnectionReached: false,
    _defaultKeepAlive: true,
    useChunkedEncodingByDefault: true,
    sendDate: false,
    _removedConnection: false,
    _removedContLen: false,
    _removedTE: false,
    strictContentLength: false,
    _contentLength: 98,
    _hasBody: true,
    _trailer: '',
    finished: true,
    _headerSent: true,
    _closed: true,
    _header: 'POST /api/public/bot/mock-bot-id/getSessions?containmentType=agent HTTP/1.1\r\n' +
      'Accept: application/json, text/plain, */*\r\n' +
      'Content-Type: application/json\r\n' +
      'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU0OTY1ODY4LCJleHAiOjE3NTQ5Njk0NjgsImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.T04rk7dxK6DoXWdJFO2TODfb0utJ8UAJsZiyQMFiSVs\r\n' +
      'User-Agent: axios/1.11.0\r\n' +
      'Content-Length: 98\r\n' +
      'Accept-Encoding: gzip, compress, deflate, br\r\n' +
      'Host: bots.kore.ai\r\n' +
      'Connection: keep-alive\r\n' +
      '\r\n',
    _keepAliveTimeout: 0,
    _onPendingData: [Function: nop],
    agent: Agent {
      _events: [Object: null prototype],
      _eventsCount: 2,
      _maxListeners: undefined,
      defaultPort: 443,
      protocol: 'https:',
      options: [Object: null prototype],
      requests: [Object: null prototype] {},
      sockets: [Object: null prototype] {},
      freeSockets: [Object: null prototype],
      keepAliveMsecs: 1000,
      keepAlive: true,
      maxSockets: Infinity,
      maxFreeSockets: 256,
      scheduling: 'lifo',
      maxTotalSockets: Infinity,
      totalSocketCount: 3,
      maxCachedSessions: 100,
      _sessionCache: [Object],
      Symbol(shapeMode): false,
      Symbol(kCapture): false
    },
    socketPath: undefined,
    method: 'POST',
    maxHeaderSize: undefined,
    insecureHTTPParser: undefined,
    joinDuplicateHeaders: undefined,
    path: '/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
    _ended: true,
    res: IncomingMessage {
      _events: [Object],
      _readableState: [ReadableState],
      _maxListeners: undefined,
      socket: null,
      httpVersionMajor: 1,
      httpVersionMinor: 1,
      httpVersion: '1.1',
      complete: true,
      rawHeaders: [Array],
      rawTrailers: [],
      joinDuplicateHeaders: undefined,
      aborted: false,
      upgrade: false,
      url: '',
      method: null,
      statusCode: 401,
      statusMessage: 'Unauthorized',
      client: [TLSSocket],
      _consuming: false,
      _dumped: false,
      req: [Circular *1],
      _eventsCount: 4,
      responseUrl: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      redirects: [],
      Symbol(shapeMode): true,
      Symbol(kCapture): false,
      Symbol(kHeaders): [Object],
      Symbol(kHeadersCount): 36,
      Symbol(kTrailers): null,
      Symbol(kTrailersCount): 0
    },
    aborted: false,
    timeoutCb: null,
    upgradeOrConnect: false,
    parser: null,
    maxHeadersCount: null,
    reusedSocket: true,
    host: 'bots.kore.ai',
    protocol: 'https:',
    _redirectable: Writable {
      _events: [Object],
      _writableState: [WritableState],
      _maxListeners: undefined,
      _options: [Object],
      _ended: true,
      _ending: true,
      _redirectCount: 0,
      _redirects: [],
      _requestBodyLength: 98,
      _requestBodyBuffers: [],
      _eventsCount: 3,
      _onNativeResponse: [Function (anonymous)],
      _currentRequest: [Circular *1],
      _currentUrl: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      _timeout: null,
      Symbol(shapeMode): true,
      Symbol(kCapture): false
    },
    Symbol(shapeMode): false,
    Symbol(kCapture): false,
    Symbol(kBytesWritten): 0,
    Symbol(kNeedDrain): false,
    Symbol(corked): 0,
    Symbol(kChunkedBuffer): [],
    Symbol(kChunkedLength): 0,
    Symbol(kSocket): TLSSocket {
      _tlsOptions: [Object],
      _secureEstablished: true,
      _securePending: false,
      _newSessionPending: false,
      _controlReleased: true,
      secureConnecting: false,
      _SNICallback: null,
      servername: 'bots.kore.ai',
      alpnProtocol: false,
      authorized: true,
      authorizationError: null,
      encrypted: true,
      _events: [Object: null prototype],
      _eventsCount: 9,
      connecting: false,
      _hadError: false,
      _parent: null,
      _host: 'bots.kore.ai',
      _closeAfterHandlingError: false,
      _readableState: [ReadableState],
      _writableState: [WritableState],
      allowHalfOpen: false,
      _maxListeners: undefined,
      _sockname: null,
      _pendingData: null,
      _pendingEncoding: '',
      server: undefined,
      _server: null,
      ssl: [TLSWrap],
      _requestCert: true,
      _rejectUnauthorized: true,
      timeout: 5000,
      parser: null,
      _httpMessage: null,
      autoSelectFamilyAttemptedAddresses: [Array],
      Symbol(alpncallback): null,
      Symbol(res): [TLSWrap],
      Symbol(verified): true,
      Symbol(pendingSession): null,
      Symbol(async_id_symbol): -1,
      Symbol(kHandle): [TLSWrap],
      Symbol(lastWriteQueueSize): 0,
      Symbol(timeout): Timeout {
        _idleTimeout: 5000,
        _idlePrev: [Timeout],
        _idleNext: [Timeout],
        _idleStart: 11082,
        _onTimeout: [Function: bound ],
        _timerArgs: undefined,
        _repeat: null,
        _destroyed: false,
        Symbol(refed): false,
        Symbol(kHasPrimitive): false,
        Symbol(asyncId): 265,
        Symbol(triggerId): 263,
        Symbol(kAsyncContextFrame): undefined
      },
      Symbol(kBuffer): null,
      Symbol(kBufferCb): null,
      Symbol(kBufferGen): null,
      Symbol(shapeMode): true,
      Symbol(kCapture): false,
      Symbol(kSetNoDelay): false,
      Symbol(kSetKeepAlive): true,
      Symbol(kSetKeepAliveInitialDelay): 1,
      Symbol(kBytesRead): 0,
      Symbol(kBytesWritten): 0,
      Symbol(connect-options): [Object]
    },
    Symbol(kOutHeaders): [Object: null prototype] {
      accept: [Array],
      'content-type': [Array],
      auth: [Array],
      'user-agent': [Array],
      'content-length': [Array],
      'accept-encoding': [Array],
      host: [Array]
    },
    Symbol(errored): null,
    Symbol(kHighWaterMark): 65536,
    Symbol(kRejectNonStandardBodyWrites): false,
    Symbol(kUniqueHeaders): null
  },
  response: {
    status: 401,
    statusText: 'Unauthorized',
    headers: Object [AxiosHeaders] {
      date: 'Tue, 12 Aug 2025 02:31:09 GMT',
      'content-type': 'application/json; charset=utf-8',
      'content-length': '58',
      connection: 'keep-alive',
      server: 'KoreServer/COMMITH',
      'access-control-allow-methods': 'GET,POST,PUT',
      'access-control-allow-headers': 'Authorization,Content-Type,X-Requested-With,X-HTTP-Method-Override,X-UserToken,X-Timezone-Offset,smartassist,state,X-Request-Id,bot-language,app-language,accountid,iId,x-timezone',
      'access-control-allow-credentials': 'true',
      'access-control-allow-origin': '*',
      'x-requesttime': '1754965869137',
      pid: '190830',
      'x-traceid': '600697e1-d728-439c-95c3-751bb8c7182a',
      'response-error-description': '{"errors":[{"msg":"Invalid SDK credentials","code":4002}]}',
      'content-security-policy': "frame-ancestors https://*.smartassist.ai https://*.kore.ai https://*.korebots.com https://kore.ai https://*.force.com https://*.zendesk.com https://*.mypurecloud.com https://*.mypurecloud.jp https://*.usw2.pure.cloud https://*.onbmc.com https://*.workspace.ai https://*.niceincontact.com https://*.kore.ai https://*.kore.com; script-src 'self' 'unsafe-inline' 'unsafe-eval' https://*.kore.ai https://*.force.com https://*.zendesk.com https://*.mypurecloud.com https://*.mypurecloud.jp https://*.usw2.pure.cloud https://*.onbmc.com https://*.pendo.io https://*.appcues.com https://*.inlinemanual.com https://inlinemanual.com  https://cdn.mxpnl.com https://www.google-analytics.com  https://maps.googleapis.com https://canny.io https://js.hs-scripts.com https://www.googletagmanager.com https://*.grammarly.com https://*.grammarly.io https://unpkg.com/ https://*.niceincontact.com",
      'x-content-type-options': 'nosniff',
      'x-xss-protection': '1; mode=block',
      'strict-transport-security': 'max-age=31536000; includeSubdomains;',
      'referrer-policy': 'strict-origin-when-cross-origin'
    },
    config: {
      transitional: [Object],
      adapter: [Array],
      transformRequest: [Array],
      transformResponse: [Array],
      timeout: 30000,
      xsrfCookieName: 'XSRF-TOKEN',
      xsrfHeaderName: 'X-XSRF-TOKEN',
      maxContentLength: -1,
      maxBodyLength: -1,
      env: [Object],
      validateStatus: [Function: validateStatus],
      headers: [Object [AxiosHeaders]],
      method: 'post',
      url: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      data: '{"dateFrom":"2025-08-01T13:00:00.000Z","dateTo":"2025-08-02T01:00:00.000Z","skip":0,"limit":10000}',
      allowAbsoluteUrls: true
    },
    request: <ref *1> ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: true,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 98,
      _hasBody: true,
      _trailer: '',
      finished: true,
      _headerSent: true,
      _closed: true,
      _header: 'POST /api/public/bot/mock-bot-id/getSessions?containmentType=agent HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU0OTY1ODY4LCJleHAiOjE3NTQ5Njk0NjgsImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.T04rk7dxK6DoXWdJFO2TODfb0utJ8UAJsZiyQMFiSVs\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 98\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: bots.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      _ended: true,
      res: [IncomingMessage],
      aborted: false,
      timeoutCb: null,
      upgradeOrConnect: false,
      parser: null,
      maxHeadersCount: null,
      reusedSocket: true,
      host: 'bots.kore.ai',
      protocol: 'https:',
      _redirectable: [Writable],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    data: { errors: [Array] }
  },
  status: 401
}
Authentication failed - throwing error to caller
Authentication failed during parallel execution - throwing error to caller
Error fetching session metadata for window Extended to 12 hours: AxiosError: Request failed with status code 401
    at settle (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/settle.js:19:12)
    at IncomingMessage.handleStreamEnd (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:599:11)
    at IncomingMessage.emit (node:events:519:35)
    at endReadableNT (node:internal/streams/readable:1701:12)
    at process.processTicksAndRejections (node:internal/process/task_queues:90:21)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async Promise.allSettled (index 0)
    at async KoreApiService.getSessionsMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:342:23)
    at async SessionSamplingService.getSessionsInTimeWindow (/Users/kengrafals/workspace/xobcat/backend/src/services/sessionSamplingService.ts:233:31)
    at async SessionSamplingService.sampleSessions (/Users/kengrafals/workspace/xobcat/backend/src/services/sessionSamplingService.ts:64:34)
    at async ParallelAutoAnalyzeService.runSamplingPhase (/Users/kengrafals/workspace/xobcat/backend/src/services/parallelAutoAnalyzeService.ts:313:30)
    at async ParallelAutoAnalyzeService.runParallelAnalysis (/Users/kengrafals/workspace/xobcat/backend/src/services/parallelAutoAnalyzeService.ts:260:30) {
  code: 'ERR_BAD_REQUEST',
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU0OTY1ODY4LCJleHAiOjE3NTQ5Njk0NjgsImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.T04rk7dxK6DoXWdJFO2TODfb0utJ8UAJsZiyQMFiSVs',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '98',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
    data: '{"dateFrom":"2025-08-01T13:00:00.000Z","dateTo":"2025-08-02T01:00:00.000Z","skip":0,"limit":10000}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> ClientRequest {
    _events: [Object: null prototype] {
      abort: [Function (anonymous)],
      aborted: [Function (anonymous)],
      connect: [Function (anonymous)],
      error: [Function (anonymous)],
      socket: [Function (anonymous)],
      timeout: [Function (anonymous)],
      finish: [Function: requestOnFinish]
    },
    _eventsCount: 7,
    _maxListeners: undefined,
    outputData: [],
    outputSize: 0,
    writable: true,
    destroyed: true,
    _last: false,
    chunkedEncoding: false,
    shouldKeepAlive: true,
    maxRequestsOnConnectionReached: false,
    _defaultKeepAlive: true,
    useChunkedEncodingByDefault: true,
    sendDate: false,
    _removedConnection: false,
    _removedContLen: false,
    _removedTE: false,
    strictContentLength: false,
    _contentLength: 98,
    _hasBody: true,
    _trailer: '',
    finished: true,
    _headerSent: true,
    _closed: true,
    _header: 'POST /api/public/bot/mock-bot-id/getSessions?containmentType=agent HTTP/1.1\r\n' +
      'Accept: application/json, text/plain, */*\r\n' +
      'Content-Type: application/json\r\n' +
      'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU0OTY1ODY4LCJleHAiOjE3NTQ5Njk0NjgsImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.T04rk7dxK6DoXWdJFO2TODfb0utJ8UAJsZiyQMFiSVs\r\n' +
      'User-Agent: axios/1.11.0\r\n' +
      'Content-Length: 98\r\n' +
      'Accept-Encoding: gzip, compress, deflate, br\r\n' +
      'Host: bots.kore.ai\r\n' +
      'Connection: keep-alive\r\n' +
      '\r\n',
    _keepAliveTimeout: 0,
    _onPendingData: [Function: nop],
    agent: Agent {
      _events: [Object: null prototype],
      _eventsCount: 2,
      _maxListeners: undefined,
      defaultPort: 443,
      protocol: 'https:',
      options: [Object: null prototype],
      requests: [Object: null prototype] {},
      sockets: [Object: null prototype] {},
      freeSockets: [Object: null prototype],
      keepAliveMsecs: 1000,
      keepAlive: true,
      maxSockets: Infinity,
      maxFreeSockets: 256,
      scheduling: 'lifo',
      maxTotalSockets: Infinity,
      totalSocketCount: 3,
      maxCachedSessions: 100,
      _sessionCache: [Object],
      Symbol(shapeMode): false,
      Symbol(kCapture): false
    },
    socketPath: undefined,
    method: 'POST',
    maxHeaderSize: undefined,
    insecureHTTPParser: undefined,
    joinDuplicateHeaders: undefined,
    path: '/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
    _ended: true,
    res: IncomingMessage {
      _events: [Object],
      _readableState: [ReadableState],
      _maxListeners: undefined,
      socket: null,
      httpVersionMajor: 1,
      httpVersionMinor: 1,
      httpVersion: '1.1',
      complete: true,
      rawHeaders: [Array],
      rawTrailers: [],
      joinDuplicateHeaders: undefined,
      aborted: false,
      upgrade: false,
      url: '',
      method: null,
      statusCode: 401,
      statusMessage: 'Unauthorized',
      client: [TLSSocket],
      _consuming: false,
      _dumped: false,
      req: [Circular *1],
      _eventsCount: 4,
      responseUrl: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      redirects: [],
      Symbol(shapeMode): true,
      Symbol(kCapture): false,
      Symbol(kHeaders): [Object],
      Symbol(kHeadersCount): 36,
      Symbol(kTrailers): null,
      Symbol(kTrailersCount): 0
    },
    aborted: false,
    timeoutCb: null,
    upgradeOrConnect: false,
    parser: null,
    maxHeadersCount: null,
    reusedSocket: true,
    host: 'bots.kore.ai',
    protocol: 'https:',
    _redirectable: Writable {
      _events: [Object],
      _writableState: [WritableState],
      _maxListeners: undefined,
      _options: [Object],
      _ended: true,
      _ending: true,
      _redirectCount: 0,
      _redirects: [],
      _requestBodyLength: 98,
      _requestBodyBuffers: [],
      _eventsCount: 3,
      _onNativeResponse: [Function (anonymous)],
      _currentRequest: [Circular *1],
      _currentUrl: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      _timeout: null,
      Symbol(shapeMode): true,
      Symbol(kCapture): false
    },
    Symbol(shapeMode): false,
    Symbol(kCapture): false,
    Symbol(kBytesWritten): 0,
    Symbol(kNeedDrain): false,
    Symbol(corked): 0,
    Symbol(kChunkedBuffer): [],
    Symbol(kChunkedLength): 0,
    Symbol(kSocket): TLSSocket {
      _tlsOptions: [Object],
      _secureEstablished: true,
      _securePending: false,
      _newSessionPending: false,
      _controlReleased: true,
      secureConnecting: false,
      _SNICallback: null,
      servername: 'bots.kore.ai',
      alpnProtocol: false,
      authorized: true,
      authorizationError: null,
      encrypted: true,
      _events: [Object: null prototype],
      _eventsCount: 9,
      connecting: false,
      _hadError: false,
      _parent: null,
      _host: 'bots.kore.ai',
      _closeAfterHandlingError: false,
      _readableState: [ReadableState],
      _writableState: [WritableState],
      allowHalfOpen: false,
      _maxListeners: undefined,
      _sockname: null,
      _pendingData: null,
      _pendingEncoding: '',
      server: undefined,
      _server: null,
      ssl: [TLSWrap],
      _requestCert: true,
      _rejectUnauthorized: true,
      timeout: 5000,
      parser: null,
      _httpMessage: null,
      autoSelectFamilyAttemptedAddresses: [Array],
      Symbol(alpncallback): null,
      Symbol(res): [TLSWrap],
      Symbol(verified): true,
      Symbol(pendingSession): null,
      Symbol(async_id_symbol): -1,
      Symbol(kHandle): [TLSWrap],
      Symbol(lastWriteQueueSize): 0,
      Symbol(timeout): Timeout {
        _idleTimeout: 5000,
        _idlePrev: [Timeout],
        _idleNext: [Timeout],
        _idleStart: 11082,
        _onTimeout: [Function: bound ],
        _timerArgs: undefined,
        _repeat: null,
        _destroyed: false,
        Symbol(refed): false,
        Symbol(kHasPrimitive): false,
        Symbol(asyncId): 265,
        Symbol(triggerId): 263,
        Symbol(kAsyncContextFrame): undefined
      },
      Symbol(kBuffer): null,
      Symbol(kBufferCb): null,
      Symbol(kBufferGen): null,
      Symbol(shapeMode): true,
      Symbol(kCapture): false,
      Symbol(kSetNoDelay): false,
      Symbol(kSetKeepAlive): true,
      Symbol(kSetKeepAliveInitialDelay): 1,
      Symbol(kBytesRead): 0,
      Symbol(kBytesWritten): 0,
      Symbol(connect-options): [Object]
    },
    Symbol(kOutHeaders): [Object: null prototype] {
      accept: [Array],
      'content-type': [Array],
      auth: [Array],
      'user-agent': [Array],
      'content-length': [Array],
      'accept-encoding': [Array],
      host: [Array]
    },
    Symbol(errored): null,
    Symbol(kHighWaterMark): 65536,
    Symbol(kRejectNonStandardBodyWrites): false,
    Symbol(kUniqueHeaders): null
  },
  response: {
    status: 401,
    statusText: 'Unauthorized',
    headers: Object [AxiosHeaders] {
      date: 'Tue, 12 Aug 2025 02:31:09 GMT',
      'content-type': 'application/json; charset=utf-8',
      'content-length': '58',
      connection: 'keep-alive',
      server: 'KoreServer/COMMITH',
      'access-control-allow-methods': 'GET,POST,PUT',
      'access-control-allow-headers': 'Authorization,Content-Type,X-Requested-With,X-HTTP-Method-Override,X-UserToken,X-Timezone-Offset,smartassist,state,X-Request-Id,bot-language,app-language,accountid,iId,x-timezone',
      'access-control-allow-credentials': 'true',
      'access-control-allow-origin': '*',
      'x-requesttime': '1754965869137',
      pid: '190830',
      'x-traceid': '600697e1-d728-439c-95c3-751bb8c7182a',
      'response-error-description': '{"errors":[{"msg":"Invalid SDK credentials","code":4002}]}',
      'content-security-policy': "frame-ancestors https://*.smartassist.ai https://*.kore.ai https://*.korebots.com https://kore.ai https://*.force.com https://*.zendesk.com https://*.mypurecloud.com https://*.mypurecloud.jp https://*.usw2.pure.cloud https://*.onbmc.com https://*.workspace.ai https://*.niceincontact.com https://*.kore.ai https://*.kore.com; script-src 'self' 'unsafe-inline' 'unsafe-eval' https://*.kore.ai https://*.force.com https://*.zendesk.com https://*.mypurecloud.com https://*.mypurecloud.jp https://*.usw2.pure.cloud https://*.onbmc.com https://*.pendo.io https://*.appcues.com https://*.inlinemanual.com https://inlinemanual.com  https://cdn.mxpnl.com https://www.google-analytics.com  https://maps.googleapis.com https://canny.io https://js.hs-scripts.com https://www.googletagmanager.com https://*.grammarly.com https://*.grammarly.io https://unpkg.com/ https://*.niceincontact.com",
      'x-content-type-options': 'nosniff',
      'x-xss-protection': '1; mode=block',
      'strict-transport-security': 'max-age=31536000; includeSubdomains;',
      'referrer-policy': 'strict-origin-when-cross-origin'
    },
    config: {
      transitional: [Object],
      adapter: [Array],
      transformRequest: [Array],
      transformResponse: [Array],
      timeout: 30000,
      xsrfCookieName: 'XSRF-TOKEN',
      xsrfHeaderName: 'X-XSRF-TOKEN',
      maxContentLength: -1,
      maxBodyLength: -1,
      env: [Object],
      validateStatus: [Function: validateStatus],
      headers: [Object [AxiosHeaders]],
      method: 'post',
      url: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      data: '{"dateFrom":"2025-08-01T13:00:00.000Z","dateTo":"2025-08-02T01:00:00.000Z","skip":0,"limit":10000}',
      allowAbsoluteUrls: true
    },
    request: <ref *1> ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: true,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 98,
      _hasBody: true,
      _trailer: '',
      finished: true,
      _headerSent: true,
      _closed: true,
      _header: 'POST /api/public/bot/mock-bot-id/getSessions?containmentType=agent HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU0OTY1ODY4LCJleHAiOjE3NTQ5Njk0NjgsImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.T04rk7dxK6DoXWdJFO2TODfb0utJ8UAJsZiyQMFiSVs\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 98\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: bots.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      _ended: true,
      res: [IncomingMessage],
      aborted: false,
      timeoutCb: null,
      upgradeOrConnect: false,
      parser: null,
      maxHeadersCount: null,
      reusedSocket: true,
      host: 'bots.kore.ai',
      protocol: 'https:',
      _redirectable: [Writable],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    data: { errors: [Array] }
  },
  status: 401
}
âœ… [SessionDiscovery] Window 3 completed in 149ms: found 0 new sessions (total: 0)
â±ï¸  TIMING: Window 3 took 149ms (0.15s)
ğŸ” [SessionDiscovery] Starting window 4/4: Extended to 6 days
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-07T13:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-07T13:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-07T13:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-07T13:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
[getSessionsMetadata] agent API call failed: AxiosError: Request failed with status code 401
    at settle (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/settle.js:19:12)
    at IncomingMessage.handleStreamEnd (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:599:11)
    at IncomingMessage.emit (node:events:519:35)
    at endReadableNT (node:internal/streams/readable:1701:12)
    at process.processTicksAndRejections (node:internal/process/task_queues:90:21)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async Promise.allSettled (index 0)
    at async KoreApiService.getSessionsMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:342:23)
    at async SessionSamplingService.getSessionsInTimeWindow (/Users/kengrafals/workspace/xobcat/backend/src/services/sessionSamplingService.ts:233:31)
    at async SessionSamplingService.sampleSessions (/Users/kengrafals/workspace/xobcat/backend/src/services/sessionSamplingService.ts:64:34)
    at async ParallelAutoAnalyzeService.runSamplingPhase (/Users/kengrafals/workspace/xobcat/backend/src/services/parallelAutoAnalyzeService.ts:313:30)
    at async ParallelAutoAnalyzeService.runParallelAnalysis (/Users/kengrafals/workspace/xobcat/backend/src/services/parallelAutoAnalyzeService.ts:260:30) {
  code: 'ERR_BAD_REQUEST',
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU0OTY1ODY5LCJleHAiOjE3NTQ5Njk0NjksImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.8ZGTe4vZjQf-Mw0LvNy3UUGKf9JWxRXbqs--Jvxmt2A',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '98',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
    data: '{"dateFrom":"2025-08-01T13:00:00.000Z","dateTo":"2025-08-07T13:00:00.000Z","skip":0,"limit":10000}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> ClientRequest {
    _events: [Object: null prototype] {
      abort: [Function (anonymous)],
      aborted: [Function (anonymous)],
      connect: [Function (anonymous)],
      error: [Function (anonymous)],
      socket: [Function (anonymous)],
      timeout: [Function (anonymous)],
      finish: [Function: requestOnFinish]
    },
    _eventsCount: 7,
    _maxListeners: undefined,
    outputData: [],
    outputSize: 0,
    writable: true,
    destroyed: true,
    _last: false,
    chunkedEncoding: false,
    shouldKeepAlive: true,
    maxRequestsOnConnectionReached: false,
    _defaultKeepAlive: true,
    useChunkedEncodingByDefault: true,
    sendDate: false,
    _removedConnection: false,
    _removedContLen: false,
    _removedTE: false,
    strictContentLength: false,
    _contentLength: 98,
    _hasBody: true,
    _trailer: '',
    finished: true,
    _headerSent: true,
    _closed: true,
    _header: 'POST /api/public/bot/mock-bot-id/getSessions?containmentType=agent HTTP/1.1\r\n' +
      'Accept: application/json, text/plain, */*\r\n' +
      'Content-Type: application/json\r\n' +
      'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU0OTY1ODY5LCJleHAiOjE3NTQ5Njk0NjksImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.8ZGTe4vZjQf-Mw0LvNy3UUGKf9JWxRXbqs--Jvxmt2A\r\n' +
      'User-Agent: axios/1.11.0\r\n' +
      'Content-Length: 98\r\n' +
      'Accept-Encoding: gzip, compress, deflate, br\r\n' +
      'Host: bots.kore.ai\r\n' +
      'Connection: keep-alive\r\n' +
      '\r\n',
    _keepAliveTimeout: 0,
    _onPendingData: [Function: nop],
    agent: Agent {
      _events: [Object: null prototype],
      _eventsCount: 2,
      _maxListeners: undefined,
      defaultPort: 443,
      protocol: 'https:',
      options: [Object: null prototype],
      requests: [Object: null prototype] {},
      sockets: [Object: null prototype] {},
      freeSockets: [Object: null prototype],
      keepAliveMsecs: 1000,
      keepAlive: true,
      maxSockets: Infinity,
      maxFreeSockets: 256,
      scheduling: 'lifo',
      maxTotalSockets: Infinity,
      totalSocketCount: 3,
      maxCachedSessions: 100,
      _sessionCache: [Object],
      Symbol(shapeMode): false,
      Symbol(kCapture): false
    },
    socketPath: undefined,
    method: 'POST',
    maxHeaderSize: undefined,
    insecureHTTPParser: undefined,
    joinDuplicateHeaders: undefined,
    path: '/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
    _ended: true,
    res: IncomingMessage {
      _events: [Object],
      _readableState: [ReadableState],
      _maxListeners: undefined,
      socket: null,
      httpVersionMajor: 1,
      httpVersionMinor: 1,
      httpVersion: '1.1',
      complete: true,
      rawHeaders: [Array],
      rawTrailers: [],
      joinDuplicateHeaders: undefined,
      aborted: false,
      upgrade: false,
      url: '',
      method: null,
      statusCode: 401,
      statusMessage: 'Unauthorized',
      client: [TLSSocket],
      _consuming: true,
      _dumped: false,
      req: [Circular *1],
      _eventsCount: 4,
      responseUrl: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      redirects: [],
      Symbol(shapeMode): true,
      Symbol(kCapture): false,
      Symbol(kHeaders): [Object],
      Symbol(kHeadersCount): 36,
      Symbol(kTrailers): null,
      Symbol(kTrailersCount): 0
    },
    aborted: false,
    timeoutCb: null,
    upgradeOrConnect: false,
    parser: null,
    maxHeadersCount: null,
    reusedSocket: true,
    host: 'bots.kore.ai',
    protocol: 'https:',
    _redirectable: Writable {
      _events: [Object],
      _writableState: [WritableState],
      _maxListeners: undefined,
      _options: [Object],
      _ended: true,
      _ending: true,
      _redirectCount: 0,
      _redirects: [],
      _requestBodyLength: 98,
      _requestBodyBuffers: [],
      _eventsCount: 3,
      _onNativeResponse: [Function (anonymous)],
      _currentRequest: [Circular *1],
      _currentUrl: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      _timeout: null,
      Symbol(shapeMode): true,
      Symbol(kCapture): false
    },
    Symbol(shapeMode): false,
    Symbol(kCapture): false,
    Symbol(kBytesWritten): 0,
    Symbol(kNeedDrain): false,
    Symbol(corked): 0,
    Symbol(kChunkedBuffer): [],
    Symbol(kChunkedLength): 0,
    Symbol(kSocket): TLSSocket {
      _tlsOptions: [Object],
      _secureEstablished: true,
      _securePending: false,
      _newSessionPending: false,
      _controlReleased: true,
      secureConnecting: false,
      _SNICallback: null,
      servername: 'bots.kore.ai',
      alpnProtocol: false,
      authorized: true,
      authorizationError: null,
      encrypted: true,
      _events: [Object: null prototype],
      _eventsCount: 9,
      connecting: false,
      _hadError: false,
      _parent: null,
      _host: 'bots.kore.ai',
      _closeAfterHandlingError: false,
      _readableState: [ReadableState],
      _writableState: [WritableState],
      allowHalfOpen: false,
      _maxListeners: undefined,
      _sockname: null,
      _pendingData: null,
      _pendingEncoding: '',
      server: undefined,
      _server: null,
      ssl: [TLSWrap],
      _requestCert: true,
      _rejectUnauthorized: true,
      timeout: 5000,
      parser: null,
      _httpMessage: null,
      autoSelectFamilyAttemptedAddresses: [Array],
      Symbol(alpncallback): null,
      Symbol(res): [TLSWrap],
      Symbol(verified): true,
      Symbol(pendingSession): null,
      Symbol(async_id_symbol): -1,
      Symbol(kHandle): [TLSWrap],
      Symbol(lastWriteQueueSize): 0,
      Symbol(timeout): Timeout {
        _idleTimeout: 5000,
        _idlePrev: [Timeout],
        _idleNext: [TimersList],
        _idleStart: 11190,
        _onTimeout: [Function: bound ],
        _timerArgs: undefined,
        _repeat: null,
        _destroyed: false,
        Symbol(refed): false,
        Symbol(kHasPrimitive): false,
        Symbol(asyncId): 311,
        Symbol(triggerId): 309,
        Symbol(kAsyncContextFrame): undefined
      },
      Symbol(kBuffer): null,
      Symbol(kBufferCb): null,
      Symbol(kBufferGen): null,
      Symbol(shapeMode): true,
      Symbol(kCapture): false,
      Symbol(kSetNoDelay): false,
      Symbol(kSetKeepAlive): true,
      Symbol(kSetKeepAliveInitialDelay): 1,
      Symbol(kBytesRead): 0,
      Symbol(kBytesWritten): 0,
      Symbol(connect-options): [Object]
    },
    Symbol(kOutHeaders): [Object: null prototype] {
      accept: [Array],
      'content-type': [Array],
      auth: [Array],
      'user-agent': [Array],
      'content-length': [Array],
      'accept-encoding': [Array],
      host: [Array]
    },
    Symbol(errored): null,
    Symbol(kHighWaterMark): 65536,
    Symbol(kRejectNonStandardBodyWrites): false,
    Symbol(kUniqueHeaders): null
  },
  response: {
    status: 401,
    statusText: 'Unauthorized',
    headers: Object [AxiosHeaders] {
      date: 'Tue, 12 Aug 2025 02:31:09 GMT',
      'content-type': 'application/json; charset=utf-8',
      'content-length': '58',
      connection: 'keep-alive',
      server: 'KoreServer/COMMITH',
      'access-control-allow-methods': 'GET,POST,PUT',
      'access-control-allow-headers': 'Authorization,Content-Type,X-Requested-With,X-HTTP-Method-Override,X-UserToken,X-Timezone-Offset,smartassist,state,X-Request-Id,bot-language,app-language,accountid,iId,x-timezone',
      'access-control-allow-credentials': 'true',
      'access-control-allow-origin': '*',
      'x-requesttime': '1754965869249',
      pid: '126933',
      'x-traceid': 'd2483a67-612c-4b9d-94bc-6f121eb4226a',
      'response-error-description': '{"errors":[{"msg":"Invalid SDK credentials","code":4002}]}',
      'content-security-policy': "frame-ancestors https://*.smartassist.ai https://*.kore.ai https://*.korebots.com https://kore.ai https://*.force.com https://*.zendesk.com https://*.mypurecloud.com https://*.mypurecloud.jp https://*.usw2.pure.cloud https://*.onbmc.com https://*.workspace.ai https://*.niceincontact.com https://*.kore.ai https://*.kore.com; script-src 'self' 'unsafe-inline' 'unsafe-eval' https://*.kore.ai https://*.force.com https://*.zendesk.com https://*.mypurecloud.com https://*.mypurecloud.jp https://*.usw2.pure.cloud https://*.onbmc.com https://*.pendo.io https://*.appcues.com https://*.inlinemanual.com https://inlinemanual.com  https://cdn.mxpnl.com https://www.google-analytics.com  https://maps.googleapis.com https://canny.io https://js.hs-scripts.com https://www.googletagmanager.com https://*.grammarly.com https://*.grammarly.io https://unpkg.com/ https://*.niceincontact.com",
      'x-content-type-options': 'nosniff',
      'x-xss-protection': '1; mode=block',
      'strict-transport-security': 'max-age=31536000; includeSubdomains;',
      'referrer-policy': 'strict-origin-when-cross-origin'
    },
    config: {
      transitional: [Object],
      adapter: [Array],
      transformRequest: [Array],
      transformResponse: [Array],
      timeout: 30000,
      xsrfCookieName: 'XSRF-TOKEN',
      xsrfHeaderName: 'X-XSRF-TOKEN',
      maxContentLength: -1,
      maxBodyLength: -1,
      env: [Object],
      validateStatus: [Function: validateStatus],
      headers: [Object [AxiosHeaders]],
      method: 'post',
      url: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      data: '{"dateFrom":"2025-08-01T13:00:00.000Z","dateTo":"2025-08-07T13:00:00.000Z","skip":0,"limit":10000}',
      allowAbsoluteUrls: true
    },
    request: <ref *1> ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: true,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 98,
      _hasBody: true,
      _trailer: '',
      finished: true,
      _headerSent: true,
      _closed: true,
      _header: 'POST /api/public/bot/mock-bot-id/getSessions?containmentType=agent HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU0OTY1ODY5LCJleHAiOjE3NTQ5Njk0NjksImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.8ZGTe4vZjQf-Mw0LvNy3UUGKf9JWxRXbqs--Jvxmt2A\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 98\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: bots.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      _ended: true,
      res: [IncomingMessage],
      aborted: false,
      timeoutCb: null,
      upgradeOrConnect: false,
      parser: null,
      maxHeadersCount: null,
      reusedSocket: true,
      host: 'bots.kore.ai',
      protocol: 'https:',
      _redirectable: [Writable],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    data: { errors: [Array] }
  },
  status: 401
}
Authentication failed - throwing error to caller
Authentication failed during parallel execution - throwing error to caller
Error fetching session metadata for window Extended to 6 days: AxiosError: Request failed with status code 401
    at settle (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/settle.js:19:12)
    at IncomingMessage.handleStreamEnd (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:599:11)
    at IncomingMessage.emit (node:events:519:35)
    at endReadableNT (node:internal/streams/readable:1701:12)
    at process.processTicksAndRejections (node:internal/process/task_queues:90:21)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async Promise.allSettled (index 0)
    at async KoreApiService.getSessionsMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:342:23)
    at async SessionSamplingService.getSessionsInTimeWindow (/Users/kengrafals/workspace/xobcat/backend/src/services/sessionSamplingService.ts:233:31)
    at async SessionSamplingService.sampleSessions (/Users/kengrafals/workspace/xobcat/backend/src/services/sessionSamplingService.ts:64:34)
    at async ParallelAutoAnalyzeService.runSamplingPhase (/Users/kengrafals/workspace/xobcat/backend/src/services/parallelAutoAnalyzeService.ts:313:30)
    at async ParallelAutoAnalyzeService.runParallelAnalysis (/Users/kengrafals/workspace/xobcat/backend/src/services/parallelAutoAnalyzeService.ts:260:30) {
  code: 'ERR_BAD_REQUEST',
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU0OTY1ODY5LCJleHAiOjE3NTQ5Njk0NjksImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.8ZGTe4vZjQf-Mw0LvNy3UUGKf9JWxRXbqs--Jvxmt2A',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '98',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
    data: '{"dateFrom":"2025-08-01T13:00:00.000Z","dateTo":"2025-08-07T13:00:00.000Z","skip":0,"limit":10000}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> ClientRequest {
    _events: [Object: null prototype] {
      abort: [Function (anonymous)],
      aborted: [Function (anonymous)],
      connect: [Function (anonymous)],
      error: [Function (anonymous)],
      socket: [Function (anonymous)],
      timeout: [Function (anonymous)],
      finish: [Function: requestOnFinish]
    },
    _eventsCount: 7,
    _maxListeners: undefined,
    outputData: [],
    outputSize: 0,
    writable: true,
    destroyed: true,
    _last: false,
    chunkedEncoding: false,
    shouldKeepAlive: true,
    maxRequestsOnConnectionReached: false,
    _defaultKeepAlive: true,
    useChunkedEncodingByDefault: true,
    sendDate: false,
    _removedConnection: false,
    _removedContLen: false,
    _removedTE: false,
    strictContentLength: false,
    _contentLength: 98,
    _hasBody: true,
    _trailer: '',
    finished: true,
    _headerSent: true,
    _closed: true,
    _header: 'POST /api/public/bot/mock-bot-id/getSessions?containmentType=agent HTTP/1.1\r\n' +
      'Accept: application/json, text/plain, */*\r\n' +
      'Content-Type: application/json\r\n' +
      'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU0OTY1ODY5LCJleHAiOjE3NTQ5Njk0NjksImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.8ZGTe4vZjQf-Mw0LvNy3UUGKf9JWxRXbqs--Jvxmt2A\r\n' +
      'User-Agent: axios/1.11.0\r\n' +
      'Content-Length: 98\r\n' +
      'Accept-Encoding: gzip, compress, deflate, br\r\n' +
      'Host: bots.kore.ai\r\n' +
      'Connection: keep-alive\r\n' +
      '\r\n',
    _keepAliveTimeout: 0,
    _onPendingData: [Function: nop],
    agent: Agent {
      _events: [Object: null prototype],
      _eventsCount: 2,
      _maxListeners: undefined,
      defaultPort: 443,
      protocol: 'https:',
      options: [Object: null prototype],
      requests: [Object: null prototype] {},
      sockets: [Object: null prototype] {},
      freeSockets: [Object: null prototype],
      keepAliveMsecs: 1000,
      keepAlive: true,
      maxSockets: Infinity,
      maxFreeSockets: 256,
      scheduling: 'lifo',
      maxTotalSockets: Infinity,
      totalSocketCount: 3,
      maxCachedSessions: 100,
      _sessionCache: [Object],
      Symbol(shapeMode): false,
      Symbol(kCapture): false
    },
    socketPath: undefined,
    method: 'POST',
    maxHeaderSize: undefined,
    insecureHTTPParser: undefined,
    joinDuplicateHeaders: undefined,
    path: '/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
    _ended: true,
    res: IncomingMessage {
      _events: [Object],
      _readableState: [ReadableState],
      _maxListeners: undefined,
      socket: null,
      httpVersionMajor: 1,
      httpVersionMinor: 1,
      httpVersion: '1.1',
      complete: true,
      rawHeaders: [Array],
      rawTrailers: [],
      joinDuplicateHeaders: undefined,
      aborted: false,
      upgrade: false,
      url: '',
      method: null,
      statusCode: 401,
      statusMessage: 'Unauthorized',
      client: [TLSSocket],
      _consuming: true,
      _dumped: false,
      req: [Circular *1],
      _eventsCount: 4,
      responseUrl: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      redirects: [],
      Symbol(shapeMode): true,
      Symbol(kCapture): false,
      Symbol(kHeaders): [Object],
      Symbol(kHeadersCount): 36,
      Symbol(kTrailers): null,
      Symbol(kTrailersCount): 0
    },
    aborted: false,
    timeoutCb: null,
    upgradeOrConnect: false,
    parser: null,
    maxHeadersCount: null,
    reusedSocket: true,
    host: 'bots.kore.ai',
    protocol: 'https:',
    _redirectable: Writable {
      _events: [Object],
      _writableState: [WritableState],
      _maxListeners: undefined,
      _options: [Object],
      _ended: true,
      _ending: true,
      _redirectCount: 0,
      _redirects: [],
      _requestBodyLength: 98,
      _requestBodyBuffers: [],
      _eventsCount: 3,
      _onNativeResponse: [Function (anonymous)],
      _currentRequest: [Circular *1],
      _currentUrl: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      _timeout: null,
      Symbol(shapeMode): true,
      Symbol(kCapture): false
    },
    Symbol(shapeMode): false,
    Symbol(kCapture): false,
    Symbol(kBytesWritten): 0,
    Symbol(kNeedDrain): false,
    Symbol(corked): 0,
    Symbol(kChunkedBuffer): [],
    Symbol(kChunkedLength): 0,
    Symbol(kSocket): TLSSocket {
      _tlsOptions: [Object],
      _secureEstablished: true,
      _securePending: false,
      _newSessionPending: false,
      _controlReleased: true,
      secureConnecting: false,
      _SNICallback: null,
      servername: 'bots.kore.ai',
      alpnProtocol: false,
      authorized: true,
      authorizationError: null,
      encrypted: true,
      _events: [Object: null prototype],
      _eventsCount: 9,
      connecting: false,
      _hadError: false,
      _parent: null,
      _host: 'bots.kore.ai',
      _closeAfterHandlingError: false,
      _readableState: [ReadableState],
      _writableState: [WritableState],
      allowHalfOpen: false,
      _maxListeners: undefined,
      _sockname: null,
      _pendingData: null,
      _pendingEncoding: '',
      server: undefined,
      _server: null,
      ssl: [TLSWrap],
      _requestCert: true,
      _rejectUnauthorized: true,
      timeout: 5000,
      parser: null,
      _httpMessage: null,
      autoSelectFamilyAttemptedAddresses: [Array],
      Symbol(alpncallback): null,
      Symbol(res): [TLSWrap],
      Symbol(verified): true,
      Symbol(pendingSession): null,
      Symbol(async_id_symbol): -1,
      Symbol(kHandle): [TLSWrap],
      Symbol(lastWriteQueueSize): 0,
      Symbol(timeout): Timeout {
        _idleTimeout: 5000,
        _idlePrev: [Timeout],
        _idleNext: [TimersList],
        _idleStart: 11190,
        _onTimeout: [Function: bound ],
        _timerArgs: undefined,
        _repeat: null,
        _destroyed: false,
        Symbol(refed): false,
        Symbol(kHasPrimitive): false,
        Symbol(asyncId): 311,
        Symbol(triggerId): 309,
        Symbol(kAsyncContextFrame): undefined
      },
      Symbol(kBuffer): null,
      Symbol(kBufferCb): null,
      Symbol(kBufferGen): null,
      Symbol(shapeMode): true,
      Symbol(kCapture): false,
      Symbol(kSetNoDelay): false,
      Symbol(kSetKeepAlive): true,
      Symbol(kSetKeepAliveInitialDelay): 1,
      Symbol(kBytesRead): 0,
      Symbol(kBytesWritten): 0,
      Symbol(connect-options): [Object]
    },
    Symbol(kOutHeaders): [Object: null prototype] {
      accept: [Array],
      'content-type': [Array],
      auth: [Array],
      'user-agent': [Array],
      'content-length': [Array],
      'accept-encoding': [Array],
      host: [Array]
    },
    Symbol(errored): null,
    Symbol(kHighWaterMark): 65536,
    Symbol(kRejectNonStandardBodyWrites): false,
    Symbol(kUniqueHeaders): null
  },
  response: {
    status: 401,
    statusText: 'Unauthorized',
    headers: Object [AxiosHeaders] {
      date: 'Tue, 12 Aug 2025 02:31:09 GMT',
      'content-type': 'application/json; charset=utf-8',
      'content-length': '58',
      connection: 'keep-alive',
      server: 'KoreServer/COMMITH',
      'access-control-allow-methods': 'GET,POST,PUT',
      'access-control-allow-headers': 'Authorization,Content-Type,X-Requested-With,X-HTTP-Method-Override,X-UserToken,X-Timezone-Offset,smartassist,state,X-Request-Id,bot-language,app-language,accountid,iId,x-timezone',
      'access-control-allow-credentials': 'true',
      'access-control-allow-origin': '*',
      'x-requesttime': '1754965869249',
      pid: '126933',
      'x-traceid': 'd2483a67-612c-4b9d-94bc-6f121eb4226a',
      'response-error-description': '{"errors":[{"msg":"Invalid SDK credentials","code":4002}]}',
      'content-security-policy': "frame-ancestors https://*.smartassist.ai https://*.kore.ai https://*.korebots.com https://kore.ai https://*.force.com https://*.zendesk.com https://*.mypurecloud.com https://*.mypurecloud.jp https://*.usw2.pure.cloud https://*.onbmc.com https://*.workspace.ai https://*.niceincontact.com https://*.kore.ai https://*.kore.com; script-src 'self' 'unsafe-inline' 'unsafe-eval' https://*.kore.ai https://*.force.com https://*.zendesk.com https://*.mypurecloud.com https://*.mypurecloud.jp https://*.usw2.pure.cloud https://*.onbmc.com https://*.pendo.io https://*.appcues.com https://*.inlinemanual.com https://inlinemanual.com  https://cdn.mxpnl.com https://www.google-analytics.com  https://maps.googleapis.com https://canny.io https://js.hs-scripts.com https://www.googletagmanager.com https://*.grammarly.com https://*.grammarly.io https://unpkg.com/ https://*.niceincontact.com",
      'x-content-type-options': 'nosniff',
      'x-xss-protection': '1; mode=block',
      'strict-transport-security': 'max-age=31536000; includeSubdomains;',
      'referrer-policy': 'strict-origin-when-cross-origin'
    },
    config: {
      transitional: [Object],
      adapter: [Array],
      transformRequest: [Array],
      transformResponse: [Array],
      timeout: 30000,
      xsrfCookieName: 'XSRF-TOKEN',
      xsrfHeaderName: 'X-XSRF-TOKEN',
      maxContentLength: -1,
      maxBodyLength: -1,
      env: [Object],
      validateStatus: [Function: validateStatus],
      headers: [Object [AxiosHeaders]],
      method: 'post',
      url: 'https://bots.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      data: '{"dateFrom":"2025-08-01T13:00:00.000Z","dateTo":"2025-08-07T13:00:00.000Z","skip":0,"limit":10000}',
      allowAbsoluteUrls: true
    },
    request: <ref *1> ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: true,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 98,
      _hasBody: true,
      _trailer: '',
      finished: true,
      _headerSent: true,
      _closed: true,
      _header: 'POST /api/public/bot/mock-bot-id/getSessions?containmentType=agent HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU0OTY1ODY5LCJleHAiOjE3NTQ5Njk0NjksImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.8ZGTe4vZjQf-Mw0LvNy3UUGKf9JWxRXbqs--Jvxmt2A\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 98\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: bots.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      _ended: true,
      res: [IncomingMessage],
      aborted: false,
      timeoutCb: null,
      upgradeOrConnect: false,
      parser: null,
      maxHeadersCount: null,
      reusedSocket: true,
      host: 'bots.kore.ai',
      protocol: 'https:',
      _redirectable: [Writable],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    data: { errors: [Array] }
  },
  status: 401
}
âœ… [SessionDiscovery] Window 4 completed in 108ms: found 0 new sessions (total: 0)
â±ï¸  TIMING: Window 4 took 108ms (0.11s)
Error in sessionSamplingService.sampleSessions: Error: Insufficient sessions found. Found 0 sessions, but need at least 10. Try expanding your time range or choosing a different date.
    at SessionSamplingService.sampleSessions (/Users/kengrafals/workspace/xobcat/backend/src/services/sessionSamplingService.ts:96:13)
    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)
    at async ParallelAutoAnalyzeService.runSamplingPhase (/Users/kengrafals/workspace/xobcat/backend/src/services/parallelAutoAnalyzeService.ts:313:30)
    at async ParallelAutoAnalyzeService.runParallelAnalysis (/Users/kengrafals/workspace/xobcat/backend/src/services/parallelAutoAnalyzeService.ts:260:30)
    at async BackgroundJobQueue.processParallelAnalysis (/Users/kengrafals/workspace/xobcat/backend/src/services/backgroundJobQueue.ts:469:7)
    at async BackgroundJobQueue.processJob (/Users/kengrafals/workspace/xobcat/backend/src/services/backgroundJobQueue.ts:149:9)
    at async Timeout._onTimeout (/Users/kengrafals/workspace/xobcat/backend/src/services/backgroundJobQueue.ts:116:9)
[ParallelAutoAnalyzeService] Analysis 4595690f-e8ad-4d0a-99fb-46a42d4e4889 failed: Error: Insufficient sessions found. Found 0 sessions, but need at least 10. Try expanding your time range or choosing a different date.
    at SessionSamplingService.sampleSessions (/Users/kengrafals/workspace/xobcat/backend/src/services/sessionSamplingService.ts:96:13)
    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)
    at async ParallelAutoAnalyzeService.runSamplingPhase (/Users/kengrafals/workspace/xobcat/backend/src/services/parallelAutoAnalyzeService.ts:313:30)
    at async ParallelAutoAnalyzeService.runParallelAnalysis (/Users/kengrafals/workspace/xobcat/backend/src/services/parallelAutoAnalyzeService.ts:260:30)
    at async BackgroundJobQueue.processParallelAnalysis (/Users/kengrafals/workspace/xobcat/backend/src/services/backgroundJobQueue.ts:469:7)
    at async BackgroundJobQueue.processJob (/Users/kengrafals/workspace/xobcat/backend/src/services/backgroundJobQueue.ts:149:9)
    at async Timeout._onTimeout (/Users/kengrafals/workspace/xobcat/backend/src/services/backgroundJobQueue.ts:116:9)
[BackgroundJobQueue] Updated job progress to final state: error
[BackgroundJobQueue] Parallel analysis job 4595690f-e8ad-4d0a-99fb-46a42d4e4889-parallel completed successfully
ğŸš€ [ParallelAutoAnalyzeRoute] Starting parallel analysis for bot ***REMOVED*** with real credentials
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=real
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
ğŸ­ ServiceFactory: Creating OpenAI service (type: real)
ğŸš€ [ParallelAutoAnalyzeService] Starting parallel analysis c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 with bot ***REMOVED***
ğŸš€ [ParallelAutoAnalyzeService] Using credentials: real
ğŸš€ [ParallelAutoAnalyzeRoute] Parallel analysis started: c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73
::1 - - [12/Aug/2025:02:31:52 +0000] "POST /api/analysis/auto-analyze/parallel/start HTTP/1.1" 200 214 "-" "axios/1.11.0"
ğŸš€ AutoAnalyzeService: Creating services for bot ***REMOVED***
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=real
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
ğŸ­ ServiceFactory: Creating OpenAI service (type: real)
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:31:52 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
[BackgroundJobQueue] Starting job processing after delay for job c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73-parallel
[BackgroundJobQueue] Starting processing for job c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73-parallel, phase: sampling
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing parallel analysis job c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73-parallel
[BackgroundJobQueue] Processing parallel analysis for bot ***REMOVED***
[BackgroundJobQueue] Using existing ParallelAutoAnalyzeService instance for bot ***REMOVED***
[BackgroundJobQueue] Session recreated for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73
[ParallelAutoAnalyzeService] Running parallel analysis for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73
[ParallelAutoAnalyzeService] Phase 0: Starting session sampling for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73

ğŸ• ============ SESSION SAMPLING STARTED ============
ğŸ• [SessionSampling] Starting session sampling at 2025-08-12T02:31:53.687Z
ğŸ” [SessionDiscovery] Starting window 1/4: Initial 3-hour window
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-01T16:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-01T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-01T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-01T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:31:54 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:31:56 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
[fetchContainmentTypeMetadata] API Response: 123 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '688ce441f9118ccf9c084272',
  '688ce41284ec0f257aa408d2',
  '688ce40ae196ca760909852f'
]
[fetchContainmentTypeMetadata] API Response: 84 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '688ce3f084ec0f257aa40505',
  '688ce2f3270e0dfdc8bda516',
  '688ce1cb509249f46abf712e'
]
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:31:58 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
[fetchContainmentTypeMetadata] API Response: 1112 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '688ce47e3a3160d25d831f04',
  '688ce4786dc148aa9fbead83',
  '688ce465712518226a45c1f5'
]
[getSessionsMetadata] agent API call succeeded with 1112 sessions
[getSessionsMetadata] selfService API call succeeded with 84 sessions
[getSessionsMetadata] dropOff API call succeeded with 123 sessions
Total session metadata retrieved: 1319 (parallel execution)
Creating 1319 SWTs from metadata (no messages)
Created 1319 SWT objects from metadata
âœ… [SessionDiscovery] Window 1 completed in 5184ms: found 1319 new sessions (total: 1319)
â±ï¸  TIMING: Window 1 took 5184ms (5.18s)
ğŸ¯ [SessionDiscovery] Target reached! Found 1319 sessions in 5185ms
ğŸ² [SessionSampling] Random sampling from 1319 sessions to 10 sessions

ğŸ“¬ ============ MESSAGE RETRIEVAL STARTED ============
ğŸ“¬ [MessageRetrieval] Starting message retrieval for 10 sampled sessions at 2025-08-12T02:31:58.872Z
Using new lazy loading approach to populate messages for 10 sampled sessions
Populating messages for 10 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 10 sessions from 2025-08-01T13:18:33.754Z to 2025-08-01T16:01:41.818Z at 2025-08-12T02:31:58.872Z
ğŸ”„ [KoreAPI] Using single API call for 10 sessions (â‰¤20)
âœ… [KoreAPI] Single call completed in 277ms: 151 messages
Retrieved 151 messages for 10 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
Populated messages for 10 SWT objects
Successfully populated messages for 10 sessions using lazy loading
Applying final filtering to 10 sessions with populated messages
Final result: 10 sessions passed filtering with populated messages

ğŸ‰ ============ SESSION SAMPLING COMPLETED ============
â±ï¸  TOTAL TIME: 5466ms (5.47s)
â±ï¸  Session Discovery: 5185ms (5.18s) - 94.9% of total
â±ï¸  Message Retrieval: 281ms (0.28s) - 5.1% of total
â±ï¸  Performance: 1.8 sessions/second
ğŸ¯ Final result: 10 sessions with messages retrieved
====================================================

[StrategicDiscoveryService] Starting discovery phase with 10 total sessions
[StrategicDiscoveryService] Discovery config: {
  targetPercentage: 50,
  minSessions: 3,
  maxSessions: 7,
  diversityStrategy: {
    sessionLengths: [ 'short', 'medium', 'long' ],
    containmentTypes: [ 'agent', 'selfService', 'dropOff' ],
    timeDistribution: 'spread'
  }
}
[StrategicDiscoveryService] Selecting 5 diverse sessions from 10 total
[StrategicDiscoveryService] Session diversity groups: { short: 1, medium: 9, early: 3, middle: 3, late: 4 }
[StrategicDiscoveryService] Selected sessions by length distribution: { short: 1, medium: 4, long: 0 }
[StrategicDiscoveryService] Selected 5 sessions for discovery

ğŸ“¦ ===== BATCH 1 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T02:31:59.154Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 0
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T02:31:59.154Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T02:31:59.155Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7427,
  existingClassifications: { intents: 0, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.



For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and another intent, classify the intent as the other i...
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:32:00 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T02:32:01.082Z',
  duration: '1926ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2127,
    completion_tokens: 225,
    total_tokens: 2352,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-0f1e26f0-dfa2-5e0f-8535-cda9872be4ae",
      "notes": "User was silent and did not respond, leading to transfer to an agent."
    },
    {
      "user_id": "u-66597e6c-35bf-5edb-bdfe-25a1c1088d9d",
      "notes": "User requested agent, session transferred to live agent."
    },
    {
      "user_id": "u-065683b2-2bfa-57eb-a8bd-b5224eeda429",
      "notes": "User requested to speak to an agent, session transferred."
    },
    {
      "user_id": "u-fccaaeba-dd8f-562f-b0e4-fa457dafa557",
      "notes": "User wanted to change leave date but was transferred to an agent after multiple prompts."
    },
    {
      "user_id": "u-104d7e8c-32eb-5601-af9e-e215804f831a",
      "notes": "User reported call out, but was transferred to an agent after verification."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2127,
  completionTokens: 225,
  totalTokens: 2352,
  cost: '$0.000303',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 1928ms (1.93s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2352 ($0.0003)
âš¡ Performance: 1219.9 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 1ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 1929ms (1.93s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2352

âœ… ===== BATCH 1 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 1929ms (1.93s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2352 ($0.0003)
âš¡ Performance: 2.6 sessions/sec
âš¡ Avg Time Per Session: 385.80ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 1 complete: 1 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 1, reasons: 0, locations: 0, total: 1 }
[StrategicDiscoveryService] Discovery phase complete: {
  totalProcessed: 5,
  uniqueIntents: 1,
  uniqueReasons: 0,
  uniqueLocations: 0,
  discoveryRate: 0.06666666666666667
}

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T02:32:01.083Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms
[ParallelAutoAnalyzeService] Using parallel config: {
  streamCount: 2,
  sessionsPerStream: 3,
  maxSessionsPerLLMCall: 50,
  syncFrequency: 'after_each_round',
  retryAttempts: 3,
  debugLogging: false
}

ğŸš€ ============ PARALLEL PROCESSING STARTED ============
â±ï¸  Start Time: 2025-08-12T02:32:01.104Z
ğŸ“Š Total Sessions: 5

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T02:32:01.104Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms

âš™ï¸  ============ PARALLEL CONFIGURATION ============
â±ï¸  Config Time: 0ms
ğŸ”§ Stream Count: 2
ğŸ“¦ Sessions Per Stream: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per API Call: 50
ğŸ¯ Debug Logging: false

ğŸ”„ ============ ROUND 1/1 STARTED ============
â±ï¸  Round 1 Start: 2025-08-12T02:32:01.104Z
ğŸ“Š Sessions Remaining: 5
[ParallelProcessingOrchestrator] Distributed 5 sessions across 2 streams: [ 'Stream 1: 3 sessions', 'Stream 2: 2 sessions' ]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 2

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 2 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T02:32:01.105Z
ğŸ“Š Sessions Assigned: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T02:32:01.105Z
ğŸ“Š Sessions to Estimate: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 3
   â€¢ Session Tokens: 779
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6279
   â€¢ Avg Per Session: 260 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6279
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 3

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6279
ğŸ“¦ Recommended Batch Size: 3
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T02:32:01.106Z
ğŸ“Š Sessions to Analyze: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 1
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T02:32:01.106Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 3,
  apiKey: 'sk-proj-...',
  promptLength: 6290,
  existingClassifications: { intents: 1, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Unknown

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and a...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T02:32:01.106Z
ğŸ“Š Sessions Assigned: 2
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T02:32:01.106Z
ğŸ“Š Sessions to Estimate: 2
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 2
   â€¢ Session Tokens: 427
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 5927
   â€¢ Avg Per Session: 214 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 5927
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0009
ğŸ“Š Recommended Batch Size: 2

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 5927
ğŸ“¦ Recommended Batch Size: 2
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0009

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T02:32:01.106Z
ğŸ“Š Sessions to Analyze: 2
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 1
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T02:32:01.106Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 2,
  apiKey: 'sk-proj-...',
  promptLength: 4950,
  existingClassifications: { intents: 1, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Unknown

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and a...
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:32:02 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T02:32:04.593Z',
  duration: '3487ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1468,
    completion_tokens: 158,
    total_tokens: 1626,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 2,
  intentsFound: [ 'Unknown' ],
  transferCount: 2,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-2cec2734-9d6d-5603-8f8c-c11cb2569787",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent regarding maternity or parental matters, leading to a transfer."
    },
    {
      "user_id": "u-6792e7ba-f90f-5a73-97f2-58de597f53da",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to report return to work, but the session was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1468,
  completionTokens: 158,
  totalTokens: 1626,
  cost: '$0.000210',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 3487ms (3.49s)
ğŸ“Š Sessions Returned: 2
ğŸ’° Tokens Used: 1626 ($0.0002)
âš¡ Performance: 466.3 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1468
   â€¢ Completion Tokens: 158
[SessionValidationService] Validating batch response: 2 input sessions, 2 response sessions
[SessionValidationService] Validation successful: all 2 sessions processed
[SessionValidationService] Validating batch response: 2 input sessions, 2 response sessions
[SessionValidationService] Validation successful: all 2 sessions processed
â±ï¸  Stream 2 Single Batch Time: 3488ms (3.49s)
[StreamProcessingService] Discovered 2 new classifications: { intents: 0, reasons: 1, locations: 1 }

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 3488ms (3.49s)
ğŸ“Š Sessions Processed: 2/2
ğŸ’° Tokens Used: 1626 ($0.0002)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1744.00ms
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:32:04 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T02:32:05.555Z',
  duration: '4449ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1783,
    completion_tokens: 243,
    total_tokens: 2026,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 3,
  intentsFound: [ 'FMLA' ],
  transferCount: 3,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-3411ae38-d015-5203-80e3-41e41295c642",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User inquired about FMLA leave and was transferred to an agent when requesting to begin a claim."
    },
    {
      "user_id": "u-05732085-d5b8-58b8-8601-5cc7e3ae3be3",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to activate FNLA and was transferred to an agent when asking to add via SMLS."
    },
    {
      "user_id": "u-098d98f8-d6ef-5927-9571-17eae6c1a8be",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent, and was transferred after indicating so."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1783,
  completionTokens: 243,
  totalTokens: 2026,
  cost: '$0.000276',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 4449ms (4.45s)
ğŸ“Š Sessions Returned: 3
ğŸ’° Tokens Used: 2026 ($0.0003)
âš¡ Performance: 455.4 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1783
   â€¢ Completion Tokens: 243
[SessionValidationService] Validating batch response: 3 input sessions, 3 response sessions
[SessionValidationService] Validation successful: all 3 sessions processed
[SessionValidationService] Validating batch response: 3 input sessions, 3 response sessions
[SessionValidationService] Validation successful: all 3 sessions processed
â±ï¸  Stream 1 Single Batch Time: 4450ms (4.45s)
[StreamProcessingService] Discovered 3 new classifications: { intents: 1, reasons: 1, locations: 1 }

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 4450ms (4.45s)
ğŸ“Š Sessions Processed: 3/3
ğŸ’° Tokens Used: 2026 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.7 sessions/sec
âš¡ Avg Time Per Session: 1483.33ms
[ParallelProcessingOrchestrator] Parallel processing complete: 2/2 streams succeeded
â±ï¸  Parallel Processing Time: 4451ms (4.45s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 2 streams
[ParallelProcessingOrchestrator] Synchronization complete: 3 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 1ms
ğŸ†• New Classifications: 3
ğŸ“Š Total Classifications: 4

âœ… ============ ROUND 1 COMPLETED ============
â±ï¸  Round 1 Total Time: 4452ms (4.45s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 0
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 4451ms (100.0%)
   â€¢ Synchronization: 1ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ‰ ============ PARALLEL PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 4452ms (4.45s)
ğŸ“Š Sessions Processed: 5/5
ğŸ”„ Total Rounds: 1
ğŸŒŠ Stream Results: 2
ğŸ’° Token Usage: 3652 tokens ($0.0005)
ğŸ“ˆ Stream Utilization: 100.0%
ğŸ¯ Performance: 1.1 sessions/second
âš¡ Avg Time Per Session: 890.40ms

ğŸ“Š Stream Performance Breakdown:
   Stream 1: 3 sessions in 4450ms (455.3 tokens/sec)
   Stream 2: 2 sessions in 3488ms (466.2 tokens/sec)
[ConflictResolutionService] Starting conflict resolution for 10 sessions
[ConflictResolutionService] Found classifications: { intents: 2, reasons: 1, locations: 1 }
[ConflictResolutionService] No conflicts detected, skipping resolution
[ParallelAutoAnalyzeService] Using real analysis summary service
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:32:06 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:32:08 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:32:10 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:32:12 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:32:14 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:32:16 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:32:18 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
[ParallelAutoAnalyzeService] Parallel analysis c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 completed successfully
[BackgroundJobQueue] Updated job progress to final state: complete
[BackgroundJobQueue] Parallel analysis job c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73-parallel completed successfully
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:32:20 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:32:22 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:32:24 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:32:26 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:32:28 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:32:30 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:32:32 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:32:34 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:32:36 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:32:38 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:32:40 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:32:42 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:32:44 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:32:46 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:32:48 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:32:50 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:32:52 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:32:54 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:02:32:56 +0000] "GET /api/analysis/auto-analyze/progress/c9d0f6e9-8d8a-4bcb-8b94-bcb09aa4ef73 HTTP/1.1" 404 46 "-" "axios/1.11.0"
[BackgroundJobQueue] Cleaned up 1 expired jobs
[BackgroundJobQueue] Cleaned up 1 expired jobs
ğŸš€ [AutoAnalyzeRoute] Starting analysis for bot ***REMOVED*** with real credentials
ğŸš€ [AutoAnalyzeService] Starting analysis 72826c46-431d-4e49-b9f6-01844eb5383f with bot ***REMOVED***
ğŸš€ [AutoAnalyzeService] Using credentials: real
ğŸš€ [AutoAnalyzeRoute] Analysis started: 72826c46-431d-4e49-b9f6-01844eb5383f
::1 - - [12/Aug/2025:14:56:13 +0000] "POST /api/analysis/auto-analyze/start HTTP/1.1" 200 205 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:13 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 478 "-" "axios/1.11.0"
[BackgroundJobQueue] Starting job processing after delay for job 72826c46-431d-4e49-b9f6-01844eb5383f-sampling
[BackgroundJobQueue] Starting processing for job 72826c46-431d-4e49-b9f6-01844eb5383f-sampling, phase: sampling
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing sampling phase for job 72826c46-431d-4e49-b9f6-01844eb5383f-sampling
[BackgroundJobQueue] Processing sampling phase for bot: ***REMOVED***
[BackgroundJobQueue] Creating real service for bot: ***REMOVED***
[BackgroundJobQueue] Full config: {
  "botId": "***REMOVED***",
  "clientId": "***REMOVED***",
  "clientSecret": "***REMOVED***",
  "baseUrl": "https://bots.kore.ai"
}
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=real
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[BackgroundJobQueue] Created service type: RealKoreApiService

ğŸ• ============ SESSION SAMPLING STARTED ============
ğŸ• [SessionSampling] Starting session sampling at 2025-08-12T14:56:14.378Z
ğŸ” [SessionDiscovery] Starting window 1/4: Initial 3-hour window
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-01T16:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-01T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-01T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-01T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
::1 - - [12/Aug/2025:14:56:14 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 533 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:15 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 533 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:16 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 533 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:17 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 533 "-" "axios/1.11.0"
[fetchContainmentTypeMetadata] API Response: 84 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '688ce3f084ec0f257aa40505',
  '688ce2f3270e0dfdc8bda516',
  '688ce1cb509249f46abf712e'
]
[fetchContainmentTypeMetadata] API Response: 123 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '688ce441f9118ccf9c084272',
  '688ce41284ec0f257aa408d2',
  '688ce40ae196ca760909852f'
]
::1 - - [12/Aug/2025:14:56:18 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 533 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:19 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 533 "-" "axios/1.11.0"
[fetchContainmentTypeMetadata] API Response: 1112 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '688ce47e3a3160d25d831f04',
  '688ce4786dc148aa9fbead83',
  '688ce465712518226a45c1f5'
]
[getSessionsMetadata] agent API call succeeded with 1112 sessions
[getSessionsMetadata] selfService API call succeeded with 84 sessions
[getSessionsMetadata] dropOff API call succeeded with 123 sessions
Total session metadata retrieved: 1319 (parallel execution)
Creating 1319 SWTs from metadata (no messages)
Created 1319 SWT objects from metadata
âœ… [SessionDiscovery] Window 1 completed in 5454ms: found 1319 new sessions (total: 1319)
â±ï¸  TIMING: Window 1 took 5454ms (5.45s)
ğŸ¯ [SessionDiscovery] Target reached! Found 1319 sessions in 5454ms
ğŸ² [SessionSampling] Random sampling from 1319 sessions to 100 sessions

ğŸ“¬ ============ MESSAGE RETRIEVAL STARTED ============
ğŸ“¬ [MessageRetrieval] Starting message retrieval for 100 sampled sessions at 2025-08-12T14:56:19.833Z
Using new lazy loading approach to populate messages for 100 sampled sessions
Populating messages for 100 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 100 sessions from 2025-08-01T13:00:49.151Z to 2025-08-01T16:01:41.818Z at 2025-08-12T14:56:19.833Z
ğŸš€ [ConcurrentBatch] Split 100 sessions into 5 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/5] Starting: 20 sessions
[Batch 2/5] Starting: 20 sessions
[Batch 3/5] Starting: 20 sessions
[Batch 4/5] Starting: 20 sessions
[Batch 5/5] Starting: 20 sessions
[Batch 2/5] Completed in 410ms: 229 messages retrieved (1/5 done)
ğŸ“Š [BatchProgress] Reporting batch 1/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 40/100 sessions (Batch 2/5)
[Batch 1/5] Completed in 417ms: 256 messages retrieved (2/5 done)
ğŸ“Š [BatchProgress] Reporting batch 2/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 60/100 sessions (Batch 3/5)
[Batch 3/5] Completed in 484ms: 258 messages retrieved (3/5 done)
ğŸ“Š [BatchProgress] Reporting batch 3/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 80/100 sessions (Batch 4/5)
::1 - - [12/Aug/2025:14:56:20 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 650 "-" "axios/1.11.0"
[Batch 5/5] Completed in 727ms: 296 messages retrieved (4/5 done)
ğŸ“Š [BatchProgress] Reporting batch 4/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 100/100 sessions (Batch 5/5)
[Batch 4/5] Completed in 769ms: 282 messages retrieved (5/5 done)
ğŸ“Š [BatchProgress] Reporting batch 5/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 100/100 sessions (Batch 6/5)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 771ms (0.77s)
â±ï¸  Batch Processing: 770ms (0.77s)
ğŸ“¦ Total batches: 5 (max 10 concurrent)
âœ… Successful batches: 5/5
ğŸ’¬ Total messages: 1321
ğŸ“ˆ Avg time per batch: 154ms
ğŸš€ Time per session: 8ms
ğŸ’ª Performance: 129.7 sessions/second
=======================================================

Retrieved 1321 messages for 100 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
Populated messages for 100 SWT objects
Successfully populated messages for 100 sessions using lazy loading
Applying final filtering to 100 sessions with populated messages
Final result: 98 sessions passed filtering with populated messages

ğŸ‰ ============ SESSION SAMPLING COMPLETED ============
â±ï¸  TOTAL TIME: 6234ms (6.23s)
â±ï¸  Session Discovery: 5454ms (5.45s) - 87.5% of total
â±ï¸  Message Retrieval: 779ms (0.78s) - 12.5% of total
â±ï¸  Performance: 15.7 sessions/second
ğŸ¯ Final result: 98 sessions with messages retrieved
====================================================

[BackgroundJobQueue] Found 98 sessions for job 72826c46-431d-4e49-b9f6-01844eb5383f-sampling
::1 - - [12/Aug/2025:14:56:21 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 630 "-" "axios/1.11.0"
[BackgroundJobQueue] Starting job processing after delay for job 72826c46-431d-4e49-b9f6-01844eb5383f-sampling-analysis
[BackgroundJobQueue] Starting processing for job 72826c46-431d-4e49-b9f6-01844eb5383f-sampling-analysis, phase: analyzing
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing analysis phase for job 72826c46-431d-4e49-b9f6-01844eb5383f-sampling-analysis with 98 sessions
ğŸ­ ServiceFactory: Creating OpenAI service (type: real)

ğŸ“¦ ===== BATCH 1 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T14:56:21.615Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Existing Classifications:
   â€¢ Intents: 0
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 1ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T14:56:21.616Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T14:56:21.616Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6242,
  existingClassifications: { intents: 0, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.



For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and another intent, classify the intent as the other i...
::1 - - [12/Aug/2025:14:56:22 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 623 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:23 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 623 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:24 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 623 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:25 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 623 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:26 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 623 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:27 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 623 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:28 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 623 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:29 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 623 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:30 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 623 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T14:56:30.900Z',
  duration: '9283ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1817,
    completion_tokens: 355,
    total_tokens: 2172,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Claim Status', 'Live Agent', 'Unknown', 'Leave Request' ],
  transferCount: 4,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-7aa650c2-dacb-529d-a301-66679494326c",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User needed to reopen an existing claim and was transferred to an agent."
    },
    {
      "user_id": "u-a49bf77a-fea7-5e81-bfd6-8be0d1a54fd0",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User repeatedly requested to speak to a receptionist and was transferred to an agent."
    },
    {
      "user_id": "u-fcc429b8-e608-5375-9290-3b5a5c61bbad",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User did not provide any input after the initial greeting."
    },
    {
      "user_id": "u-b9df841b-f247-5c85-9739-cfc2cd7dd43a",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to start a new leave and was transferred to an agent."
    },
    {
      "user_id": "u-ae20f95d-6878-5287-80b5-f033ed8c36a7",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a representative and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1817,
  completionTokens: 355,
  totalTokens: 2172,
  cost: '$0.000486',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 9284ms (9.28s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2172 ($0.0005)
âš¡ Performance: 234.0 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 9284ms (9.28s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2172

âœ… ===== BATCH 1 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 9285ms (9.29s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2172 ($0.0005)
âš¡ Performance: 0.5 sessions/sec
âš¡ Avg Time Per Session: 1857.00ms
â±ï¸  Metadata Processing: 1ms
::1 - - [12/Aug/2025:14:56:31 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 647 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:32 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 647 "-" "axios/1.11.0"

ğŸ“¦ ===== BATCH 2 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T14:56:32.904Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Existing Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 1ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T14:56:32.906Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T14:56:32.907Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 8349,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billi...
::1 - - [12/Aug/2025:14:56:33 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 647 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:34 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 647 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:35 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 647 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:36 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 647 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:37 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 647 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:38 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 647 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:39 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 647 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:40 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 647 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:41 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 647 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:42 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 647 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T14:56:42.838Z',
  duration: '9931ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 2354,
    completion_tokens: 345,
    total_tokens: 2699,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Live Agent', 'Leave Request' ],
  transferCount: 3,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-fe504076-d831-5a5a-a9a5-45dcf8dfe2da",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative and was transferred."
    },
    {
      "user_id": "u-97bfa65d-8080-5633-9252-13a25c4243f1",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-e0e91d61-c794-544d-9096-de0f144b845e",
      "general_intent": "Leave Request",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User successfully submitted a leave request without needing a live agent."
    },
    {
      "user_id": "u-c789290a-b66f-5fb0-941f-ced49cebeff8",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-5526d3d2-3b5f-5e52-9c2b-88a64afc20b9",
      "general_intent": "Leave Request",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User successfully submitted a time entry without needing a live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2354,
  completionTokens: 345,
  totalTokens: 2699,
  cost: '$0.000560',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 9932ms (9.93s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2699 ($0.0006)
âš¡ Performance: 271.7 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 1ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 9933ms (9.93s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2699

âœ… ===== BATCH 2 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 9935ms (9.94s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2699 ($0.0006)
âš¡ Performance: 0.5 sessions/sec
âš¡ Avg Time Per Session: 1987.00ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:14:56:43 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:44 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"

ğŸ“¦ ===== BATCH 3 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T14:56:44.841Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Existing Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T14:56:44.841Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T14:56:44.842Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6979,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billi...
::1 - - [12/Aug/2025:14:56:45 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:46 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:47 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:48 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:49 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:50 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:51 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:52 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:53 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:54 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:55 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:56 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T14:56:57.646Z',
  duration: '12804ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1980,
    completion_tokens: 380,
    total_tokens: 2360,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Leave Request', 'Live Agent' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-1925910e-6776-555e-b242-59ab203d47c3",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to set up parental leave but did not have a leave request number."
    },
    {
      "user_id": "u-0a5237c3-99cc-5dff-a7f4-b2ab7861fc8d",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to report a return to work but was unable to due to leave request status."
    },
    {
      "user_id": "u-7e1e3377-532c-5ee9-aded-4081c8d3e280",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User tried to report a return to work but did not provide a zip code."
    },
    {
      "user_id": "u-20e35ef0-7405-5c80-a2d7-00a10f226031",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative and pressed star."
    },
    {
      "user_id": "u-30c2ac22-17af-5f0b-bb88-4f418be57a9f",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User expressed a desire to contact customer service and pressed star."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1980,
  completionTokens: 380,
  totalTokens: 2360,
  cost: '$0.000525',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 12806ms (12.81s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2360 ($0.0005)
âš¡ Performance: 184.3 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 12806ms (12.81s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2360

âœ… ===== BATCH 3 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 12807ms (12.81s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2360 ($0.0005)
âš¡ Performance: 0.4 sessions/sec
âš¡ Avg Time Per Session: 2561.40ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:14:56:57 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:56:58 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"

ğŸ“¦ ===== BATCH 4 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T14:56:59.649Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Existing Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T14:56:59.649Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T14:56:59.650Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7099,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billi...
::1 - - [12/Aug/2025:14:56:59 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:00 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:01 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:02 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:03 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:04 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:05 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:06 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:07 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:08 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T14:57:08.733Z',
  duration: '9083ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 2002,
    completion_tokens: 347,
    total_tokens: 2349,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Live Agent', 'Claim Status', 'Unknown' ],
  transferCount: 4,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-0737c84c-e7a0-50bc-8309-7f1ce7e034ce",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-ed14dd5f-9e4b-57af-9328-42914333690e",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked for an agent and was transferred."
    },
    {
      "user_id": "u-f3e5dec6-3452-509a-b8b1-db7471b61976",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User checked on claim extension status and requested a representative."
    },
    {
      "user_id": "u-38a74c62-4844-57ab-b158-f1c69f7360f2",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User requested a letter but the bot could not understand the request."
    },
    {
      "user_id": "u-a5679862-10fa-56b0-948e-6edb724d1b1e",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2002,
  completionTokens: 347,
  totalTokens: 2349,
  cost: '$0.000508',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 9084ms (9.08s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2349 ($0.0005)
âš¡ Performance: 258.6 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 9084ms (9.08s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2349

âœ… ===== BATCH 4 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 9085ms (9.09s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2349 ($0.0005)
âš¡ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1817.00ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:14:57:09 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:10 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"

ğŸ“¦ ===== BATCH 5 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T14:57:10.733Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Existing Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T14:57:10.734Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T14:57:10.734Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7512,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billi...
::1 - - [12/Aug/2025:14:57:11 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:12 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:13 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:14 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:15 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:16 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:17 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:18 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:19 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T14:57:19.973Z',
  duration: '9239ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 2103,
    completion_tokens: 382,
    total_tokens: 2485,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Leave Request', 'Claim Status', 'Live Agent' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-bc569b9b-2d8d-5d14-a374-0f9da8c2cbbd",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to open a new leave request and was transferred to an agent."
    },
    {
      "user_id": "u-74f8fab5-ffc0-5659-b30c-f8517b58efa4",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to put in a new claim for an employee and was transferred to an agent."
    },
    {
      "user_id": "u-4c6f597d-4979-52e0-b8d8-775f53e48b5e",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-02f70a1b-15b8-59e1-8727-b0ed1e991bb7",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User expressed a desire to speak with a representative and was transferred."
    },
    {
      "user_id": "u-3411ae38-d015-5203-80e3-41e41295c642",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to begin a FMLA claim and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2103,
  completionTokens: 382,
  totalTokens: 2485,
  cost: '$0.000545',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 9240ms (9.24s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2485 ($0.0005)
âš¡ Performance: 268.9 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 9240ms (9.24s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2485

âœ… ===== BATCH 5 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 9241ms (9.24s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2485 ($0.0005)
âš¡ Performance: 0.5 sessions/sec
âš¡ Avg Time Per Session: 1848.20ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:14:57:20 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:21 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"

ğŸ“¦ ===== BATCH 6 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T14:57:21.976Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Existing Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T14:57:21.977Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T14:57:21.977Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7894,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billi...
::1 - - [12/Aug/2025:14:57:22 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:23 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:24 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:25 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:26 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:27 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:28 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:29 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T14:57:29.988Z',
  duration: '8010ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 2212,
    completion_tokens: 366,
    total_tokens: 2578,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Leave Request', 'Unknown', 'Live Agent' ],
  transferCount: 4,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-ed2a6900-cc11-5ba3-a57d-2d597c235e8d",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to open a new leave request but was transferred to an agent."
    },
    {
      "user_id": "u-a46b8356-a373-55cc-bdb5-af718f8803b7",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked for FMLA questions and requested a representative, leading to a transfer."
    },
    {
      "user_id": "u-3097557d-0127-5116-8b3d-a42c9eba13f7",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User successfully submitted a time entry without needing a transfer."
    },
    {
      "user_id": "u-83b9f524-58e6-5a08-96dd-2e7e8a17bc24",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative, resulting in a transfer."
    },
    {
      "user_id": "u-9cd42df6-3c96-5b25-97c1-2520f30c7286",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to change leave request dates and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2212,
  completionTokens: 366,
  totalTokens: 2578,
  cost: '$0.000551',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 8011ms (8.01s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2578 ($0.0006)
âš¡ Performance: 321.8 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 8012ms (8.01s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2578

âœ… ===== BATCH 6 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 8012ms (8.01s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2578 ($0.0006)
âš¡ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1602.40ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:14:57:30 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:31 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"

ğŸ“¦ ===== BATCH 7 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T14:57:31.988Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Existing Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 1ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T14:57:31.989Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T14:57:31.989Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6869,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billi...
::1 - - [12/Aug/2025:14:57:32 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:33 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:34 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:35 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:36 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:37 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:38 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T14:57:39.263Z',
  duration: '7274ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1940,
    completion_tokens: 353,
    total_tokens: 2293,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Leave Request', 'Unknown', 'Claim Status' ],
  transferCount: 4,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-5c8cb922-0995-53d7-8764-f2d952f2a9ac",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested customer service for a disability claim."
    },
    {
      "user_id": "u-839dda27-65d0-5659-93f0-1f267e9e3460",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent."
    },
    {
      "user_id": "u-abd392ea-0980-5186-a26d-c82759d0940f",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with a representative but did not have a leave request number."
    },
    {
      "user_id": "u-05b8af23-b3e6-5d4f-808a-a74fa15876a4",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to update a claim and was transferred to an agent."
    },
    {
      "user_id": "u-23d7df28-d811-5299-b8d2-092d0ed08dea",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User inquired about claim status and was prompted for a leave request number."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1940,
  completionTokens: 353,
  totalTokens: 2293,
  cost: '$0.000503',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 7275ms (7.28s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2293 ($0.0005)
âš¡ Performance: 315.2 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 7275ms (7.28s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2293

âœ… ===== BATCH 7 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 7276ms (7.28s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2293 ($0.0005)
âš¡ Performance: 0.7 sessions/sec
âš¡ Avg Time Per Session: 1455.20ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:14:57:39 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 635 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:40 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 635 "-" "axios/1.11.0"

ğŸ“¦ ===== BATCH 8 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T14:57:41.266Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Existing Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T14:57:41.266Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T14:57:41.266Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6525,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billi...
::1 - - [12/Aug/2025:14:57:41 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 635 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:42 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 635 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:43 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 635 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:44 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 635 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:45 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 635 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:46 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 635 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:47 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 635 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:48 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 635 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:49 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 635 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T14:57:50.113Z',
  duration: '8847ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1862,
    completion_tokens: 346,
    total_tokens: 2208,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Leave Request', 'Live Agent', 'Unknown' ],
  transferCount: 3,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-5cf96661-1c29-5b34-9cee-897d8278025c",
      "general_intent": "Leave Request",
      "session_outcome": "Contained",
      "notes": "User inquired about notifying the bot regarding an upcoming surgery but did not provide a leave request number."
    },
    {
      "user_id": "u-19506dc4-0d0e-55ae-bce0-60c4d556cedb",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred."
    },
    {
      "user_id": "u-a8b6d715-6490-576b-8e02-5dab2d7824bd",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User mentioned 'Claim Specialist' and was transferred to an agent."
    },
    {
      "user_id": "u-0a3dcb44-4756-5c2a-adef-04d789ebe37d",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User provided an unclear response and the bot closed the conversation."
    },
    {
      "user_id": "u-83367ef1-1451-5b71-be93-0eb6bb9ad8e8",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to extend leave but was transferred to an agent after repeated unclear responses."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1862,
  completionTokens: 346,
  totalTokens: 2208,
  cost: '$0.000487',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 8849ms (8.85s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2208 ($0.0005)
âš¡ Performance: 249.5 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 8849ms (8.85s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2208

âœ… ===== BATCH 8 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 8850ms (8.85s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2208 ($0.0005)
âš¡ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1770.00ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:14:57:51 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:52 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"

ğŸ“¦ ===== BATCH 9 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T14:57:52.117Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Existing Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T14:57:52.118Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T14:57:52.119Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7015,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billi...
::1 - - [12/Aug/2025:14:57:53 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:54 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:55 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:56 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:57 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:58 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:57:59 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:00 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 636 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T14:58:00.188Z',
  duration: '8069ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1997,
    completion_tokens: 352,
    total_tokens: 2349,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Leave Request', 'Live Agent', 'Claim Status' ],
  transferCount: 4,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-dfa2e6ed-fce1-56bc-97a7-27fa77cec412",
      "general_intent": "Leave Request",
      "session_outcome": "Contained",
      "notes": "User attempted to track times but did not provide the required input."
    },
    {
      "user_id": "u-5f52551c-a94e-51f1-8e60-ea2cf0160bf4",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and then attempted to explain but was unclear, leading to a transfer."
    },
    {
      "user_id": "u-56ee72ef-8e4c-515d-94e8-873157d58a71",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested customer service and was transferred to an agent."
    },
    {
      "user_id": "u-39428f13-144d-5c62-9346-e54d623ca235",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested customer service and was transferred to an agent."
    },
    {
      "user_id": "u-e1259ebf-8b67-5312-a190-e66ecec69b48",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User inquired about short term disability information but was unclear, leading to a transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1997,
  completionTokens: 352,
  totalTokens: 2349,
  cost: '$0.000511',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 8071ms (8.07s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2349 ($0.0005)
âš¡ Performance: 291.0 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 8071ms (8.07s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2349

âœ… ===== BATCH 9 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 8072ms (8.07s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2349 ($0.0005)
âš¡ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1614.40ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:14:58:01 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 637 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:02 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 637 "-" "axios/1.11.0"

ğŸ“¦ ===== BATCH 10 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T14:58:02.192Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Existing Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T14:58:02.194Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T14:58:02.194Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6713,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billi...
::1 - - [12/Aug/2025:14:58:03 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:04 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:05 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:06 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:07 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:08 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:09 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:10 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:11 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:12 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:13 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:14 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:15 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T14:58:15.430Z',
  duration: '13235ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1901,
    completion_tokens: 364,
    total_tokens: 2265,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Live Agent', 'Leave Request', 'Unknown' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-198a10bc-3467-515f-86af-b5c8253f0daa",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a customer representative and was transferred."
    },
    {
      "user_id": "u-93424bff-d9b9-5a3f-a563-bdc649c184db",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to change the starting date for FMLA and was transferred after asking for a representative."
    },
    {
      "user_id": "u-9ab4f073-c034-5c6d-93b7-3079ebbe1ddd",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred."
    },
    {
      "user_id": "u-a6484d20-cd08-5551-8625-a9f7cafd3bf2",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent in Spanish and was transferred."
    },
    {
      "user_id": "u-9799a71c-d99c-5727-90bc-af1a99430599",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and the bot transferred them to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1901,
  completionTokens: 364,
  totalTokens: 2265,
  cost: '$0.000504',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 13236ms (13.24s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2265 ($0.0005)
âš¡ Performance: 171.1 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 13237ms (13.24s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2265

âœ… ===== BATCH 10 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 13240ms (13.24s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2265 ($0.0005)
âš¡ Performance: 0.4 sessions/sec
âš¡ Avg Time Per Session: 2648.00ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:14:58:16 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 637 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:17 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 637 "-" "axios/1.11.0"

ğŸ“¦ ===== BATCH 11 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T14:58:17.433Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Existing Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T14:58:17.433Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T14:58:17.433Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7267,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billi...
::1 - - [12/Aug/2025:14:58:18 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:19 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:20 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:21 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:22 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:23 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:24 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:25 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T14:58:25.369Z',
  duration: '7935ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 2079,
    completion_tokens: 355,
    total_tokens: 2434,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Leave Request', 'Claim Status', 'Live Agent' ],
  transferCount: 4,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-5c9380fe-4d5f-56fa-826c-43e6b6318eb4",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a form and was transferred to an agent."
    },
    {
      "user_id": "u-73646ed4-a894-56d2-a255-6c9cf6514908",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested FMLA assistance and was transferred to an agent."
    },
    {
      "user_id": "u-d2380712-9b8a-5019-bcf3-1113cc839de2",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User successfully submitted a time entry without needing a transfer."
    },
    {
      "user_id": "u-24fb865c-8857-553f-962e-2120c18dca3f",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an operator and was transferred to an agent."
    },
    {
      "user_id": "u-b71d23d3-3906-5a83-bcf5-e92d7ba43b66",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to file a claim and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2079,
  completionTokens: 355,
  totalTokens: 2434,
  cost: '$0.000525',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 7936ms (7.94s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2434 ($0.0005)
âš¡ Performance: 306.7 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 1ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 7937ms (7.94s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2434

âœ… ===== BATCH 11 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 7938ms (7.94s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2434 ($0.0005)
âš¡ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1587.60ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:14:58:26 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 650 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:27 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 650 "-" "axios/1.11.0"

ğŸ“¦ ===== BATCH 12 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T14:58:27.372Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Existing Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T14:58:27.373Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T14:58:27.373Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7694,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billi...
::1 - - [12/Aug/2025:14:58:28 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 650 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:29 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 650 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:30 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 650 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:31 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 650 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:32 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 650 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:33 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 650 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:34 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 650 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:35 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 650 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T14:58:36.302Z',
  duration: '8928ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 2160,
    completion_tokens: 334,
    total_tokens: 2494,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Leave Request', 'Live Agent', 'Unknown' ],
  transferCount: 4,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-463e08b2-de81-5187-b098-53e276c658ad",
      "general_intent": "Leave Request",
      "session_outcome": "Contained",
      "notes": "User successfully submitted a leave request for absence."
    },
    {
      "user_id": "u-14310cc9-b1be-557d-b7e5-bf90be8b8245",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative and was transferred."
    },
    {
      "user_id": "u-0dd5226b-3563-5c8d-99fc-2a59a078ac57",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a representative and was transferred."
    },
    {
      "user_id": "u-09001f38-0ee0-5007-9551-5c362bc7c1a8",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with a representative and was transferred."
    },
    {
      "user_id": "u-4d3bb41d-61fa-562b-8e84-a484403eb025",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User initiated a claim but was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2160,
  completionTokens: 334,
  totalTokens: 2494,
  cost: '$0.000524',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 8929ms (8.93s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2494 ($0.0005)
âš¡ Performance: 279.3 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 1ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 8930ms (8.93s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2494

âœ… ===== BATCH 12 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 8931ms (8.93s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2494 ($0.0005)
âš¡ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1786.20ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:14:58:36 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:37 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"

ğŸ“¦ ===== BATCH 13 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T14:58:38.304Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Existing Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T14:58:38.304Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T14:58:38.304Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 8288,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billi...
::1 - - [12/Aug/2025:14:58:38 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:39 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:40 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:41 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:42 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:43 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:44 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:45 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:46 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T14:58:46.390Z',
  duration: '8086ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 2342,
    completion_tokens: 355,
    total_tokens: 2697,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Claim Status', 'Unknown', 'Maternity Leave' ],
  transferCount: 3,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-82f1a2e3-d40f-57fe-b5a0-c19892bb0501",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent after receiving claim status information."
    },
    {
      "user_id": "u-3f92a32a-a9b9-562a-9aa5-4ccf0eb1f509",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User pressed star to connect with an agent after expressing a desire for customer service."
    },
    {
      "user_id": "u-eb1e3d65-b449-50f0-8a7c-3026d73b4301",
      "general_intent": "Maternity Leave",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User successfully submitted maternity leave details and ended the session."
    },
    {
      "user_id": "u-1eb8a938-7020-556c-bf97-2f8991a43abd",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User received information about their leave request but did not provide further input."
    },
    {
      "user_id": "u-7031792d-7da7-5b90-a434-e72713302be1",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a representative but did not provide further input before transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2342,
  completionTokens: 355,
  totalTokens: 2697,
  cost: '$0.000564',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 8086ms (8.09s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2697 ($0.0006)
âš¡ Performance: 333.5 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 8086ms (8.09s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2697

âœ… ===== BATCH 13 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 8086ms (8.09s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2697 ($0.0006)
âš¡ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1617.20ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:14:58:47 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:48 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"

ğŸ“¦ ===== BATCH 14 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T14:58:48.392Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Existing Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T14:58:48.392Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T14:58:48.393Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 8776,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Maternity Leave, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Clai...
::1 - - [12/Aug/2025:14:58:49 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:50 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:51 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:52 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:53 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:54 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:55 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:56 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T14:58:57.188Z',
  duration: '8795ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 2394,
    completion_tokens: 346,
    total_tokens: 2740,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Leave Request', 'Unknown', 'Live Agent' ],
  transferCount: 4,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-6788ba0f-1eeb-5f14-a1e3-3d2770c3ca75",
      "general_intent": "Leave Request",
      "session_outcome": "Contained",
      "notes": "User successfully submitted multiple time entries for leave."
    },
    {
      "user_id": "u-6bdb87f5-217d-59b2-9df2-f16887e1a9af",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested information on FMLA and was transferred to a representative."
    },
    {
      "user_id": "u-e2b9696e-24be-54fc-b7d7-70977981bde0",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a person and was transferred."
    },
    {
      "user_id": "u-58d96774-e650-5afc-83aa-4376be4dd567",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-39b79275-0c68-58e3-aba4-4103fd96b687",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User initiated a new claim request and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2394,
  completionTokens: 346,
  totalTokens: 2740,
  cost: '$0.000567',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 8796ms (8.80s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2740 ($0.0006)
âš¡ Performance: 311.5 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 8796ms (8.80s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2740

âœ… ===== BATCH 14 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 8796ms (8.80s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2740 ($0.0006)
âš¡ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1759.20ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:14:58:57 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:58:58 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"

ğŸ“¦ ===== BATCH 15 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T14:58:59.190Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Existing Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T14:58:59.190Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T14:58:59.191Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7118,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Maternity Leave, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Clai...
::1 - - [12/Aug/2025:14:58:59 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:00 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:01 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:02 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:03 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:04 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:05 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:06 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:07 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:08 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T14:59:09.213Z',
  duration: '10022ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 2004,
    completion_tokens: 366,
    total_tokens: 2370,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Leave Request', 'Unknown', 'Maternity Leave' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-ed25d73c-b989-5475-a4d9-0d58da24a886",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested job accommodations and was transferred for assistance with a new leave request."
    },
    {
      "user_id": "u-28b52f5e-67b3-597b-8d32-384944924de4",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred."
    },
    {
      "user_id": "u-030c34c2-b949-5172-8876-56ceae186158",
      "general_intent": "Maternity Leave",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was trying to discuss an intermittent leave of absence but was transferred after failing to provide the leave request number."
    },
    {
      "user_id": "u-52880569-0139-5a39-88a7-0594353c95ab",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-3e006f5b-bc45-52e1-adf0-be3f40b3de61",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2004,
  completionTokens: 366,
  totalTokens: 2370,
  cost: '$0.000520',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 10023ms (10.02s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2370 ($0.0005)
âš¡ Performance: 236.5 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 10023ms (10.02s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2370

âœ… ===== BATCH 15 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 10024ms (10.02s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2370 ($0.0005)
âš¡ Performance: 0.5 sessions/sec
âš¡ Avg Time Per Session: 2004.80ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:14:59:09 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:10 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"

ğŸ“¦ ===== BATCH 16 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T14:59:11.218Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Existing Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T14:59:11.218Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T14:59:11.219Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 8649,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Maternity Leave, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Clai...
::1 - - [12/Aug/2025:14:59:11 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:12 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:13 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:14 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:15 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:16 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:17 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:18 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 639 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T14:59:19.383Z',
  duration: '8164ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 2375,
    completion_tokens: 350,
    total_tokens: 2725,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Live Agent', 'Claim Status', 'Leave Request' ],
  transferCount: 4,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-f927ad3c-027f-547c-972c-f79023c0cdcd",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to talk to a customer representative and was transferred."
    },
    {
      "user_id": "u-e9aee0eb-8295-558b-9c46-b00c43e11cdf",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User expressed a desire to speak with an agent and was transferred."
    },
    {
      "user_id": "u-54872510-60e1-5cfd-bdc0-16344a16e4db",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User started with a claim status inquiry but requested customer service and was transferred."
    },
    {
      "user_id": "u-68d061c5-2275-5588-a971-d2db5ef12644",
      "general_intent": "Leave Request",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User successfully submitted a leave request without needing to transfer."
    },
    {
      "user_id": "u-8eddd306-bbdb-5215-a142-b268b5025c4e",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent in Spanish and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2375,
  completionTokens: 350,
  totalTokens: 2725,
  cost: '$0.000566',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 8166ms (8.17s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2725 ($0.0006)
âš¡ Performance: 333.7 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 8166ms (8.17s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2725

âœ… ===== BATCH 16 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 8167ms (8.17s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2725 ($0.0006)
âš¡ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1633.40ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:14:59:19 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:20 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"

ğŸ“¦ ===== BATCH 17 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T14:59:21.386Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Existing Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T14:59:21.387Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T14:59:21.387Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7602,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Maternity Leave, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Clai...
::1 - - [12/Aug/2025:14:59:21 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:22 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:23 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:24 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:25 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:26 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:27 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:28 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:29 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T14:59:29.693Z',
  duration: '8306ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 2144,
    completion_tokens: 357,
    total_tokens: 2501,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Leave Request', 'Live Agent' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-0167d19d-dbaf-590b-a131-7d95c7966789",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to be transferred to a short term disability tax person."
    },
    {
      "user_id": "u-a8dcfbdf-1d45-5234-9958-3634eecf0be4",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with a representative."
    },
    {
      "user_id": "u-803e30a8-545e-5f2a-8df2-cf0e593045d1",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User could not provide the leave request number and was transferred."
    },
    {
      "user_id": "u-37d47b83-9f6b-5849-8849-03acc4f45db2",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent."
    },
    {
      "user_id": "u-2897afc4-93c6-5232-82f5-dc7e01868fec",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User expressed a need for customer service and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2144,
  completionTokens: 357,
  totalTokens: 2501,
  cost: '$0.000536',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 8307ms (8.31s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2501 ($0.0005)
âš¡ Performance: 301.1 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 8307ms (8.31s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2501

âœ… ===== BATCH 17 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 8308ms (8.31s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2501 ($0.0005)
âš¡ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1661.60ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:14:59:30 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 649 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:31 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 649 "-" "axios/1.11.0"

ğŸ“¦ ===== BATCH 18 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T14:59:31.695Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Existing Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T14:59:31.695Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T14:59:31.696Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7594,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Maternity Leave, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Clai...
::1 - - [12/Aug/2025:14:59:32 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 649 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:33 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 649 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:34 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 649 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:35 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 649 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:36 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 649 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:37 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 649 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:38 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 649 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:39 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 649 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T14:59:39.907Z',
  duration: '8211ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 2127,
    completion_tokens: 380,
    total_tokens: 2507,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Leave Request', 'Live Agent', 'Unknown', 'Claim Status' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-8929a6bb-4c1b-5b22-8dfb-08e928828bc2",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was unable to provide necessary information for leave request and was transferred to an agent."
    },
    {
      "user_id": "u-7e736a78-57a2-532a-9114-b4c0aaed50ea",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative after not having a leave request number."
    },
    {
      "user_id": "u-b587ed90-5270-585c-aa09-14adb668c1c8",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User explicitly requested to speak to a live person and was transferred."
    },
    {
      "user_id": "u-8f05f1bb-f822-58d3-9e6d-62c7fddee623",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User did not respond to prompts, leading to a transfer to an agent."
    },
    {
      "user_id": "u-406d15a8-b0ef-5a58-9cd9-8c880f6907af",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative after failing to provide a leave request number."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2127,
  completionTokens: 380,
  totalTokens: 2507,
  cost: '$0.000547',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 8213ms (8.21s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2507 ($0.0005)
âš¡ Performance: 305.2 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 8213ms (8.21s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2507

âœ… ===== BATCH 18 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 8213ms (8.21s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2507 ($0.0005)
âš¡ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1642.60ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:14:59:40 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 649 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:41 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 649 "-" "axios/1.11.0"

ğŸ“¦ ===== BATCH 19 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T14:59:41.910Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Existing Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T14:59:41.910Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T14:59:41.910Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6499,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Maternity Leave, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Clai...
::1 - - [12/Aug/2025:14:59:42 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 649 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:43 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 649 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:44 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 649 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:45 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 649 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:46 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 649 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:47 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 649 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:48 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 649 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:49 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 649 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:50 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 649 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T14:59:51.444Z',
  duration: '9533ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1875,
    completion_tokens: 367,
    total_tokens: 2242,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Leave Request', 'Unknown' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-ffe3e81f-afb4-5911-92c8-553c4556ebc3",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to talk to a representative about FMLA."
    },
    {
      "user_id": "u-f8db1ba4-c4d4-55f7-ac64-603b38ae70d8",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User repeatedly requested an agent but did not provide further input."
    },
    {
      "user_id": "u-8d22652e-2444-5944-b0dd-620dd9fca241",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to file a new claim and was transferred."
    },
    {
      "user_id": "u-a47a2731-7593-5c76-98be-2fe2cc9a78e1",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and did not provide necessary information, leading to a transfer."
    },
    {
      "user_id": "u-6d8d6bde-8bac-5bca-ab4d-c461c90a50d7",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User indicated a need to speak to a representative about something else."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1875,
  completionTokens: 367,
  totalTokens: 2242,
  cost: '$0.000501',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 9534ms (9.53s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2242 ($0.0005)
âš¡ Performance: 235.2 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 9535ms (9.54s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2242

âœ… ===== BATCH 19 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 9536ms (9.54s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2242 ($0.0005)
âš¡ Performance: 0.5 sessions/sec
âš¡ Avg Time Per Session: 1907.20ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:14:59:51 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:52 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"

ğŸ“¦ ===== BATCH 20 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T14:59:53.446Z
ğŸ“Š Sessions in Batch: 3
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Existing Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 3
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T14:59:53.446Z
ğŸ“Š Sessions to Analyze: 3

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T14:59:53.446Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 3,
  apiKey: 'sk-proj-...',
  promptLength: 6243,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Maternity Leave, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Clai...
::1 - - [12/Aug/2025:14:59:53 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:54 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:55 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:56 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:57 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:14:59:58 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 638 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T14:59:58.952Z',
  duration: '5505ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1793,
    completion_tokens: 225,
    total_tokens: 2018,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 3,
  intentsFound: [ 'Leave Request', 'Unknown' ],
  transferCount: 3,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-7ba4d5cb-6a75-5378-aa2e-68b5f8fc0b66",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to someone after verifying their leave request."
    },
    {
      "user_id": "u-61a96974-0636-5f5a-bb39-3531def8fd51",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User expressed a desire to speak to an agent but did not provide clear intent."
    },
    {
      "user_id": "u-c845017c-b3a6-5d48-93a6-e45714faa322",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and unresponsive, leading to a transfer to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1793,
  completionTokens: 225,
  totalTokens: 2018,
  cost: '$0.000404',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 5507ms (5.51s)
ğŸ“Š Sessions Returned: 3
ğŸ’° Tokens Used: 2018 ($0.0004)
âš¡ Performance: 366.4 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 3
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 5507ms (5.51s)
ğŸ“Š Regular Sessions Processed: 3
ğŸ’° Regular Tokens Used: 2018

âœ… ===== BATCH 20 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 5508ms (5.51s)
ğŸ“Š Sessions Processed: 3/3
ğŸ’° Total Tokens: 2018 ($0.0004)
âš¡ Performance: 0.5 sessions/sec
âš¡ Avg Time Per Session: 1836.00ms
â±ï¸  Metadata Processing: 0ms
[BackgroundJobQueue] Session analysis completed for job 72826c46-431d-4e49-b9f6-01844eb5383f-sampling-analysis, processed 98 sessions
::1 - - [12/Aug/2025:14:59:59 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 653 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:00:00 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 653 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:00:01 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 653 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:00:02 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 653 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:00:03 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 653 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:00:04 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 653 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:00:05 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 653 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:00:06 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 653 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:00:07 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 653 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:00:08 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 653 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:00:09 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 653 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:00:10 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 653 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:00:11 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 653 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:00:12 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 653 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:00:13 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 653 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:00:14 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 653 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:00:15 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 653 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:00:16 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 653 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:00:17 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 653 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:00:18 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 653 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:00:19 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 653 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:00:20 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 653 "-" "axios/1.11.0"
[BackgroundJobQueue] Analysis summary generated for job 72826c46-431d-4e49-b9f6-01844eb5383f-sampling-analysis
[BackgroundJobQueue] Analysis completed for job 72826c46-431d-4e49-b9f6-01844eb5383f-sampling-analysis, processed 98 sessions
[BackgroundJobQueue] Results successfully stored in AutoAnalyzeService for analysis 72826c46-431d-4e49-b9f6-01844eb5383f
[BackgroundJobQueue] Analysis 72826c46-431d-4e49-b9f6-01844eb5383f completed with 98 sessions
::1 - - [12/Aug/2025:15:00:21 +0000] "GET /api/analysis/auto-analyze/progress/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 669 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:00:21 +0000] "GET /api/analysis/auto-analyze/results/72826c46-431d-4e49-b9f6-01844eb5383f HTTP/1.1" 200 703969 "-" "axios/1.11.0"
ğŸš€ [ParallelAutoAnalyzeRoute] Starting parallel analysis for bot ***REMOVED*** with real credentials
ğŸš€ [ParallelAutoAnalyzeService] Starting parallel analysis e237bcd4-2e07-445d-9bd0-b318a12b9ad1 with bot ***REMOVED***
ğŸš€ [ParallelAutoAnalyzeService] Using credentials: real
ğŸš€ [ParallelAutoAnalyzeRoute] Parallel analysis started: e237bcd4-2e07-445d-9bd0-b318a12b9ad1
::1 - - [12/Aug/2025:15:11:33 +0000] "POST /api/analysis/auto-analyze/parallel/start HTTP/1.1" 200 214 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:11:33 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
[BackgroundJobQueue] Starting job processing after delay for job e237bcd4-2e07-445d-9bd0-b318a12b9ad1-parallel
[BackgroundJobQueue] Starting processing for job e237bcd4-2e07-445d-9bd0-b318a12b9ad1-parallel, phase: sampling
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing parallel analysis job e237bcd4-2e07-445d-9bd0-b318a12b9ad1-parallel
[BackgroundJobQueue] Processing parallel analysis for bot ***REMOVED***
[BackgroundJobQueue] Using existing ParallelAutoAnalyzeService instance for bot ***REMOVED***
[BackgroundJobQueue] Session recreated for e237bcd4-2e07-445d-9bd0-b318a12b9ad1
[ParallelAutoAnalyzeService] Running parallel analysis for e237bcd4-2e07-445d-9bd0-b318a12b9ad1
[ParallelAutoAnalyzeService] Phase 0: Starting session sampling for e237bcd4-2e07-445d-9bd0-b318a12b9ad1

ğŸ• ============ SESSION SAMPLING STARTED ============
ğŸ• [SessionSampling] Starting session sampling at 2025-08-12T15:11:34.303Z
ğŸ” [SessionDiscovery] Starting window 1/4: Initial 3-hour window
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-01T16:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-01T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-01T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-01T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:11:35 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:11:37 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
[fetchContainmentTypeMetadata] API Response: 84 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '688ce3f084ec0f257aa40505',
  '688ce2f3270e0dfdc8bda516',
  '688ce1cb509249f46abf712e'
]
[fetchContainmentTypeMetadata] API Response: 123 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '688ce441f9118ccf9c084272',
  '688ce41284ec0f257aa408d2',
  '688ce40ae196ca760909852f'
]
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:11:39 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
[fetchContainmentTypeMetadata] API Response: 1112 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '688ce47e3a3160d25d831f04',
  '688ce4786dc148aa9fbead83',
  '688ce465712518226a45c1f5'
]
[getSessionsMetadata] agent API call succeeded with 1112 sessions
[getSessionsMetadata] selfService API call succeeded with 84 sessions
[getSessionsMetadata] dropOff API call succeeded with 123 sessions
Total session metadata retrieved: 1319 (parallel execution)
Creating 1319 SWTs from metadata (no messages)
Created 1319 SWT objects from metadata
âœ… [SessionDiscovery] Window 1 completed in 5498ms: found 1319 new sessions (total: 1319)
â±ï¸  TIMING: Window 1 took 5498ms (5.50s)
ğŸ¯ [SessionDiscovery] Target reached! Found 1319 sessions in 5498ms
ğŸ² [SessionSampling] Random sampling from 1319 sessions to 100 sessions

ğŸ“¬ ============ MESSAGE RETRIEVAL STARTED ============
ğŸ“¬ [MessageRetrieval] Starting message retrieval for 100 sampled sessions at 2025-08-12T15:11:39.802Z
Using new lazy loading approach to populate messages for 100 sampled sessions
Populating messages for 100 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 100 sessions from 2025-08-01T13:00:57.758Z to 2025-08-01T15:59:58.943Z at 2025-08-12T15:11:39.802Z
ğŸš€ [ConcurrentBatch] Split 100 sessions into 5 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/5] Starting: 20 sessions
[Batch 2/5] Starting: 20 sessions
[Batch 3/5] Starting: 20 sessions
[Batch 4/5] Starting: 20 sessions
[Batch 5/5] Starting: 20 sessions
[Batch 2/5] Completed in 348ms: 230 messages retrieved (1/5 done)
ğŸ“Š [BatchProgress] Reporting batch 1/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 40/100 sessions (Batch 2/5)
[Batch 1/5] Completed in 371ms: 258 messages retrieved (2/5 done)
ğŸ“Š [BatchProgress] Reporting batch 2/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 60/100 sessions (Batch 3/5)
[Batch 3/5] Completed in 429ms: 290 messages retrieved (3/5 done)
ğŸ“Š [BatchProgress] Reporting batch 3/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 80/100 sessions (Batch 4/5)
[Batch 4/5] Completed in 686ms: 295 messages retrieved (4/5 done)
ğŸ“Š [BatchProgress] Reporting batch 4/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 100/100 sessions (Batch 5/5)
[Batch 5/5] Completed in 754ms: 265 messages retrieved (5/5 done)
ğŸ“Š [BatchProgress] Reporting batch 5/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 100/100 sessions (Batch 6/5)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 755ms (0.76s)
â±ï¸  Batch Processing: 755ms (0.76s)
ğŸ“¦ Total batches: 5 (max 10 concurrent)
âœ… Successful batches: 5/5
ğŸ’¬ Total messages: 1338
ğŸ“ˆ Avg time per batch: 151ms
ğŸš€ Time per session: 8ms
ğŸ’ª Performance: 132.5 sessions/second
=======================================================

Retrieved 1338 messages for 100 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
Populated messages for 100 SWT objects
Successfully populated messages for 100 sessions using lazy loading
Applying final filtering to 100 sessions with populated messages
Final result: 99 sessions passed filtering with populated messages

ğŸ‰ ============ SESSION SAMPLING COMPLETED ============
â±ï¸  TOTAL TIME: 6261ms (6.26s)
â±ï¸  Session Discovery: 5498ms (5.50s) - 87.8% of total
â±ï¸  Message Retrieval: 762ms (0.76s) - 12.2% of total
â±ï¸  Performance: 15.8 sessions/second
ğŸ¯ Final result: 99 sessions with messages retrieved
====================================================

[StrategicDiscoveryService] Starting discovery phase with 99 total sessions
[StrategicDiscoveryService] Discovery config: {
  targetPercentage: 15,
  minSessions: 19,
  maxSessions: 150,
  diversityStrategy: {
    sessionLengths: [ 'short', 'medium', 'long' ],
    containmentTypes: [ 'agent', 'selfService', 'dropOff' ],
    timeDistribution: 'spread'
  }
}
[StrategicDiscoveryService] Selecting 19 diverse sessions from 99 total
[StrategicDiscoveryService] Session diversity groups: { short: 24, medium: 73, long: 2, early: 33, middle: 33, late: 33 }
[StrategicDiscoveryService] Selected sessions by length distribution: { short: 9, medium: 8, long: 2 }
[StrategicDiscoveryService] Selected 19 sessions for discovery

ğŸ“¦ ===== BATCH 2 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T15:11:40.565Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Existing Classifications:
   â€¢ Intents: 0
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T15:11:40.565Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:11:40.565Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6313,
  existingClassifications: { intents: 0, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.



For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and another intent, classify the intent as the other i...
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:11:41 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:11:43 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:11:45 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:11:47 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:11:49 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:11:50.025Z',
  duration: '9460ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1838,
    completion_tokens: 366,
    total_tokens: 2204,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Live Agent', 'Unknown' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-92d38b38-a5ff-5f62-ae66-02333ba24855",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative and was transferred."
    },
    {
      "user_id": "u-5b5547e7-d8fd-517b-b0b5-380bd799c8c4",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a live agent but was not responsive after the transfer request."
    },
    {
      "user_id": "u-21ec5510-3818-5161-82bf-b38a6dcff7a1",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent and was transferred."
    },
    {
      "user_id": "u-e50be5c1-b6f4-5124-8519-b58a697c11ea",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-98c0a72c-fd7f-5752-8e0e-c106c25fcb44",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent initially but requested assistance with a new leave request and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1838,
  completionTokens: 366,
  totalTokens: 2204,
  cost: '$0.000495',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 9460ms (9.46s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2204 ($0.0005)
âš¡ Performance: 233.0 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 9460ms (9.46s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2204

âœ… ===== BATCH 2 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 9460ms (9.46s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2204 ($0.0005)
âš¡ Performance: 0.5 sessions/sec
âš¡ Avg Time Per Session: 1892.00ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 1 complete: 4 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 2, reasons: 1, locations: 1, total: 4 }

ğŸ“¦ ===== BATCH 3 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T15:11:50.025Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Existing Classifications:
   â€¢ Intents: 2
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T15:11:50.026Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:11:50.026Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 10023,
  existingClassifications: { intents: 2, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Age...
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:11:51 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:11:53 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:11:55 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:11:57 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:11:58.220Z',
  duration: '8194ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 2749,
    completion_tokens: 316,
    total_tokens: 3065,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Unknown', 'Live Agent', 'Claim Status', 'Time entry' ],
  transferCount: 2,
  containedCount: 3
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-3565170c-4cff-5ca6-b3fe-1866edda5673",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "The user did not provide any input, and the bot closed the conversation."
    },
    {
      "user_id": "u-e4f4b47d-19cb-55fb-9b32-729b579dd83b",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "The user requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-e909ac4b-f7e0-595a-bfa7-32108c008b5d",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "The user was checking claim status but was transferred to an agent."
    },
    {
      "user_id": "u-3ca0675c-d077-5492-8cff-f31b3cdbce61",
      "general_intent": "Time entry",
      "session_outcome": "Contained",
      "notes": "The user successfully submitted a time entry and ended the conversation."
    },
    {
      "user_id": "u-34e85be2-6630-588b-91ef-5129736f774f",
      "general_intent": "Time entry",
      "session_outcome": "Contained",
      "notes": "The user successfully submitted a time entry and ended the conversation."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2749,
  completionTokens: 316,
  totalTokens: 3065,
  cost: '$0.000602',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 8195ms (8.20s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 3065 ($0.0006)
âš¡ Performance: 374.0 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 8196ms (8.20s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 3065

âœ… ===== BATCH 3 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 8197ms (8.20s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 3065 ($0.0006)
âš¡ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1639.40ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 2 complete: 2 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 4, reasons: 1, locations: 1, total: 6 }

ğŸ“¦ ===== BATCH 4 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T15:11:58.222Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Existing Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T15:11:58.222Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:11:58.222Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6547,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Time entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing"...
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:11:59 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:12:01 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:12:03 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:12:05 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:12:07.261Z',
  duration: '9039ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1866,
    completion_tokens: 352,
    total_tokens: 2218,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Unknown', 'Claim Status' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-ce269639-663c-5286-86bc-c847e486b827",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative but did not provide further input."
    },
    {
      "user_id": "u-971a1fe2-cd03-5c8a-bb33-df1430a3c69a",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to provide a leave request number but could not recall their employee number."
    },
    {
      "user_id": "u-692518ed-7ad0-5622-a48e-960aa2d9ab22",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User explicitly requested to speak to an agent."
    },
    {
      "user_id": "u-7aa650c2-dacb-529d-a301-66679494326c",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to reopen an existing claim and was transferred."
    },
    {
      "user_id": "u-e909ac4b-f7e0-595a-bfa7-32108c008b5d",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User initiated a claim status check but was transferred before completion."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1866,
  completionTokens: 352,
  totalTokens: 2218,
  cost: '$0.000491',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 9040ms (9.04s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2218 ($0.0005)
âš¡ Performance: 245.4 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 9040ms (9.04s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2218

âœ… ===== BATCH 4 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 9040ms (9.04s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2218 ($0.0005)
âš¡ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1808.00ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 3 complete: 0 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 4, reasons: 1, locations: 1, total: 6 }

ğŸ“¦ ===== BATCH 5 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T15:12:07.262Z
ğŸ“Š Sessions in Batch: 4
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Existing Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 4
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T15:12:07.262Z
ğŸ“Š Sessions to Analyze: 4

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:12:07.262Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5110,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Time entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing"...
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:12:07 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:12:09 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:12:11 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:12:13 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:12:13.619Z',
  duration: '6357ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1500,
    completion_tokens: 232,
    total_tokens: 1732,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown', 'Live Agent' ],
  transferCount: 1,
  containedCount: 3
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-947ced04-ab4d-5fdc-85b0-91d35e627df4",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "The session ended without any user input."
    },
    {
      "user_id": "u-c801c18a-d095-547b-8c6e-4338068137c4",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "The session ended without any user input."
    },
    {
      "user_id": "u-765b99b3-36aa-5c13-8214-1106f8edd0fd",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "The session ended without any user input."
    },
    {
      "user_id": "u-468bd576-55b8-5a4b-8507-6fb85f75b8e7",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "The user requested to speak with a representative and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1500,
  completionTokens: 232,
  totalTokens: 1732,
  cost: '$0.000364',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 6357ms (6.36s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1732 ($0.0004)
âš¡ Performance: 272.5 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 4
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 6357ms (6.36s)
ğŸ“Š Regular Sessions Processed: 4
ğŸ’° Regular Tokens Used: 1732

âœ… ===== BATCH 5 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 6357ms (6.36s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Total Tokens: 1732 ($0.0004)
âš¡ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1589.25ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 4 complete: 0 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 4, reasons: 1, locations: 1, total: 6 }
[StrategicDiscoveryService] Discovery phase complete: {
  totalProcessed: 19,
  uniqueIntents: 4,
  uniqueReasons: 1,
  uniqueLocations: 1,
  discoveryRate: 0.4
}

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T15:12:13.620Z
ğŸ§  Model: gpt-4o-mini
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 128,000 tokens
ğŸŒŠ Recommended Streams: 4
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms
[ParallelAutoAnalyzeService] Using parallel config: {
  streamCount: 4,
  sessionsPerStream: 21,
  maxSessionsPerLLMCall: 50,
  syncFrequency: 'after_each_round',
  retryAttempts: 3,
  debugLogging: false
}

ğŸš€ ============ PARALLEL PROCESSING STARTED ============
â±ï¸  Start Time: 2025-08-12T15:12:13.622Z
ğŸ“Š Total Sessions: 81

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T15:12:13.622Z
ğŸ§  Model: gpt-4o-mini
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 128,000 tokens
ğŸŒŠ Recommended Streams: 4
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms

âš™ï¸  ============ PARALLEL CONFIGURATION ============
â±ï¸  Config Time: 0ms
ğŸ”§ Stream Count: 4
ğŸ“¦ Sessions Per Stream: 21
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per API Call: 50
ğŸ¯ Debug Logging: false

ğŸ”„ ============ ROUND 1/1 STARTED ============
â±ï¸  Round 1 Start: 2025-08-12T15:12:13.622Z
ğŸ“Š Sessions Remaining: 81
[ParallelProcessingOrchestrator] Distributed 81 sessions across 4 streams: [
  'Stream 1: 21 sessions',
  'Stream 2: 21 sessions',
  'Stream 3: 21 sessions',
  'Stream 4: 18 sessions'
]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 4

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 4 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T15:12:13.622Z
ğŸ“Š Sessions Assigned: 21
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T15:12:13.622Z
ğŸ“Š Sessions to Estimate: 21
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 21
   â€¢ Session Tokens: 4160
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 9660
   â€¢ Avg Per Session: 198 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 9660
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0023
ğŸ“Š Recommended Batch Size: 21

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 9660
ğŸ“¦ Recommended Batch Size: 21
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0023

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:12:13.622Z
ğŸ“Š Sessions to Analyze: 21
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:12:13.623Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 21,
  apiKey: 'sk-proj-...',
  promptLength: 18968,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Time entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing"...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T15:12:13.623Z
ğŸ“Š Sessions Assigned: 21
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T15:12:13.623Z
ğŸ“Š Sessions to Estimate: 21
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 21
   â€¢ Session Tokens: 4619
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 10119
   â€¢ Avg Per Session: 220 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 10119
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0024
ğŸ“Š Recommended Batch Size: 21

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 10119
ğŸ“¦ Recommended Batch Size: 21
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0024

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:12:13.623Z
ğŸ“Š Sessions to Analyze: 21
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:12:13.623Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 21,
  apiKey: 'sk-proj-...',
  promptLength: 21017,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Time entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing"...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T15:12:13.623Z
ğŸ“Š Sessions Assigned: 21
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T15:12:13.624Z
ğŸ“Š Sessions to Estimate: 21
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 21
   â€¢ Session Tokens: 4614
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 10114
   â€¢ Avg Per Session: 220 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 10114
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0024
ğŸ“Š Recommended Batch Size: 21

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 10114
ğŸ“¦ Recommended Batch Size: 21
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0024

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:12:13.624Z
ğŸ“Š Sessions to Analyze: 21
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:12:13.624Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 21,
  apiKey: 'sk-proj-...',
  promptLength: 21020,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Time entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing"...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T15:12:13.624Z
ğŸ“Š Sessions Assigned: 18
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T15:12:13.624Z
ğŸ“Š Sessions to Estimate: 18
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 18
   â€¢ Session Tokens: 3990
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 9490
   â€¢ Avg Per Session: 222 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 9490
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0023
ğŸ“Š Recommended Batch Size: 18

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 1ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 9490
ğŸ“¦ Recommended Batch Size: 18
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0023

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:12:13.625Z
ğŸ“Š Sessions to Analyze: 18
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:12:13.625Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 18,
  apiKey: 'sk-proj-...',
  promptLength: 18557,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Time entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing"...
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:12:15 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:12:17 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:12:19 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:12:21 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:12:23 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:12:25 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:12:27 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:12:29 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:12:31 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:12:33 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:12:35 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:12:37 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:12:39 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:12:41 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:12:43.109Z',
  duration: '29486ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 5689,
    completion_tokens: 1321,
    total_tokens: 7010,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 20,
  intentsFound: [ 'Claim Status', 'Unknown', 'Time entry' ],
  transferCount: 18,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-c9bf10c7-db2f-5167-a422-e3b1124e961f",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative after being informed about the leave request status."
    },
    {
      "user_id": "u-fdaba618-154f-5179-be22-858db33f9b74",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested an agent directly."
    },
    {
      "user_id": "u-f72ff374-43aa-594d-a010-6a7b7b1ee17b",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User expressed a need to talk to someone."
    },
    {
      "user_id": "u-01c6d51d-a4de-5631-99bd-7ceb2e876356",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to talk to an agent."
    },
    {
      "user_id": "u-f42b48bc-6356-50b1-a115-f43b4af3424f",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to talk to an agent."
    },
    {
      "user_id": "u-f93e9fd0-d0d8-5fd4-ac08-7060882a3d04",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative."
    },
    {
      "user_id": "u-a11c521b-c438-544c-b38f-2fd7a032f6cc",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User expressed a desire to speak with an agent."
    },
    {
      "user_id": "u-8559b019-02e7-522a-afaf-844a7d43f73e",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "Session ended without user input."
    },
    {
      "user_id": "u-357561b5-1f26-53a8-95c7-26f8ff95562d",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak to an agent."
    },
    {
      "user_id": "u-fb9a614e-5b64-5940-b0ac-1e9e028a0bac",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative."
    },
    {
      "user_id": "u-df175f15-fbc9-5ae5-a2be-b171556f2765",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to report a return to work but was unable due to leave request status."
    },
    {
      "user_id": "u-08f95050-a8a1-5eda-a51c-3d20c94b4be1",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative."
    },
    {
      "user_id": "u-ea3e0114-dae2-5f18-b642-b3c788445a96",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User expressed a desire to speak with an agent."
    },
    {
      "user_id": "u-40b982aa-95f2-5b1f-88a7-2b62231f8b4e",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to check into short term disability."
    },
    {
      "user_id": "u-0bfad52b-73e2-5fa3-8f39-781c11cdc194",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to request time off."
    },
    {
      "user_id": "u-8222b5ed-f068-516e-b293-570d69e4a2f5",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested administrator access."
    },
    {
      "user_id": "u-7042b41b-51df-5445-9cc3-83e337b0c08d",
      "general_intent": "Time entry",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User successfully submitted time entries."
    },
    {
      "user_id": "u-791aaa2b-cbc3-527b-9055-f87988f34b26",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User needed help filling out a worksheet."
    },
    {
      "user_id": "u-fccaaeba-dd8f-562f-b0e4-fa457dafa557",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to change their leave date."
    },
    {
      "user_id": "u-c15dd7a0-a896-5b09-af21-845bee9c35b7",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested customer service."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 5689,
  completionTokens: 1321,
  totalTokens: 7010,
  cost: '$0.001646',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 29487ms (29.49s)
ğŸ“Š Sessions Returned: 20
ğŸ’° Tokens Used: 7010 ($0.0016)
âš¡ Performance: 237.7 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 5689
   â€¢ Completion Tokens: 1321
[SessionValidationService] Validating batch response: 21 input sessions, 20 response sessions
[SessionValidationService] Validation issues found: { missing: 1, errors: 0, details: [] }
[Stream 2] 1 sessions missing, attempting retries

ğŸ”„ ===== RETRY 1/3 (Stream 2) =====
â±ï¸  Retry Start: 2025-08-12T15:12:43.113Z
ğŸ“Š Missing Sessions: 1

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:12:43.113Z
ğŸ“Š Sessions to Analyze: 1
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:12:43.113Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 1,
  apiKey: 'sk-proj-...',
  promptLength: 4182,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Time entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing"...
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:12:43 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:12:44.569Z',
  duration: '30945ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 5680,
    completion_tokens: 1381,
    total_tokens: 7061,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 20,
  intentsFound: [ 'Unknown', 'Live Agent', 'Claim Status', 'Time entry', 'Report' ],
  transferCount: 17,
  containedCount: 3
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-7af4dcf5-6b55-5ffa-a5f0-d707c11858bc",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and the bot transferred to an agent."
    },
    {
      "user_id": "u-ae03877d-3047-5d98-af22-f641a9178c92",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred."
    },
    {
      "user_id": "u-0f5a5da2-7964-53a5-bf47-d91d5bff1687",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User repeatedly requested to speak to a representative and was transferred."
    },
    {
      "user_id": "u-7d553e42-6104-54f4-990e-4c1d88f57e16",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was trying to update the status and requested to speak to an agent."
    },
    {
      "user_id": "u-066d46fb-77b4-518d-89ff-cee8185a74c8",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to talk with customer service and was transferred."
    },
    {
      "user_id": "u-6a51bc58-8c9e-557d-849c-f445e85d7f34",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to adjust their request and was transferred."
    },
    {
      "user_id": "u-57626a3d-3347-5994-8f85-ffd9b209c79a",
      "general_intent": "Time entry",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User successfully submitted a time entry."
    },
    {
      "user_id": "u-2897afc4-93c6-5232-82f5-dc7e01868fec",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-3097557d-0127-5116-8b3d-a42c9eba13f7",
      "general_intent": "Time entry",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User successfully submitted a time entry."
    },
    {
      "user_id": "u-60454d57-c282-5ab9-9aea-33abafb9e26f",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to talk to customer service and was transferred."
    },
    {
      "user_id": "u-04284bcb-0f42-52ff-a9e6-749503acc45b",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-e2b9696e-24be-54fc-b7d7-70977981bde0",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-10e60e4d-0a90-5d3b-9a46-a3f8073c951c",
      "general_intent": "Report",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to report an absence and was transferred."
    },
    {
      "user_id": "u-3466ee04-543c-5314-a490-c027d2ef349f",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-d24288b2-3cde-5b93-90a5-eee36e1e3ab4",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to recertify for FMLA and was transferred."
    },
    {
      "user_id": "u-c5348f76-7f6e-5a61-b72b-d69a85a38b83",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-1c515447-62d3-51e0-bb02-af65981f7021",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and the bot closed the conversation."
    },
    {
      "user_id": "u-80974de8-4fb9-5dfc-87b5-137b7f85ee1b",
      "general_intent": "Report",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to report an absence and was transferred."
    },
    {
      "user_id": "u-9d0db34f-eb16-587f-b2bf-94ffc74fded3",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User was silent and the bot closed the conversation."
    },
    {
      "user_id": "u-5fff7604-80c7-55f9-9a23-437e56d50590",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 5680,
  completionTokens: 1381,
  totalTokens: 7061,
  cost: '$0.001681',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 30945ms (30.95s)
ğŸ“Š Sessions Returned: 20
ğŸ’° Tokens Used: 7061 ($0.0017)
âš¡ Performance: 228.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 5680
   â€¢ Completion Tokens: 1381
[SessionValidationService] Validating batch response: 21 input sessions, 20 response sessions
[SessionValidationService] Validation issues found: { missing: 1, errors: 0, details: [] }
[Stream 3] 1 sessions missing, attempting retries

ğŸ”„ ===== RETRY 1/3 (Stream 3) =====
â±ï¸  Retry Start: 2025-08-12T15:12:44.570Z
ğŸ“Š Missing Sessions: 1

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:12:44.570Z
ğŸ“Š Sessions to Analyze: 1
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:12:44.570Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 1,
  apiKey: 'sk-proj-...',
  promptLength: 4093,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Time entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing"...
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:12:45 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:12:45.627Z',
  duration: '2514ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1235,
    completion_tokens: 82,
    total_tokens: 1317,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 1,
  intentsFound: [ 'Unknown' ],
  transferCount: 1,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-8a9608ab-6733-5125-bb35-d10f0d28ab0a",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to someone about applying for FMLA, leading to a transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1235,
  completionTokens: 82,
  totalTokens: 1317,
  cost: '$0.000234',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2514ms (2.51s)
ğŸ“Š Sessions Returned: 1
ğŸ’° Tokens Used: 1317 ($0.0002)
âš¡ Performance: 523.9 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1235
   â€¢ Completion Tokens: 82
[SessionValidationService] Validating batch response: 1 input sessions, 1 response sessions
[SessionValidationService] Validation successful: all 1 sessions processed
[SessionValidationService] Merging 20 original + 1 retry results
[SessionValidationService] Merge complete: 21 total sessions
âœ… Stream 2 Retry 1 Results:
   â€¢ Processed: 1 sessions
   â€¢ Still Missing: 0 sessions
[SessionValidationService] Validating batch response: 21 input sessions, 21 response sessions
[SessionValidationService] Validation successful: all 21 sessions processed
â±ï¸  Stream 2 Single Batch Time: 32005ms (32.01s)

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 32005ms (32.01s)
ğŸ“Š Sessions Processed: 21/21
ğŸ’° Tokens Used: 8327 ($0.0019)
ğŸ”„ Retry Attempts: 1
ğŸ¯ Performance: 0.7 sessions/sec
âš¡ Avg Time Per Session: 1524.05ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:12:46.274Z',
  duration: '32649ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 5003,
    completion_tokens: 1263,
    total_tokens: 6266,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 18,
  intentsFound: [ 'Unknown', 'Claim Status' ],
  transferCount: 18,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-bdaf2614-f003-50e2-98d1-240b56b26230",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to set up FMLA and was transferred to a representative."
    },
    {
      "user_id": "u-32937434-5b81-5696-9954-50b15c95bda4",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked to connect to customer service and was transferred."
    },
    {
      "user_id": "u-f71a4af5-527f-594b-874b-aec58cb1641c",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to open a new claim and was transferred."
    },
    {
      "user_id": "u-07820c47-2983-5385-b00c-b56b3b5a92a8",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative and was transferred."
    },
    {
      "user_id": "u-6a6d4369-1d2f-502d-a1ca-4f9090dc4dcb",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked to talk to customer service and was transferred."
    },
    {
      "user_id": "u-52aaf37c-953d-5f8e-b561-47331b18c07f",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent and was transferred."
    },
    {
      "user_id": "u-28b52f5e-67b3-597b-8d32-384944924de4",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked for a representative and was transferred."
    },
    {
      "user_id": "u-841f25bb-7410-5dab-af92-1d727a7905c1",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and then confirmed wanting to open a new leave request, leading to a transfer."
    },
    {
      "user_id": "u-e628da22-79d2-501a-8d1c-102141bb8d9a",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User inquired about claim status but was transferred after failing to get clarification."
    },
    {
      "user_id": "u-dbe484c6-c68d-512b-a7ae-8fdb9954e513",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative and was transferred."
    },
    {
      "user_id": "u-767ddb42-ef86-59a1-9c55-80f8e737a8ac",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked for customer service and was transferred."
    },
    {
      "user_id": "u-b29c72ec-5275-5d59-bb14-df49f9e92882",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User inquired about communication from their doctor and was transferred."
    },
    {
      "user_id": "u-4570eb11-ed62-57c0-845e-5b38a5a4b0fa",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to report return to work and was transferred."
    },
    {
      "user_id": "u-5130989e-e430-51b2-b42c-0b4e8e621040",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested an FMLA extension and was transferred."
    },
    {
      "user_id": "u-69310905-230a-5802-8091-9f0f024691fc",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked for an associate and was transferred."
    },
    {
      "user_id": "u-4035c296-3138-573e-bf48-092b31270dd5",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-4a8b8e06-fb0e-5201-940c-73a9ec2bbc2c",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to extend their leave and was transferred."
    },
    {
      "user_id": "u-abc113b4-9ee6-5d21-b257-e91f871c3e79",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to extend their leave and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 5003,
  completionTokens: 1263,
  totalTokens: 6266,
  cost: '$0.001508',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 32649ms (32.65s)
ğŸ“Š Sessions Returned: 18
ğŸ’° Tokens Used: 6266 ($0.0015)
âš¡ Performance: 191.9 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 5003
   â€¢ Completion Tokens: 1263
[SessionValidationService] Validating batch response: 18 input sessions, 18 response sessions
[SessionValidationService] Validation successful: all 18 sessions processed
[SessionValidationService] Validating batch response: 18 input sessions, 18 response sessions
[SessionValidationService] Validation successful: all 18 sessions processed
â±ï¸  Stream 4 Single Batch Time: 32650ms (32.65s)

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 32651ms (32.65s)
ğŸ“Š Sessions Processed: 18/18
ğŸ’° Tokens Used: 6266 ($0.0015)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1813.94ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:12:46.925Z',
  duration: '2355ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1212,
    completion_tokens: 76,
    total_tokens: 1288,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 1,
  intentsFound: [ 'Unknown' ],
  transferCount: 1,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-5a781f65-ed3c-5add-b3cb-c7eaf48241ad",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1212,
  completionTokens: 76,
  totalTokens: 1288,
  cost: '$0.000227',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2356ms (2.36s)
ğŸ“Š Sessions Returned: 1
ğŸ’° Tokens Used: 1288 ($0.0002)
âš¡ Performance: 546.7 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1212
   â€¢ Completion Tokens: 76
[SessionValidationService] Validating batch response: 1 input sessions, 1 response sessions
[SessionValidationService] Validation successful: all 1 sessions processed
[SessionValidationService] Merging 20 original + 1 retry results
[SessionValidationService] Merge complete: 21 total sessions
âœ… Stream 3 Retry 1 Results:
   â€¢ Processed: 1 sessions
   â€¢ Still Missing: 0 sessions
[SessionValidationService] Validating batch response: 21 input sessions, 21 response sessions
[SessionValidationService] Validation successful: all 21 sessions processed
â±ï¸  Stream 3 Single Batch Time: 33302ms (33.30s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 33304ms (33.30s)
ğŸ“Š Sessions Processed: 21/21
ğŸ’° Tokens Used: 8349 ($0.0019)
ğŸ”„ Retry Attempts: 1
ğŸ¯ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1585.90ms
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:12:47 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:12:49 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:12:50.333Z',
  duration: '36710ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 5132,
    completion_tokens: 1447,
    total_tokens: 6579,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 20,
  intentsFound: [ 'Claim Status', 'Live Agent', 'Time entry', 'Unknown' ],
  transferCount: 19,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-faf6fb93-a41f-50b9-9027-6d18c7093c06",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User had questions about an existing claim and was transferred to an agent."
    },
    {
      "user_id": "u-5aaba5b1-8e39-55ec-a6e8-48709254cf2c",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with a representative about pending leave and was transferred."
    },
    {
      "user_id": "u-b3123263-3e9d-570b-a3a3-1127ce6e4144",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested customer service and was transferred to an agent."
    },
    {
      "user_id": "u-0c6405fe-2d9b-5f8c-b745-eb87f2e47488",
      "general_intent": "Time entry",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to enter time but was unable to provide the correct date and was transferred."
    },
    {
      "user_id": "u-a795cf67-4ac4-53ca-85a8-ffb10f7a6ffe",
      "general_intent": "Time entry",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User tried to submit time but encountered issues and was transferred."
    },
    {
      "user_id": "u-fd83dec0-3185-5c96-b763-bd1fed788768",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to make a claim but was unable to provide necessary information and was transferred."
    },
    {
      "user_id": "u-5d25e1b7-de52-56cf-98c8-8b026aaf48db",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to file a new claim and was transferred."
    },
    {
      "user_id": "u-f407532f-117b-5571-9fac-e9f6633cb76c",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to someone and was transferred."
    },
    {
      "user_id": "u-f3e5dec6-3452-509a-b8b1-db7471b61976",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User checked on claim extension status and requested a representative, leading to a transfer."
    },
    {
      "user_id": "u-c7b6454e-f6fd-5cef-bb96-5a959e756b64",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to report a return to work but was unable to do so and was transferred."
    },
    {
      "user_id": "u-b46db90e-b6f0-5dd8-800a-cdb0561a215c",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to talk to a representative and was transferred."
    },
    {
      "user_id": "u-48f5093b-3830-5b12-868d-cf42012df484",
      "general_intent": "Time entry",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User successfully submitted a time entry and ended the session."
    },
    {
      "user_id": "u-72b5b2ba-8a2b-5b63-88b2-f2f2c5a05445",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User inquired about claim status and requested to speak with a representative, resulting in a transfer."
    },
    {
      "user_id": "u-e41929e3-a76f-55e5-9e91-a790a31378c3",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested customer service and was transferred."
    },
    {
      "user_id": "u-e9aee0eb-8295-558b-9c46-b00c43e11cdf",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent and was transferred."
    },
    {
      "user_id": "u-52880569-0139-5a39-88a7-0594353c95ab",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-94d62cbe-677b-5952-82eb-9071843e53f6",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to talk to an agent and was transferred."
    },
    {
      "user_id": "u-0e9c51b6-8b9c-55f3-80b3-11510e580ee8",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-e883d288-7e92-56f6-a51c-47c65358997e",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent and was transferred."
    },
    {
      "user_id": "u-9256d615-23ea-5e69-ae21-e5d478a25651",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User inquired about certification documentation and requested to talk to an agent, leading to a transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 5132,
  completionTokens: 1447,
  totalTokens: 6579,
  cost: '$0.001638',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 36712ms (36.71s)
ğŸ“Š Sessions Returned: 20
ğŸ’° Tokens Used: 6579 ($0.0016)
âš¡ Performance: 179.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 5132
   â€¢ Completion Tokens: 1447
[SessionValidationService] Validating batch response: 21 input sessions, 20 response sessions
[SessionValidationService] Validation issues found: { missing: 1, errors: 0, details: [] }
[Stream 1] 1 sessions missing, attempting retries

ğŸ”„ ===== RETRY 1/3 (Stream 1) =====
â±ï¸  Retry Start: 2025-08-12T15:12:50.335Z
ğŸ“Š Missing Sessions: 1

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:12:50.335Z
ğŸ“Š Sessions to Analyze: 1
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:12:50.335Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 1,
  apiKey: 'sk-proj-...',
  promptLength: 3777,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Time entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing"...
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:12:51 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:12:52.234Z',
  duration: '1899ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1139,
    completion_tokens: 64,
    total_tokens: 1203,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 1,
  intentsFound: [ 'Unknown' ],
  transferCount: 0,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-1d519720-9e68-5e41-a2e0-51d636317b20",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "The user did not provide any input, and the bot closed the conversation."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1139,
  completionTokens: 64,
  totalTokens: 1203,
  cost: '$0.000209',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1899ms (1.90s)
ğŸ“Š Sessions Returned: 1
ğŸ’° Tokens Used: 1203 ($0.0002)
âš¡ Performance: 633.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1139
   â€¢ Completion Tokens: 64
[SessionValidationService] Validating batch response: 1 input sessions, 1 response sessions
[SessionValidationService] Validation successful: all 1 sessions processed
[SessionValidationService] Merging 20 original + 1 retry results
[SessionValidationService] Merge complete: 21 total sessions
âœ… Stream 1 Retry 1 Results:
   â€¢ Processed: 1 sessions
   â€¢ Still Missing: 0 sessions
[SessionValidationService] Validating batch response: 21 input sessions, 21 response sessions
[SessionValidationService] Validation successful: all 21 sessions processed
â±ï¸  Stream 1 Single Batch Time: 38612ms (38.61s)

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 38612ms (38.61s)
ğŸ“Š Sessions Processed: 21/21
ğŸ’° Tokens Used: 7782 ($0.0018)
ğŸ”„ Retry Attempts: 1
ğŸ¯ Performance: 0.5 sessions/sec
âš¡ Avg Time Per Session: 1838.67ms
[ParallelProcessingOrchestrator] Parallel processing complete: 4/4 streams succeeded
â±ï¸  Parallel Processing Time: 38612ms (38.61s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 4 streams
[ParallelProcessingOrchestrator] Synchronization complete: 1 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 1
ğŸ“Š Total Classifications: 7

âœ… ============ ROUND 1 COMPLETED ============
â±ï¸  Round 1 Total Time: 38613ms (38.61s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 0
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 38612ms (100.0%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ‰ ============ PARALLEL PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 38613ms (38.61s)
ğŸ“Š Sessions Processed: 81/81
ğŸ”„ Total Rounds: 1
ğŸŒŠ Stream Results: 4
ğŸ’° Token Usage: 30724 tokens ($0.0071)
ğŸ“ˆ Stream Utilization: 100.0%
ğŸ¯ Performance: 2.1 sessions/second
âš¡ Avg Time Per Session: 476.70ms

ğŸ“Š Stream Performance Breakdown:
   Stream 1: 21 sessions in 38612ms (201.5 tokens/sec)
   Stream 2: 21 sessions in 32005ms (260.2 tokens/sec)
   Stream 3: 21 sessions in 33304ms (250.7 tokens/sec)
   Stream 4: 18 sessions in 32651ms (191.9 tokens/sec)
[ConflictResolutionService] Starting conflict resolution for 100 sessions
[ConflictResolutionService] Found classifications: { intents: 5, reasons: 1, locations: 1 }
[ConflictResolutionService] Calling LLM for conflict resolution with model gpt-4o-mini
ğŸ”§ Conflict Resolution Prompt Preview: You are reviewing classifications from parallel analysis streams. Identify any semantic duplicates and choose the canonical version for each group.

**Instructions:**
1. Look for classifications that refer to the same concept but use different wording
2. For each group of duplicates, choose the most...
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:12:53 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
[ConflictResolutionService] LLM conflict resolution complete: { intents: 6, reasons: 3, locations: 1, tokens: 734, cost: 0.0001632 }
ğŸ”§ Conflict Resolution Response: {
  "generalIntents": [
    {
      "canonical": "Claim Status",
      "aliases": [
        "Claim Inquiry"
      ]
    },
    {
      "canonical": "Live Agent",
      "aliases": [
        "Transfer to Human"
      ]
    },
    {
      "canonical": "Report",
      "aliases": []
    },
    {
      "canonical": "Time Entry",
      "aliases": [
        "Time Log"
      ]
    },
    {
      "canonical": "Unknown",
      "aliases": []
    },
    {
      "canonical": "Unknown Intent",
      "aliases": [
        "Unrecognized"
      ]
    }
  ],
  "transferReasons": [
    {
      "canonical": "Live Agent Request",
      "aliases": []
    },
    {
      "canonical": "Transfer to Live Agent",
      "aliases": []
    },
    {
      "canonical": "Request Human Assistance",
      "aliases": []
    }
  ],
  "dropOffLocations": [
    {
      "canonical": "Help Offer Prompt",
      "aliases": [
        "Assistance Offer"
      ]
    }
  ]
}
[ConflictResolutionService] Applying resolutions to 100 sessions
[ConflictResolutionService] Applied 0 classification mappings across 100 sessions
[ConflictResolutionService] Identified 0 potential conflict groups
[ConflictResolutionService] Conflict resolution complete in 3119ms: { conflictsFound: 0, conflictsResolved: 10, canonicalMappings: 5 }
[ParallelAutoAnalyzeService] Using real analysis summary service
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:12:55 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:12:57 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:12:59 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:13:01 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:13:03 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:13:05 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:13:07 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:13:09 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:13:11 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:13:13 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:13:15 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:13:17 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
[ParallelAutoAnalyzeService] Parallel analysis e237bcd4-2e07-445d-9bd0-b318a12b9ad1 completed successfully
[BackgroundJobQueue] Updated job progress to final state: complete
[BackgroundJobQueue] Parallel analysis job e237bcd4-2e07-445d-9bd0-b318a12b9ad1-parallel completed successfully
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:13:19 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:13:21 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:13:23 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:13:25 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:13:27 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:13:29 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:13:31 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:13:33 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:13:35 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:13:37 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:13:39 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:13:41 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:13:43 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:13:45 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:13:47 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:13:49 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:13:51 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:13:53 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:13:55 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:13:57 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:13:59 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:14:01 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:14:03 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:14:05 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:14:07 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:14:09 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:14:11 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:14:13 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:14:15 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:14:17 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:14:19 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:14:21 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:14:23 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:14:25 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:14:27 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:14:29 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:14:31 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:14:33 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:14:35 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:14:37 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:14:39 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:14:41 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:14:43 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:14:45 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:14:47 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:14:49 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:14:51 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:14:53 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:14:55 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:14:57 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:14:59 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:15:01 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:15:03 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:15:06 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:15:08 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:15:10 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:15:12 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:15:14 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:15:16 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:15:18 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:15:20 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:15:22 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:15:24 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:15:26 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:15:28 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:15:30 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:15:32 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:15:34 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:15:36 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:15:38 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:15:40 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:15:42 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:15:44 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:15:46 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:15:48 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:15:50 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:15:52 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:15:54 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:15:56 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:15:58 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:16:00 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:16:02 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:16:04 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:16:06 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:16:08 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:16:10 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:16:12 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:16:14 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:16:16 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:16:18 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:16:20 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:16:22 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:16:24 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:16:26 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:16:28 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:16:30 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:16:32 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:16:34 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
Failed to get progress for e237bcd4-2e07-445d-9bd0-b318a12b9ad1: Error: Analysis not found
    at AutoAnalyzeService.getProgress (/Users/kengrafals/workspace/xobcat/backend/src/services/autoAnalyzeService.ts:112:13)
    at <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/autoAnalyze.ts:146:47)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at next (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:149:13)
    at Route.dispatch (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/route.js:119:3)
    at Layer.handle [as handle_request] (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/layer.js:95:5)
    at /Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:284:15
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:365:14)
    at param (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:376:14)
    at router.process_params (/Users/kengrafals/workspace/xobcat/backend/node_modules/express/lib/router/index.js:421:3)
::1 - - [12/Aug/2025:15:16:36 +0000] "GET /api/analysis/auto-analyze/progress/e237bcd4-2e07-445d-9bd0-b318a12b9ad1 HTTP/1.1" 404 46 "-" "axios/1.11.0"
ğŸš€ [ParallelAutoAnalyzeRoute] Starting parallel analysis for bot ***REMOVED*** with real credentials
ğŸš€ [ParallelAutoAnalyzeService] Starting parallel analysis d94d825f-db3b-4e78-b31b-57fc288ef1fa with bot ***REMOVED***
ğŸš€ [ParallelAutoAnalyzeService] Using credentials: real
ğŸš€ [ParallelAutoAnalyzeRoute] Parallel analysis started: d94d825f-db3b-4e78-b31b-57fc288ef1fa
::1 - - [12/Aug/2025:15:21:32 +0000] "POST /api/analysis/auto-analyze/parallel/start HTTP/1.1" 200 214 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:21:32 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 541 "-" "axios/1.11.0"
[BackgroundJobQueue] Starting job processing after delay for job d94d825f-db3b-4e78-b31b-57fc288ef1fa-parallel
[BackgroundJobQueue] Starting processing for job d94d825f-db3b-4e78-b31b-57fc288ef1fa-parallel, phase: sampling
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing parallel analysis job d94d825f-db3b-4e78-b31b-57fc288ef1fa-parallel
[BackgroundJobQueue] Processing parallel analysis for bot ***REMOVED***
[BackgroundJobQueue] Using existing ParallelAutoAnalyzeService instance for bot ***REMOVED***
[BackgroundJobQueue] Session recreated for d94d825f-db3b-4e78-b31b-57fc288ef1fa
[ParallelAutoAnalyzeService] Running parallel analysis for d94d825f-db3b-4e78-b31b-57fc288ef1fa
[ParallelAutoAnalyzeService] Phase 0: Starting session sampling for d94d825f-db3b-4e78-b31b-57fc288ef1fa

ğŸ• ============ SESSION SAMPLING STARTED ============
ğŸ• [SessionSampling] Starting session sampling at 2025-08-12T15:21:33.637Z
ğŸ” [SessionDiscovery] Starting window 1/4: Initial 3-hour window
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-01T16:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-01T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-01T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-01T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
::1 - - [12/Aug/2025:15:21:33 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 714 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:21:34 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 714 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:21:35 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 714 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:21:36 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 714 "-" "axios/1.11.0"
[fetchContainmentTypeMetadata] API Response: 84 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '688ce3f084ec0f257aa40505',
  '688ce2f3270e0dfdc8bda516',
  '688ce1cb509249f46abf712e'
]
[fetchContainmentTypeMetadata] API Response: 123 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '688ce441f9118ccf9c084272',
  '688ce41284ec0f257aa408d2',
  '688ce40ae196ca760909852f'
]
::1 - - [12/Aug/2025:15:21:37 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 714 "-" "axios/1.11.0"
[fetchContainmentTypeMetadata] API Response: 1112 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '688ce47e3a3160d25d831f04',
  '688ce4786dc148aa9fbead83',
  '688ce465712518226a45c1f5'
]
[getSessionsMetadata] agent API call succeeded with 1112 sessions
[getSessionsMetadata] selfService API call succeeded with 84 sessions
[getSessionsMetadata] dropOff API call succeeded with 123 sessions
Total session metadata retrieved: 1319 (parallel execution)
Creating 1319 SWTs from metadata (no messages)
Created 1319 SWT objects from metadata
âœ… [SessionDiscovery] Window 1 completed in 4722ms: found 1319 new sessions (total: 1319)
â±ï¸  TIMING: Window 1 took 4722ms (4.72s)
ğŸ¯ [SessionDiscovery] Target reached! Found 1319 sessions in 4722ms
ğŸ² [SessionSampling] Random sampling from 1319 sessions to 100 sessions

ğŸ“¬ ============ MESSAGE RETRIEVAL STARTED ============
ğŸ“¬ [MessageRetrieval] Starting message retrieval for 100 sampled sessions at 2025-08-12T15:21:38.359Z
Using new lazy loading approach to populate messages for 100 sampled sessions
Populating messages for 100 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 100 sessions from 2025-08-01T13:00:19.940Z to 2025-08-01T15:56:12.471Z at 2025-08-12T15:21:38.359Z
ğŸš€ [ConcurrentBatch] Split 100 sessions into 5 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/5] Starting: 20 sessions
[Batch 2/5] Starting: 20 sessions
[Batch 3/5] Starting: 20 sessions
[Batch 4/5] Starting: 20 sessions
[Batch 5/5] Starting: 20 sessions
::1 - - [12/Aug/2025:15:21:38 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 714 "-" "axios/1.11.0"
[Batch 3/5] Completed in 388ms: 207 messages retrieved (1/5 done)
ğŸ“Š [BatchProgress] Reporting batch 1/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 40/100 sessions (Batch 2/5)
[Batch 2/5] Completed in 412ms: 253 messages retrieved (2/5 done)
ğŸ“Š [BatchProgress] Reporting batch 2/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 60/100 sessions (Batch 3/5)
[Batch 1/5] Completed in 453ms: 346 messages retrieved (3/5 done)
ğŸ“Š [BatchProgress] Reporting batch 3/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 80/100 sessions (Batch 4/5)
[Batch 5/5] Completed in 643ms: 240 messages retrieved (4/5 done)
ğŸ“Š [BatchProgress] Reporting batch 4/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 100/100 sessions (Batch 5/5)
[Batch 4/5] Completed in 645ms: 301 messages retrieved (5/5 done)
ğŸ“Š [BatchProgress] Reporting batch 5/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 100/100 sessions (Batch 6/5)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 646ms (0.65s)
â±ï¸  Batch Processing: 646ms (0.65s)
ğŸ“¦ Total batches: 5 (max 10 concurrent)
âœ… Successful batches: 5/5
ğŸ’¬ Total messages: 1347
ğŸ“ˆ Avg time per batch: 129ms
ğŸš€ Time per session: 6ms
ğŸ’ª Performance: 154.8 sessions/second
=======================================================

Retrieved 1347 messages for 100 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
Populated messages for 100 SWT objects
Successfully populated messages for 100 sessions using lazy loading
Applying final filtering to 100 sessions with populated messages
Final result: 100 sessions passed filtering with populated messages

ğŸ‰ ============ SESSION SAMPLING COMPLETED ============
â±ï¸  TOTAL TIME: 5373ms (5.37s)
â±ï¸  Session Discovery: 4722ms (4.72s) - 87.9% of total
â±ï¸  Message Retrieval: 651ms (0.65s) - 12.1% of total
â±ï¸  Performance: 18.6 sessions/second
ğŸ¯ Final result: 100 sessions with messages retrieved
====================================================

[StrategicDiscoveryService] Starting discovery phase with 100 total sessions
[StrategicDiscoveryService] Discovery config: {
  targetPercentage: 15,
  minSessions: 20,
  maxSessions: 150,
  diversityStrategy: {
    sessionLengths: [ 'short', 'medium', 'long' ],
    containmentTypes: [ 'agent', 'selfService', 'dropOff' ],
    timeDistribution: 'spread'
  }
}
[StrategicDiscoveryService] Selecting 20 diverse sessions from 100 total
[StrategicDiscoveryService] Session diversity groups: { short: 24, medium: 75, long: 1, early: 33, middle: 33, late: 34 }
[StrategicDiscoveryService] Selected sessions by length distribution: { short: 8, medium: 11, long: 1 }
[StrategicDiscoveryService] Selected 20 sessions for discovery

ğŸ“¦ ===== BATCH 6 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T15:21:39.011Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Existing Classifications:
   â€¢ Intents: 0
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T15:21:39.011Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:21:39.012Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7320,
  existingClassifications: { intents: 0, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.



For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and another intent, classify the intent as the other i...
::1 - - [12/Aug/2025:15:21:39 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 920 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:21:40 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 920 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:21:41 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 920 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:21:42 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 920 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:21:43 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 920 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:21:44 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 920 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:21:45 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 920 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:21:46 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 920 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:21:47 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 920 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:21:48 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 920 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:21:49 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 920 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:21:50 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 920 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:21:51.624Z',
  duration: '12612ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 2101,
    completion_tokens: 380,
    total_tokens: 2481,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Leave Request', 'Live Agent', 'New Leave' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-32026754-d556-51fd-a688-310250d4f317",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Invalid Leave Request Number",
      "drop_off_location": "Leave Request Number Prompt",
      "notes": "User attempted to provide a leave request number but was unable to verify it, leading to a transfer."
    },
    {
      "user_id": "u-08f95050-a8a1-5eda-a51c-3d20c94b4be1",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred."
    },
    {
      "user_id": "u-abe08300-684c-5d5f-ae6f-e468ab4ec1bb",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Invalid Leave Request Input",
      "drop_off_location": "Leave Request Confirmation Prompt",
      "notes": "User attempted to confirm a leave request but failed to provide valid input, resulting in a transfer."
    },
    {
      "user_id": "u-107a76eb-960d-5e00-8f66-c615ffecb3d6",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User expressed the need to speak to a representative and was transferred."
    },
    {
      "user_id": "u-b9df841b-f247-5c85-9739-cfc2cd7dd43a",
      "general_intent": "New Leave",
      "session_outcome": "Transfer",
      "transfer_reason": "New Leave Request",
      "drop_off_location": "New Leave Request Prompt",
      "notes": "User initiated a request to start a new leave and was transferred for assistance."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2101,
  completionTokens: 380,
  totalTokens: 2481,
  cost: '$0.000543',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 12614ms (12.61s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2481 ($0.0005)
âš¡ Performance: 196.7 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 12614ms (12.61s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2481

âœ… ===== BATCH 6 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 12614ms (12.61s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2481 ($0.0005)
âš¡ Performance: 0.4 sessions/sec
âš¡ Avg Time Per Session: 2522.80ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 1 complete: 11 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 3, reasons: 4, locations: 4, total: 11 }

ğŸ“¦ ===== BATCH 7 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T15:21:51.625Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Existing Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 4
   â€¢ Locations: 4

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T15:21:51.625Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:21:51.625Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 10152,
  existingClassifications: { intents: 3, transferReasons: 4, dropOffLocations: 4 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Leave Request, Live Agent, New Leave
Existing Transfer Reason classifications: Invalid Leave Request Input, Invalid Leave Request Number, Live Agent Request, New Leave Request
Existing Drop-Off Location classifications: Help Offer Prompt, Leave Request Confirmation Prompt, Leave Request Number Prompt, New Leave Request Prompt

For each session, provi...
::1 - - [12/Aug/2025:15:21:51 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 923 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:21:52 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 923 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:21:53 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 923 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:21:54 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 923 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:21:55 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 923 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:21:56 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 923 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:21:57 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 923 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:21:58 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 923 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:21:59 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 923 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:22:00.226Z',
  duration: '8601ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 2784,
    completion_tokens: 347,
    total_tokens: 3131,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Live Agent', 'New Leave', 'Leave Request' ],
  transferCount: 2,
  containedCount: 3
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-e2d0c3a3-c80d-5ed9-ba55-1fa95af61ae8",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative and was transferred."
    },
    {
      "user_id": "u-3b65fc43-948d-5dd1-a3fb-7f0a627db3c7",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to speak to an agent but repeated input led to a transfer."
    },
    {
      "user_id": "u-68d061c5-2275-5588-a971-d2db5ef12644",
      "general_intent": "New Leave",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User successfully submitted a time entry for absence without needing a transfer."
    },
    {
      "user_id": "u-57a5857d-8de5-568a-983e-52da97dac7e0",
      "general_intent": "New Leave",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User successfully submitted multiple time entries without needing a transfer."
    },
    {
      "user_id": "u-2c78f008-74a7-5e8a-972b-fbeacba0a471",
      "general_intent": "Leave Request",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User inquired about extending time off but was informed to visit the website."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2784,
  completionTokens: 347,
  totalTokens: 3131,
  cost: '$0.000626',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 8602ms (8.60s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 3131 ($0.0006)
âš¡ Performance: 364.0 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 8602ms (8.60s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 3131

âœ… ===== BATCH 7 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 8602ms (8.60s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 3131 ($0.0006)
âš¡ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1720.40ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 2 complete: 0 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 3, reasons: 4, locations: 4, total: 11 }

ğŸ“¦ ===== BATCH 8 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T15:22:00.227Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Existing Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 4
   â€¢ Locations: 4

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T15:22:00.227Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:22:00.227Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6835,
  existingClassifications: { intents: 3, transferReasons: 4, dropOffLocations: 4 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Leave Request, Live Agent, New Leave
Existing Transfer Reason classifications: Invalid Leave Request Input, Invalid Leave Request Number, Live Agent Request, New Leave Request
Existing Drop-Off Location classifications: Help Offer Prompt, Leave Request Confirmation Prompt, Leave Request Number Prompt, New Leave Request Prompt

For each session, provi...
::1 - - [12/Aug/2025:15:22:00 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 923 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:01 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 923 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:02 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 923 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:03 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 923 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:04 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 923 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:05 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 923 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:06 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 923 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:07 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 923 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:08 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 923 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:09 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 923 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:10 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 923 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:11 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 923 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:22:12.055Z',
  duration: '11828ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1924,
    completion_tokens: 365,
    total_tokens: 2289,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Live Agent' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-c15dd7a0-a896-5b09-af21-845bee9c35b7",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested customer service and was transferred to an agent."
    },
    {
      "user_id": "u-c0f12b34-6169-5c85-bfb3-c5a1f5ee68f5",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User explicitly stated the need to speak with an agent and was transferred."
    },
    {
      "user_id": "u-4dc34de3-f8e4-536c-96f4-7f4286592edc",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User mentioned wanting a representative and was transferred to an agent."
    },
    {
      "user_id": "u-f274aefb-774a-55db-afa2-4a362f3af9f2",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-84f96537-4404-5645-a88d-2deeb8263550",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User indicated the need for an assistant and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1924,
  completionTokens: 365,
  totalTokens: 2289,
  cost: '$0.000508',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 11829ms (11.83s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2289 ($0.0005)
âš¡ Performance: 193.5 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 11829ms (11.83s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2289

âœ… ===== BATCH 8 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 11829ms (11.83s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2289 ($0.0005)
âš¡ Performance: 0.4 sessions/sec
âš¡ Avg Time Per Session: 2365.80ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 3 complete: 0 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 3, reasons: 4, locations: 4, total: 11 }

ğŸ“¦ ===== BATCH 9 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T15:22:12.056Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Existing Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 4
   â€¢ Locations: 4

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T15:22:12.056Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:22:12.056Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6259,
  existingClassifications: { intents: 3, transferReasons: 4, dropOffLocations: 4 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Leave Request, Live Agent, New Leave
Existing Transfer Reason classifications: Invalid Leave Request Input, Invalid Leave Request Number, Live Agent Request, New Leave Request
Existing Drop-Off Location classifications: Help Offer Prompt, Leave Request Confirmation Prompt, Leave Request Number Prompt, New Leave Request Prompt

For each session, provi...
::1 - - [12/Aug/2025:15:22:12 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 923 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:13 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 923 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:14 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 923 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:15 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 923 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:16 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 923 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:17 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 923 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:18 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 923 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:19 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 923 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:20 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 923 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:21 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 923 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:22:22.288Z',
  duration: '10231ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1817,
    completion_tokens: 366,
    total_tokens: 2183,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Live Agent', 'New Leave', 'Claim Status', 'Unknown' ],
  transferCount: 3,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-fcbaeee7-2bff-5eac-992f-b2002002b227",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred."
    },
    {
      "user_id": "u-3f59b6a7-5292-5972-8946-93ce3df80a72",
      "general_intent": "New Leave",
      "session_outcome": "Transfer",
      "transfer_reason": "Invalid Leave Request Input",
      "drop_off_location": "New Leave Request Prompt",
      "notes": "User attempted to provide an update but was unable to communicate effectively, leading to a transfer."
    },
    {
      "user_id": "u-e8ecc20b-7dd5-5dd6-bce3-fb5cc86dbf4a",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User successfully checked the status of their leave request and received confirmation that it was approved."
    },
    {
      "user_id": "u-21f7350e-9b11-588b-ac16-3197fa285f82",
      "general_intent": "New Leave",
      "session_outcome": "Transfer",
      "transfer_reason": "Invalid Leave Request Input",
      "drop_off_location": "New Leave Request Prompt",
      "notes": "User was silent when prompted for input, resulting in a transfer to an agent."
    },
    {
      "user_id": "u-1d519720-9e68-5e41-a2e0-51d636317b20",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User did not provide any input, and the bot closed the conversation."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1817,
  completionTokens: 366,
  totalTokens: 2183,
  cost: '$0.000492',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 10233ms (10.23s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2183 ($0.0005)
âš¡ Performance: 213.3 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 10233ms (10.23s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2183

âœ… ===== BATCH 9 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 10233ms (10.23s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2183 ($0.0005)
âš¡ Performance: 0.5 sessions/sec
âš¡ Avg Time Per Session: 2046.60ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 4 complete: 2 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 5, reasons: 4, locations: 4, total: 13 }
[StrategicDiscoveryService] Discovery phase complete: {
  totalProcessed: 20,
  uniqueIntents: 5,
  uniqueReasons: 4,
  uniqueLocations: 4,
  discoveryRate: 0.8666666666666667
}

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T15:22:22.290Z
ğŸ§  Model: gpt-4o-mini
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 1ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 128,000 tokens
ğŸŒŠ Recommended Streams: 4
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms
[ParallelAutoAnalyzeService] Using parallel config: {
  streamCount: 4,
  sessionsPerStream: 20,
  maxSessionsPerLLMCall: 50,
  syncFrequency: 'after_each_round',
  retryAttempts: 3,
  debugLogging: false
}

ğŸš€ ============ PARALLEL PROCESSING STARTED ============
â±ï¸  Start Time: 2025-08-12T15:22:22.290Z
ğŸ“Š Total Sessions: 80

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T15:22:22.290Z
ğŸ§  Model: gpt-4o-mini
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 128,000 tokens
ğŸŒŠ Recommended Streams: 4
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms

âš™ï¸  ============ PARALLEL CONFIGURATION ============
â±ï¸  Config Time: 0ms
ğŸ”§ Stream Count: 4
ğŸ“¦ Sessions Per Stream: 20
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per API Call: 50
ğŸ¯ Debug Logging: false

ğŸ”„ ============ ROUND 1/1 STARTED ============
â±ï¸  Round 1 Start: 2025-08-12T15:22:22.290Z
ğŸ“Š Sessions Remaining: 80
[ParallelProcessingOrchestrator] Distributed 80 sessions across 4 streams: [
  'Stream 1: 20 sessions',
  'Stream 2: 20 sessions',
  'Stream 3: 20 sessions',
  'Stream 4: 20 sessions'
]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 4

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 4 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T15:22:22.290Z
ğŸ“Š Sessions Assigned: 20
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T15:22:22.290Z
ğŸ“Š Sessions to Estimate: 20
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 20
   â€¢ Session Tokens: 4843
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 10343
   â€¢ Avg Per Session: 242 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 10343
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0025
ğŸ“Š Recommended Batch Size: 20

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 10343
ğŸ“¦ Recommended Batch Size: 20
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0025

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:22:22.290Z
ğŸ“Š Sessions to Analyze: 20
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 4
   â€¢ Locations: 4

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:22:22.291Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 20,
  apiKey: 'sk-proj-...',
  promptLength: 22429,
  existingClassifications: { intents: 5, transferReasons: 4, dropOffLocations: 4 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, New Leave, Unknown
Existing Transfer Reason classifications: Invalid Leave Request Input, Invalid Leave Request Number, Live Agent Request, New Leave Request
Existing Drop-Off Location classifications: Help Offer Prompt, Leave Request Confirmation Prompt, Leave Request Number Prompt, New Leave Request Prompt

...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T15:22:22.291Z
ğŸ“Š Sessions Assigned: 20
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T15:22:22.291Z
ğŸ“Š Sessions to Estimate: 20
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 20
   â€¢ Session Tokens: 3934
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 9434
   â€¢ Avg Per Session: 197 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 9434
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0023
ğŸ“Š Recommended Batch Size: 20

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 9434
ğŸ“¦ Recommended Batch Size: 20
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0023

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:22:22.291Z
ğŸ“Š Sessions to Analyze: 20
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 4
   â€¢ Locations: 4

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:22:22.291Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 20,
  apiKey: 'sk-proj-...',
  promptLength: 18126,
  existingClassifications: { intents: 5, transferReasons: 4, dropOffLocations: 4 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, New Leave, Unknown
Existing Transfer Reason classifications: Invalid Leave Request Input, Invalid Leave Request Number, Live Agent Request, New Leave Request
Existing Drop-Off Location classifications: Help Offer Prompt, Leave Request Confirmation Prompt, Leave Request Number Prompt, New Leave Request Prompt

...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T15:22:22.291Z
ğŸ“Š Sessions Assigned: 20
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T15:22:22.291Z
ğŸ“Š Sessions to Estimate: 20
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 20
   â€¢ Session Tokens: 4193
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 9693
   â€¢ Avg Per Session: 210 tokens
   â€¢ Estimation Time: 1ms
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 9693
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0023
ğŸ“Š Recommended Batch Size: 20

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 1ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 9693
ğŸ“¦ Recommended Batch Size: 20
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0023

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:22:22.292Z
ğŸ“Š Sessions to Analyze: 20
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 4
   â€¢ Locations: 4

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:22:22.293Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 20,
  apiKey: 'sk-proj-...',
  promptLength: 19351,
  existingClassifications: { intents: 5, transferReasons: 4, dropOffLocations: 4 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, New Leave, Unknown
Existing Transfer Reason classifications: Invalid Leave Request Input, Invalid Leave Request Number, Live Agent Request, New Leave Request
Existing Drop-Off Location classifications: Help Offer Prompt, Leave Request Confirmation Prompt, Leave Request Number Prompt, New Leave Request Prompt

...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T15:22:22.293Z
ğŸ“Š Sessions Assigned: 20
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T15:22:22.293Z
ğŸ“Š Sessions to Estimate: 20
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 20
   â€¢ Session Tokens: 3938
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 9438
   â€¢ Avg Per Session: 197 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 9438
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0023
ğŸ“Š Recommended Batch Size: 20

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 9438
ğŸ“¦ Recommended Batch Size: 20
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0023

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:22:22.293Z
ğŸ“Š Sessions to Analyze: 20
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 4
   â€¢ Locations: 4

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:22:22.294Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 20,
  apiKey: 'sk-proj-...',
  promptLength: 18254,
  existingClassifications: { intents: 5, transferReasons: 4, dropOffLocations: 4 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, New Leave, Unknown
Existing Transfer Reason classifications: Invalid Leave Request Input, Invalid Leave Request Number, Live Agent Request, New Leave Request
Existing Drop-Off Location classifications: Help Offer Prompt, Leave Request Confirmation Prompt, Leave Request Number Prompt, New Leave Request Prompt

...
::1 - - [12/Aug/2025:15:22:22 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1340 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:23 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1340 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:24 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1340 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:25 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1340 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:26 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1340 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:27 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1340 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:29 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1340 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:30 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1340 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:31 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1340 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:32 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1340 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:33 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1340 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:34 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1340 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:35 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1340 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:36 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1340 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:37 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1340 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:38 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1340 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:39 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1340 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:40 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1340 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:41 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1340 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:42 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1340 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:43 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1340 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:44 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1340 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:45 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1340 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:46 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1340 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:47 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1340 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:48 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1340 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:22:48.729Z',
  duration: '26438ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 6013,
    completion_tokens: 1262,
    total_tokens: 7275,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 18,
  intentsFound: [
    'Claim Status',
    'New Leave',
    'Live Agent',
    'Unknown',
    'Time Entry'
  ],
  transferCount: 16,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-11ddf817-5377-5a96-ba37-e6bac7b38e22",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "New Leave Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked about claim status and was transferred for assistance with a new leave request."
    },
    {
      "user_id": "u-5104cfab-d60d-5e1e-bbb0-52443becb283",
      "general_intent": "New Leave",
      "session_outcome": "Transfer",
      "transfer_reason": "New Leave Request",
      "drop_off_location": "Leave Request Number Prompt",
      "notes": "User inquired about medical leave and was transferred to open a new leave request."
    },
    {
      "user_id": "u-4c6f597d-4979-52e0-b8d8-775f53e48b5e",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-940fb86f-5e21-50bf-bf9d-e36a1852c526",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User expressed a need to speak with a representative and was transferred."
    },
    {
      "user_id": "u-478775ad-886e-5f8e-a300-836b5e538e85",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "",
      "notes": "User requested login assistance and was transferred."
    },
    {
      "user_id": "u-803e30a8-545e-5f2a-8df2-cf0e593045d1",
      "general_intent": "New Leave",
      "session_outcome": "Transfer",
      "transfer_reason": "Invalid Leave Request Input",
      "drop_off_location": "Leave Request Number Prompt",
      "notes": "User did not know their leave request number and was transferred for assistance."
    },
    {
      "user_id": "u-a6978468-90b7-5587-90d7-332d81678b60",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative after checking claim status."
    },
    {
      "user_id": "u-a47a2731-7593-5c76-98be-2fe2cc9a78e1",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "",
      "notes": "User was silent and then transferred to an agent."
    },
    {
      "user_id": "u-1e24e484-5210-5239-b4d9-13b8d9e18590",
      "general_intent": "New Leave",
      "session_outcome": "Transfer",
      "transfer_reason": "New Leave Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User repeatedly requested to apply for FMLA and was transferred."
    },
    {
      "user_id": "u-17861c4e-0de2-5325-b33e-b90ed23e1cd1",
      "general_intent": "Time Entry",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User successfully submitted a time entry and ended the session."
    },
    {
      "user_id": "u-398a93d9-0f98-5ee5-9fea-68cd8ca7b475",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred."
    },
    {
      "user_id": "u-39ab7ef4-fa48-5b7c-944e-b677006de466",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred."
    },
    {
      "user_id": "u-20468381-dd9d-5c86-9a19-d17d46f5d2c0",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred."
    },
    {
      "user_id": "u-1c515447-62d3-51e0-bb02-af65981f7021",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User was silent and the session ended without a transfer."
    },
    {
      "user_id": "u-0167d19d-dbaf-590b-a131-7d95c7966789",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-0d1e594c-7986-5aca-a975-7fe71f919e04",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to extend leave after checking claim status and was transferred."
    },
    {
      "user_id": "u-048fc09a-acf6-5cea-a145-3c54fe1b3512",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "",
      "notes": "User did not have their leave request number and was transferred."
    },
    {
      "user_id": "u-ec2b3b0e-10f3-59ea-977f-9d35b1959acd",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to talk to an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 6013,
  completionTokens: 1262,
  totalTokens: 7275,
  cost: '$0.001659',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 26439ms (26.44s)
ğŸ“Š Sessions Returned: 18
ğŸ’° Tokens Used: 7275 ($0.0017)
âš¡ Performance: 275.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 6013
   â€¢ Completion Tokens: 1262
[SessionValidationService] Validating batch response: 20 input sessions, 18 response sessions
[SessionValidationService] Validation issues found: { missing: 2, errors: 0, details: [] }
[Stream 1] 2 sessions missing, attempting retries

ğŸ”„ ===== RETRY 1/3 (Stream 1) =====
â±ï¸  Retry Start: 2025-08-12T15:22:48.730Z
ğŸ“Š Missing Sessions: 2

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:22:48.730Z
ğŸ“Š Sessions to Analyze: 2
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 4
   â€¢ Locations: 4

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:22:48.730Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 2,
  apiKey: 'sk-proj-...',
  promptLength: 6011,
  existingClassifications: { intents: 5, transferReasons: 4, dropOffLocations: 4 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, New Leave, Unknown
Existing Transfer Reason classifications: Invalid Leave Request Input, Invalid Leave Request Number, Live Agent Request, New Leave Request
Existing Drop-Off Location classifications: Help Offer Prompt, Leave Request Confirmation Prompt, Leave Request Number Prompt, New Leave Request Prompt

...
::1 - - [12/Aug/2025:15:22:49 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1340 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:50 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1340 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:22:50.374Z',
  duration: '28080ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 4960,
    completion_tokens: 1370,
    total_tokens: 6330,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 20,
  intentsFound: [
    'Leave Request',
    'Live Agent',
    'Claim Status',
    'New Leave',
    'Unknown',
    'Cancel FMLA'
  ],
  transferCount: 17,
  containedCount: 3
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-5585170e-046b-56ed-9f11-89ebc80a17ba",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Invalid Leave Request Number",
      "drop_off_location": "Leave Request Number Prompt",
      "notes": "User was unable to provide a leave request number and was transferred."
    },
    {
      "user_id": "u-e03474f1-ccbd-5a30-ac74-353851ab1ca3",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent and was transferred."
    },
    {
      "user_id": "u-1ff79543-478e-54ae-9cff-c136c63d65ce",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User inquired about claim status but did not provide further input."
    },
    {
      "user_id": "u-f8e67fd7-26c6-5869-a7c5-b1ce38835272",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Invalid Leave Request Input",
      "drop_off_location": "Leave Request Number Prompt",
      "notes": "User's claim was denied, and they were transferred after failing to provide further input."
    },
    {
      "user_id": "u-19211614-ceb2-562c-9b94-a123d6946add",
      "general_intent": "New Leave",
      "session_outcome": "Transfer",
      "transfer_reason": "New Leave Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to know how to get FMLA and was transferred."
    },
    {
      "user_id": "u-c9e7d1bc-aa93-5fbc-a614-04c77b12f695",
      "general_intent": "New Leave",
      "session_outcome": "Transfer",
      "transfer_reason": "New Leave Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to start a new claim and was transferred."
    },
    {
      "user_id": "u-cbd7d914-883a-5194-b127-4801ece95644",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a representative after checking claim status and was transferred."
    },
    {
      "user_id": "u-c0afc26b-9cf0-5e00-9e21-afb7c950b015",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent after receiving claim information and was transferred."
    },
    {
      "user_id": "u-56ee72ef-8e4c-515d-94e8-873157d58a71",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested customer service and was transferred."
    },
    {
      "user_id": "u-f9d34304-6fba-5c19-af4c-a65413fbcc09",
      "general_intent": "New Leave",
      "session_outcome": "Transfer",
      "transfer_reason": "New Leave Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User mentioned leave extension and was transferred."
    },
    {
      "user_id": "u-35b15ab6-454a-5903-871a-2b089b009326",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to talk to an agent and was transferred."
    },
    {
      "user_id": "u-a0666913-4d58-5b94-a76c-680d742c0f6f",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested customer service and was transferred."
    },
    {
      "user_id": "u-389c32a2-ca0b-56f5-9192-0e64459136f7",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred."
    },
    {
      "user_id": "u-49cc1e38-5568-5330-b7f1-938ded4f54f1",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred."
    },
    {
      "user_id": "u-5f0da122-7749-5e50-904e-79526a431799",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User was silent and the session ended without input."
    },
    {
      "user_id": "u-182c80a2-0aef-5853-96ab-32bc0b30eba4",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested customer service and was transferred."
    },
    {
      "user_id": "u-406d15a8-b0ef-5a58-9cd9-8c880f6907af",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Invalid Leave Request Number",
      "drop_off_location": "Leave Request Number Prompt",
      "notes": "User could not provide a leave request number and was transferred."
    },
    {
      "user_id": "u-c6944750-06cd-5a87-956f-eda6cde9eb30",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-d0e0e09d-ead6-5ff0-aec2-e4951795294c",
      "general_intent": "Cancel FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Invalid Leave Request Number",
      "drop_off_location": "Leave Request Number Prompt",
      "notes": "User's leave request number did not match records and was transferred."
    },
    {
      "user_id": "u-a95e2bb0-01d0-5cee-9de7-0ab054116df0",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User was silent and the session ended without input."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 4960,
  completionTokens: 1370,
  totalTokens: 6330,
  cost: '$0.001566',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 28082ms (28.08s)
ğŸ“Š Sessions Returned: 20
ğŸ’° Tokens Used: 6330 ($0.0016)
âš¡ Performance: 225.4 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 4960
   â€¢ Completion Tokens: 1370
[SessionValidationService] Validating batch response: 20 input sessions, 20 response sessions
[SessionValidationService] Validation successful: all 20 sessions processed
[SessionValidationService] Validating batch response: 20 input sessions, 20 response sessions
[SessionValidationService] Validation successful: all 20 sessions processed
â±ï¸  Stream 4 Single Batch Time: 28083ms (28.08s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 28083ms (28.08s)
ğŸ“Š Sessions Processed: 20/20
ğŸ’° Tokens Used: 6330 ($0.0016)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.7 sessions/sec
âš¡ Avg Time Per Session: 1404.15ms
::1 - - [12/Aug/2025:15:22:51 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1343 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:22:51.729Z',
  duration: '29436ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 5200,
    completion_tokens: 1331,
    total_tokens: 6531,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 20,
  intentsFound: [
    'FMLA questions',
    'New Leave',
    'Live Agent',
    'Unknown',
    'Report Absence',
    'FMLA usage',
    'Report Time',
    'Claim Status',
    'Leave Request'
  ],
  transferCount: 15,
  containedCount: 5
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-a46b8356-a373-55cc-bdb5-af718f8803b7",
      "general_intent": "FMLA questions",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked about FMLA questions and was transferred to a representative."
    },
    {
      "user_id": "u-0c634e3c-8e47-5bd1-bbf8-5cee8b3201f3",
      "general_intent": "New Leave",
      "session_outcome": "Transfer",
      "transfer_reason": "New Leave Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User initiated a new leave request and was transferred to an agent."
    },
    {
      "user_id": "u-4babac50-16b2-5e87-af6d-07f703f455d8",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative and was transferred."
    },
    {
      "user_id": "u-3369cf5d-53d9-5aec-a131-10243badd0ab",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User asked to talk to an agent but the session was not transferred."
    },
    {
      "user_id": "u-b6c42c42-a61b-52d7-b540-d306fa3d9d4a",
      "general_intent": "New Leave",
      "session_outcome": "Transfer",
      "transfer_reason": "New Leave Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User needed to close a previous FMLA request and was transferred."
    },
    {
      "user_id": "u-0dd5226b-3563-5c8d-99fc-2a59a078ac57",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-239d8f7d-9337-591f-9609-ac3bbd3191ea",
      "general_intent": "Report Absence",
      "session_outcome": "Contained",
      "notes": "User successfully reported an absence without needing a transfer."
    },
    {
      "user_id": "u-e90ecfbc-8076-5478-9110-5aa17ac54426",
      "general_intent": "FMLA usage",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to confirm last FMLA usage and was transferred."
    },
    {
      "user_id": "u-21ec5510-3818-5161-82bf-b38a6dcff7a1",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-9d0db34f-eb16-587f-b2bf-94ffc74fded3",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "Session ended without user input."
    },
    {
      "user_id": "u-ea09f536-f15d-5921-9b24-38dfc4dda89e",
      "general_intent": "New Leave",
      "session_outcome": "Transfer",
      "transfer_reason": "New Leave Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User started a new leave of absence and was transferred."
    },
    {
      "user_id": "u-e0e91d61-c794-544d-9096-de0f144b845e",
      "general_intent": "Report Time",
      "session_outcome": "Contained",
      "notes": "User successfully reported time without needing a transfer."
    },
    {
      "user_id": "u-3c731aeb-9f38-5af1-ac18-927c43341327",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-787a5144-68f9-5e75-8993-f50702d3492e",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User needed to talk to an agent and was transferred."
    },
    {
      "user_id": "u-a62a9657-6995-50b6-a91a-b82ce64b5906",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User inquired about claim status and was transferred."
    },
    {
      "user_id": "u-70821212-7794-5b9b-b961-b0150869f9cd",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-9b950db6-01a2-513e-8c26-a20cc29b9b5c",
      "general_intent": "Report Time",
      "session_outcome": "Contained",
      "notes": "User successfully reported time without needing a transfer."
    },
    {
      "user_id": "u-b6911ee8-f79d-5931-8d01-ddaf56fb63ab",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to discuss a leave request and was transferred."
    },
    {
      "user_id": "u-839310f0-10cb-5a49-a7fd-9bae76c87257",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-e4f4b47d-19cb-55fb-9b32-729b579dd83b",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 5200,
  completionTokens: 1331,
  totalTokens: 6531,
  cost: '$0.001579',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 29439ms (29.44s)
ğŸ“Š Sessions Returned: 20
ğŸ’° Tokens Used: 6531 ($0.0016)
âš¡ Performance: 221.8 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 5200
   â€¢ Completion Tokens: 1331
[SessionValidationService] Validating batch response: 20 input sessions, 20 response sessions
[SessionValidationService] Validation successful: all 20 sessions processed
[SessionValidationService] Validating batch response: 20 input sessions, 20 response sessions
[SessionValidationService] Validation successful: all 20 sessions processed
â±ï¸  Stream 3 Single Batch Time: 29439ms (29.44s)
[StreamProcessingService] Discovered 4 new classifications: { intents: 4, reasons: 0, locations: 0 }

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 29440ms (29.44s)
ğŸ“Š Sessions Processed: 20/20
ğŸ’° Tokens Used: 6531 ($0.0016)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.7 sessions/sec
âš¡ Avg Time Per Session: 1472.00ms
::1 - - [12/Aug/2025:15:22:52 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1346 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:22:52.317Z',
  duration: '3587ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1713,
    completion_tokens: 139,
    total_tokens: 1852,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 2,
  intentsFound: [ 'Time entry', 'Claim Status' ],
  transferCount: 1,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-fca0acbd-a6e9-5268-8d94-fe8f87f3ad1d",
      "general_intent": "Time entry",
      "session_outcome": "Contained",
      "notes": "User successfully submitted a time entry for an absence."
    },
    {
      "user_id": "u-72b5b2ba-8a2b-5b63-88b2-f2f2c5a05445",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative after confirming their claim status."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1713,
  completionTokens: 139,
  totalTokens: 1852,
  cost: '$0.000340',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 3587ms (3.59s)
ğŸ“Š Sessions Returned: 2
ğŸ’° Tokens Used: 1852 ($0.0003)
âš¡ Performance: 516.3 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1713
   â€¢ Completion Tokens: 139
[SessionValidationService] Validating batch response: 2 input sessions, 2 response sessions
[SessionValidationService] Validation successful: all 2 sessions processed
[SessionValidationService] Merging 18 original + 2 retry results
[SessionValidationService] Merge complete: 20 total sessions
âœ… Stream 1 Retry 1 Results:
   â€¢ Processed: 2 sessions
   â€¢ Still Missing: 0 sessions
[SessionValidationService] Validating batch response: 20 input sessions, 20 response sessions
[SessionValidationService] Validation successful: all 20 sessions processed
â±ï¸  Stream 1 Single Batch Time: 30027ms (30.03s)
[StreamProcessingService] Discovered 2 new classifications: { intents: 2, reasons: 0, locations: 0 }

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 30027ms (30.03s)
ğŸ“Š Sessions Processed: 20/20
ğŸ’° Tokens Used: 9127 ($0.0020)
ğŸ”„ Retry Attempts: 1
ğŸ¯ Performance: 0.7 sessions/sec
âš¡ Avg Time Per Session: 1501.35ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:22:52.886Z',
  duration: '30595ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 4838,
    completion_tokens: 1407,
    total_tokens: 6245,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 20,
  intentsFound: [
    'Claim Status',
    'Live Agent',
    'New Leave',
    'Track Time',
    'Unknown'
  ],
  transferCount: 17,
  containedCount: 3
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-d5283029-b70b-5943-966f-48e3a55e5bf4",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Leave Request Number Prompt",
      "notes": "User did not have the leave request number and was transferred to an agent."
    },
    {
      "user_id": "u-5b7afe28-40f9-530c-996a-780e9f5c2635",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative and was transferred."
    },
    {
      "user_id": "u-9f824a43-7e7d-52ad-8fbc-86967ba6f015",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-ac01e922-5fdc-5a3d-8962-4fd391ffd34b",
      "general_intent": "New Leave",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Leave Request Number Prompt",
      "notes": "User did not know the leave request number and was transferred to an agent."
    },
    {
      "user_id": "u-52aaf37c-953d-5f8e-b561-47331b18c07f",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-83775d60-2263-5e61-83e5-c20cf2aa5252",
      "general_intent": "Track Time",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User successfully submitted a time entry without needing a transfer."
    },
    {
      "user_id": "u-18e25ed1-fe5b-5c00-8506-88effc4fabdd",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-c7b6454e-f6fd-5cef-bb96-5a959e756b64",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User wanted to report a return to work but was unable to do so."
    },
    {
      "user_id": "u-f3e5dec6-3452-509a-b8b1-db7471b61976",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User checked on claim extension status and requested a representative."
    },
    {
      "user_id": "u-d58dce95-f9da-510a-9cba-6db904b5de70",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User did not provide any input after the initial greeting."
    },
    {
      "user_id": "u-52663033-d4df-54d4-b1a3-d3215b023c4a",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-8a9608ab-6733-5125-bb35-d10f0d28ab0a",
      "general_intent": "New Leave",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak about applying for FMLA and was transferred."
    },
    {
      "user_id": "u-a11c521b-c438-544c-b38f-2fd7a032f6cc",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-41ed4e63-17ec-5966-a680-7760ad837d2d",
      "general_intent": "New Leave",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User needed to open a new claim and was transferred."
    },
    {
      "user_id": "u-d6c0ca13-8f1c-5676-98a8-fd01e3a2465d",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Leave Request Number Prompt",
      "notes": "User did not have the leave request number and requested a representative."
    },
    {
      "user_id": "u-fb9a614e-5b64-5940-b0ac-1e9e028a0bac",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-0a335e1f-03a1-50c4-bd23-ba66013a61fe",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak about a denial issue and was transferred."
    },
    {
      "user_id": "u-2af5846d-93b1-5465-972e-64f7e811f0ac",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-8e0b9254-b3b2-5cd9-b3af-11d4915843ad",
      "general_intent": "New Leave",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User needed to adjust their leave and was transferred."
    },
    {
      "user_id": "u-c429451b-d385-51df-b134-c65284f20050",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 4838,
  completionTokens: 1407,
  totalTokens: 6245,
  cost: '$0.001570',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 30595ms (30.59s)
ğŸ“Š Sessions Returned: 20
ğŸ’° Tokens Used: 6245 ($0.0016)
âš¡ Performance: 204.1 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 4838
   â€¢ Completion Tokens: 1407
[SessionValidationService] Validating batch response: 20 input sessions, 20 response sessions
[SessionValidationService] Validation successful: all 20 sessions processed
[SessionValidationService] Validating batch response: 20 input sessions, 20 response sessions
[SessionValidationService] Validation successful: all 20 sessions processed
â±ï¸  Stream 2 Single Batch Time: 30596ms (30.60s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 30596ms (30.60s)
ğŸ“Š Sessions Processed: 20/20
ğŸ’° Tokens Used: 6245 ($0.0016)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.7 sessions/sec
âš¡ Avg Time Per Session: 1529.80ms
[ParallelProcessingOrchestrator] Parallel processing complete: 4/4 streams succeeded
â±ï¸  Parallel Processing Time: 30597ms (30.60s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 4 streams
[ParallelProcessingOrchestrator] Synchronization complete: 8 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 8
ğŸ“Š Total Classifications: 21

âœ… ============ ROUND 1 COMPLETED ============
â±ï¸  Round 1 Total Time: 30598ms (30.60s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 0
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 30597ms (100.0%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ‰ ============ PARALLEL PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 30598ms (30.60s)
ğŸ“Š Sessions Processed: 80/80
ğŸ”„ Total Rounds: 1
ğŸŒŠ Stream Results: 4
ğŸ’° Token Usage: 28233 tokens ($0.0067)
ğŸ“ˆ Stream Utilization: 100.0%
ğŸ¯ Performance: 2.6 sessions/second
âš¡ Avg Time Per Session: 382.48ms

ğŸ“Š Stream Performance Breakdown:
   Stream 1: 20 sessions in 30027ms (304.0 tokens/sec)
   Stream 2: 20 sessions in 30596ms (204.1 tokens/sec)
   Stream 3: 20 sessions in 29440ms (221.8 tokens/sec)
   Stream 4: 20 sessions in 28083ms (225.4 tokens/sec)
[ConflictResolutionService] Starting conflict resolution for 100 sessions
[ConflictResolutionService] Found classifications: { intents: 13, reasons: 4, locations: 4 }
[ConflictResolutionService] Calling LLM for conflict resolution with model gpt-4o-mini
ğŸ”§ Conflict Resolution Prompt Preview: You are reviewing classifications from parallel analysis streams. Identify any semantic duplicates and choose the canonical version for each group.

**Instructions:**
1. Look for classifications that refer to the same concept but use different wording
2. For each group of duplicates, choose the most...
::1 - - [12/Aug/2025:15:22:53 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1352 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:54 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1352 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:55 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1352 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:56 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1352 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:57 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1352 "-" "axios/1.11.0"
[ConflictResolutionService] LLM conflict resolution complete: { intents: 3, reasons: 2, locations: 1, tokens: 846, cost: 0.00018405 }
ğŸ”§ Conflict Resolution Response: {
  "generalIntents": [
    {
      "canonical": "Leave Request",
      "aliases": [
        "New Leave",
        "FMLA questions",
        "FMLA usage"
      ]
    },
    {
      "canonical": "Time Entry",
      "aliases": [
        "Time entry",
        "Report Time",
        "Track Time"
      ]
    },
    {
      "canonical": "Cancel FMLA",
      "aliases": [
        "FMLA questions"
      ]
    }
  ],
  "transferReasons": [
    {
      "canonical": "Invalid Leave Request",
      "aliases": [
        "Invalid Leave Request Input",
        "Invalid Leave Request Number"
      ]
    },
    {
      "canonical": "New Leave Request",
      "aliases": [
        "Live Agent Request"
      ]
    }
  ],
  "dropOffLocations": [
    {
      "canonical": "Leave Request Prompt",
      "aliases": [
        "Leave Request Confirmation Prompt",
        "Leave Request Number Prompt",
        "New Leave Request Prompt"
      ]
    }
  ]
}
[ConflictResolutionService] Applying resolutions to 100 sessions
[ConflictResolutionService] Applied 109 classification mappings across 100 sessions
[ConflictResolutionService] Identified 5 potential conflict groups
[ConflictResolutionService] Conflict resolution complete in 4822ms: { conflictsFound: 5, conflictsResolved: 6, canonicalMappings: 13 }
[ParallelAutoAnalyzeService] Using real analysis summary service
::1 - - [12/Aug/2025:15:22:58 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1434 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:22:59 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1434 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:23:00 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1434 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:23:01 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1434 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:23:02 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1434 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:23:03 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1434 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:23:04 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1434 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:23:05 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1434 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:23:06 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1434 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:23:07 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1434 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:23:08 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1434 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:23:09 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1434 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:23:10 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1434 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:23:11 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1434 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:23:12 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1434 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:23:13 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1434 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:23:14 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1434 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:23:15 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1434 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:23:16 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1434 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:23:17 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1434 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:23:18 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1434 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:23:19 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1434 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:23:20 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1434 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:23:21 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1434 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:23:22 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1434 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:23:23 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1434 "-" "axios/1.11.0"
[ParallelAutoAnalyzeService] Parallel analysis d94d825f-db3b-4e78-b31b-57fc288ef1fa completed successfully
[BackgroundJobQueue] Updated job progress to final state: complete
[BackgroundJobQueue] Parallel analysis job d94d825f-db3b-4e78-b31b-57fc288ef1fa-parallel completed successfully
::1 - - [12/Aug/2025:15:23:24 +0000] "GET /api/analysis/auto-analyze/parallel/progress/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 1475 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:23:24 +0000] "GET /api/analysis/auto-analyze/parallel/results/d94d825f-db3b-4e78-b31b-57fc288ef1fa HTTP/1.1" 200 718702 "-" "axios/1.11.0"
11:41:13 AM [tsx] change in ./src/services/parallelAutoAnalyzeService.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
11:41:51 AM [tsx] change in ./src/services/parallelProcessingOrchestratorService.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
ğŸš€ [ParallelAutoAnalyzeRoute] Starting parallel analysis for bot ***REMOVED*** with real credentials
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=real
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
ğŸ­ ServiceFactory: Creating OpenAI service (type: real)
ğŸš€ [ParallelAutoAnalyzeService] Starting parallel analysis ae758fd2-dc98-4990-8c42-6d1be3710591 with bot ***REMOVED***
ğŸš€ [ParallelAutoAnalyzeService] Using credentials: real
ğŸš€ [ParallelAutoAnalyzeRoute] Parallel analysis started: ae758fd2-dc98-4990-8c42-6d1be3710591
::1 - - [12/Aug/2025:15:42:20 +0000] "POST /api/analysis/auto-analyze/parallel/start HTTP/1.1" 200 214 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:42:20 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 541 "-" "axios/1.11.0"
[BackgroundJobQueue] Starting job processing after delay for job ae758fd2-dc98-4990-8c42-6d1be3710591-parallel
[BackgroundJobQueue] Starting processing for job ae758fd2-dc98-4990-8c42-6d1be3710591-parallel, phase: sampling
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing parallel analysis job ae758fd2-dc98-4990-8c42-6d1be3710591-parallel
[BackgroundJobQueue] Processing parallel analysis for bot ***REMOVED***
[BackgroundJobQueue] Using existing ParallelAutoAnalyzeService instance for bot ***REMOVED***
[BackgroundJobQueue] Session recreated for ae758fd2-dc98-4990-8c42-6d1be3710591
[ParallelAutoAnalyzeService] Running parallel analysis for ae758fd2-dc98-4990-8c42-6d1be3710591
[ParallelAutoAnalyzeService] Phase 0: Starting session sampling for ae758fd2-dc98-4990-8c42-6d1be3710591

ğŸ• ============ SESSION SAMPLING STARTED ============
ğŸ• [SessionSampling] Starting session sampling at 2025-08-12T15:42:21.294Z
ğŸ” [SessionDiscovery] Starting window 1/4: Initial 3-hour window
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-01T16:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-01T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-01T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-01T13:00:00.000Z",
  "dateTo": "2025-08-01T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
::1 - - [12/Aug/2025:15:42:21 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 714 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:42:22 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 714 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:42:23 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 714 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:42:24 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 714 "-" "axios/1.11.0"
[fetchContainmentTypeMetadata] API Response: 84 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '688ce3f084ec0f257aa40505',
  '688ce2f3270e0dfdc8bda516',
  '688ce1cb509249f46abf712e'
]
[fetchContainmentTypeMetadata] API Response: 123 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '688ce441f9118ccf9c084272',
  '688ce41284ec0f257aa408d2',
  '688ce40ae196ca760909852f'
]
::1 - - [12/Aug/2025:15:42:25 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 714 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:42:26 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 714 "-" "axios/1.11.0"
[fetchContainmentTypeMetadata] API Response: 1112 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '688ce47e3a3160d25d831f04',
  '688ce4786dc148aa9fbead83',
  '688ce465712518226a45c1f5'
]
[getSessionsMetadata] agent API call succeeded with 1112 sessions
[getSessionsMetadata] selfService API call succeeded with 84 sessions
[getSessionsMetadata] dropOff API call succeeded with 123 sessions
Total session metadata retrieved: 1319 (parallel execution)
Creating 1319 SWTs from metadata (no messages)
Created 1319 SWT objects from metadata
âœ… [SessionDiscovery] Window 1 completed in 5322ms: found 1319 new sessions (total: 1319)
â±ï¸  TIMING: Window 1 took 5322ms (5.32s)
ğŸ¯ [SessionDiscovery] Target reached! Found 1319 sessions in 5322ms
ğŸ² [SessionSampling] Random sampling from 1319 sessions to 100 sessions

ğŸ“¬ ============ MESSAGE RETRIEVAL STARTED ============
ğŸ“¬ [MessageRetrieval] Starting message retrieval for 100 sampled sessions at 2025-08-12T15:42:26.618Z
Using new lazy loading approach to populate messages for 100 sampled sessions
Populating messages for 100 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 100 sessions from 2025-08-01T13:02:39.840Z to 2025-08-01T15:58:58.273Z at 2025-08-12T15:42:26.618Z
ğŸš€ [ConcurrentBatch] Split 100 sessions into 5 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/5] Starting: 20 sessions
[Batch 2/5] Starting: 20 sessions
[Batch 3/5] Starting: 20 sessions
[Batch 4/5] Starting: 20 sessions
[Batch 5/5] Starting: 20 sessions
[Batch 2/5] Completed in 344ms: 205 messages retrieved (1/5 done)
ğŸ“Š [BatchProgress] Reporting batch 1/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 40/100 sessions (Batch 2/5)
[Batch 3/5] Completed in 352ms: 219 messages retrieved (2/5 done)
ğŸ“Š [BatchProgress] Reporting batch 2/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 60/100 sessions (Batch 3/5)
[Batch 1/5] Completed in 390ms: 284 messages retrieved (3/5 done)
ğŸ“Š [BatchProgress] Reporting batch 3/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 80/100 sessions (Batch 4/5)
[Batch 5/5] Completed in 489ms: 231 messages retrieved (4/5 done)
ğŸ“Š [BatchProgress] Reporting batch 4/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 100/100 sessions (Batch 5/5)
::1 - - [12/Aug/2025:15:42:27 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 815 "-" "axios/1.11.0"
[Batch 4/5] Completed in 837ms: 242 messages retrieved (5/5 done)
ğŸ“Š [BatchProgress] Reporting batch 5/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 100/100 sessions (Batch 6/5)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 838ms (0.84s)
â±ï¸  Batch Processing: 838ms (0.84s)
ğŸ“¦ Total batches: 5 (max 10 concurrent)
âœ… Successful batches: 5/5
ğŸ’¬ Total messages: 1181
ğŸ“ˆ Avg time per batch: 168ms
ğŸš€ Time per session: 8ms
ğŸ’ª Performance: 119.3 sessions/second
=======================================================

Retrieved 1181 messages for 100 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
Populated messages for 100 SWT objects
Successfully populated messages for 100 sessions using lazy loading
Applying final filtering to 100 sessions with populated messages
Final result: 99 sessions passed filtering with populated messages

ğŸ‰ ============ SESSION SAMPLING COMPLETED ============
â±ï¸  TOTAL TIME: 6170ms (6.17s)
â±ï¸  Session Discovery: 5322ms (5.32s) - 86.3% of total
â±ï¸  Message Retrieval: 846ms (0.85s) - 13.7% of total
â±ï¸  Performance: 16.0 sessions/second
ğŸ¯ Final result: 99 sessions with messages retrieved
====================================================

[StrategicDiscoveryService] Starting discovery phase with 99 total sessions
[StrategicDiscoveryService] Discovery config: {
  targetPercentage: 15,
  minSessions: 9,
  maxSessions: 14,
  diversityStrategy: {
    sessionLengths: [ 'short', 'medium', 'long' ],
    containmentTypes: [ 'agent', 'selfService', 'dropOff' ],
    timeDistribution: 'spread'
  }
}
[StrategicDiscoveryService] Selecting 14 diverse sessions from 99 total
[StrategicDiscoveryService] Session diversity groups: { short: 34, medium: 65, early: 33, middle: 33, late: 33 }
[StrategicDiscoveryService] Selected sessions by length distribution: { short: 5, medium: 9, long: 0 }
[StrategicDiscoveryService] Selected 14 sessions for discovery

ğŸ“¦ ===== BATCH 1 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T15:42:27.466Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Existing Classifications:
   â€¢ Intents: 0
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T15:42:27.466Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:42:27.468Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6206,
  existingClassifications: { intents: 0, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.



For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and another intent, classify the intent as the other i...
::1 - - [12/Aug/2025:15:42:28 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 920 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:42:29 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 920 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:42:30 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 920 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:42:31 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 920 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:42:32 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 920 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:42:33 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 920 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:42:34 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 920 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:42:34.936Z',
  duration: '7468ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1809,
    completion_tokens: 360,
    total_tokens: 2169,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Live Agent', 'New Claim' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-46f4b5b0-a6ef-5bf9-af2d-24974937620c",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred."
    },
    {
      "user_id": "u-23205d6d-a0f5-5089-9609-46c994d49f0c",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred."
    },
    {
      "user_id": "u-af30e0c7-1d41-508d-ae3f-e72a7f1c2d6e",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested customer service and was transferred."
    },
    {
      "user_id": "u-afa1496a-657d-54cd-9c1f-06ed3dcb2a39",
      "general_intent": "New Claim",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to start a new claim and was transferred."
    },
    {
      "user_id": "u-98273ef9-f407-55c3-930a-8391973b4fdf",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1809,
  completionTokens: 360,
  totalTokens: 2169,
  cost: '$0.000487',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 7471ms (7.47s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2169 ($0.0005)
âš¡ Performance: 290.3 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 7471ms (7.47s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2169

âœ… ===== BATCH 1 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 7471ms (7.47s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2169 ($0.0005)
âš¡ Performance: 0.7 sessions/sec
âš¡ Avg Time Per Session: 1494.20ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 1 complete: 4 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 2, reasons: 1, locations: 1, total: 4 }

ğŸ“¦ ===== BATCH 2 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T15:42:34.937Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Existing Classifications:
   â€¢ Intents: 2
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 1ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T15:42:34.938Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:42:34.938Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7938,
  existingClassifications: { intents: 2, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Live Agent, New Claim
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live A...
::1 - - [12/Aug/2025:15:42:35 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 937 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:42:36 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 937 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:42:37 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 937 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:42:38 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 937 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:42:39 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 937 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:42:40 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 937 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:42:41 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 937 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:42:41.917Z',
  duration: '6979ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 2230,
    completion_tokens: 333,
    total_tokens: 2563,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Unknown', 'Live Agent', 'Claim Status', 'New Claim' ],
  transferCount: 3,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-04ce0018-7c49-5230-8a33-2574965f0567",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User attempted to cancel a day off but did not provide the required information."
    },
    {
      "user_id": "u-2b454bab-05b3-5baa-8f27-9d6baca5023d",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative and was transferred."
    },
    {
      "user_id": "u-2ea323ea-9561-54f6-981e-a6ca37d2e11c",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative and was transferred."
    },
    {
      "user_id": "u-0e546ef2-a742-5243-bdfe-deeb1811e8b7",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User successfully submitted a time entry for an absence."
    },
    {
      "user_id": "u-a90f4169-9f8f-597f-9fc7-62a0bb2a1141",
      "general_intent": "New Claim",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to apply for ADA and was transferred for assistance."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2230,
  completionTokens: 333,
  totalTokens: 2563,
  cost: '$0.000534',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 6980ms (6.98s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2563 ($0.0005)
âš¡ Performance: 367.2 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 6980ms (6.98s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2563

âœ… ===== BATCH 2 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 6981ms (6.98s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2563 ($0.0005)
âš¡ Performance: 0.7 sessions/sec
âš¡ Avg Time Per Session: 1396.20ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 2 complete: 2 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 4, reasons: 1, locations: 1, total: 6 }

ğŸ“¦ ===== BATCH 3 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T15:42:41.919Z
ğŸ“Š Sessions in Batch: 4
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Existing Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 4
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T15:42:41.919Z
ğŸ“Š Sessions to Analyze: 4

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:42:41.920Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7123,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, New Claim, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing",...
::1 - - [12/Aug/2025:15:42:42 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 938 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:42:43 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 938 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:42:44 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 938 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:42:45 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 938 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:42:46 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 938 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:42:47 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 938 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:42:48.336Z',
  duration: '6416ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 2015,
    completion_tokens: 296,
    total_tokens: 2311,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown', 'New Claim', 'Live Agent' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-389c32a2-ca0b-56f5-9192-0e64459136f7",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to communicate with customer service after providing information about their license request."
    },
    {
      "user_id": "u-fc998e03-44ce-53df-943c-dee0d06b20ed",
      "general_intent": "New Claim",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to open a new claim but did not have the necessary leave request number."
    },
    {
      "user_id": "u-2badef03-c3eb-5536-8e42-bdb7be81722f",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred."
    },
    {
      "user_id": "u-d730fccf-76f8-50c4-b88b-e1ca3129d97f",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User expressed a desire to speak with customer service and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2015,
  completionTokens: 296,
  totalTokens: 2311,
  cost: '$0.000480',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 6417ms (6.42s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2311 ($0.0005)
âš¡ Performance: 360.1 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 4
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 6418ms (6.42s)
ğŸ“Š Regular Sessions Processed: 4
ğŸ’° Regular Tokens Used: 2311

âœ… ===== BATCH 3 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 6418ms (6.42s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Total Tokens: 2311 ($0.0005)
âš¡ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1604.50ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 3 complete: 0 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 4, reasons: 1, locations: 1, total: 6 }
[StrategicDiscoveryService] Discovery phase complete: {
  totalProcessed: 14,
  uniqueIntents: 4,
  uniqueReasons: 1,
  uniqueLocations: 1,
  discoveryRate: 0.4
}

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T15:42:48.338Z
ğŸ§  Model: gpt-4o-mini
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 128,000 tokens
ğŸŒŠ Recommended Streams: 4
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms
[ParallelProcessingOrchestrator] Configuration for 85 sessions:
  Design: 8 streams Ã— 4 sessions = 32 per round
  Optimal: 8 streams Ã— 4 sessions = 32 per round
  Estimated Rounds: 3
[ParallelAutoAnalyzeService] Using parallel config: {
  streamCount: 8,
  sessionsPerStream: 4,
  maxSessionsPerLLMCall: 50,
  syncFrequency: 'after_each_round',
  retryAttempts: 3,
  debugLogging: false
}

ğŸš€ ============ PARALLEL PROCESSING STARTED ============
â±ï¸  Start Time: 2025-08-12T15:42:48.368Z
ğŸ“Š Total Sessions: 85

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T15:42:48.368Z
ğŸ§  Model: gpt-4o-mini
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 128,000 tokens
ğŸŒŠ Recommended Streams: 4
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms

âš™ï¸  ============ PARALLEL CONFIGURATION ============
â±ï¸  Config Time: 0ms
ğŸ”§ Stream Count: 8
ğŸ“¦ Sessions Per Stream: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per API Call: 50
ğŸ¯ Debug Logging: false

ğŸ”„ ============ ROUND 1/3 STARTED ============
â±ï¸  Round 1 Start: 2025-08-12T15:42:48.369Z
ğŸ“Š Sessions Remaining: 85
[ParallelProcessingOrchestrator] Distributed 32 sessions across 8 streams: [
  'Stream 1: 4 sessions',
  'Stream 2: 4 sessions',
  'Stream 3: 4 sessions',
  'Stream 4: 4 sessions',
  'Stream 5: 4 sessions',
  'Stream 6: 4 sessions',
  'Stream 7: 4 sessions',
  'Stream 8: 4 sessions'
]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 8

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 8 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T15:42:48.369Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T15:42:48.369Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 861
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6361
   â€¢ Avg Per Session: 215 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6361
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6361
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:42:48.370Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:42:48.370Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6759,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, New Claim, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing",...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T15:42:48.370Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T15:42:48.370Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 938
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6438
   â€¢ Avg Per Session: 235 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6438
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6438
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:42:48.370Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:42:48.370Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7076,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, New Claim, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing",...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T15:42:48.370Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T15:42:48.370Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 774
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6274
   â€¢ Avg Per Session: 194 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6274
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6274
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:42:48.371Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:42:48.371Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6370,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, New Claim, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing",...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T15:42:48.371Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T15:42:48.371Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 723
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6223
   â€¢ Avg Per Session: 181 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6223
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6223
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:42:48.371Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:42:48.371Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6076,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, New Claim, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing",...

ğŸŒŠ ===== STREAM 5 PROCESSING START =====
â±ï¸  Stream 5 Start: 2025-08-12T15:42:48.371Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T15:42:48.371Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 826
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6326
   â€¢ Avg Per Session: 207 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6326
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 5) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6326
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015

âš¡ Stream 5: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:42:48.371Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:42:48.371Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6575,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, New Claim, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing",...

ğŸŒŠ ===== STREAM 6 PROCESSING START =====
â±ï¸  Stream 6 Start: 2025-08-12T15:42:48.371Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T15:42:48.371Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 706
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6206
   â€¢ Avg Per Session: 177 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6206
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 6) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6206
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015

âš¡ Stream 6: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:42:48.371Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:42:48.371Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6006,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, New Claim, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing",...

ğŸŒŠ ===== STREAM 7 PROCESSING START =====
â±ï¸  Stream 7 Start: 2025-08-12T15:42:48.372Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T15:42:48.372Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 852
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6352
   â€¢ Avg Per Session: 213 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6352
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 7) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6352
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015

âš¡ Stream 7: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:42:48.372Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:42:48.372Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6668,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, New Claim, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing",...

ğŸŒŠ ===== STREAM 8 PROCESSING START =====
â±ï¸  Stream 8 Start: 2025-08-12T15:42:48.372Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T15:42:48.372Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 660
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6160
   â€¢ Avg Per Session: 165 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6160
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 8) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6160
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015

âš¡ Stream 8: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:42:48.372Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:42:48.372Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5819,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, New Claim, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing",...
::1 - - [12/Aug/2025:15:42:48 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1701 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:42:49 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1701 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:42:50 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1701 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:42:51 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1701 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:42:52 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1701 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:42:53 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1701 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:42:54.140Z',
  duration: '5770ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1927,
    completion_tokens: 262,
    total_tokens: 2189,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown', 'New Claim', 'Live Agent' ],
  transferCount: 2,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-4a4c1bbe-1236-5635-b0cb-80f31d3d09e5",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User submitted a time entry successfully and ended the conversation."
    },
    {
      "user_id": "u-7b3afe1f-9efd-5586-9866-ca2b25e2b95f",
      "general_intent": "New Claim",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to reopen a claim and was transferred to an agent."
    },
    {
      "user_id": "u-2bd143bf-194a-5cd1-b524-08fc36091750",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with a representative and was transferred."
    },
    {
      "user_id": "u-be715ecc-5bb8-56e4-842a-9412af06f6e5",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User did not provide a leave request number and the bot could not assist further."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1927,
  completionTokens: 262,
  totalTokens: 2189,
  cost: '$0.000446',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 5771ms (5.77s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2189 ($0.0004)
âš¡ Performance: 379.3 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1927
   â€¢ Completion Tokens: 262
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 1 Single Batch Time: 5772ms (5.77s)

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 5773ms (5.77s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2189 ($0.0004)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.7 sessions/sec
âš¡ Avg Time Per Session: 1443.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:42:54.539Z',
  duration: '6168ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1734,
    completion_tokens: 298,
    total_tokens: 2032,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown', 'New Claim' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-c2e2afa7-126f-5691-b6cf-e84de6e5d806",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a representative after asking about medical certification verification."
    },
    {
      "user_id": "u-fb3124dd-b764-5098-98ac-a7f023e2a4d1",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User expressed a desire to speak with someone and was transferred to an agent."
    },
    {
      "user_id": "u-dc2f47a2-f1af-57c8-ad21-14f052e9271f",
      "general_intent": "New Claim",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to report a leave but was unable to do so and requested a representative."
    },
    {
      "user_id": "u-05b8af23-b3e6-5d4f-808a-a74fa15876a4",
      "general_intent": "New Claim",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to update a claim and was transferred to a representative."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1734,
  completionTokens: 298,
  totalTokens: 2032,
  cost: '$0.000439',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 6168ms (6.17s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2032 ($0.0004)
âš¡ Performance: 329.4 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1734
   â€¢ Completion Tokens: 298
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 4 Single Batch Time: 6168ms (6.17s)

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 6168ms (6.17s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2032 ($0.0004)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1542.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:42:54.578Z',
  duration: '6207ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1878,
    completion_tokens: 299,
    total_tokens: 2177,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Claim Status' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-ae323de8-6545-5c35-8405-af98494927c7",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to customer service and was transferred."
    },
    {
      "user_id": "u-f8c04a56-cc7d-5916-9058-fcf54b2b29b4",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User inquired about claim status but requested customer service and was transferred."
    },
    {
      "user_id": "u-28a1cd28-ae6c-53d2-9029-cf6346d28e4d",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User checked claim status and then requested to talk to an agent, leading to a transfer."
    },
    {
      "user_id": "u-0d2b24f1-1993-5421-97ab-a1ec5a2fcdcd",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User simply requested an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1878,
  completionTokens: 299,
  totalTokens: 2177,
  cost: '$0.000461',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 6207ms (6.21s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2177 ($0.0005)
âš¡ Performance: 350.7 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1878
   â€¢ Completion Tokens: 299
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 5 Single Batch Time: 6207ms (6.21s)

âœ… ===== STREAM 5 PROCESSING COMPLETE =====
â±ï¸  Stream 5 Total Time: 6207ms (6.21s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2177 ($0.0005)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1551.75ms
::1 - - [12/Aug/2025:15:42:54 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1707 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:42:54.592Z',
  duration: '6220ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1872,
    completion_tokens: 290,
    total_tokens: 2162,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown', 'New Claim' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-1bf07f3d-b845-5ca0-9f75-654db94b7804",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to sign up for FMLA but requested to talk to a representative."
    },
    {
      "user_id": "u-cdb7440c-3212-5a67-a651-12b20b0a53e5",
      "general_intent": "New Claim",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User needed to start a claim for caregiver FMLA but did not have the required information."
    },
    {
      "user_id": "u-765b99b3-36aa-5c13-8214-1106f8edd0fd",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "The session ended without any user input."
    },
    {
      "user_id": "u-be0864f9-c8fa-521e-93bd-949252fecb48",
      "general_intent": "New Claim",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to submit a new leave but did not have the necessary information."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1872,
  completionTokens: 290,
  totalTokens: 2162,
  cost: '$0.000455',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 6220ms (6.22s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2162 ($0.0005)
âš¡ Performance: 347.6 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1872
   â€¢ Completion Tokens: 290
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 7 Single Batch Time: 6220ms (6.22s)

âœ… ===== STREAM 7 PROCESSING COMPLETE =====
â±ï¸  Stream 7 Total Time: 6220ms (6.22s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2162 ($0.0005)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1555.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:42:54.641Z',
  duration: '6269ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1730,
    completion_tokens: 297,
    total_tokens: 2027,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown', 'New Claim', 'Claim Status' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-abd8bca7-513c-526a-9c03-b8174aec0b85",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred."
    },
    {
      "user_id": "u-3b297cbf-7da2-5aae-8755-cf0f4ca5b0ec",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User needed information about an FMLA form and was transferred."
    },
    {
      "user_id": "u-e650f203-9217-5052-aa8b-262311d2a9f5",
      "general_intent": "New Claim",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to start a new FMLA case and was transferred."
    },
    {
      "user_id": "u-b03713a1-b619-5a99-9d45-205579b79ac9",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User inquired about claim status and requested to talk to a person, leading to a transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1730,
  completionTokens: 297,
  totalTokens: 2027,
  cost: '$0.000438',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 6270ms (6.27s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2027 ($0.0004)
âš¡ Performance: 323.3 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1730
   â€¢ Completion Tokens: 297
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 6 Single Batch Time: 6270ms (6.27s)

âœ… ===== STREAM 6 PROCESSING COMPLETE =====
â±ï¸  Stream 6 Total Time: 6270ms (6.27s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2027 ($0.0004)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1567.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:42:54.743Z',
  duration: '6372ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1827,
    completion_tokens: 311,
    total_tokens: 2138,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown', 'New Claim', 'Claim Status' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-e9f07410-a3f6-57a1-8f43-f0ec6bdc46e9",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested assistance but was not clear, leading to a transfer to an agent."
    },
    {
      "user_id": "u-2350bff6-8f05-5929-8f3f-229f6662c45c",
      "general_intent": "New Claim",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to initiate a new leave request but was transferred to an agent for assistance."
    },
    {
      "user_id": "u-0058b805-3aed-5dfd-89d4-30527c990d14",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User inquired about claim status and was transferred to a representative after receiving the status."
    },
    {
      "user_id": "u-a53a8cbd-ad82-5cc8-9c88-443f5d47d716",
      "general_intent": "New Claim",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User attempted to request a new leave but did not provide the necessary information, leading to the session being closed."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1827,
  completionTokens: 311,
  totalTokens: 2138,
  cost: '$0.000461',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 6373ms (6.37s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2138 ($0.0005)
âš¡ Performance: 335.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1827
   â€¢ Completion Tokens: 311
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 3 Single Batch Time: 6374ms (6.37s)

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 6374ms (6.37s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2138 ($0.0005)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1593.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:42:54.916Z',
  duration: '6546ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1985,
    completion_tokens: 308,
    total_tokens: 2293,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'New Claim', 'Unknown', 'Claim Status' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-362c1ee5-8f55-5560-bfbc-a0608c4a8d44",
      "general_intent": "New Claim",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested assistance with a continuous FMLA but was transferred to an agent."
    },
    {
      "user_id": "u-b1b45088-91f2-5750-a287-71bc8647f707",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked about reporting absence but was transferred after providing an operator response."
    },
    {
      "user_id": "u-62e74f9e-4c02-5430-93fc-b35e94b04762",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User inquired about FMLA coverage for a grandchild but was transferred after multiple attempts to clarify."
    },
    {
      "user_id": "u-54000c10-cad2-53d9-9362-09efd9fcd9ed",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User successfully submitted a time entry but was transferred after a system error regarding the absence."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1985,
  completionTokens: 308,
  totalTokens: 2293,
  cost: '$0.000483',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 6546ms (6.55s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2293 ($0.0005)
âš¡ Performance: 350.3 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1985
   â€¢ Completion Tokens: 308
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 2 Single Batch Time: 6547ms (6.55s)

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 6547ms (6.55s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2293 ($0.0005)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1636.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:42:54.987Z',
  duration: '6614ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1692,
    completion_tokens: 312,
    total_tokens: 2004,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status', 'New Claim', 'Live Agent' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-20e350a8-253e-5d25-9984-751433e6528c",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to check the status of their leave request and was transferred to customer service."
    },
    {
      "user_id": "u-98c0a72c-fd7f-5752-8e0e-c106c25fcb44",
      "general_intent": "New Claim",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent initially but was transferred to an agent for assistance with a new leave request."
    },
    {
      "user_id": "u-1587f5a4-9286-5e4a-8404-b3f31aacaaa0",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred after pressing star."
    },
    {
      "user_id": "u-c7cd5ba0-5c35-5cad-8eeb-f80d065392e6",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User expressed the need to speak with a representative and was transferred after pressing star."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1692,
  completionTokens: 312,
  totalTokens: 2004,
  cost: '$0.000441',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 6615ms (6.62s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2004 ($0.0004)
âš¡ Performance: 302.9 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1692
   â€¢ Completion Tokens: 312
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 8 Single Batch Time: 6616ms (6.62s)

âœ… ===== STREAM 8 PROCESSING COMPLETE =====
â±ï¸  Stream 8 Total Time: 6616ms (6.62s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2004 ($0.0004)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1654.00ms
[ParallelProcessingOrchestrator] Parallel processing complete: 8/8 streams succeeded
â±ï¸  Parallel Processing Time: 6619ms (6.62s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 8 streams
[ParallelProcessingOrchestrator] Synchronization complete: 0 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 0
ğŸ“Š Total Classifications: 6

âœ… ============ ROUND 1 COMPLETED ============
â±ï¸  Round 1 Total Time: 6619ms (6.62s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 53
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 6619ms (100.0%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ”„ ============ ROUND 2/3 STARTED ============
â±ï¸  Round 2 Start: 2025-08-12T15:42:54.988Z
ğŸ“Š Sessions Remaining: 53
[ParallelProcessingOrchestrator] Distributed 32 sessions across 8 streams: [
  'Stream 1: 4 sessions',
  'Stream 2: 4 sessions',
  'Stream 3: 4 sessions',
  'Stream 4: 4 sessions',
  'Stream 5: 4 sessions',
  'Stream 6: 4 sessions',
  'Stream 7: 4 sessions',
  'Stream 8: 4 sessions'
]
â±ï¸  Session Distribution Time: 1ms
ğŸŒŠ Active Streams: 8

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 8 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T15:42:54.989Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T15:42:54.989Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 708
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6208
   â€¢ Avg Per Session: 177 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6208
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6208
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:42:54.989Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:42:54.989Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6000,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, New Claim, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing",...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T15:42:54.990Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T15:42:54.990Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 628
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6128
   â€¢ Avg Per Session: 157 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6128
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6128
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:42:54.990Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:42:54.990Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5606,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, New Claim, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing",...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T15:42:54.990Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T15:42:54.990Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 821
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6321
   â€¢ Avg Per Session: 205 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6321
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6321
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:42:54.990Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:42:54.991Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6518,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, New Claim, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing",...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T15:42:54.991Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T15:42:54.991Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 641
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6141
   â€¢ Avg Per Session: 160 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6141
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6141
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:42:54.991Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:42:54.991Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5710,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, New Claim, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing",...

ğŸŒŠ ===== STREAM 5 PROCESSING START =====
â±ï¸  Stream 5 Start: 2025-08-12T15:42:54.991Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T15:42:54.991Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 680
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6180
   â€¢ Avg Per Session: 170 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6180
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 5) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6180
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015

âš¡ Stream 5: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:42:54.991Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:42:54.991Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5845,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, New Claim, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing",...

ğŸŒŠ ===== STREAM 6 PROCESSING START =====
â±ï¸  Stream 6 Start: 2025-08-12T15:42:54.991Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T15:42:54.992Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 864
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6364
   â€¢ Avg Per Session: 216 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6364
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 6) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6364
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015

âš¡ Stream 6: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:42:54.992Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:42:54.992Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6713,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, New Claim, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing",...

ğŸŒŠ ===== STREAM 7 PROCESSING START =====
â±ï¸  Stream 7 Start: 2025-08-12T15:42:54.992Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T15:42:54.992Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 828
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6328
   â€¢ Avg Per Session: 207 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6328
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 7) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6328
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015

âš¡ Stream 7: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:42:54.992Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:42:54.992Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6502,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, New Claim, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing",...

ğŸŒŠ ===== STREAM 8 PROCESSING START =====
â±ï¸  Stream 8 Start: 2025-08-12T15:42:54.992Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T15:42:54.992Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 705
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6205
   â€¢ Avg Per Session: 176 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6205
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 8) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6205
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015

âš¡ Stream 8: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:42:54.993Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:42:54.993Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5959,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, New Claim, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing",...
::1 - - [12/Aug/2025:15:42:55 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1701 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:42:56 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1701 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:42:57 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1701 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:42:58 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1701 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:42:59 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1701 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:43:00 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1701 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:43:00.724Z',
  duration: '5732ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1890,
    completion_tokens: 280,
    total_tokens: 2170,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'New Claim', 'Claim Status' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-ba093af9-9e60-5cb1-9bb1-e951069d97a2",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred."
    },
    {
      "user_id": "u-2a5ef76f-88e8-592d-a5fd-f672ef836475",
      "general_intent": "New Claim",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to open a new claim but was transferred to an agent for assistance."
    },
    {
      "user_id": "u-9d4299c2-3cca-5725-9079-c19cf1b637f0",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User successfully submitted a time entry without needing to transfer."
    },
    {
      "user_id": "u-644b6d1b-3584-5726-b148-d70efdee8014",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1890,
  completionTokens: 280,
  totalTokens: 2170,
  cost: '$0.000451',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 5732ms (5.73s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2170 ($0.0005)
âš¡ Performance: 378.6 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1890
   â€¢ Completion Tokens: 280
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 6 Single Batch Time: 5732ms (5.73s)

âœ… ===== STREAM 6 PROCESSING COMPLETE =====
â±ï¸  Stream 6 Total Time: 5733ms (5.73s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2170 ($0.0005)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.7 sessions/sec
âš¡ Avg Time Per Session: 1433.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:43:00.895Z',
  duration: '5904ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1854,
    completion_tokens: 291,
    total_tokens: 2145,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'New Claim', 'Claim Status', 'Unknown' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-76b3cea1-90a8-5c29-875d-d78ceff4d1d8",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent."
    },
    {
      "user_id": "u-e72f18bf-1cf5-5545-af5e-0fa1d8fb32da",
      "general_intent": "New Claim",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User initiated a new claim request and was transferred to an agent."
    },
    {
      "user_id": "u-24970c75-c205-5274-877f-8745af07aa7a",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User inquired about the status of their claim and was transferred to an agent."
    },
    {
      "user_id": "u-16d0bfd9-cafa-5d76-a23e-77e739e07537",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User mentioned having a fax number and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1854,
  completionTokens: 291,
  totalTokens: 2145,
  cost: '$0.000453',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 5907ms (5.91s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2145 ($0.0005)
âš¡ Performance: 363.1 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1854
   â€¢ Completion Tokens: 291
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 3 Single Batch Time: 5907ms (5.91s)

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 5907ms (5.91s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2145 ($0.0005)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.7 sessions/sec
âš¡ Avg Time Per Session: 1476.75ms
::1 - - [12/Aug/2025:15:43:01 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1705 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:43:01.901Z',
  duration: '6908ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1706,
    completion_tokens: 287,
    total_tokens: 1993,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'New Claim' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-14310cc9-b1be-557d-b7e5-bf90be8b8245",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative and was transferred."
    },
    {
      "user_id": "u-47e80318-fa57-5c99-8522-bc04df3b6e2a",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent and was transferred."
    },
    {
      "user_id": "u-0f4cbdce-af99-5daf-b430-b1f180bf44f3",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative and was transferred."
    },
    {
      "user_id": "u-bdaf2614-f003-50e2-98d1-240b56b26230",
      "general_intent": "New Claim",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to set up FMLA and was transferred to a representative."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1706,
  completionTokens: 287,
  totalTokens: 1993,
  cost: '$0.000428',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 6908ms (6.91s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1993 ($0.0004)
âš¡ Performance: 288.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1706
   â€¢ Completion Tokens: 287
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 8 Single Batch Time: 6908ms (6.91s)

âœ… ===== STREAM 8 PROCESSING COMPLETE =====
â±ï¸  Stream 8 Total Time: 6909ms (6.91s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1993 ($0.0004)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1727.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:43:01.971Z',
  duration: '6982ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1729,
    completion_tokens: 282,
    total_tokens: 2011,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Claim Status' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-787a5144-68f9-5e75-8993-f50702d3492e",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to talk to an agent and was transferred."
    },
    {
      "user_id": "u-4aa466e4-7707-591d-aebf-c8012121280d",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User inquired about the status of their leave and received a denial response."
    },
    {
      "user_id": "u-0e39c3ad-a66e-5418-9ed0-4c3fadcdc306",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to talk to a representative and was transferred."
    },
    {
      "user_id": "u-acf40e6e-ed05-5df3-947c-b504d0d5233b",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User expressed the need to speak to an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1729,
  completionTokens: 282,
  totalTokens: 2011,
  cost: '$0.000429',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 6982ms (6.98s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2011 ($0.0004)
âš¡ Performance: 288.0 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1729
   â€¢ Completion Tokens: 282
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 1 Single Batch Time: 6983ms (6.98s)

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 6983ms (6.98s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2011 ($0.0004)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1745.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:43:01.999Z',
  duration: '7008ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1682,
    completion_tokens: 282,
    total_tokens: 1964,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-46e68591-6dec-529a-a3e0-adf818eaf393",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative and was transferred."
    },
    {
      "user_id": "u-b4be637e-ae9e-5eac-b9c9-6b98412d008b",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User expressed a need to talk to a representative and was transferred."
    },
    {
      "user_id": "u-bd877866-8331-59ad-9da8-68389cf33e63",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to talk to a representative and was transferred."
    },
    {
      "user_id": "u-6301c03b-4fad-538d-8aea-1f166ee2298d",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a representative and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1682,
  completionTokens: 282,
  totalTokens: 1964,
  cost: '$0.000421',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 7009ms (7.01s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1964 ($0.0004)
âš¡ Performance: 280.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1682
   â€¢ Completion Tokens: 282
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 5 Single Batch Time: 7009ms (7.01s)

âœ… ===== STREAM 5 PROCESSING COMPLETE =====
â±ï¸  Stream 5 Total Time: 7009ms (7.01s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1964 ($0.0004)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1752.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:43:02.478Z',
  duration: '7488ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1618,
    completion_tokens: 284,
    total_tokens: 1902,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown', 'New Claim', 'Live Agent' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-09b3d384-ff12-5a5a-a2d7-7be1a49d22d6",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "The user did not provide any input, and the bot closed the conversation."
    },
    {
      "user_id": "u-b165d99b-45c6-50fb-ae11-3fe4a6c72497",
      "general_intent": "New Claim",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "The user requested to file a claim and was transferred to an agent."
    },
    {
      "user_id": "u-a6484d20-cd08-5551-8625-a9f7cafd3bf2",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "The user requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-1b308d7a-ef77-585b-b592-abab690ba93f",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "The user expressed a desire to speak with customer service and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1618,
  completionTokens: 284,
  totalTokens: 1902,
  cost: '$0.000413',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 7488ms (7.49s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1902 ($0.0004)
âš¡ Performance: 254.0 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1618
   â€¢ Completion Tokens: 284
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 2 Single Batch Time: 7488ms (7.49s)

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 7489ms (7.49s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1902 ($0.0004)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.5 sessions/sec
âš¡ Avg Time Per Session: 1872.25ms
::1 - - [12/Aug/2025:15:43:02 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1713 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:43:02.850Z',
  duration: '7859ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1668,
    completion_tokens: 277,
    total_tokens: 1945,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Unknown' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-e032d8e0-776c-5807-8213-f620059cdc76",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent but did not provide further input."
    },
    {
      "user_id": "u-7af4dcf5-6b55-5ffa-a5f0-d707c11858bc",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and did not respond to the bot's questions."
    },
    {
      "user_id": "u-871052f1-5195-514c-9add-87037ec6c575",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User explicitly requested to speak with an agent."
    },
    {
      "user_id": "u-de29ee29-821e-5f9e-9b1e-8a283dfec4ac",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User provided unclear responses and did not lead to a transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1668,
  completionTokens: 277,
  totalTokens: 1945,
  cost: '$0.000416',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 7859ms (7.86s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1945 ($0.0004)
âš¡ Performance: 247.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1668
   â€¢ Completion Tokens: 277
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 4 Single Batch Time: 7860ms (7.86s)

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 7860ms (7.86s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1945 ($0.0004)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.5 sessions/sec
âš¡ Avg Time Per Session: 1965.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:43:03.244Z',
  duration: '8252ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1828,
    completion_tokens: 286,
    total_tokens: 2114,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown', 'Claim Status' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-3763704d-65f6-5042-82c5-0c4d6ba3c8b7",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to someone after asking about FMLA."
    },
    {
      "user_id": "u-74bc22c2-2874-53eb-a2a7-224cbd52358b",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User expressed a desire to speak with a representative."
    },
    {
      "user_id": "u-0d7db48c-fd80-58ca-a211-3cb35c9ffa10",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent."
    },
    {
      "user_id": "u-98745b36-0269-5448-b788-5357151c0558",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User inquired about claim status but later requested to speak to a representative."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1828,
  completionTokens: 286,
  totalTokens: 2114,
  cost: '$0.000446',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 8252ms (8.25s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2114 ($0.0004)
âš¡ Performance: 256.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1828
   â€¢ Completion Tokens: 286
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 7 Single Batch Time: 8252ms (8.25s)

âœ… ===== STREAM 7 PROCESSING COMPLETE =====
â±ï¸  Stream 7 Total Time: 8252ms (8.25s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2114 ($0.0004)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.5 sessions/sec
âš¡ Avg Time Per Session: 2063.00ms
[ParallelProcessingOrchestrator] Parallel processing complete: 8/8 streams succeeded
â±ï¸  Parallel Processing Time: 8255ms (8.26s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 8 streams
[ParallelProcessingOrchestrator] Synchronization complete: 0 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 1ms
ğŸ†• New Classifications: 0
ğŸ“Š Total Classifications: 6

âœ… ============ ROUND 2 COMPLETED ============
â±ï¸  Round 2 Total Time: 8257ms (8.26s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 21
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 1ms (0.0%)
   â€¢ Parallel Processing: 8255ms (100.0%)
   â€¢ Synchronization: 1ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ”„ ============ ROUND 3/3 STARTED ============
â±ï¸  Round 3 Start: 2025-08-12T15:43:03.245Z
ğŸ“Š Sessions Remaining: 21
[ParallelProcessingOrchestrator] Distributed 21 sessions across 6 streams: [
  'Stream 1: 4 sessions',
  'Stream 2: 4 sessions',
  'Stream 3: 4 sessions',
  'Stream 4: 4 sessions',
  'Stream 5: 4 sessions',
  'Stream 6: 1 sessions'
]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 6

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 6 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T15:43:03.245Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T15:43:03.245Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 806
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6306
   â€¢ Avg Per Session: 202 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6306
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6306
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:43:03.245Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:43:03.245Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6490,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, New Claim, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing",...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T15:43:03.245Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T15:43:03.245Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 727
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6227
   â€¢ Avg Per Session: 182 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6227
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6227
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:43:03.245Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:43:03.245Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6059,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, New Claim, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing",...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T15:43:03.245Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T15:43:03.245Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 719
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6219
   â€¢ Avg Per Session: 180 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6219
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6219
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:43:03.246Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:43:03.246Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6082,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, New Claim, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing",...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T15:43:03.246Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T15:43:03.246Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 929
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6429
   â€¢ Avg Per Session: 232 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6429
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6429
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:43:03.246Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:43:03.246Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7030,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, New Claim, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing",...

ğŸŒŠ ===== STREAM 5 PROCESSING START =====
â±ï¸  Stream 5 Start: 2025-08-12T15:43:03.246Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T15:43:03.246Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 789
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6289
   â€¢ Avg Per Session: 197 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6289
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 5) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6289
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0015

âš¡ Stream 5: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:43:03.246Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:43:03.246Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6315,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, New Claim, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing",...

ğŸŒŠ ===== STREAM 6 PROCESSING START =====
â±ï¸  Stream 6 Start: 2025-08-12T15:43:03.246Z
ğŸ“Š Sessions Assigned: 1
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T15:43:03.246Z
ğŸ“Š Sessions to Estimate: 1
ğŸ§  Model: gpt-4o-mini
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 1
   â€¢ Session Tokens: 134
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 5634
   â€¢ Avg Per Session: 134 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4o-mini context window: 128000 tokens
[TokenManagementService] Max sessions per call for gpt-4o-mini: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 5634
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0014
ğŸ“Š Recommended Batch Size: 1

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 6) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 5634
ğŸ“¦ Recommended Batch Size: 1
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0014

âš¡ Stream 6: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T15:43:03.246Z
ğŸ“Š Sessions to Analyze: 1
ğŸ§  Model: gpt-4o-mini
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T15:43:03.246Z',
  model: 'gpt-4o-mini',
  modelId: 'gpt-4o-mini',
  sessionCount: 1,
  apiKey: 'sk-proj-...',
  promptLength: 3897,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, New Claim, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing",...
::1 - - [12/Aug/2025:15:43:03 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1511 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:43:04 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1511 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:43:05.480Z',
  duration: '2234ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1170,
    completion_tokens: 82,
    total_tokens: 1252,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 1,
  intentsFound: [ 'New Claim' ],
  transferCount: 1,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-22b5f9b8-76a0-53d2-b12f-5ba6b80203fa",
      "general_intent": "New Claim",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested assistance with a new claim but was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1170,
  completionTokens: 82,
  totalTokens: 1252,
  cost: '$0.000225',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2234ms (2.23s)
ğŸ“Š Sessions Returned: 1
ğŸ’° Tokens Used: 1252 ($0.0002)
âš¡ Performance: 560.4 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1170
   â€¢ Completion Tokens: 82
[SessionValidationService] Validating batch response: 1 input sessions, 1 response sessions
[SessionValidationService] Validation successful: all 1 sessions processed
[SessionValidationService] Validating batch response: 1 input sessions, 1 response sessions
[SessionValidationService] Validation successful: all 1 sessions processed
â±ï¸  Stream 6 Single Batch Time: 2235ms (2.23s)

âœ… ===== STREAM 6 PROCESSING COMPLETE =====
â±ï¸  Stream 6 Total Time: 2235ms (2.23s)
ğŸ“Š Sessions Processed: 1/1
ğŸ’° Tokens Used: 1252 ($0.0002)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.4 sessions/sec
âš¡ Avg Time Per Session: 2235.00ms
::1 - - [12/Aug/2025:15:43:05 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1513 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:43:06 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1513 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:43:07 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1513 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:43:08 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1513 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:43:08.749Z',
  duration: '5503ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1746,
    completion_tokens: 292,
    total_tokens: 2038,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Claim Status', 'New Claim' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-457f0af7-ac00-57fd-9a7d-c4f3f4997044",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative."
    },
    {
      "user_id": "u-e1259ebf-8b67-5312-a190-e66ecec69b48",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to get information on short term disability but was transferred to an agent."
    },
    {
      "user_id": "u-32ef949b-0f66-5a4e-836a-94aa2f03a37b",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User inquired about a fax and was transferred to an agent."
    },
    {
      "user_id": "u-9a70411f-c84b-5278-8e45-cc3df5eca779",
      "general_intent": "New Claim",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User initiated a new claim and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1746,
  completionTokens: 292,
  totalTokens: 2038,
  cost: '$0.000437',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 5503ms (5.50s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2038 ($0.0004)
âš¡ Performance: 370.3 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1746
   â€¢ Completion Tokens: 292
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 3 Single Batch Time: 5503ms (5.50s)

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 5504ms (5.50s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2038 ($0.0004)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.7 sessions/sec
âš¡ Avg Time Per Session: 1376.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:43:08.779Z',
  duration: '5533ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1981,
    completion_tokens: 287,
    total_tokens: 2268,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Unknown', 'Claim Status' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-e2b9696e-24be-54fc-b7d7-70977981bde0",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a person and was transferred to an agent."
    },
    {
      "user_id": "u-1eb26869-c8cf-5e74-9b57-78bbd5f5780c",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User successfully submitted a time entry but the session ended without further input."
    },
    {
      "user_id": "u-b4bfe538-4e74-584c-a337-c0e78dcd513a",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested help logging into their account after checking claim status and was transferred to an agent."
    },
    {
      "user_id": "u-a7db2465-195d-50eb-a73b-c571ee12283e",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1981,
  completionTokens: 287,
  totalTokens: 2268,
  cost: '$0.000469',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 5533ms (5.53s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2268 ($0.0005)
âš¡ Performance: 409.9 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1981
   â€¢ Completion Tokens: 287
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 4 Single Batch Time: 5533ms (5.53s)

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 5533ms (5.53s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2268 ($0.0005)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.7 sessions/sec
âš¡ Avg Time Per Session: 1383.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:43:08.844Z',
  duration: '5599ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1857,
    completion_tokens: 300,
    total_tokens: 2157,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status', 'Live Agent', 'Unknown' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-89c97244-5947-52a1-a439-e2431f2f6e4e",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent after receiving claim approval information."
    },
    {
      "user_id": "u-a8809c87-c034-5e4e-81d0-d4739763660c",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User pressed star to connect with an agent after expressing the desire to speak with one."
    },
    {
      "user_id": "u-83b9f524-58e6-5a08-96dd-2e7e8a17bc24",
      "general_intent": "Live Agent",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User expressed the need to speak to a representative but did not proceed to transfer."
    },
    {
      "user_id": "u-803e30a8-545e-5f2a-8df2-cf0e593045d1",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was unable to provide the required information and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1857,
  completionTokens: 300,
  totalTokens: 2157,
  cost: '$0.000459',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 5600ms (5.60s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2157 ($0.0005)
âš¡ Performance: 385.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1857
   â€¢ Completion Tokens: 300
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 1 Single Batch Time: 5600ms (5.60s)

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 5600ms (5.60s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2157 ($0.0005)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.7 sessions/sec
âš¡ Avg Time Per Session: 1400.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:43:09.553Z',
  duration: '6308ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1734,
    completion_tokens: 271,
    total_tokens: 2005,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status', 'Unknown' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-38d941bf-85a6-5060-86e0-d8cfbfefa3be",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User requested claim status but did not provide a leave request number."
    },
    {
      "user_id": "u-cc69b4bf-2a7c-5a30-bec7-b2f64c463154",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked to speak to a representative and was transferred."
    },
    {
      "user_id": "u-50fe3568-06bf-53f4-ad62-454c81abe586",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative and was transferred."
    },
    {
      "user_id": "u-967e019a-3cd7-5502-bd71-6f3b4e7bf12f",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to connect to customer service and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1734,
  completionTokens: 271,
  totalTokens: 2005,
  cost: '$0.000423',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 6309ms (6.31s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2005 ($0.0004)
âš¡ Performance: 317.8 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1734
   â€¢ Completion Tokens: 271
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 2 Single Batch Time: 6309ms (6.31s)

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 6309ms (6.31s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2005 ($0.0004)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1577.25ms
::1 - - [12/Aug/2025:15:43:09 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1521 "-" "axios/1.11.0"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T15:43:09.775Z',
  duration: '6529ms',
  model: 'gpt-4o-mini-2024-07-18',
  usage: {
    prompt_tokens: 1793,
    completion_tokens: 298,
    total_tokens: 2091,
    prompt_tokens_details: { cached_tokens: 1024, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'New Claim', 'Unknown', 'Live Agent' ],
  transferCount: 2,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-27f80a81-7957-560c-a1cc-196be36981f8",
      "general_intent": "New Claim",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested assistance with a new leave and was transferred after a silent response."
    },
    {
      "user_id": "u-7a45fa2e-13f7-5ebb-916e-b6e40386f235",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User inquired about extending a leave of absence but did not provide further input, leading to the session being closed."
    },
    {
      "user_id": "u-52a76cce-6913-5a1c-9730-d2a03cb43f20",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User inquired about family leave of absence but did not respond further, resulting in the session being closed."
    },
    {
      "user_id": "u-8d472192-981a-5d06-8f35-19f268164dbb",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred after pressing star."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1793,
  completionTokens: 298,
  totalTokens: 2091,
  cost: '$0.000448',
  modelUsedForCost: 'gpt-4o-mini'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 6530ms (6.53s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2091 ($0.0004)
âš¡ Performance: 320.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1793
   â€¢ Completion Tokens: 298
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 5 Single Batch Time: 6530ms (6.53s)

âœ… ===== STREAM 5 PROCESSING COMPLETE =====
â±ï¸  Stream 5 Total Time: 6530ms (6.53s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2091 ($0.0004)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1632.50ms
[ParallelProcessingOrchestrator] Parallel processing complete: 6/6 streams succeeded
â±ï¸  Parallel Processing Time: 6532ms (6.53s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 6 streams
[ParallelProcessingOrchestrator] Synchronization complete: 0 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 0
ğŸ“Š Total Classifications: 6

âœ… ============ ROUND 3 COMPLETED ============
â±ï¸  Round 3 Total Time: 6532ms (6.53s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 0
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 6532ms (100.0%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ‰ ============ PARALLEL PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 21409ms (21.41s)
ğŸ“Š Sessions Processed: 85/85
ğŸ”„ Total Rounds: 3
ğŸŒŠ Stream Results: 22
ğŸ’° Token Usage: 45077 tokens ($0.0095)
ğŸ“ˆ Stream Utilization: 100.0%
ğŸ¯ Performance: 4.0 sessions/second
âš¡ Avg Time Per Session: 251.87ms

ğŸ“Š Stream Performance Breakdown:
   Stream 1: 4 sessions in 5773ms (379.2 tokens/sec)
   Stream 2: 4 sessions in 6547ms (350.2 tokens/sec)
   Stream 3: 4 sessions in 6374ms (335.4 tokens/sec)
   Stream 4: 4 sessions in 6168ms (329.4 tokens/sec)
   Stream 5: 4 sessions in 6207ms (350.7 tokens/sec)
   Stream 6: 4 sessions in 6270ms (323.3 tokens/sec)
   Stream 7: 4 sessions in 6220ms (347.6 tokens/sec)
   Stream 8: 4 sessions in 6616ms (302.9 tokens/sec)
   Stream 1: 4 sessions in 6983ms (288.0 tokens/sec)
   Stream 2: 4 sessions in 7489ms (254.0 tokens/sec)
   Stream 3: 4 sessions in 5907ms (363.1 tokens/sec)
   Stream 4: 4 sessions in 7860ms (247.5 tokens/sec)
   Stream 5: 4 sessions in 7009ms (280.2 tokens/sec)
   Stream 6: 4 sessions in 5733ms (378.5 tokens/sec)
   Stream 7: 4 sessions in 8252ms (256.2 tokens/sec)
   Stream 8: 4 sessions in 6909ms (288.5 tokens/sec)
   Stream 1: 4 sessions in 5600ms (385.2 tokens/sec)
   Stream 2: 4 sessions in 6309ms (317.8 tokens/sec)
   Stream 3: 4 sessions in 5504ms (370.3 tokens/sec)
   Stream 4: 4 sessions in 5533ms (409.9 tokens/sec)
   Stream 5: 4 sessions in 6530ms (320.2 tokens/sec)
   Stream 6: 1 sessions in 2235ms (560.2 tokens/sec)
[ConflictResolutionService] Starting conflict resolution for 99 sessions
[ConflictResolutionService] Found classifications: { intents: 4, reasons: 1, locations: 1 }
[ConflictResolutionService] No conflicts detected, skipping resolution
[ParallelAutoAnalyzeService] Using real analysis summary service
::1 - - [12/Aug/2025:15:43:10 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1604 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:43:11 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1604 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:43:12 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1604 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:43:13 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1604 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:43:14 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1604 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:43:15 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1604 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:43:16 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1604 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:43:17 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1604 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:43:18 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1604 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:43:19 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1604 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:43:20 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1604 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:43:21 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1604 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:43:22 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1604 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:43:23 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1604 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:43:24 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1604 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:43:25 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1604 "-" "axios/1.11.0"
[ParallelAutoAnalyzeService] Parallel analysis ae758fd2-dc98-4990-8c42-6d1be3710591 completed successfully
[BackgroundJobQueue] Updated job progress to final state: complete
[BackgroundJobQueue] Parallel analysis job ae758fd2-dc98-4990-8c42-6d1be3710591-parallel completed successfully
::1 - - [12/Aug/2025:15:43:26 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 1644 "-" "axios/1.11.0"
::1 - - [12/Aug/2025:15:43:26 +0000] "GET /api/analysis/auto-analyze/parallel/results/ae758fd2-dc98-4990-8c42-6d1be3710591 HTTP/1.1" 200 654960 "-" "axios/1.11.0"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T15:56:07.142Z",
  "dateTo": "2025-08-12T15:57:07.142Z",
  "skip": 0,
  "limit": 1
}
::1 - - [12/Aug/2025:15:57:11 +0000] "GET /api/kore/test HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 1 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [ '689b6425bb458dd6a4293995' ]
[getSessionsMetadataForConnectionTest] Single API call succeeded with 1 sessions
::1 - - [12/Aug/2025:15:57:26 +0000] "GET /health HTTP/1.1" 200 190 "-" "curl/8.7.1"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T15:56:59.376Z",
  "dateTo": "2025-08-12T15:57:59.376Z",
  "skip": 0,
  "limit": 1
}
[fetchContainmentTypeMetadata] API Response: 1 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [ '689b64511dffa49ef37083a2' ]
[getSessionsMetadataForConnectionTest] Single API call succeeded with 1 sessions
::1 - - [12/Aug/2025:15:58:02 +0000] "GET /api/kore/test HTTP/1.1" 200 889 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[Direct API] Fetching real Kore.ai sessions from 2025-08-05T15:58:02.797Z to 2025-08-12T15:58:02.797Z for User Bot st-90549... (limit=50)
Retrieving sessions from 2025-08-05T15:58:02.797Z to 2025-08-12T15:58:02.797Z (limit=50), populateMessages=true...
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T15:58:02.797Z",
  "dateTo": "2025-08-12T15:58:02.797Z",
  "limit": 50
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T15:58:02.797Z",
  "dateTo": "2025-08-12T15:58:02.797Z",
  "skip": 0,
  "limit": 50
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T15:58:02.797Z",
  "dateTo": "2025-08-12T15:58:02.797Z",
  "skip": 0,
  "limit": 50
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T15:58:02.797Z",
  "dateTo": "2025-08-12T15:58:02.797Z",
  "skip": 0,
  "limit": 50
}
::1 - - [12/Aug/2025:15:58:13 +0000] "GET /api/analysis/sessions?limit=50 HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[getSessionsMetadata] agent API call failed: AxiosError: timeout of 30000ms exceeded
    at RedirectableRequest.handleRequestTimeout (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:657:16)
    at RedirectableRequest.emit (node:events:507:28)
    at Timeout.<anonymous> (/Users/kengrafals/workspace/xobcat/node_modules/follow-redirects/index.js:221:12)
    at listOnTimeout (node:internal/timers:608:17)
    at process.processTimers (node:internal/timers:543:7)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at runNextTicks (node:internal/process/task_queues:65:5)
    at listOnTimeout (node:internal/timers:569:9)
    at process.processTimers (node:internal/timers:543:7)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async Promise.allSettled (index 0)
    at async KoreApiService.getSessionsMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:342:23)
    at async SWTService.generateSWTs (/Users/kengrafals/workspace/xobcat/backend/src/services/swtService.ts:214:29)
    at async <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/analysis.ts:92:18) {
  code: 'ECONNABORTED',
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMTQyODIsImV4cCI6MTc1NTAxNzg4MiwiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.y4QHo8eitKresXvjXUfhgdZGZbY75Kw5Ca-fS_r-oKo',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '95',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
    data: '{"dateFrom":"2025-08-05T15:58:02.797Z","dateTo":"2025-08-12T15:58:02.797Z","skip":0,"limit":50}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> Writable {
    _events: {
      close: undefined,
      error: [Function: handleRequestError],
      prefinish: undefined,
      finish: undefined,
      drain: undefined,
      response: [Function: handleResponse],
      socket: [Array],
      timeout: undefined,
      abort: undefined
    },
    _writableState: WritableState {
      highWaterMark: 65536,
      length: 0,
      corked: 0,
      onwrite: [Function: bound onwrite],
      writelen: 0,
      bufferedIndex: 0,
      pendingcb: 0,
      Symbol(kState): 17580812,
      Symbol(kBufferedValue): null
    },
    _maxListeners: undefined,
    _options: {
      maxRedirects: 21,
      maxBodyLength: Infinity,
      protocol: 'https:',
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
      method: 'POST',
      headers: [Object: null prototype],
      agents: [Object],
      auth: undefined,
      family: undefined,
      beforeRedirect: [Function: dispatchBeforeRedirect],
      beforeRedirects: [Object],
      hostname: 'bots.kore.ai',
      port: '',
      agent: undefined,
      nativeProtocols: [Object],
      pathname: '/api/public/bot/***REMOVED***/getSessions',
      search: '?containmentType=agent'
    },
    _ended: true,
    _ending: true,
    _redirectCount: 0,
    _redirects: [],
    _requestBodyLength: 95,
    _requestBodyBuffers: [ [Object] ],
    _eventsCount: 3,
    _onNativeResponse: [Function (anonymous)],
    _currentRequest: ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: false,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 95,
      _hasBody: true,
      _trailer: '',
      finished: true,
      _headerSent: true,
      _closed: false,
      _header: 'POST /api/public/bot/***REMOVED***/getSessions?containmentType=agent HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMTQyODIsImV4cCI6MTc1NTAxNzg4MiwiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.y4QHo8eitKresXvjXUfhgdZGZbY75Kw5Ca-fS_r-oKo\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 95\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: bots.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
      _ended: false,
      res: null,
      aborted: false,
      timeoutCb: [Function: emitRequestTimeout],
      upgradeOrConnect: false,
      parser: [HTTPParser],
      maxHeadersCount: null,
      reusedSocket: true,
      host: 'bots.kore.ai',
      protocol: 'https:',
      _redirectable: [Circular *1],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    _currentUrl: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
    _timeout: null,
    Symbol(shapeMode): true,
    Symbol(kCapture): false
  }
}
[getSessionsMetadata] selfService API call failed: AxiosError: timeout of 30000ms exceeded
    at RedirectableRequest.handleRequestTimeout (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:657:16)
    at RedirectableRequest.emit (node:events:507:28)
    at Timeout.<anonymous> (/Users/kengrafals/workspace/xobcat/node_modules/follow-redirects/index.js:221:12)
    at listOnTimeout (node:internal/timers:608:17)
    at process.processTimers (node:internal/timers:543:7)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at runNextTicks (node:internal/process/task_queues:65:5)
    at listOnTimeout (node:internal/timers:569:9)
    at process.processTimers (node:internal/timers:543:7)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async Promise.allSettled (index 1)
    at async KoreApiService.getSessionsMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:342:23)
    at async SWTService.generateSWTs (/Users/kengrafals/workspace/xobcat/backend/src/services/swtService.ts:214:29)
    at async <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/analysis.ts:92:18) {
  code: 'ECONNABORTED',
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMTQyODIsImV4cCI6MTc1NTAxNzg4MiwiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.y4QHo8eitKresXvjXUfhgdZGZbY75Kw5Ca-fS_r-oKo',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '95',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService',
    data: '{"dateFrom":"2025-08-05T15:58:02.797Z","dateTo":"2025-08-12T15:58:02.797Z","skip":0,"limit":50}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> Writable {
    _events: {
      close: undefined,
      error: [Function: handleRequestError],
      prefinish: undefined,
      finish: undefined,
      drain: undefined,
      response: [Function: handleResponse],
      socket: [Array],
      timeout: undefined,
      abort: undefined
    },
    _writableState: WritableState {
      highWaterMark: 65536,
      length: 0,
      corked: 0,
      onwrite: [Function: bound onwrite],
      writelen: 0,
      bufferedIndex: 0,
      pendingcb: 0,
      Symbol(kState): 17580812,
      Symbol(kBufferedValue): null
    },
    _maxListeners: undefined,
    _options: {
      maxRedirects: 21,
      maxBodyLength: Infinity,
      protocol: 'https:',
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=selfService',
      method: 'POST',
      headers: [Object: null prototype],
      agents: [Object],
      auth: undefined,
      family: undefined,
      beforeRedirect: [Function: dispatchBeforeRedirect],
      beforeRedirects: [Object],
      hostname: 'bots.kore.ai',
      port: '',
      agent: undefined,
      nativeProtocols: [Object],
      pathname: '/api/public/bot/***REMOVED***/getSessions',
      search: '?containmentType=selfService'
    },
    _ended: true,
    _ending: true,
    _redirectCount: 0,
    _redirects: [],
    _requestBodyLength: 95,
    _requestBodyBuffers: [ [Object] ],
    _eventsCount: 3,
    _onNativeResponse: [Function (anonymous)],
    _currentRequest: ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: false,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 95,
      _hasBody: true,
      _trailer: '',
      finished: true,
      _headerSent: true,
      _closed: false,
      _header: 'POST /api/public/bot/***REMOVED***/getSessions?containmentType=selfService HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMTQyODIsImV4cCI6MTc1NTAxNzg4MiwiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.y4QHo8eitKresXvjXUfhgdZGZbY75Kw5Ca-fS_r-oKo\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 95\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: bots.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=selfService',
      _ended: false,
      res: null,
      aborted: false,
      timeoutCb: [Function: emitRequestTimeout],
      upgradeOrConnect: false,
      parser: [HTTPParser],
      maxHeadersCount: null,
      reusedSocket: false,
      host: 'bots.kore.ai',
      protocol: 'https:',
      _redirectable: [Circular *1],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    _currentUrl: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService',
    _timeout: null,
    Symbol(shapeMode): true,
    Symbol(kCapture): false
  }
}
[getSessionsMetadata] dropOff API call failed: AxiosError: timeout of 30000ms exceeded
    at RedirectableRequest.handleRequestTimeout (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:657:16)
    at RedirectableRequest.emit (node:events:507:28)
    at Timeout.<anonymous> (/Users/kengrafals/workspace/xobcat/node_modules/follow-redirects/index.js:221:12)
    at listOnTimeout (node:internal/timers:608:17)
    at process.processTimers (node:internal/timers:543:7)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at runNextTicks (node:internal/process/task_queues:65:5)
    at listOnTimeout (node:internal/timers:569:9)
    at process.processTimers (node:internal/timers:543:7)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async Promise.allSettled (index 2)
    at async KoreApiService.getSessionsMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:342:23)
    at async SWTService.generateSWTs (/Users/kengrafals/workspace/xobcat/backend/src/services/swtService.ts:214:29)
    at async <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/analysis.ts:92:18) {
  code: 'ECONNABORTED',
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMTQyODIsImV4cCI6MTc1NTAxNzg4MiwiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.y4QHo8eitKresXvjXUfhgdZGZbY75Kw5Ca-fS_r-oKo',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '95',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff',
    data: '{"dateFrom":"2025-08-05T15:58:02.797Z","dateTo":"2025-08-12T15:58:02.797Z","skip":0,"limit":50}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> Writable {
    _events: {
      close: undefined,
      error: [Function: handleRequestError],
      prefinish: undefined,
      finish: undefined,
      drain: undefined,
      response: [Function: handleResponse],
      socket: [Array],
      timeout: undefined,
      abort: undefined
    },
    _writableState: WritableState {
      highWaterMark: 65536,
      length: 0,
      corked: 0,
      onwrite: [Function: bound onwrite],
      writelen: 0,
      bufferedIndex: 0,
      pendingcb: 0,
      Symbol(kState): 17580812,
      Symbol(kBufferedValue): null
    },
    _maxListeners: undefined,
    _options: {
      maxRedirects: 21,
      maxBodyLength: Infinity,
      protocol: 'https:',
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff',
      method: 'POST',
      headers: [Object: null prototype],
      agents: [Object],
      auth: undefined,
      family: undefined,
      beforeRedirect: [Function: dispatchBeforeRedirect],
      beforeRedirects: [Object],
      hostname: 'bots.kore.ai',
      port: '',
      agent: undefined,
      nativeProtocols: [Object],
      pathname: '/api/public/bot/***REMOVED***/getSessions',
      search: '?containmentType=dropOff'
    },
    _ended: true,
    _ending: true,
    _redirectCount: 0,
    _redirects: [],
    _requestBodyLength: 95,
    _requestBodyBuffers: [ [Object] ],
    _eventsCount: 3,
    _onNativeResponse: [Function (anonymous)],
    _currentRequest: ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: false,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 95,
      _hasBody: true,
      _trailer: '',
      finished: true,
      _headerSent: true,
      _closed: false,
      _header: 'POST /api/public/bot/***REMOVED***/getSessions?containmentType=dropOff HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMTQyODIsImV4cCI6MTc1NTAxNzg4MiwiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.y4QHo8eitKresXvjXUfhgdZGZbY75Kw5Ca-fS_r-oKo\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 95\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: bots.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff',
      _ended: false,
      res: null,
      aborted: false,
      timeoutCb: [Function: emitRequestTimeout],
      upgradeOrConnect: false,
      parser: [HTTPParser],
      maxHeadersCount: null,
      reusedSocket: false,
      host: 'bots.kore.ai',
      protocol: 'https:',
      _redirectable: [Circular *1],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    _currentUrl: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff',
    _timeout: null,
    Symbol(shapeMode): true,
    Symbol(kCapture): false
  }
}
Total session metadata retrieved: 0 (parallel execution)
Retrieved 0 session metadata objects
No sessions found in the specified date range
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T15:58:29.961Z",
  "dateTo": "2025-08-12T15:59:29.961Z",
  "skip": 0,
  "limit": 1
}
[fetchContainmentTypeMetadata] API Response: 1 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [ '689b64baf54cdbf3deeff90c' ]
[getSessionsMetadataForConnectionTest] Single API call succeeded with 1 sessions
::1 - - [12/Aug/2025:15:59:32 +0000] "GET /api/kore/test HTTP/1.1" 200 851 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[Direct API] Fetching real Kore.ai sessions from 2025-08-05T15:59:33.476Z to 2025-08-12T15:59:33.476Z for User Bot st-90549... (limit=50)
Retrieving sessions from 2025-08-05T15:59:33.476Z to 2025-08-12T15:59:33.476Z (limit=50), populateMessages=true...
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T15:59:33.476Z",
  "dateTo": "2025-08-12T15:59:33.476Z",
  "limit": 50
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T15:59:33.476Z",
  "dateTo": "2025-08-12T15:59:33.476Z",
  "skip": 0,
  "limit": 50
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T15:59:33.476Z",
  "dateTo": "2025-08-12T15:59:33.476Z",
  "skip": 0,
  "limit": 50
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T15:59:33.476Z",
  "dateTo": "2025-08-12T15:59:33.476Z",
  "skip": 0,
  "limit": 50
}
::1 - - [12/Aug/2025:15:59:34 +0000] "GET /api/analysis/sessions?limit=50 HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 50 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b64baf54cdbf3deeff90c',
  '689b64b81fa10dad3e9cf5e4',
  '689b64b344ce186ba53af636'
]
[fetchContainmentTypeMetadata] API Response: 50 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b64e3dcfd96eb5e755353',
  '689b64e0144f8feea17e6096',
  '689b64df04e17fb1eb50b5f1'
]
[fetchContainmentTypeMetadata] API Response: 50 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b5fa505a45fff8903b3b2',
  '689b5ed544ce186ba53a290c',
  '689b5e381fa10dad3e9c1511'
]
[getSessionsMetadata] agent API call succeeded with 50 sessions
[getSessionsMetadata] selfService API call succeeded with 50 sessions
[getSessionsMetadata] dropOff API call succeeded with 50 sessions
Total session metadata retrieved: 150 (parallel execution)
Retrieved 150 session metadata objects
Creating 150 SWTs from metadata (no messages)
Created 150 SWT objects from metadata
Populating messages for all sessions (legacy behavior)
Populating messages for 150 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 150 sessions from 2025-08-12T14:46:45.512Z to 2025-08-12T15:59:32.067Z at 2025-08-12T15:59:36.234Z
ğŸš€ [ConcurrentBatch] Split 150 sessions into 8 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/8] Starting: 20 sessions
[Batch 2/8] Starting: 20 sessions
[Batch 3/8] Starting: 20 sessions
[Batch 4/8] Starting: 20 sessions
[Batch 5/8] Starting: 20 sessions
[Batch 6/8] Starting: 20 sessions
[Batch 7/8] Starting: 20 sessions
[Batch 8/8] Starting: 10 sessions
[Batch 3/8] Completed in 209ms: 159 messages retrieved (1/8 done)
[Batch 1/8] Completed in 217ms: 188 messages retrieved (2/8 done)
[Batch 2/8] Completed in 267ms: 248 messages retrieved (3/8 done)
[Batch 6/8] Completed in 449ms: 198 messages retrieved (4/8 done)
[Batch 8/8] Completed in 449ms: 88 messages retrieved (5/8 done)
[Batch 4/8] Completed in 543ms: 271 messages retrieved (6/8 done)
[Batch 7/8] Completed in 595ms: 230 messages retrieved (7/8 done)
[Batch 5/8] Completed in 713ms: 521 messages retrieved (8/8 done)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 715ms (0.71s)
â±ï¸  Batch Processing: 715ms (0.71s)
ğŸ“¦ Total batches: 8 (max 10 concurrent)
âœ… Successful batches: 8/8
ğŸ’¬ Total messages: 1903
ğŸ“ˆ Avg time per batch: 89ms
ğŸš€ Time per session: 5ms
ğŸ’ª Performance: 209.8 sessions/second
=======================================================

Retrieved 1903 messages for 150 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
Populated messages for 150 SWT objects
Generated 150 SWT objects in 3482ms using layered architecture
ğŸš€ [AutoAnalyzeRoute] Starting analysis for bot ***REMOVED*** with real credentials
ğŸš€ AutoAnalyzeService: Creating services for bot ***REMOVED***
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
ğŸ­ ServiceFactory: Creating OpenAI service (type: real)
ğŸš€ [AutoAnalyzeService] Starting analysis 517d4a25-5ec8-4028-832e-f2494fde8bbd with bot ***REMOVED***
ğŸš€ [AutoAnalyzeService] Using credentials: real
ğŸš€ [AutoAnalyzeRoute] Analysis started: 517d4a25-5ec8-4028-832e-f2494fde8bbd
::1 - - [12/Aug/2025:15:59:52 +0000] "POST /api/analysis/auto-analyze/start HTTP/1.1" 200 205 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:15:59:52 +0000] "GET /api/analysis/auto-analyze/progress/517d4a25-5ec8-4028-832e-f2494fde8bbd HTTP/1.1" 200 478 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:15:59:52 +0000] "GET /api/analysis/auto-analyze/progress/517d4a25-5ec8-4028-832e-f2494fde8bbd HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[BackgroundJobQueue] Starting job processing after delay for job 517d4a25-5ec8-4028-832e-f2494fde8bbd-sampling
[BackgroundJobQueue] Starting processing for job 517d4a25-5ec8-4028-832e-f2494fde8bbd-sampling, phase: sampling
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing sampling phase for job 517d4a25-5ec8-4028-832e-f2494fde8bbd-sampling
[BackgroundJobQueue] Processing sampling phase for bot: ***REMOVED***
[BackgroundJobQueue] Creating real service for bot: ***REMOVED***
[BackgroundJobQueue] Full config: {
  "botId": "***REMOVED***",
  "clientId": "***REMOVED***",
  "clientSecret": "***REMOVED***",
  "baseUrl": "https://bots.kore.ai"
}
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[BackgroundJobQueue] Created service type: RealKoreApiService

ğŸ• ============ SESSION SAMPLING STARTED ============
ğŸ• [SessionSampling] Starting session sampling at 2025-08-12T15:59:53.334Z
ğŸ” [SessionDiscovery] Starting window 1/4: Initial 3-hour window
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
::1 - - [12/Aug/2025:15:59:54 +0000] "GET /api/analysis/auto-analyze/progress/517d4a25-5ec8-4028-832e-f2494fde8bbd HTTP/1.1" 200 533 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:15:59:56 +0000] "GET /api/analysis/auto-analyze/progress/517d4a25-5ec8-4028-832e-f2494fde8bbd HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 80 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a1287849680ad9fe59e',
  '689229f9583056c6108e38fb',
  '68922914f8bee7ba6c3e67b8'
]
[fetchContainmentTypeMetadata] API Response: 139 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6a14dd27c3112087cd',
  '68922a22ef03d8ad2ec7b4ba',
  '68922a1278c1fe09a079719c'
]
::1 - - [12/Aug/2025:15:59:58 +0000] "GET /api/analysis/auto-analyze/progress/517d4a25-5ec8-4028-832e-f2494fde8bbd HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 1338 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6d14dd27c31120888b',
  '68922a62e3804084741191d5',
  '68922a523a3160d25de144c8'
]
[getSessionsMetadata] agent API call succeeded with 1338 sessions
[getSessionsMetadata] selfService API call succeeded with 80 sessions
[getSessionsMetadata] dropOff API call succeeded with 139 sessions
Total session metadata retrieved: 1557 (parallel execution)
Creating 1557 SWTs from metadata (no messages)
Created 1557 SWT objects from metadata
âœ… [SessionDiscovery] Window 1 completed in 5961ms: found 1557 new sessions (total: 1557)
â±ï¸  TIMING: Window 1 took 5961ms (5.96s)
ğŸ¯ [SessionDiscovery] Target reached! Found 1557 sessions in 5961ms
ğŸ² [SessionSampling] Random sampling from 1557 sessions to 10 sessions

ğŸ“¬ ============ MESSAGE RETRIEVAL STARTED ============
ğŸ“¬ [MessageRetrieval] Starting message retrieval for 10 sampled sessions at 2025-08-12T15:59:59.296Z
Using new lazy loading approach to populate messages for 10 sampled sessions
Populating messages for 10 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 10 sessions from 2025-08-05T13:02:08.497Z to 2025-08-05T15:00:41.867Z at 2025-08-12T15:59:59.296Z
ğŸ”„ [KoreAPI] Using single API call for 10 sessions (â‰¤20)
âœ… [KoreAPI] Single call completed in 271ms: 121 messages
Retrieved 121 messages for 10 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
Populated messages for 10 SWT objects
Successfully populated messages for 10 sessions using lazy loading
Applying final filtering to 10 sessions with populated messages
Final result: 9 sessions passed filtering with populated messages

ğŸ‰ ============ SESSION SAMPLING COMPLETED ============
â±ï¸  TOTAL TIME: 6234ms (6.23s)
â±ï¸  Session Discovery: 5961ms (5.96s) - 95.6% of total
â±ï¸  Message Retrieval: 272ms (0.27s) - 4.4% of total
â±ï¸  Performance: 1.4 sessions/second
ğŸ¯ Final result: 9 sessions with messages retrieved
====================================================

[BackgroundJobQueue] Found 9 sessions for job 517d4a25-5ec8-4028-832e-f2494fde8bbd-sampling
::1 - - [12/Aug/2025:16:00:00 +0000] "GET /api/analysis/auto-analyze/progress/517d4a25-5ec8-4028-832e-f2494fde8bbd HTTP/1.1" 200 527 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[BackgroundJobQueue] Starting job processing after delay for job 517d4a25-5ec8-4028-832e-f2494fde8bbd-sampling-analysis
[BackgroundJobQueue] Starting processing for job 517d4a25-5ec8-4028-832e-f2494fde8bbd-sampling-analysis, phase: analyzing
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing analysis phase for job 517d4a25-5ec8-4028-832e-f2494fde8bbd-sampling-analysis with 9 sessions
ğŸ­ ServiceFactory: Creating OpenAI service (type: real)

ğŸ“¦ ===== BATCH 1 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:00:00.572Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 0
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:00:00.572Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:00:00.573Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7289,
  existingClassifications: { intents: 0, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.



For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and another intent, classify the intent as the other i...
::1 - - [12/Aug/2025:16:00:02 +0000] "GET /api/analysis/auto-analyze/progress/517d4a25-5ec8-4028-832e-f2494fde8bbd HTTP/1.1" 200 519 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:00:04.340Z',
  duration: '3767ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2086,
    completion_tokens: 374,
    total_tokens: 2460,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Unknown' ],
  transferCount: 4,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-8ce3bc0e-54ba-5e2f-b5f4-68ed2c4a7a29",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "Session involved the user attempting to inquire about a medical leave but ultimately being transferred due to silence and no further input."
    },
    {
      "user_id": "u-42bc83ad-4850-5f70-a135-dc698ab12113",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative and was transferred to an agent."
    },
    {
      "user_id": "u-f6125d54-5ca8-5bae-9e19-b9a173113f45",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to reapply for FMLA and requested to speak with an agent, resulting in transfer."
    },
    {
      "user_id": "u-f6c53c85-1897-52ca-8a4a-4bfb2362b592",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User inquired about claim status, was unable to provide request number, and was transferred to an agent."
    },
    {
      "user_id": "u-ed64c08d-dc63-59ff-b026-a681a76a8306",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User mentioned 'Customer service' and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2086,
  completionTokens: 374,
  totalTokens: 2460,
  cost: '$0.000358',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 3768ms (3.77s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2460 ($0.0004)
âš¡ Performance: 652.9 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 3769ms (3.77s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2460

âœ… ===== BATCH 1 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 3769ms (3.77s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2460 ($0.0004)
âš¡ Performance: 1.3 sessions/sec
âš¡ Avg Time Per Session: 753.80ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:16:00:04 +0000] "GET /api/analysis/auto-analyze/progress/517d4a25-5ec8-4028-832e-f2494fde8bbd HTTP/1.1" 200 543 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"

ğŸ“¦ ===== BATCH 2 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:00:06.341Z
ğŸ“Š Sessions in Batch: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 1
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 4
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:00:06.341Z
ğŸ“Š Sessions to Analyze: 4

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:00:06.341Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6389,
  existingClassifications: { intents: 1, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provid...
::1 - - [12/Aug/2025:16:00:06 +0000] "GET /api/analysis/auto-analyze/progress/517d4a25-5ec8-4028-832e-f2494fde8bbd HTTP/1.1" 200 543 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:00:08 +0000] "GET /api/analysis/auto-analyze/progress/517d4a25-5ec8-4028-832e-f2494fde8bbd HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:00:09.172Z',
  duration: '2830ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1804,
    completion_tokens: 286,
    total_tokens: 2090,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Unknown' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-42c7b397-fd47-5241-8b19-49fab7008a25",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-9d101f6f-e7ea-57aa-b111-e2f074ad969c",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a new leave and was transferred to an agent."
    },
    {
      "user_id": "u-19e20948-c346-5385-a819-b19e71b75eec",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent and was transferred."
    },
    {
      "user_id": "u-d38e1cfe-1404-533b-b2b9-ea12af6e54ae",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested assistance with SNA and short term disability, transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1804,
  completionTokens: 286,
  totalTokens: 2090,
  cost: '$0.000295',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2832ms (2.83s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2090 ($0.0003)
âš¡ Performance: 738.0 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 4
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2832ms (2.83s)
ğŸ“Š Regular Sessions Processed: 4
ğŸ’° Regular Tokens Used: 2090

âœ… ===== BATCH 2 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2832ms (2.83s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Total Tokens: 2090 ($0.0003)
âš¡ Performance: 1.4 sessions/sec
âš¡ Avg Time Per Session: 708.00ms
â±ï¸  Metadata Processing: 0ms
[BackgroundJobQueue] Session analysis completed for job 517d4a25-5ec8-4028-832e-f2494fde8bbd-sampling-analysis, processed 9 sessions
::1 - - [12/Aug/2025:16:00:10 +0000] "GET /api/analysis/auto-analyze/progress/517d4a25-5ec8-4028-832e-f2494fde8bbd HTTP/1.1" 200 545 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:00:12 +0000] "GET /api/analysis/auto-analyze/progress/517d4a25-5ec8-4028-832e-f2494fde8bbd HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:00:14 +0000] "GET /api/analysis/auto-analyze/progress/517d4a25-5ec8-4028-832e-f2494fde8bbd HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:00:16 +0000] "GET /api/analysis/auto-analyze/progress/517d4a25-5ec8-4028-832e-f2494fde8bbd HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:00:18 +0000] "GET /api/analysis/auto-analyze/progress/517d4a25-5ec8-4028-832e-f2494fde8bbd HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:00:20 +0000] "GET /api/analysis/auto-analyze/progress/517d4a25-5ec8-4028-832e-f2494fde8bbd HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:00:22 +0000] "GET /api/analysis/auto-analyze/progress/517d4a25-5ec8-4028-832e-f2494fde8bbd HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:00:24 +0000] "GET /api/analysis/auto-analyze/progress/517d4a25-5ec8-4028-832e-f2494fde8bbd HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:00:26 +0000] "GET /api/analysis/auto-analyze/progress/517d4a25-5ec8-4028-832e-f2494fde8bbd HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:00:28 +0000] "GET /api/analysis/auto-analyze/progress/517d4a25-5ec8-4028-832e-f2494fde8bbd HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:00:30 +0000] "GET /api/analysis/auto-analyze/progress/517d4a25-5ec8-4028-832e-f2494fde8bbd HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[BackgroundJobQueue] Analysis summary generated for job 517d4a25-5ec8-4028-832e-f2494fde8bbd-sampling-analysis
[BackgroundJobQueue] Analysis completed for job 517d4a25-5ec8-4028-832e-f2494fde8bbd-sampling-analysis, processed 9 sessions
[BackgroundJobQueue] Results successfully stored in AutoAnalyzeService for analysis 517d4a25-5ec8-4028-832e-f2494fde8bbd
[BackgroundJobQueue] Analysis 517d4a25-5ec8-4028-832e-f2494fde8bbd completed with 9 sessions
::1 - - [12/Aug/2025:16:00:32 +0000] "GET /api/analysis/auto-analyze/progress/517d4a25-5ec8-4028-832e-f2494fde8bbd HTTP/1.1" 200 561 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:00:32 +0000] "GET /api/analysis/auto-analyze/results/517d4a25-5ec8-4028-832e-f2494fde8bbd HTTP/1.1" 200 70068 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T16:03:39.778Z",
  "dateTo": "2025-08-12T16:04:39.778Z",
  "skip": 0,
  "limit": 1
}
::1 - - [12/Aug/2025:16:04:39 +0000] "GET /api/kore/test HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 1 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [ '689b65eb6ebd43e3e6319e7c' ]
[getSessionsMetadataForConnectionTest] Single API call succeeded with 1 sessions
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T16:04:18.254Z",
  "dateTo": "2025-08-12T16:05:18.254Z",
  "skip": 0,
  "limit": 1
}
[fetchContainmentTypeMetadata] API Response: 1 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [ '689b6617296df1d830cc89e6' ]
[getSessionsMetadataForConnectionTest] Single API call succeeded with 1 sessions
::1 - - [12/Aug/2025:16:05:21 +0000] "GET /api/kore/test HTTP/1.1" 200 851 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T16:06:55.788Z",
  "dateTo": "2025-08-12T16:07:55.788Z",
  "skip": 0,
  "limit": 1
}
[fetchContainmentTypeMetadata] API Response: 1 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [ '689b66c8f32c5185525da73b' ]
[getSessionsMetadataForConnectionTest] Single API call succeeded with 1 sessions
::1 - - [12/Aug/2025:16:07:58 +0000] "GET /api/kore/test HTTP/1.1" 200 796 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[Direct API] Fetching real Kore.ai sessions from 2025-08-05T16:07:59.418Z to 2025-08-12T16:07:59.418Z for User Bot st-90549... (limit=50)
Retrieving sessions from 2025-08-05T16:07:59.418Z to 2025-08-12T16:07:59.418Z (limit=50), populateMessages=true...
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T16:07:59.418Z",
  "dateTo": "2025-08-12T16:07:59.418Z",
  "limit": 50
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T16:07:59.418Z",
  "dateTo": "2025-08-12T16:07:59.418Z",
  "skip": 0,
  "limit": 50
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T16:07:59.418Z",
  "dateTo": "2025-08-12T16:07:59.418Z",
  "skip": 0,
  "limit": 50
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T16:07:59.418Z",
  "dateTo": "2025-08-12T16:07:59.418Z",
  "skip": 0,
  "limit": 50
}
::1 - - [12/Aug/2025:16:08:00 +0000] "GET /api/analysis/sessions?limit=50 HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 50 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b66c8f32c5185525da73b',
  '689b66c20989a8bc72a295e5',
  '689b66b69516e359d07afaf1'
]
[fetchContainmentTypeMetadata] API Response: 50 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b66de144f8feea17ea6a6',
  '689b66deb1f082150b526c5d',
  '689b66d6886ba2d0d2496f19'
]
[fetchContainmentTypeMetadata] API Response: 50 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b6222224c97ecf1334098',
  '689b619cac87f2139d64b160',
  '689b614f144f8feea17de848'
]
[getSessionsMetadata] agent API call succeeded with 50 sessions
[getSessionsMetadata] selfService API call succeeded with 50 sessions
[getSessionsMetadata] dropOff API call succeeded with 50 sessions
Total session metadata retrieved: 150 (parallel execution)
Retrieved 150 session metadata objects
Creating 150 SWTs from metadata (no messages)
Created 150 SWT objects from metadata
Populating messages for all sessions (legacy behavior)
Populating messages for 150 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 150 sessions from 2025-08-12T14:52:09.865Z to 2025-08-12T16:07:58.621Z at 2025-08-12T16:08:05.906Z
ğŸš€ [ConcurrentBatch] Split 150 sessions into 8 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/8] Starting: 20 sessions
[Batch 2/8] Starting: 20 sessions
[Batch 3/8] Starting: 20 sessions
[Batch 4/8] Starting: 20 sessions
[Batch 5/8] Starting: 20 sessions
[Batch 6/8] Starting: 20 sessions
[Batch 7/8] Starting: 20 sessions
[Batch 8/8] Starting: 10 sessions
[Batch 1/8] Completed in 210ms: 225 messages retrieved (1/8 done)
[Batch 3/8] Completed in 262ms: 167 messages retrieved (2/8 done)
[Batch 2/8] Completed in 312ms: 256 messages retrieved (3/8 done)
[Batch 4/8] Completed in 438ms: 261 messages retrieved (4/8 done)
[Batch 8/8] Completed in 439ms: 119 messages retrieved (5/8 done)
[Batch 7/8] Completed in 470ms: 196 messages retrieved (6/8 done)
[Batch 6/8] Completed in 543ms: 226 messages retrieved (7/8 done)
[Batch 5/8] Completed in 681ms: 562 messages retrieved (8/8 done)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 681ms (0.68s)
â±ï¸  Batch Processing: 681ms (0.68s)
ğŸ“¦ Total batches: 8 (max 10 concurrent)
âœ… Successful batches: 8/8
ğŸ’¬ Total messages: 2012
ğŸ“ˆ Avg time per batch: 85ms
ğŸš€ Time per session: 5ms
ğŸ’ª Performance: 220.3 sessions/second
=======================================================

Retrieved 2012 messages for 150 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
Populated messages for 150 SWT objects
Generated 150 SWT objects in 7178ms using layered architecture
ğŸš€ [AutoAnalyzeRoute] Starting analysis for bot ***REMOVED*** with real credentials
ğŸš€ [AutoAnalyzeService] Starting analysis 221c0688-5d6b-4721-9725-02bf4b36750b with bot ***REMOVED***
ğŸš€ [AutoAnalyzeService] Using credentials: real
ğŸš€ [AutoAnalyzeRoute] Analysis started: 221c0688-5d6b-4721-9725-02bf4b36750b
::1 - - [12/Aug/2025:16:08:18 +0000] "POST /api/analysis/auto-analyze/start HTTP/1.1" 200 205 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:08:18 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 479 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:08:18 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[BackgroundJobQueue] Starting job processing after delay for job 221c0688-5d6b-4721-9725-02bf4b36750b-sampling
[BackgroundJobQueue] Starting processing for job 221c0688-5d6b-4721-9725-02bf4b36750b-sampling, phase: sampling
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing sampling phase for job 221c0688-5d6b-4721-9725-02bf4b36750b-sampling
[BackgroundJobQueue] Processing sampling phase for bot: ***REMOVED***
[BackgroundJobQueue] Creating real service for bot: ***REMOVED***
[BackgroundJobQueue] Full config: {
  "botId": "***REMOVED***",
  "clientId": "***REMOVED***",
  "clientSecret": "***REMOVED***",
  "baseUrl": "https://bots.kore.ai"
}
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[BackgroundJobQueue] Created service type: RealKoreApiService

ğŸ• ============ SESSION SAMPLING STARTED ============
ğŸ• [SessionSampling] Starting session sampling at 2025-08-12T16:08:19.229Z
ğŸ” [SessionDiscovery] Starting window 1/4: Initial 3-hour window
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
::1 - - [12/Aug/2025:16:08:20 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 534 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 80 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a1287849680ad9fe59e',
  '689229f9583056c6108e38fb',
  '68922914f8bee7ba6c3e67b8'
]
[fetchContainmentTypeMetadata] API Response: 139 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6a14dd27c3112087cd',
  '68922a22ef03d8ad2ec7b4ba',
  '68922a1278c1fe09a079719c'
]
::1 - - [12/Aug/2025:16:08:22 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:08:24 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 1338 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6d14dd27c31120888b',
  '68922a62e3804084741191d5',
  '68922a523a3160d25de144c8'
]
[getSessionsMetadata] agent API call succeeded with 1338 sessions
[getSessionsMetadata] selfService API call succeeded with 80 sessions
[getSessionsMetadata] dropOff API call succeeded with 139 sessions
Total session metadata retrieved: 1557 (parallel execution)
Creating 1557 SWTs from metadata (no messages)
Created 1557 SWT objects from metadata
âœ… [SessionDiscovery] Window 1 completed in 5177ms: found 1557 new sessions (total: 1557)
â±ï¸  TIMING: Window 1 took 5177ms (5.18s)
ğŸ¯ [SessionDiscovery] Target reached! Found 1557 sessions in 5178ms
ğŸ² [SessionSampling] Random sampling from 1557 sessions to 100 sessions

ğŸ“¬ ============ MESSAGE RETRIEVAL STARTED ============
ğŸ“¬ [MessageRetrieval] Starting message retrieval for 100 sampled sessions at 2025-08-12T16:08:24.407Z
Using new lazy loading approach to populate messages for 100 sampled sessions
Populating messages for 100 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 100 sessions from 2025-08-05T13:06:05.472Z to 2025-08-05T15:59:42.366Z at 2025-08-12T16:08:24.408Z
ğŸš€ [ConcurrentBatch] Split 100 sessions into 5 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/5] Starting: 20 sessions
[Batch 2/5] Starting: 20 sessions
[Batch 3/5] Starting: 20 sessions
[Batch 4/5] Starting: 20 sessions
[Batch 5/5] Starting: 20 sessions
[Batch 1/5] Completed in 453ms: 238 messages retrieved (1/5 done)
ğŸ“Š [BatchProgress] Reporting batch 1/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 40/100 sessions (Batch 2/5)
[Batch 2/5] Completed in 502ms: 272 messages retrieved (2/5 done)
ğŸ“Š [BatchProgress] Reporting batch 2/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 60/100 sessions (Batch 3/5)
[Batch 3/5] Completed in 534ms: 263 messages retrieved (3/5 done)
ğŸ“Š [BatchProgress] Reporting batch 3/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 80/100 sessions (Batch 4/5)
[Batch 5/5] Completed in 536ms: 227 messages retrieved (4/5 done)
ğŸ“Š [BatchProgress] Reporting batch 4/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 100/100 sessions (Batch 5/5)
[Batch 4/5] Completed in 829ms: 274 messages retrieved (5/5 done)
ğŸ“Š [BatchProgress] Reporting batch 5/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 100/100 sessions (Batch 6/5)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 829ms (0.83s)
â±ï¸  Batch Processing: 829ms (0.83s)
ğŸ“¦ Total batches: 5 (max 10 concurrent)
âœ… Successful batches: 5/5
ğŸ’¬ Total messages: 1274
ğŸ“ˆ Avg time per batch: 166ms
ğŸš€ Time per session: 8ms
ğŸ’ª Performance: 120.6 sessions/second
=======================================================

Retrieved 1274 messages for 100 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
Populated messages for 100 SWT objects
Successfully populated messages for 100 sessions using lazy loading
Applying final filtering to 100 sessions with populated messages
Final result: 99 sessions passed filtering with populated messages

ğŸ‰ ============ SESSION SAMPLING COMPLETED ============
â±ï¸  TOTAL TIME: 6016ms (6.02s)
â±ï¸  Session Discovery: 5178ms (5.18s) - 86.1% of total
â±ï¸  Message Retrieval: 838ms (0.84s) - 13.9% of total
â±ï¸  Performance: 16.5 sessions/second
ğŸ¯ Final result: 99 sessions with messages retrieved
====================================================

[BackgroundJobQueue] Found 99 sessions for job 221c0688-5d6b-4721-9725-02bf4b36750b-sampling
[BackgroundJobQueue] Starting job processing after delay for job 221c0688-5d6b-4721-9725-02bf4b36750b-sampling-analysis
[BackgroundJobQueue] Starting processing for job 221c0688-5d6b-4721-9725-02bf4b36750b-sampling-analysis, phase: analyzing
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing analysis phase for job 221c0688-5d6b-4721-9725-02bf4b36750b-sampling-analysis with 99 sessions
ğŸ­ ServiceFactory: Creating OpenAI service (type: real)

ğŸ“¦ ===== BATCH 1 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:08:26.246Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 0
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:08:26.246Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:08:26.246Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6482,
  existingClassifications: { intents: 0, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.



For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and another intent, classify the intent as the other i...
::1 - - [12/Aug/2025:16:08:26 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 624 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:08:28 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:08:28.914Z',
  duration: '2668ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1857,
    completion_tokens: 247,
    total_tokens: 2104,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-d750e7e3-9344-54af-9556-e24814a20d67",
      "notes": "User wanted to learn about work account and file a new lease, but the session was transferred to an agent after some clarification."
    },
    {
      "user_id": "u-b93c3019-7e72-5074-83b3-5d1c64bb0739",
      "notes": "User indicated desire to speak with an agent, session was transferred to an agent."
    },
    {
      "user_id": "u-e76e8344-8237-5eab-a823-3c66840bd0a5",
      "notes": "User wanted to speak with an agent, session was transferred to an agent."
    },
    {
      "user_id": "u-6c28d079-1d8c-5503-b65e-6d15144db25c",
      "notes": "User inquired about denied claim, session was transferred to an agent."
    },
    {
      "user_id": "u-1212bf3c-aabd-5360-9fdf-364f35ab957b",
      "notes": "User wanted to speak with an agent, session was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1857,
  completionTokens: 247,
  totalTokens: 2104,
  cost: '$0.000285',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2668ms (2.67s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2104 ($0.0003)
âš¡ Performance: 788.6 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2669ms (2.67s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2104

âœ… ===== BATCH 1 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2669ms (2.67s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2104 ($0.0003)
âš¡ Performance: 1.9 sessions/sec
âš¡ Avg Time Per Session: 533.80ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:16:08:30 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 648 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"

ğŸ“¦ ===== BATCH 2 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:08:30.917Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 1
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:08:30.918Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:08:30.918Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6208,
  existingClassifications: { intents: 1, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Unknown

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and a...
::1 - - [12/Aug/2025:16:08:32 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 648 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:08:32.989Z',
  duration: '2071ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1788,
    completion_tokens: 291,
    total_tokens: 2079,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Unknown' ],
  transferCount: 4,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-18c41c8d-d820-5ec9-aa61-42518ff12695",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-29aeefce-9f22-5329-82de-f7d9053f628b",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-b7afdec1-75b0-514e-89e8-f8d9140002b0",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-da7db518-a59d-58a1-84de-a178b0542b3b",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-552412b5-9316-5e90-9cbc-0c29bbc77227",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User attempted to request a leave but did not provide the leave request number and ended the session."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1788,
  completionTokens: 291,
  totalTokens: 2079,
  cost: '$0.000295',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2072ms (2.07s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2079 ($0.0003)
âš¡ Performance: 1003.4 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2072ms (2.07s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2079

âœ… ===== BATCH 2 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2074ms (2.07s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2079 ($0.0003)
âš¡ Performance: 2.4 sessions/sec
âš¡ Avg Time Per Session: 414.80ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:16:08:34 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 636 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"

ğŸ“¦ ===== BATCH 3 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:08:34.993Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 1
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:08:34.993Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:08:34.994Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7117,
  existingClassifications: { intents: 1, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provid...
::1 - - [12/Aug/2025:16:08:36 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 636 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:08:38 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:08:38.313Z',
  duration: '3319ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2004,
    completion_tokens: 355,
    total_tokens: 2359,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Leave Request', 'Unknown' ],
  transferCount: 4,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-2ead0b8d-922b-5174-84f8-8ebd0092bf9a",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and transferred to an agent for a new leave request."
    },
    {
      "user_id": "u-f3c1f0bb-0581-5a23-a39f-e9d296295b6a",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with someone, but no input was received before transfer."
    },
    {
      "user_id": "u-beb9edc9-4cbb-51b7-91f2-fac28dd36393",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested customer service, but no input was received before transfer."
    },
    {
      "user_id": "u-de30632c-b736-5946-9239-cdbd7828b708",
      "general_intent": "Leave Request",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User reported time for a specific date and successfully submitted a leave request."
    },
    {
      "user_id": "u-de274296-a874-513d-ab33-123a5fd4b613",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested customer service, but no input was received before transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2004,
  completionTokens: 355,
  totalTokens: 2359,
  cost: '$0.000342',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 3321ms (3.32s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2359 ($0.0003)
âš¡ Performance: 710.3 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 3321ms (3.32s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2359

âœ… ===== BATCH 3 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 3321ms (3.32s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2359 ($0.0003)
âš¡ Performance: 1.5 sessions/sec
âš¡ Avg Time Per Session: 664.20ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:16:08:40 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 648 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"

ğŸ“¦ ===== BATCH 4 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:08:40.315Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 2
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:08:40.315Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:08:40.316Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 8234,
  existingClassifications: { intents: 2, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Leave Request, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live ...
::1 - - [12/Aug/2025:16:08:42 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 648 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:08:42.501Z',
  duration: '2185ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2274,
    completion_tokens: 338,
    total_tokens: 2612,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Claim Status', 'Leave Request', 'Live Agent' ],
  transferCount: 4,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-02042eba-0448-5b00-9c7e-0b4e7e656088",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak to a representative after discussing claim denial."
    },
    {
      "user_id": "u-782053ba-f998-534c-ac07-5137fdf931a9",
      "general_intent": "Leave Request",
      "session_outcome": "Contained",
      "notes": "User reported a leave request and verified details without transfer."
    },
    {
      "user_id": "u-d319b17c-277a-5e74-9743-802f416a7b7b",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a live representative, session transferred."
    },
    {
      "user_id": "u-cba82dcf-2164-592f-b963-69555fce3e70",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked for claim status and was transferred to an agent."
    },
    {
      "user_id": "u-6f80061b-ccd9-500a-bff6-5f3460028b32",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a live agent, session transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2274,
  completionTokens: 338,
  totalTokens: 2612,
  cost: '$0.000363',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2186ms (2.19s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2612 ($0.0004)
âš¡ Performance: 1194.9 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2187ms (2.19s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2612

âœ… ===== BATCH 4 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2187ms (2.19s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2612 ($0.0004)
âš¡ Performance: 2.3 sessions/sec
âš¡ Avg Time Per Session: 437.40ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:16:08:44 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 648 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"

ğŸ“¦ ===== BATCH 5 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:08:44.504Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:08:44.504Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:08:44.504Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 8539,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billi...
::1 - - [12/Aug/2025:16:08:46 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 648 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:08:47.060Z',
  duration: '2556ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2362,
    completion_tokens: 344,
    total_tokens: 2706,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Leave Request', 'Live Agent', 'Unknown', 'Claim Status' ],
  transferCount: 3,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-89c952e4-2057-5483-9001-ae326ccb454e",
      "general_intent": "Leave Request",
      "session_outcome": "Contained",
      "notes": "User was verifying leave request details and submitting a time entry without transfer."
    },
    {
      "user_id": "u-7f9ae213-90c7-50d0-a34a-1ea336dcd53e",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent, session transferred to live agent."
    },
    {
      "user_id": "u-15956a83-8711-5b0c-b766-187dbee7dbe6",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent, session transferred to live agent."
    },
    {
      "user_id": "u-a5c1ffcf-7e67-5d31-99c0-8904b49fa3ef",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to sign up for FMLA, session transferred to live agent."
    },
    {
      "user_id": "u-c3dd0050-687b-5de4-8dd0-353ad921e383",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User checked claim status and inquired about FMLA requirements without transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2362,
  completionTokens: 344,
  totalTokens: 2706,
  cost: '$0.000374',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2556ms (2.56s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2706 ($0.0004)
âš¡ Performance: 1058.7 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 1ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2557ms (2.56s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2706

âœ… ===== BATCH 5 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2557ms (2.56s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2706 ($0.0004)
âš¡ Performance: 2.0 sessions/sec
âš¡ Avg Time Per Session: 511.40ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:16:08:48 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 649 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"

ğŸ“¦ ===== BATCH 6 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:08:49.063Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:08:49.063Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:08:49.064Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7636,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billi...
::1 - - [12/Aug/2025:16:08:50 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 649 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:08:51.863Z',
  duration: '2799ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2157,
    completion_tokens: 374,
    total_tokens: 2531,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Leave Request' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-fb03cc4b-00eb-569f-b079-aab2ee118a52",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to provide leave request details but was unable to, leading to transfer to an agent."
    },
    {
      "user_id": "u-39af02c4-68c5-5564-8da8-83bd0ad3d5b2",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative, resulting in transfer to an agent."
    },
    {
      "user_id": "u-d367a635-dc15-5b32-a4e4-ef283e322964",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and then asked to speak with an agent, leading to transfer."
    },
    {
      "user_id": "u-fe558fcb-fc70-5e53-a5f8-b0375d082f05",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative, resulting in transfer."
    },
    {
      "user_id": "u-2836171a-c12b-5622-b7de-8c0263dfeccc",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User expressed desire to speak to a live person, leading to transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2157,
  completionTokens: 374,
  totalTokens: 2531,
  cost: '$0.000365',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2800ms (2.80s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2531 ($0.0004)
âš¡ Performance: 903.9 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2800ms (2.80s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2531

âœ… ===== BATCH 6 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2801ms (2.80s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2531 ($0.0004)
âš¡ Performance: 1.8 sessions/sec
âš¡ Avg Time Per Session: 560.20ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:16:08:52 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 637 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"

ğŸ“¦ ===== BATCH 7 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:08:53.867Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:08:53.867Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:08:53.868Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7263,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billi...
::1 - - [12/Aug/2025:16:08:54 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 637 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:08:55.855Z',
  duration: '1987ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2047,
    completion_tokens: 241,
    total_tokens: 2288,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-b633a5b6-445a-5820-96d5-8394d56f8468",
      "notes": "User requested to speak with an agent, session was transferred to a live agent."
    },
    {
      "user_id": "u-9b912fb5-60d7-5e4c-9aa2-dd41b68711ea",
      "notes": "User requested to speak with an agent, session was transferred to a live agent."
    },
    {
      "user_id": "u-a2245c39-8eb0-500a-9762-4053cd67434f",
      "notes": "User provided claim details and successfully submitted a time entry, session was contained."
    },
    {
      "user_id": "u-4b214d25-87ef-54e5-bd84-72b968c358cd",
      "notes": "User requested to speak with an agent, session was transferred to a live agent."
    },
    {
      "user_id": "u-29555d49-006e-5a3c-b98d-269e178f6f26",
      "notes": "User requested information about a payment in Spanish, session was closed without transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2047,
  completionTokens: 241,
  totalTokens: 2288,
  cost: '$0.000301',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 1989ms (1.99s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2288 ($0.0003)
âš¡ Performance: 1150.3 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 1989ms (1.99s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2288

âœ… ===== BATCH 7 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 1989ms (1.99s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2288 ($0.0003)
âš¡ Performance: 2.5 sessions/sec
âš¡ Avg Time Per Session: 397.80ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:16:08:56 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 637 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"

ğŸ“¦ ===== BATCH 8 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:08:57.858Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:08:57.858Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:08:57.859Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6871,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billi...
::1 - - [12/Aug/2025:16:08:58 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 637 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:09:00 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:09:00.467Z',
  duration: '2608ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1955,
    completion_tokens: 340,
    total_tokens: 2295,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Live Agent', 'Unknown', 'Time Entry' ],
  transferCount: 3,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-4878a5c4-cbe1-5adc-a205-781497bab80a",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-a9ba3dc6-b0ca-5f71-aebc-9f8db9e1c2ff",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User attempted to update FMLA but was unable to provide required information, session ended without transfer."
    },
    {
      "user_id": "u-d2c766a4-4198-5bdb-90eb-b69d0d5ffc1f",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-bad71d3a-3b6c-52bd-ad87-9b089ecb5f84",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User was silent and did not provide input, session ended without transfer."
    },
    {
      "user_id": "u-c0e9ddd4-b78e-528f-a102-51e553408340",
      "general_intent": "Time Entry",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted help with time entry and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1955,
  completionTokens: 340,
  totalTokens: 2295,
  cost: '$0.000332',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2610ms (2.61s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2295 ($0.0003)
âš¡ Performance: 879.3 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2610ms (2.61s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2295

âœ… ===== BATCH 8 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2610ms (2.61s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2295 ($0.0003)
âš¡ Performance: 1.9 sessions/sec
âš¡ Avg Time Per Session: 522.00ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:16:09:02 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 637 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"

ğŸ“¦ ===== BATCH 9 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:09:02.470Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:09:02.470Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:09:02.471Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6897,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Sta...
::1 - - [12/Aug/2025:16:09:04 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 637 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:09:06.101Z',
  duration: '3630ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1962,
    completion_tokens: 361,
    total_tokens: 2323,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Leave Request', 'Unknown' ],
  transferCount: 4,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-734dac40-8f47-5a1a-a579-413438089f81",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative after discussing leave request status."
    },
    {
      "user_id": "u-8375a5b5-fb93-54fd-b586-f61f5e5b296e",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User indicated desire for customer service but did not proceed to transfer or specify a clear intent."
    },
    {
      "user_id": "u-8f14dc6b-d4f1-5b65-bb19-2d1e9f609422",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to make a new leave request, session transferred to an agent."
    },
    {
      "user_id": "u-efaa7bfe-9d0d-59fe-ae98-d3928d99678d",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent for leave-related questions."
    },
    {
      "user_id": "u-5f50487d-35f7-59e6-8a7d-3552721d3947",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to verify paperwork and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1962,
  completionTokens: 361,
  totalTokens: 2323,
  cost: '$0.000341',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 3631ms (3.63s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2323 ($0.0003)
âš¡ Performance: 639.8 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 3631ms (3.63s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2323

âœ… ===== BATCH 9 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 3632ms (3.63s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2323 ($0.0003)
âš¡ Performance: 1.4 sessions/sec
âš¡ Avg Time Per Session: 726.40ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:16:09:06 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 636 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"

ğŸ“¦ ===== BATCH 10 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:09:08.108Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:09:08.109Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:09:08.109Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6885,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Sta...
::1 - - [12/Aug/2025:16:09:08 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 637 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:09:10 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:09:10.766Z',
  duration: '2657ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1949,
    completion_tokens: 358,
    total_tokens: 2307,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Leave Request', 'Claim Status', 'Live Agent' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-2fc9737c-5152-509c-b76f-b9f4d70381f0",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to extend leave but was transferred to an agent."
    },
    {
      "user_id": "u-3ccd4175-c809-5d5a-84fb-c35b8a629042",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User inquired about claim status and was transferred to an agent."
    },
    {
      "user_id": "u-4156b13b-c2a9-5667-a1fb-0e037ffe1c6c",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a representative and was transferred."
    },
    {
      "user_id": "u-06b553ed-51f4-5a8c-83e6-a3dbce521c86",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative and was transferred."
    },
    {
      "user_id": "u-f0dbca70-303f-5549-96ab-dbd6a24aea48",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User expressed desire to speak to an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1949,
  completionTokens: 358,
  totalTokens: 2307,
  cost: '$0.000338',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2659ms (2.66s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2307 ($0.0003)
âš¡ Performance: 867.6 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2659ms (2.66s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2307

âœ… ===== BATCH 10 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2660ms (2.66s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2307 ($0.0003)
âš¡ Performance: 1.9 sessions/sec
âš¡ Avg Time Per Session: 532.00ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:16:09:12 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 638 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"

ğŸ“¦ ===== BATCH 11 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:09:12.769Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:09:12.769Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:09:12.769Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7944,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Sta...
::1 - - [12/Aug/2025:16:09:14 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 639 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:09:15.534Z',
  duration: '2764ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2269,
    completion_tokens: 351,
    total_tokens: 2620,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Live Agent', 'Unknown', 'Claim Status', 'Leave Request' ],
  transferCount: 4,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-a9ffd182-223c-50c6-84ba-2bf86cac602e",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a support agent and was transferred."
    },
    {
      "user_id": "u-5d9e4eaf-168b-5d79-8ec9-a2984c8a6400",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User provided inputs but was not transferred; session was handled by bot."
    },
    {
      "user_id": "u-d112df13-7068-5eec-9a13-52b980bd67c9",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted claim status info and was transferred to a live agent."
    },
    {
      "user_id": "u-0b712589-a8dc-58e8-9b7e-1b068a943fe6",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to create a leave of absence and was transferred."
    },
    {
      "user_id": "u-5d9592b1-8c66-5fe8-a385-cad93741d26f",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2269,
  completionTokens: 351,
  totalTokens: 2620,
  cost: '$0.000367',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2765ms (2.77s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2620 ($0.0004)
âš¡ Performance: 947.6 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2765ms (2.77s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2620

âœ… ===== BATCH 11 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2766ms (2.77s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2620 ($0.0004)
âš¡ Performance: 1.8 sessions/sec
âš¡ Avg Time Per Session: 553.20ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:16:09:16 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 651 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"

ğŸ“¦ ===== BATCH 12 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:09:17.536Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:09:17.536Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:09:17.537Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 8336,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Sta...
::1 - - [12/Aug/2025:16:09:18 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 651 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:09:19.560Z',
  duration: '2023ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2324,
    completion_tokens: 261,
    total_tokens: 2585,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-6565476f-52d8-573c-94dc-6b118a0fc72b",
      "notes": "User was silent and did not receive assistance, session was transferred to an agent."
    },
    {
      "user_id": "u-c397e884-d3c5-548a-b8a7-935f7b6e324d",
      "notes": "User attempted to file a claim but was transferred to an agent after multiple unsuccessful attempts to provide information."
    },
    {
      "user_id": "u-241b4bed-a0a3-5c87-8d49-e58c9e541fed",
      "notes": "User requested to start a claim, session was transferred to an agent."
    },
    {
      "user_id": "u-5035766f-c388-5cd0-bd5d-d1640658a3d6",
      "notes": "User asked about setting up FMLA, then requested to speak to a person, session was transferred to an agent."
    },
    {
      "user_id": "u-84baa148-35fa-5529-9a4b-da648e66b650",
      "notes": "User provided claim details and submitted time entries successfully, then asked for help with login issues, session was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2324,
  completionTokens: 261,
  totalTokens: 2585,
  cost: '$0.000337',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2025ms (2.02s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2585 ($0.0003)
âš¡ Performance: 1276.5 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2025ms (2.02s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2585

âœ… ===== BATCH 12 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2025ms (2.02s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2585 ($0.0003)
âš¡ Performance: 2.5 sessions/sec
âš¡ Avg Time Per Session: 405.00ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:16:09:20 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 650 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"

ğŸ“¦ ===== BATCH 13 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:09:21.563Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:09:21.563Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:09:21.564Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7081,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Sta...
::1 - - [12/Aug/2025:16:09:22 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 650 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:09:24 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:09:24.528Z',
  duration: '2964ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1993,
    completion_tokens: 386,
    total_tokens: 2379,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Time Entry', 'Live Agent', 'FMLA' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-45d4e4e2-23d8-5c36-b487-1a8c3c0efb02",
      "general_intent": "Time Entry",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was trying to report time but was transferred to an agent after multiple unsuccessful attempts to provide leave request or employee number."
    },
    {
      "user_id": "u-eba515a9-d390-5526-a477-1945354c2f8e",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with a representative and was transferred to an agent."
    },
    {
      "user_id": "u-8bf10140-4cf9-5643-8c36-3298d039ca6f",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested tracking status and was transferred to an agent."
    },
    {
      "user_id": "u-8b5ad367-27f8-55dc-adf9-39f553cd0081",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked about paperwork and money, then was transferred to an agent."
    },
    {
      "user_id": "u-292903d1-7ca8-5186-a93f-44fe78a57675",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked about FMLA and requested to speak with a representative, then was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1993,
  completionTokens: 386,
  totalTokens: 2379,
  cost: '$0.000354',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2965ms (2.96s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2379 ($0.0004)
âš¡ Performance: 802.4 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2965ms (2.96s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2379

âœ… ===== BATCH 13 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2966ms (2.97s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2379 ($0.0004)
âš¡ Performance: 1.7 sessions/sec
âš¡ Avg Time Per Session: 593.20ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:16:09:26 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 650 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"

ğŸ“¦ ===== BATCH 14 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:09:26.530Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 6
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:09:26.531Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:09:26.531Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6666,
  existingClassifications: { intents: 6, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, FMLA, Leave Request, Live Agent, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Cla...
::1 - - [12/Aug/2025:16:09:28 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 650 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:09:29.095Z',
  duration: '2564ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1909,
    completion_tokens: 375,
    total_tokens: 2284,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'FMLA', 'Unknown' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-246d0398-13e6-550f-bd13-82607c91c1e7",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative regarding FMLA renewal and was transferred."
    },
    {
      "user_id": "u-a3fac934-5ea1-5c89-9592-516eb987e711",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User discussed family leave denial and was transferred to an agent."
    },
    {
      "user_id": "u-a74dd190-1d1c-5cf2-a0ca-640d034b337b",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to start a claim for FMLA and was transferred to an agent."
    },
    {
      "user_id": "u-b36cc8dc-5a3e-5548-8a1c-917130856581",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested customer service and was transferred to an agent."
    },
    {
      "user_id": "u-58146c1f-17a8-5a9d-a5ca-612c9fad684b",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a new open FMLA and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1909,
  completionTokens: 375,
  totalTokens: 2284,
  cost: '$0.000341',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2566ms (2.57s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2284 ($0.0003)
âš¡ Performance: 890.1 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2566ms (2.57s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2284

âœ… ===== BATCH 14 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2566ms (2.57s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2284 ($0.0003)
âš¡ Performance: 1.9 sessions/sec
âš¡ Avg Time Per Session: 513.20ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:16:09:30 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 650 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"

ğŸ“¦ ===== BATCH 15 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:09:31.097Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 6
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:09:31.097Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:09:31.098Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7187,
  existingClassifications: { intents: 6, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, FMLA, Leave Request, Live Agent, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Cla...
::1 - - [12/Aug/2025:16:09:32 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 650 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:09:34.035Z',
  duration: '2937ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2041,
    completion_tokens: 375,
    total_tokens: 2416,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Leave Request', 'Claim Status', 'FMLA' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-0afcbb17-d319-5547-a823-7022e4105f1b",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to report return to work date but was transferred to an agent."
    },
    {
      "user_id": "u-74d21e4c-4e47-5ab6-93ff-72d6a9b2be50",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to start a new claim and was transferred to an agent."
    },
    {
      "user_id": "u-f4ddee85-f593-587d-8183-b18f3268aae0",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User tried to file a leave of absence but was transferred to an agent after multiple failed attempts."
    },
    {
      "user_id": "u-9d101f6f-e7ea-57aa-b111-e2f074ad969c",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to request leave and was transferred to an agent."
    },
    {
      "user_id": "u-1757239c-98f8-553f-94ab-7510f946933b",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User inquired about FMLA and was transferred to a live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2041,
  completionTokens: 375,
  totalTokens: 2416,
  cost: '$0.000354',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2938ms (2.94s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2416 ($0.0004)
âš¡ Performance: 822.3 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2939ms (2.94s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2416

âœ… ===== BATCH 15 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2939ms (2.94s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2416 ($0.0004)
âš¡ Performance: 1.7 sessions/sec
âš¡ Avg Time Per Session: 587.80ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:16:09:34 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 650 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"

ğŸ“¦ ===== BATCH 16 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:09:36.037Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 6
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:09:36.037Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:09:36.038Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6800,
  existingClassifications: { intents: 6, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, FMLA, Leave Request, Live Agent, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Cla...
::1 - - [12/Aug/2025:16:09:36 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 650 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:09:37.879Z',
  duration: '1841ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1944,
    completion_tokens: 256,
    total_tokens: 2200,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-46fc5e91-0905-5b23-9e90-6dc0bb5557d5",
      "notes": "User requested to speak to a person, session was transferred to an agent."
    },
    {
      "user_id": "u-529428c1-ba0f-5668-851e-4bbabb4e411d",
      "notes": "User attempted to get help with time entry but did not provide sufficient input, session was not transferred."
    },
    {
      "user_id": "u-7ac6ccb2-b441-575f-89ef-a472a3f3b1e1",
      "notes": "User provided claim and leave request details, then requested to speak with a representative, session was transferred to an agent."
    },
    {
      "user_id": "u-56891aab-8dbe-5f75-bb38-1c98101c68ec",
      "notes": "User inquired about leave request paperwork, session was transferred to an agent."
    },
    {
      "user_id": "u-4e5aa05c-2163-5359-912b-ad826a074166",
      "notes": "User was silent and then indicated intent to open a new leave request, session was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1944,
  completionTokens: 256,
  totalTokens: 2200,
  cost: '$0.000297',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 1843ms (1.84s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2200 ($0.0003)
âš¡ Performance: 1193.7 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 1843ms (1.84s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2200

âœ… ===== BATCH 16 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 1843ms (1.84s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2200 ($0.0003)
âš¡ Performance: 2.7 sessions/sec
âš¡ Avg Time Per Session: 368.60ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:16:09:38 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 650 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"

ğŸ“¦ ===== BATCH 17 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:09:39.881Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 6
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:09:39.882Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:09:39.882Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6458,
  existingClassifications: { intents: 6, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, FMLA, Leave Request, Live Agent, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Cla...
::1 - - [12/Aug/2025:16:09:40 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 200 650 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:09:42 +0000] "GET /api/analysis/auto-analyze/progress/221c0688-5d6b-4721-9725-02bf4b36750b HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:09:42.877Z',
  duration: '2995ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1849,
    completion_tokens: 342,
    total_tokens: 2191,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Claim Status', 'FMLA', 'Unknown' ],
  transferCount: 3,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-bfc8e1db-3e8f-5b36-a13c-b4f338f2c403",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User inquired about claim status and was transferred to a live agent."
    },
    {
      "user_id": "u-98be0d84-6090-5baa-a837-4451fa57c7a6",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative and was transferred to an agent."
    },
    {
      "user_id": "u-5f941af9-d04c-5b86-a8b3-2c1deafdf899",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User was silent and did not provide input, session was closed by the bot."
    },
    {
      "user_id": "u-679899c2-4146-5a48-9bbd-a7065c494323",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User did not respond; session was closed by the bot."
    },
    {
      "user_id": "u-47c37255-0e49-5754-a0de-f1dabc352edc",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked about short term disability and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1849,
  completionTokens: 342,
  totalTokens: 2191,
  cost: '$0.000322',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2995ms (3.00s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2191 ($0.0003)
âš¡ Performance: 731.6 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2995ms (3.00s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2191

âœ… ===== BATCH 17 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2997ms (3.00s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2191 ($0.0003)
âš¡ Performance: 1.7 sessions/sec
âš¡ Avg Time Per Session: 599.40ms
â±ï¸  Metadata Processing: 0ms

ğŸ“¦ ===== BATCH 18 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:09:44.878Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 6
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:09:44.878Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:09:44.878Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7519,
  existingClassifications: { intents: 6, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, FMLA, Leave Request, Live Agent, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Cla...
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:09:47.001Z',
  duration: '2123ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2148,
    completion_tokens: 250,
    total_tokens: 2398,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-dc242480-65e4-5c12-96c8-83897ec90702",
      "notes": "User inquired about setting up FMLA or leave of absence, but did not complete the process."
    },
    {
      "user_id": "u-cb5b459e-7502-5b8d-9e4b-2eeb3bc67cb3",
      "notes": "User requested to speak to a representative, and was transferred to an agent."
    },
    {
      "user_id": "u-dae579d0-d327-5f2f-b379-c05e5f622e03",
      "notes": "User requested to initiate a new FMLA request after denial, and was transferred to an agent."
    },
    {
      "user_id": "u-f4a1fc0a-ce9c-5a81-8c70-656d8bf9bfb1",
      "notes": "User discussed claim and time off, but session was ended without transfer."
    },
    {
      "user_id": "u-fee88222-96bd-5420-af66-18a0a1ef76d2",
      "notes": "User requested to file FMLA and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2148,
  completionTokens: 250,
  totalTokens: 2398,
  cost: '$0.000315',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2124ms (2.12s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2398 ($0.0003)
âš¡ Performance: 1129.0 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2124ms (2.12s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2398

âœ… ===== BATCH 18 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2124ms (2.12s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2398 ($0.0003)
âš¡ Performance: 2.4 sessions/sec
âš¡ Avg Time Per Session: 424.80ms
â±ï¸  Metadata Processing: 0ms

ğŸ“¦ ===== BATCH 19 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:09:49.003Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 6
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:09:49.004Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:09:49.014Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7649,
  existingClassifications: { intents: 6, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, FMLA, Leave Request, Live Agent, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Cla...
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:09:51.623Z',
  duration: '2609ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2177,
    completion_tokens: 353,
    total_tokens: 2530,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'FMLA', 'Claim Status' ],
  transferCount: 4,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-07423326-d46a-5637-8b6b-5f390fc1716a",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User indicated a desire to speak with an agent, session was transferred."
    },
    {
      "user_id": "u-de593bf4-872b-5661-8e57-45522202f90f",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User indicated a desire to speak with an agent, session was transferred."
    },
    {
      "user_id": "u-24865ed3-ba99-52c8-9167-0df42ca91a98",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User indicated a desire to speak with an agent, session was transferred."
    },
    {
      "user_id": "u-6828969f-1f93-53be-8ed4-e3b5020fe9ac",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested claim status and was transferred to an agent."
    },
    {
      "user_id": "u-0cd5d775-712e-5c8d-ad14-699b6b220d23",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User requested customer service but did not get transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2177,
  completionTokens: 353,
  totalTokens: 2530,
  cost: '$0.000359',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2619ms (2.62s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2530 ($0.0004)
âš¡ Performance: 966.0 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2619ms (2.62s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2530

âœ… ===== BATCH 19 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2620ms (2.62s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2530 ($0.0004)
âš¡ Performance: 1.9 sessions/sec
âš¡ Avg Time Per Session: 524.00ms
â±ï¸  Metadata Processing: 0ms

ğŸ“¦ ===== BATCH 20 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:09:53.624Z
ğŸ“Š Sessions in Batch: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 6
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 4
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:09:53.625Z
ğŸ“Š Sessions to Analyze: 4

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:09:53.625Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6320,
  existingClassifications: { intents: 6, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, FMLA, Leave Request, Live Agent, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Cla...
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:09:55.239Z',
  duration: '1614ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1811,
    completion_tokens: 193,
    total_tokens: 2004,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-de3db11f-27d1-5377-857d-8cc49d427165",
      "notes": "User requested to speak with an agent, session was transferred."
    },
    {
      "user_id": "u-8ce3bc0e-54ba-5e2f-b5f4-68ed2c4a7a29",
      "notes": "User attempted to verify leave request and personal details, then transferred to an agent after no response."
    },
    {
      "user_id": "u-92fe0dd2-bcb8-5a20-a56a-8ee4a1093b03",
      "notes": "User requested to speak with an agent, session was transferred."
    },
    {
      "user_id": "u-f6d00604-c865-5bd0-b28e-9bca4dc4f0c1",
      "notes": "User requested to speak with an agent, session was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1811,
  completionTokens: 193,
  totalTokens: 2004,
  cost: '$0.000258',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 1614ms (1.61s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2004 ($0.0003)
âš¡ Performance: 1241.6 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 4
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 1614ms (1.61s)
ğŸ“Š Regular Sessions Processed: 4
ğŸ’° Regular Tokens Used: 2004

âœ… ===== BATCH 20 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 1615ms (1.61s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Total Tokens: 2004 ($0.0003)
âš¡ Performance: 2.5 sessions/sec
âš¡ Avg Time Per Session: 403.75ms
â±ï¸  Metadata Processing: 0ms
[BackgroundJobQueue] Session analysis completed for job 221c0688-5d6b-4721-9725-02bf4b36750b-sampling-analysis, processed 99 sessions
[BackgroundJobQueue] Analysis summary generated for job 221c0688-5d6b-4721-9725-02bf4b36750b-sampling-analysis
[BackgroundJobQueue] Analysis completed for job 221c0688-5d6b-4721-9725-02bf4b36750b-sampling-analysis, processed 99 sessions
[BackgroundJobQueue] Results successfully stored in AutoAnalyzeService for analysis 221c0688-5d6b-4721-9725-02bf4b36750b
[BackgroundJobQueue] Analysis 221c0688-5d6b-4721-9725-02bf4b36750b completed with 99 sessions
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T16:10:04.766Z",
  "dateTo": "2025-08-12T16:11:04.766Z",
  "skip": 0,
  "limit": 1
}
[fetchContainmentTypeMetadata] API Response: 1 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [ '689b6771dcfd96eb5e75b0c6' ]
[getSessionsMetadataForConnectionTest] Single API call succeeded with 1 sessions
::1 - - [12/Aug/2025:16:11:07 +0000] "GET /api/kore/test HTTP/1.1" 200 851 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[Direct API] Fetching real Kore.ai sessions from 2025-08-05T16:11:08.181Z to 2025-08-12T16:11:08.181Z for User Bot st-90549... (limit=50)
Retrieving sessions from 2025-08-05T16:11:08.181Z to 2025-08-12T16:11:08.181Z (limit=50), populateMessages=true...
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T16:11:08.181Z",
  "dateTo": "2025-08-12T16:11:08.181Z",
  "limit": 50
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T16:11:08.181Z",
  "dateTo": "2025-08-12T16:11:08.181Z",
  "skip": 0,
  "limit": 50
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T16:11:08.181Z",
  "dateTo": "2025-08-12T16:11:08.181Z",
  "skip": 0,
  "limit": 50
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T16:11:08.181Z",
  "dateTo": "2025-08-12T16:11:08.181Z",
  "skip": 0,
  "limit": 50
}
::1 - - [12/Aug/2025:16:11:09 +0000] "GET /api/analysis/sessions?limit=50 HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 50 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b67750a261bd4437302d1',
  '689b6771dcfd96eb5e75b0c6',
  '689b676cd0ca50f0ddb75cae'
]
[fetchContainmentTypeMetadata] API Response: 50 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b6345cc9c7f5ad064fdb5',
  '689b6310a672546ebf547457',
  '689b62e4f54cdbf3deefbde0'
]
[fetchContainmentTypeMetadata] API Response: 50 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b67908b529fd4faaebb2c',
  '689b678f296df1d830ccbe32',
  '689b678e3d161a676154012c'
]
[getSessionsMetadata] agent API call succeeded with 50 sessions
[getSessionsMetadata] selfService API call succeeded with 50 sessions
[getSessionsMetadata] dropOff API call succeeded with 50 sessions
Total session metadata retrieved: 150 (parallel execution)
Retrieved 150 session metadata objects
Creating 150 SWTs from metadata (no messages)
Created 150 SWT objects from metadata
Populating messages for all sessions (legacy behavior)
Populating messages for 150 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 150 sessions from 2025-08-12T14:59:01.542Z to 2025-08-12T16:11:06.998Z at 2025-08-12T16:11:11.668Z
ğŸš€ [ConcurrentBatch] Split 150 sessions into 8 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/8] Starting: 20 sessions
[Batch 2/8] Starting: 20 sessions
[Batch 3/8] Starting: 20 sessions
[Batch 4/8] Starting: 20 sessions
[Batch 5/8] Starting: 20 sessions
[Batch 6/8] Starting: 20 sessions
[Batch 7/8] Starting: 20 sessions
[Batch 8/8] Starting: 10 sessions
[Batch 3/8] Completed in 210ms: 195 messages retrieved (1/8 done)
[Batch 2/8] Completed in 214ms: 205 messages retrieved (2/8 done)
[Batch 1/8] Completed in 217ms: 219 messages retrieved (3/8 done)
[Batch 8/8] Completed in 331ms: 76 messages retrieved (4/8 done)
[Batch 6/8] Completed in 387ms: 186 messages retrieved (5/8 done)
[Batch 7/8] Completed in 521ms: 256 messages retrieved (6/8 done)
[Batch 4/8] Completed in 554ms: 305 messages retrieved (7/8 done)
[Batch 5/8] Completed in 675ms: 574 messages retrieved (8/8 done)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 675ms (0.68s)
â±ï¸  Batch Processing: 675ms (0.68s)
ğŸ“¦ Total batches: 8 (max 10 concurrent)
âœ… Successful batches: 8/8
ğŸ’¬ Total messages: 2016
ğŸ“ˆ Avg time per batch: 84ms
ğŸš€ Time per session: 5ms
ğŸ’ª Performance: 222.2 sessions/second
=======================================================

Retrieved 2016 messages for 150 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
Populated messages for 150 SWT objects
Generated 150 SWT objects in 4170ms using layered architecture
ğŸš€ [AutoAnalyzeRoute] Starting analysis for bot ***REMOVED*** with real credentials
ğŸš€ [AutoAnalyzeService] Starting analysis e1ecf062-ef9a-4860-a5d9-75eb3685e321 with bot ***REMOVED***
ğŸš€ [AutoAnalyzeService] Using credentials: real
ğŸš€ [AutoAnalyzeRoute] Analysis started: e1ecf062-ef9a-4860-a5d9-75eb3685e321
::1 - - [12/Aug/2025:16:11:27 +0000] "POST /api/analysis/auto-analyze/start HTTP/1.1" 200 205 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:11:27 +0000] "GET /api/analysis/auto-analyze/progress/e1ecf062-ef9a-4860-a5d9-75eb3685e321 HTTP/1.1" 200 479 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:11:27 +0000] "GET /api/analysis/auto-analyze/progress/e1ecf062-ef9a-4860-a5d9-75eb3685e321 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[BackgroundJobQueue] Starting job processing after delay for job e1ecf062-ef9a-4860-a5d9-75eb3685e321-sampling
[BackgroundJobQueue] Starting processing for job e1ecf062-ef9a-4860-a5d9-75eb3685e321-sampling, phase: sampling
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing sampling phase for job e1ecf062-ef9a-4860-a5d9-75eb3685e321-sampling
[BackgroundJobQueue] Processing sampling phase for bot: ***REMOVED***
[BackgroundJobQueue] Creating real service for bot: ***REMOVED***
[BackgroundJobQueue] Full config: {
  "botId": "***REMOVED***",
  "clientId": "***REMOVED***",
  "clientSecret": "***REMOVED***",
  "baseUrl": "https://bots.kore.ai"
}
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[BackgroundJobQueue] Created service type: RealKoreApiService

ğŸ• ============ SESSION SAMPLING STARTED ============
ğŸ• [SessionSampling] Starting session sampling at 2025-08-12T16:11:28.159Z
ğŸ” [SessionDiscovery] Starting window 1/4: Initial 3-hour window
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
::1 - - [12/Aug/2025:16:11:29 +0000] "GET /api/analysis/auto-analyze/progress/e1ecf062-ef9a-4860-a5d9-75eb3685e321 HTTP/1.1" 200 534 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 80 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a1287849680ad9fe59e',
  '689229f9583056c6108e38fb',
  '68922914f8bee7ba6c3e67b8'
]
[fetchContainmentTypeMetadata] API Response: 139 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6a14dd27c3112087cd',
  '68922a22ef03d8ad2ec7b4ba',
  '68922a1278c1fe09a079719c'
]
::1 - - [12/Aug/2025:16:11:31 +0000] "GET /api/analysis/auto-analyze/progress/e1ecf062-ef9a-4860-a5d9-75eb3685e321 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 1338 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6d14dd27c31120888b',
  '68922a62e3804084741191d5',
  '68922a523a3160d25de144c8'
]
[getSessionsMetadata] agent API call succeeded with 1338 sessions
[getSessionsMetadata] selfService API call succeeded with 80 sessions
[getSessionsMetadata] dropOff API call succeeded with 139 sessions
Total session metadata retrieved: 1557 (parallel execution)
Creating 1557 SWTs from metadata (no messages)
Created 1557 SWT objects from metadata
âœ… [SessionDiscovery] Window 1 completed in 5059ms: found 1557 new sessions (total: 1557)
â±ï¸  TIMING: Window 1 took 5059ms (5.06s)
ğŸ¯ [SessionDiscovery] Target reached! Found 1557 sessions in 5059ms
ğŸ² [SessionSampling] Random sampling from 1557 sessions to 100 sessions

ğŸ“¬ ============ MESSAGE RETRIEVAL STARTED ============
ğŸ“¬ [MessageRetrieval] Starting message retrieval for 100 sampled sessions at 2025-08-12T16:11:33.219Z
Using new lazy loading approach to populate messages for 100 sampled sessions
Populating messages for 100 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 100 sessions from 2025-08-05T13:04:28.845Z to 2025-08-05T15:59:32.792Z at 2025-08-12T16:11:33.219Z
ğŸš€ [ConcurrentBatch] Split 100 sessions into 5 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/5] Starting: 20 sessions
[Batch 2/5] Starting: 20 sessions
[Batch 3/5] Starting: 20 sessions
[Batch 4/5] Starting: 20 sessions
[Batch 5/5] Starting: 20 sessions
::1 - - [12/Aug/2025:16:11:33 +0000] "GET /api/analysis/auto-analyze/progress/e1ecf062-ef9a-4860-a5d9-75eb3685e321 HTTP/1.1" 200 554 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[Batch 1/5] Completed in 354ms: 226 messages retrieved (1/5 done)
ğŸ“Š [BatchProgress] Reporting batch 1/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 40/100 sessions (Batch 2/5)
[Batch 2/5] Completed in 368ms: 235 messages retrieved (2/5 done)
ğŸ“Š [BatchProgress] Reporting batch 2/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 60/100 sessions (Batch 3/5)
[Batch 3/5] Completed in 372ms: 243 messages retrieved (3/5 done)
ğŸ“Š [BatchProgress] Reporting batch 3/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 80/100 sessions (Batch 4/5)
[Batch 5/5] Completed in 634ms: 242 messages retrieved (4/5 done)
ğŸ“Š [BatchProgress] Reporting batch 4/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 100/100 sessions (Batch 5/5)
[Batch 4/5] Completed in 717ms: 251 messages retrieved (5/5 done)
ğŸ“Š [BatchProgress] Reporting batch 5/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 100/100 sessions (Batch 6/5)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 718ms (0.72s)
â±ï¸  Batch Processing: 717ms (0.72s)
ğŸ“¦ Total batches: 5 (max 10 concurrent)
âœ… Successful batches: 5/5
ğŸ’¬ Total messages: 1197
ğŸ“ˆ Avg time per batch: 143ms
ğŸš€ Time per session: 7ms
ğŸ’ª Performance: 139.3 sessions/second
=======================================================

Retrieved 1197 messages for 100 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
Populated messages for 100 SWT objects
Successfully populated messages for 100 sessions using lazy loading
Applying final filtering to 100 sessions with populated messages
Final result: 98 sessions passed filtering with populated messages

ğŸ‰ ============ SESSION SAMPLING COMPLETED ============
â±ï¸  TOTAL TIME: 5786ms (5.79s)
â±ï¸  Session Discovery: 5059ms (5.06s) - 87.4% of total
â±ï¸  Message Retrieval: 726ms (0.73s) - 12.5% of total
â±ï¸  Performance: 16.9 sessions/second
ğŸ¯ Final result: 98 sessions with messages retrieved
====================================================

[BackgroundJobQueue] Found 98 sessions for job e1ecf062-ef9a-4860-a5d9-75eb3685e321-sampling
[BackgroundJobQueue] Starting job processing after delay for job e1ecf062-ef9a-4860-a5d9-75eb3685e321-sampling-analysis
[BackgroundJobQueue] Starting processing for job e1ecf062-ef9a-4860-a5d9-75eb3685e321-sampling-analysis, phase: analyzing
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing analysis phase for job e1ecf062-ef9a-4860-a5d9-75eb3685e321-sampling-analysis with 98 sessions
ğŸ­ ServiceFactory: Creating OpenAI service (type: real)

ğŸ“¦ ===== BATCH 1 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:11:34.949Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 0
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:11:34.950Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:11:34.951Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6211,
  existingClassifications: { intents: 0, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.



For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and another intent, classify the intent as the other i...
::1 - - [12/Aug/2025:16:11:35 +0000] "GET /api/analysis/auto-analyze/progress/e1ecf062-ef9a-4860-a5d9-75eb3685e321 HTTP/1.1" 200 624 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:11:37 +0000] "GET /api/analysis/auto-analyze/progress/e1ecf062-ef9a-4860-a5d9-75eb3685e321 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:11:38.391Z',
  duration: '3440ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1814,
    completion_tokens: 284,
    total_tokens: 2098,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Unknown' ],
  transferCount: 4,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-4ae9b8c5-e32d-5e70-8506-e5284ccb5cbb",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Operator Request",
      "drop_off_location": "Leave request number"
    },
    {
      "user_id": "u-1841b6a9-7ee9-52cf-9e63-0100836efa87",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User was silent and session was closed due to no input."
    },
    {
      "user_id": "u-c40f3a23-e535-50a2-83dd-a0d673e2cfa3",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-8a8e8a17-dd33-5a51-89ac-02caad080706",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Help Offer Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-068666a7-515b-508d-8607-5433f8d8fcf3",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1814,
  completionTokens: 284,
  totalTokens: 2098,
  cost: '$0.000295',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 3442ms (3.44s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2098 ($0.0003)
âš¡ Performance: 609.5 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 3442ms (3.44s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2098

âœ… ===== BATCH 1 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 3443ms (3.44s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2098 ($0.0003)
âš¡ Performance: 1.5 sessions/sec
âš¡ Avg Time Per Session: 688.60ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:16:11:39 +0000] "GET /api/analysis/auto-analyze/progress/e1ecf062-ef9a-4860-a5d9-75eb3685e321 HTTP/1.1" 200 634 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"

ğŸ“¦ ===== BATCH 2 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:11:40.395Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 1
   â€¢ Reasons: 3
   â€¢ Locations: 2

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:11:40.396Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:11:40.396Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6690,
  existingClassifications: { intents: 1, transferReasons: 3, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Unknown
Existing Transfer Reason classifications: Help Offer Request, Live Agent Request, Operator Request
Existing Drop-Off Location classifications: Help Offer Prompt, Leave request number

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Cl...
::1 - - [12/Aug/2025:16:11:41 +0000] "GET /api/analysis/auto-analyze/progress/e1ecf062-ef9a-4860-a5d9-75eb3685e321 HTTP/1.1" 200 634 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:11:43 +0000] "GET /api/analysis/auto-analyze/progress/e1ecf062-ef9a-4860-a5d9-75eb3685e321 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:11:43.428Z',
  duration: '3032ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1906,
    completion_tokens: 342,
    total_tokens: 2248,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Unknown', 'Claim status', 'Live Agent' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-003b28d6-e53e-5f07-8bd8-028ab5ff6107",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Help Offer Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak to an agent, session transferred."
    },
    {
      "user_id": "u-bfbb40fe-2882-5386-9d49-a9abd4caab64",
      "general_intent": "Claim status",
      "session_outcome": "Transfer",
      "transfer_reason": "Help Offer Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User provided claim info but was transferred after record mismatch."
    },
    {
      "user_id": "u-ed64c08d-dc63-59ff-b026-a681a76a8306",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Help Offer Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted customer service, session transferred."
    },
    {
      "user_id": "u-e78d1e6a-a69e-5343-abb6-f9832cb94213",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Help Offer Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted customer service, session transferred."
    },
    {
      "user_id": "u-2836171a-c12b-5622-b7de-8c0263dfeccc",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Help Offer Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a live person, session transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1906,
  completionTokens: 342,
  totalTokens: 2248,
  cost: '$0.000327',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 3033ms (3.03s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2248 ($0.0003)
âš¡ Performance: 741.2 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 3033ms (3.03s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2248

âœ… ===== BATCH 2 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 3033ms (3.03s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2248 ($0.0003)
âš¡ Performance: 1.6 sessions/sec
âš¡ Avg Time Per Session: 606.60ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:16:11:45 +0000] "GET /api/analysis/auto-analyze/progress/e1ecf062-ef9a-4860-a5d9-75eb3685e321 HTTP/1.1" 200 648 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"

ğŸ“¦ ===== BATCH 3 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:11:45.430Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 3
   â€¢ Locations: 2

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:11:45.430Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:11:45.430Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7451,
  existingClassifications: { intents: 3, transferReasons: 3, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim status, Live Agent, Unknown
Existing Transfer Reason classifications: Help Offer Request, Live Agent Request, Operator Request
Existing Drop-Off Location classifications: Help Offer Prompt, Leave request number

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 wo...
::1 - - [12/Aug/2025:16:11:47 +0000] "GET /api/analysis/auto-analyze/progress/e1ecf062-ef9a-4860-a5d9-75eb3685e321 HTTP/1.1" 200 648 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:11:47.546Z',
  duration: '2116ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2111,
    completion_tokens: 244,
    total_tokens: 2355,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-ebdfb9d2-11b8-59bd-9a01-b43c63a4726a",
      "notes": "User wanted to speak with an agent, session was transferred to a live agent."
    },
    {
      "user_id": "u-d2ec229e-700f-5754-a760-a67d7daa71cc",
      "notes": "User inquired about a new claim, verified account, and was transferred to an agent when no specific request was made."
    },
    {
      "user_id": "u-48551807-4d52-50e3-a209-f49923052de5",
      "notes": "User wanted to request informal papers, was transferred to an agent after initial misunderstanding."
    },
    {
      "user_id": "u-a8813964-0ab0-5b3d-b845-f701b2d48b7b",
      "notes": "User wanted to start a new claim, session was transferred to an agent."
    },
    {
      "user_id": "u-a14ea96c-0359-520d-9cc8-4f5dc6d032b0",
      "notes": "User requested FMLA paperwork, session was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2111,
  completionTokens: 244,
  totalTokens: 2355,
  cost: '$0.000309',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2116ms (2.12s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2355 ($0.0003)
âš¡ Performance: 1112.9 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2117ms (2.12s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2355

âœ… ===== BATCH 3 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2118ms (2.12s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2355 ($0.0003)
âš¡ Performance: 2.4 sessions/sec
âš¡ Avg Time Per Session: 423.60ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:16:11:49 +0000] "GET /api/analysis/auto-analyze/progress/e1ecf062-ef9a-4860-a5d9-75eb3685e321 HTTP/1.1" 200 636 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"

ğŸ“¦ ===== BATCH 4 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:11:49.549Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 3
   â€¢ Locations: 2

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:11:49.549Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:11:49.550Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7283,
  existingClassifications: { intents: 3, transferReasons: 3, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim status, Live Agent, Unknown
Existing Transfer Reason classifications: Help Offer Request, Live Agent Request, Operator Request
Existing Drop-Off Location classifications: Help Offer Prompt, Leave request number

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 wo...
::1 - - [12/Aug/2025:16:11:51 +0000] "GET /api/analysis/auto-analyze/progress/e1ecf062-ef9a-4860-a5d9-75eb3685e321 HTTP/1.1" 200 636 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:11:51.543Z',
  duration: '1993ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2073,
    completion_tokens: 308,
    total_tokens: 2381,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Unknown' ],
  transferCount: 3,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-a8e42b18-1aef-5789-940c-0c6afc1403cd",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User attempted to get online but did not specify a clear request, session was closed without transfer."
    },
    {
      "user_id": "u-f9689b57-d0c3-5965-9872-64fdba93d27f",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User tried to check leave requests and open a new one, but the session was closed without transfer."
    },
    {
      "user_id": "u-fd7d3e52-abc8-5442-8f02-dfc372e2f17c",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "notes": "User wanted to start a new leave but provided an invalid response, leading to transfer."
    },
    {
      "user_id": "u-26ccd4e1-65b1-5022-a9f9-164fb96f598a",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "notes": "User requested to speak with an agent, resulting in transfer."
    },
    {
      "user_id": "u-51a8dbb9-240d-5f3b-bb81-189c0efc59fb",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "notes": "User requested to speak with an agent, resulting in transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2073,
  completionTokens: 308,
  totalTokens: 2381,
  cost: '$0.000331',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 1994ms (1.99s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2381 ($0.0003)
âš¡ Performance: 1194.1 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 1ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 1995ms (2.00s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2381

âœ… ===== BATCH 4 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 1996ms (2.00s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2381 ($0.0003)
âš¡ Performance: 2.5 sessions/sec
âš¡ Avg Time Per Session: 399.20ms
â±ï¸  Metadata Processing: 0ms
::1 - - [12/Aug/2025:16:11:53 +0000] "GET /api/analysis/auto-analyze/progress/e1ecf062-ef9a-4860-a5d9-75eb3685e321 HTTP/1.1" 200 636 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"

ğŸ“¦ ===== BATCH 5 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:11:53.545Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 3
   â€¢ Locations: 2

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:11:53.545Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:11:53.545Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6829,
  existingClassifications: { intents: 3, transferReasons: 3, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim status, Live Agent, Unknown
Existing Transfer Reason classifications: Help Offer Request, Live Agent Request, Operator Request
Existing Drop-Off Location classifications: Help Offer Prompt, Leave request number

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 wo...
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:11:56.061Z',
  duration: '2516ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1961,
    completion_tokens: 339,
    total_tokens: 2300,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Live Agent', 'Claim Status', 'Eligibility' ],
  transferCount: 3,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-a4f83c4d-652d-57f9-87ae-37d59be6750f",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested customer service and was transferred to an agent."
    },
    {
      "user_id": "u-d95e2dad-08f5-5f1f-931a-3d57fdb5494c",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User attempted to report a new leave and encountered issues, but was not transferred."
    },
    {
      "user_id": "u-210cd6c1-abd9-5a56-8167-06628f08e8cd",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to talk to a person and was transferred to an agent."
    },
    {
      "user_id": "u-84f77b3d-9435-55bf-b853-84bace42a7ed",
      "general_intent": "Eligibility",
      "session_outcome": "Contained",
      "notes": "User inquired about eligibility for leave, but was not transferred."
    },
    {
      "user_id": "u-7af63530-e0da-5bc1-86ae-d21d64a27293",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak to a representative and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1961,
  completionTokens: 339,
  totalTokens: 2300,
  cost: '$0.000332',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2517ms (2.52s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2300 ($0.0003)
âš¡ Performance: 913.8 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2517ms (2.52s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2300

âœ… ===== BATCH 5 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2517ms (2.52s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2300 ($0.0003)
âš¡ Performance: 2.0 sessions/sec
âš¡ Avg Time Per Session: 503.40ms
â±ï¸  Metadata Processing: 0ms

ğŸ“¦ ===== BATCH 6 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:11:58.064Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 3
   â€¢ Locations: 2

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:11:58.064Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:11:58.064Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6417,
  existingClassifications: { intents: 5, transferReasons: 3, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Eligibility, Live Agent, Unknown
Existing Transfer Reason classifications: Help Offer Request, Live Agent Request, Operator Request
Existing Drop-Off Location classifications: Help Offer Prompt, Leave request number

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to...
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:11:59.693Z',
  duration: '1629ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1838,
    completion_tokens: 242,
    total_tokens: 2080,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-f0801b85-aa4e-5d51-8b7d-66b3a984583c",
      "notes": "User wanted to speak with an agent, session transferred."
    },
    {
      "user_id": "u-06d38663-c3ec-53a1-a667-d0b653968c50",
      "notes": "User wanted to speak with an agent, session transferred, but no input received."
    },
    {
      "user_id": "u-5dbbc253-d0bd-5b69-9e53-6a0b0a57b2a3",
      "notes": "User wanted to speak with an agent, session transferred, but no input received."
    },
    {
      "user_id": "u-5f275d3d-03dd-5f57-8145-92286c70a3df",
      "notes": "User wanted to speak with an agent, session transferred, but no input received."
    },
    {
      "user_id": "u-a13f2641-d017-5638-8f4e-2c93a5305855",
      "notes": "User wanted to speak with an agent, session transferred, but no input received."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1838,
  completionTokens: 242,
  totalTokens: 2080,
  cost: '$0.000281',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 1630ms (1.63s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2080 ($0.0003)
âš¡ Performance: 1276.1 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 1630ms (1.63s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2080

âœ… ===== BATCH 6 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 1631ms (1.63s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2080 ($0.0003)
âš¡ Performance: 3.1 sessions/sec
âš¡ Avg Time Per Session: 326.20ms
â±ï¸  Metadata Processing: 0ms

ğŸ“¦ ===== BATCH 7 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:12:01.696Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 3
   â€¢ Locations: 2

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:12:01.696Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:12:01.697Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6749,
  existingClassifications: { intents: 5, transferReasons: 3, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Eligibility, Live Agent, Unknown
Existing Transfer Reason classifications: Help Offer Request, Live Agent Request, Operator Request
Existing Drop-Off Location classifications: Help Offer Prompt, Leave request number

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to...
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:12:04.113Z',
  duration: '2416ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1920,
    completion_tokens: 345,
    total_tokens: 2265,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Unknown', 'Claim Status' ],
  transferCount: 4,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-fcc48d46-8c38-50be-98ab-62fd35b592fa",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to start FMLA, session transferred to an agent."
    },
    {
      "user_id": "u-96618d9f-871d-5b97-aa75-a0b14ffa7026",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested agent, session transferred to an agent."
    },
    {
      "user_id": "u-52960756-2139-5afd-8c27-605c345da070",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a representative, session transferred to an agent."
    },
    {
      "user_id": "u-2337f5fb-8df7-5bc2-846f-d04fb002ffa3",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User provided claim request number and personal info, session handled by bot."
    },
    {
      "user_id": "u-cbff4915-48e1-57c6-a533-2c8b355e03e6",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a representative, session transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1920,
  completionTokens: 345,
  totalTokens: 2265,
  cost: '$0.000330',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2418ms (2.42s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2265 ($0.0003)
âš¡ Performance: 936.7 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2418ms (2.42s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2265

âœ… ===== BATCH 7 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2419ms (2.42s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2265 ($0.0003)
âš¡ Performance: 2.1 sessions/sec
âš¡ Avg Time Per Session: 483.80ms
â±ï¸  Metadata Processing: 0ms

ğŸ“¦ ===== BATCH 8 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:12:06.116Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 3
   â€¢ Locations: 2

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:12:06.117Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:12:06.118Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 8185,
  existingClassifications: { intents: 5, transferReasons: 3, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Eligibility, Live Agent, Unknown
Existing Transfer Reason classifications: Help Offer Request, Live Agent Request, Operator Request
Existing Drop-Off Location classifications: Help Offer Prompt, Leave request number

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to...
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:12:08.650Z',
  duration: '2531ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2344,
    completion_tokens: 249,
    total_tokens: 2593,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-8126563b-e494-55d5-9511-40288ef17b49",
      "notes": "User needed help with a claim and was prompted for a leave request number, but the session did not transfer to an agent."
    },
    {
      "user_id": "u-fae74977-505e-5930-90b7-797fe2280c22",
      "notes": "User was silent and provided minimal input, leading to session closure without transfer."
    },
    {
      "user_id": "u-ab41b38a-0cab-59fb-b5db-fedde61b339b",
      "notes": "User successfully verified account, checked claim status, and submitted a time entry, with no transfer."
    },
    {
      "user_id": "u-697c4440-7625-52cb-87b3-236a443a5d37",
      "notes": "User attempted to extend a claim, but the session transferred to an agent due to inability to proceed."
    },
    {
      "user_id": "u-1dd19dc4-dc07-5d8d-94c9-00073d90ae6a",
      "notes": "User ended the session without any specific request, leading to session closure."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2344,
  completionTokens: 249,
  totalTokens: 2593,
  cost: '$0.000334',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2534ms (2.53s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2593 ($0.0003)
âš¡ Performance: 1023.3 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2534ms (2.53s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2593

âœ… ===== BATCH 8 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2536ms (2.54s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2593 ($0.0003)
âš¡ Performance: 2.0 sessions/sec
âš¡ Avg Time Per Session: 507.20ms
â±ï¸  Metadata Processing: 0ms

ğŸ“¦ ===== BATCH 9 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:12:10.653Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 3
   â€¢ Locations: 2

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:12:10.653Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:12:10.653Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7367,
  existingClassifications: { intents: 5, transferReasons: 3, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Eligibility, Live Agent, Unknown
Existing Transfer Reason classifications: Help Offer Request, Live Agent Request, Operator Request
Existing Drop-Off Location classifications: Help Offer Prompt, Leave request number

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to...
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:12:12.449Z',
  duration: '1796ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2079,
    completion_tokens: 241,
    total_tokens: 2320,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-19507be8-2eea-5f1d-8546-bf2b8039c6d0",
      "notes": "User wanted to update leave but was transferred to an agent."
    },
    {
      "user_id": "u-52df30cc-e1e6-59fe-9b09-52f141a1fe41",
      "notes": "User requested to speak to an agent, was transferred after star input."
    },
    {
      "user_id": "u-5536c5f6-429f-58ac-930a-e847017d3d4d",
      "notes": "User wanted to speak to an agent, was transferred after agent request."
    },
    {
      "user_id": "u-53ac09d6-06f7-5a8b-a1a9-e7d6b8623e78",
      "notes": "User wanted to speak to an agent, was transferred after star input."
    },
    {
      "user_id": "u-7142eab7-a13a-575f-8e6b-120a99b87df5",
      "notes": "User wanted to return to work, was transferred after account verification."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2079,
  completionTokens: 241,
  totalTokens: 2320,
  cost: '$0.000304',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 1797ms (1.80s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2320 ($0.0003)
âš¡ Performance: 1291.0 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 1797ms (1.80s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2320

âœ… ===== BATCH 9 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 1797ms (1.80s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2320 ($0.0003)
âš¡ Performance: 2.8 sessions/sec
âš¡ Avg Time Per Session: 359.40ms
â±ï¸  Metadata Processing: 1ms

ğŸ“¦ ===== BATCH 10 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:12:14.452Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 3
   â€¢ Locations: 2

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:12:14.452Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:12:14.453Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6275,
  existingClassifications: { intents: 5, transferReasons: 3, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Eligibility, Live Agent, Unknown
Existing Transfer Reason classifications: Help Offer Request, Live Agent Request, Operator Request
Existing Drop-Off Location classifications: Help Offer Prompt, Leave request number

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to...
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:12:17.632Z',
  duration: '3179ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1796,
    completion_tokens: 352,
    total_tokens: 2148,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Unknown' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-c44a16a0-c616-56be-976a-543dfdeadef0",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Help Offer Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted customer service and was transferred to an agent."
    },
    {
      "user_id": "u-349afa4f-29cd-53f8-ad37-94c91db888d1",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Help Offer Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested paperwork help and was transferred to an agent."
    },
    {
      "user_id": "u-658c97ec-4558-58dd-b360-671da6c71d81",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Help Offer Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and then transferred to an agent."
    },
    {
      "user_id": "u-54dae05a-5dc4-5704-a1c2-d3c04780598c",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Help Offer Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-00e6c2f0-c8f4-533a-bd08-1e5b2dfd253b",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Help Offer Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User mentioned 'newly request' and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1796,
  completionTokens: 352,
  totalTokens: 2148,
  cost: '$0.000320',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 3180ms (3.18s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2148 ($0.0003)
âš¡ Performance: 675.5 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 3180ms (3.18s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2148

âœ… ===== BATCH 10 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 3180ms (3.18s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2148 ($0.0003)
âš¡ Performance: 1.6 sessions/sec
âš¡ Avg Time Per Session: 636.00ms
â±ï¸  Metadata Processing: 0ms

ğŸ“¦ ===== BATCH 11 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:12:19.634Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 3
   â€¢ Locations: 2

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:12:19.634Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:12:19.635Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7501,
  existingClassifications: { intents: 5, transferReasons: 3, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Eligibility, Live Agent, Unknown
Existing Transfer Reason classifications: Help Offer Request, Live Agent Request, Operator Request
Existing Drop-Off Location classifications: Help Offer Prompt, Leave request number

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to...
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:12:21.583Z',
  duration: '1948ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2121,
    completion_tokens: 254,
    total_tokens: 2375,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-14c5ba2d-cf60-5242-bbed-41edfc1611a5",
      "notes": "User submitted a leave request for a day off and confirmed details, session was handled by bot."
    },
    {
      "user_id": "u-f92c8c54-1d77-5b21-9e16-518d4912fc67",
      "notes": "User requested to speak to an agent, session was transferred to a live agent."
    },
    {
      "user_id": "u-30342e26-d14c-5c12-95dc-da2f8fc4f5b0",
      "notes": "User requested to speak to an agent, session was transferred to a live agent."
    },
    {
      "user_id": "u-a56d9452-9d50-59e8-a174-14885c44a01a",
      "notes": "User requested to speak to an agent, session was transferred to a live agent."
    },
    {
      "user_id": "u-ca3e19f9-69e9-54d3-8f1e-5d5f2b2d1714",
      "notes": "User requested to speak to an agent, session was transferred to a live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2121,
  completionTokens: 254,
  totalTokens: 2375,
  cost: '$0.000314',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 1950ms (1.95s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2375 ($0.0003)
âš¡ Performance: 1217.9 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 1950ms (1.95s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2375

âœ… ===== BATCH 11 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 1950ms (1.95s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2375 ($0.0003)
âš¡ Performance: 2.6 sessions/sec
âš¡ Avg Time Per Session: 390.00ms
â±ï¸  Metadata Processing: 0ms

ğŸ“¦ ===== BATCH 12 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:12:23.586Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 3
   â€¢ Locations: 2

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:12:23.586Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:12:23.586Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 8882,
  existingClassifications: { intents: 5, transferReasons: 3, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Eligibility, Live Agent, Unknown
Existing Transfer Reason classifications: Help Offer Request, Live Agent Request, Operator Request
Existing Drop-Off Location classifications: Help Offer Prompt, Leave request number

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to...
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:12:25.236Z',
  duration: '1650ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2454,
    completion_tokens: 234,
    total_tokens: 2688,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-c5999dc1-e5d5-53a2-bf78-9d98d083fb28",
      "notes": "User requested to speak with a representative, session was transferred to an agent."
    },
    {
      "user_id": "u-f0baa8b8-3aad-5a4b-9ce7-102c9be791e2",
      "notes": "User attempted to report time and provided details, session was not transferred."
    },
    {
      "user_id": "u-b8305407-3859-561d-afc9-720b16a842ab",
      "notes": "User requested short term disability, then transferred to an agent after clarification."
    },
    {
      "user_id": "u-41226b73-1d00-5e18-b194-63112ca264ea",
      "notes": "User requested short term disability, session was transferred after clarification."
    },
    {
      "user_id": "u-e2cd5112-f2b9-5944-815e-ca8ab31c4d7c",
      "notes": "User inquired about FMLA paperwork and coverage, session was transferred after multiple clarifications."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2454,
  completionTokens: 234,
  totalTokens: 2688,
  cost: '$0.000339',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 1651ms (1.65s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2688 ($0.0003)
âš¡ Performance: 1628.1 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 1651ms (1.65s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2688

âœ… ===== BATCH 12 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 1651ms (1.65s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2688 ($0.0003)
âš¡ Performance: 3.0 sessions/sec
âš¡ Avg Time Per Session: 330.20ms
â±ï¸  Metadata Processing: 0ms

ğŸ“¦ ===== BATCH 13 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:12:27.238Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 3
   â€¢ Locations: 2

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:12:27.239Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:12:27.239Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6674,
  existingClassifications: { intents: 5, transferReasons: 3, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Eligibility, Live Agent, Unknown
Existing Transfer Reason classifications: Help Offer Request, Live Agent Request, Operator Request
Existing Drop-Off Location classifications: Help Offer Prompt, Leave request number

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to...
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:12:29.590Z',
  duration: '2351ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1902,
    completion_tokens: 364,
    total_tokens: 2266,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Live Agent', 'Unknown', 'Claim Status' ],
  transferCount: 4,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-42bc83ad-4850-5f70-a135-dc698ab12113",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative and was transferred to an agent."
    },
    {
      "user_id": "u-32aa6ce6-e23c-5a0c-a845-1b43e62b315c",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested password reset and was transferred to an agent."
    },
    {
      "user_id": "u-14c71ffe-0eaf-5a4a-9ad2-a55ecb42b0ca",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested customer service and was transferred to an agent."
    },
    {
      "user_id": "u-6e7f4a6f-bc52-505f-8814-0142529a5206",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User simply said 'Agent' and was transferred to an agent."
    },
    {
      "user_id": "u-64bd9ac5-2e64-5ed1-95da-5a4e112f4b9f",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User attempted to track time off, but the session was transferred after requesting a transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1902,
  completionTokens: 364,
  totalTokens: 2266,
  cost: '$0.000336',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2351ms (2.35s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2266 ($0.0003)
âš¡ Performance: 963.8 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2351ms (2.35s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2266

âœ… ===== BATCH 13 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2352ms (2.35s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2266 ($0.0003)
âš¡ Performance: 2.1 sessions/sec
âš¡ Avg Time Per Session: 470.40ms
â±ï¸  Metadata Processing: 0ms

ğŸ“¦ ===== BATCH 14 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:12:31.592Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 3
   â€¢ Locations: 2

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:12:31.592Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:12:31.593Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7294,
  existingClassifications: { intents: 5, transferReasons: 3, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Eligibility, Live Agent, Unknown
Existing Transfer Reason classifications: Help Offer Request, Live Agent Request, Operator Request
Existing Drop-Off Location classifications: Help Offer Prompt, Leave request number

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to...
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:12:34.104Z',
  duration: '2511ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2083,
    completion_tokens: 371,
    total_tokens: 2454,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [
    'Unknown',
    'Live Agent',
    'Return to work',
    'Customer Service',
    'Claim Status'
  ],
  transferCount: 4,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-7f0b86d9-51f2-565f-8055-f82051a27741",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Help Offer Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to report time used but was unable to provide leave request number, leading to transfer."
    },
    {
      "user_id": "u-e5923564-85f8-500c-a044-6fab4c621538",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a customer service person, resulting in transfer to an agent."
    },
    {
      "user_id": "u-ae0987ae-f14d-53fa-8e1e-f23d500e3a3d",
      "general_intent": "Return to work",
      "session_outcome": "Contained",
      "notes": "User provided leave request number and return date, session was handled by bot without transfer."
    },
    {
      "user_id": "u-8880a06a-07f2-5f67-936e-bac4ce00ae0c",
      "general_intent": "Customer Service",
      "session_outcome": "Transfer",
      "transfer_reason": "Help Offer Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested customer service, resulting in transfer to an agent."
    },
    {
      "user_id": "u-e4f3fb70-9c89-5975-a53c-06b10acb25c2",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Help Offer Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User checked claim status and then requested to talk to a representative, leading to transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2083,
  completionTokens: 371,
  totalTokens: 2454,
  cost: '$0.000357',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2513ms (2.51s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2454 ($0.0004)
âš¡ Performance: 976.5 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2513ms (2.51s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2454

âœ… ===== BATCH 14 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2513ms (2.51s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2454 ($0.0004)
âš¡ Performance: 2.0 sessions/sec
âš¡ Avg Time Per Session: 502.60ms
â±ï¸  Metadata Processing: 0ms

ğŸ“¦ ===== BATCH 15 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:12:36.106Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 3
   â€¢ Locations: 2

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:12:36.107Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:12:36.107Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7146,
  existingClassifications: { intents: 7, transferReasons: 3, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Customer Service, Eligibility, Live Agent, Return to work, Unknown
Existing Transfer Reason classifications: Help Offer Request, Live Agent Request, Operator Request
Existing Drop-Off Location classifications: Help Offer Prompt, Leave request number

For each session, provide the following classifications:

1. **General In...
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:12:37.855Z',
  duration: '1748ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2023,
    completion_tokens: 281,
    total_tokens: 2304,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Claim Status', 'Unknown' ],
  transferCount: 4,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-96112b41-cb11-5f15-9eed-c66738459d19",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User reported birth for claim, provided details, and successfully submitted delivery information."
    },
    {
      "user_id": "u-67f6c29d-5c28-5507-9f57-b275c529d341",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-48f4a31f-236a-5794-9d03-40a9cfc780c3",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-39cac19d-f44e-503d-a400-970067f0742b",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-a3fac934-5ea1-5c89-9592-516eb987e711",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2023,
  completionTokens: 281,
  totalTokens: 2304,
  cost: '$0.000315',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 1749ms (1.75s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2304 ($0.0003)
âš¡ Performance: 1317.3 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 1ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 1750ms (1.75s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2304

âœ… ===== BATCH 15 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 1750ms (1.75s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2304 ($0.0003)
âš¡ Performance: 2.9 sessions/sec
âš¡ Avg Time Per Session: 350.00ms
â±ï¸  Metadata Processing: 0ms

ğŸ“¦ ===== BATCH 16 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:12:39.858Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 3
   â€¢ Locations: 2

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:12:39.858Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:12:39.859Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7359,
  existingClassifications: { intents: 7, transferReasons: 3, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Customer Service, Eligibility, Live Agent, Return to work, Unknown
Existing Transfer Reason classifications: Help Offer Request, Live Agent Request, Operator Request
Existing Drop-Off Location classifications: Help Offer Prompt, Leave request number

For each session, provide the following classifications:

1. **General In...
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:12:42.095Z',
  duration: '2236ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2078,
    completion_tokens: 284,
    total_tokens: 2362,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Live Agent', 'Unknown' ],
  transferCount: 3,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-428c0f1a-7211-5d29-8abd-2f04a9910ca5",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-c223cbf0-83fb-593b-b1b5-777786e94bdb",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User did not provide input after initial prompt, session was closed."
    },
    {
      "user_id": "u-125c0153-0f88-5bbc-83e4-9251d332332d",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User wanted to speak to a representative but did not get transferred, session was closed."
    },
    {
      "user_id": "u-de174894-b92c-5397-8adb-996f7479b588",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Help Offer Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-588b636f-00aa-5c40-ad72-c1e4be50384c",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Help Offer Request",
      "drop_off_location": "Help Offer Prompt"
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2078,
  completionTokens: 284,
  totalTokens: 2362,
  cost: '$0.000321',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2238ms (2.24s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2362 ($0.0003)
âš¡ Performance: 1055.4 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2238ms (2.24s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2362

âœ… ===== BATCH 16 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2238ms (2.24s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2362 ($0.0003)
âš¡ Performance: 2.2 sessions/sec
âš¡ Avg Time Per Session: 447.60ms
â±ï¸  Metadata Processing: 0ms

ğŸ“¦ ===== BATCH 17 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:12:44.096Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 3
   â€¢ Locations: 2

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:12:44.096Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:12:44.097Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6785,
  existingClassifications: { intents: 7, transferReasons: 3, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Customer Service, Eligibility, Live Agent, Return to work, Unknown
Existing Transfer Reason classifications: Help Offer Request, Live Agent Request, Operator Request
Existing Drop-Off Location classifications: Help Offer Prompt, Leave request number

For each session, provide the following classifications:

1. **General In...
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:12:45.941Z',
  duration: '1844ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1924,
    completion_tokens: 247,
    total_tokens: 2171,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-7ae9690f-b454-5bc8-9ea8-de2964fbd2fa",
      "notes": "User inquired about parental leave but did not have specific details or request, leading to transfer to a live agent."
    },
    {
      "user_id": "u-014636f8-2374-5f0e-803c-d53dd3acc3b5",
      "notes": "User requested to speak with an agent, session transferred to a live agent."
    },
    {
      "user_id": "u-d84531a8-4c6b-5a3b-b467-5deddd5c4dc7",
      "notes": "User requested to speak with an agent, session transferred to a live agent."
    },
    {
      "user_id": "u-25d943ff-d30e-581c-94c5-287ea3452a4d",
      "notes": "User asked about leave of absence, session transferred to a live agent."
    },
    {
      "user_id": "u-deb45f93-7f30-596a-9c41-04c3a625a222",
      "notes": "User requested to speak with an agent, session transferred to a live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1924,
  completionTokens: 247,
  totalTokens: 2171,
  cost: '$0.000291',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 1846ms (1.85s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2171 ($0.0003)
âš¡ Performance: 1176.1 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 1846ms (1.85s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2171

âœ… ===== BATCH 17 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 1846ms (1.85s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2171 ($0.0003)
âš¡ Performance: 2.7 sessions/sec
âš¡ Avg Time Per Session: 369.20ms
â±ï¸  Metadata Processing: 0ms

ğŸ“¦ ===== BATCH 18 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:12:47.943Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 3
   â€¢ Locations: 2

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:12:47.943Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:12:47.943Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7517,
  existingClassifications: { intents: 7, transferReasons: 3, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Customer Service, Eligibility, Live Agent, Return to work, Unknown
Existing Transfer Reason classifications: Help Offer Request, Live Agent Request, Operator Request
Existing Drop-Off Location classifications: Help Offer Prompt, Leave request number

For each session, provide the following classifications:

1. **General In...
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:12:49.839Z',
  duration: '1895ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2127,
    completion_tokens: 243,
    total_tokens: 2370,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-5f135adb-065b-59bf-bc7d-4afa34e20c42",
      "notes": "User attempted to access leave request information but did not have the request number, and was transferred to an agent for further assistance."
    },
    {
      "user_id": "u-403bae97-df2d-530a-909d-0f8a67aa8e00",
      "notes": "User checked leave request status and inquired about adding to it, but was ultimately transferred to an agent."
    },
    {
      "user_id": "u-dbac7073-f003-5193-ad9d-fdbf05616f73",
      "notes": "User inquired about claim status but the session was not completed."
    },
    {
      "user_id": "u-bd119e77-c6c7-51ab-9c96-3e442946edc5",
      "notes": "Session was closed without user input, no transfer occurred."
    },
    {
      "user_id": "u-979f5376-5c34-59e4-a576-6c89d72b5e22",
      "notes": "User inquired about leave approval and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2127,
  completionTokens: 243,
  totalTokens: 2370,
  cost: '$0.000310',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 1896ms (1.90s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2370 ($0.0003)
âš¡ Performance: 1250.0 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 1896ms (1.90s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2370

âœ… ===== BATCH 18 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 1897ms (1.90s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2370 ($0.0003)
âš¡ Performance: 2.6 sessions/sec
âš¡ Avg Time Per Session: 379.40ms
â±ï¸  Metadata Processing: 0ms

ğŸ“¦ ===== BATCH 19 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:12:51.841Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 3
   â€¢ Locations: 2

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 1ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:12:51.842Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:12:51.842Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6496,
  existingClassifications: { intents: 7, transferReasons: 3, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Customer Service, Eligibility, Live Agent, Return to work, Unknown
Existing Transfer Reason classifications: Help Offer Request, Live Agent Request, Operator Request
Existing Drop-Off Location classifications: Help Offer Prompt, Leave request number

For each session, provide the following classifications:

1. **General In...
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:12:54.267Z',
  duration: '2425ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1826,
    completion_tokens: 345,
    total_tokens: 2171,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Unknown' ],
  transferCount: 4,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-a26767c6-fe2c-5f92-aa9c-0a94fc39f296",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Help Offer Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak to someone about FMLA paperwork and was transferred."
    },
    {
      "user_id": "u-cebce5d1-b27c-5bec-ab58-3dbee734303b",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Help Offer Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent about leave and was transferred."
    },
    {
      "user_id": "u-9d101f6f-e7ea-57aa-b111-e2f074ad969c",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Help Offer Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested leave and was transferred to assist with new leave requests."
    },
    {
      "user_id": "u-79631d4c-1336-53ae-a41f-ce3740dee921",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "Session ended without user input."
    },
    {
      "user_id": "u-7230a3db-9085-5a8b-9d0f-4dcca585e78f",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Help Offer Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak about opening a new claim and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1826,
  completionTokens: 345,
  totalTokens: 2171,
  cost: '$0.000321',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2426ms (2.43s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2171 ($0.0003)
âš¡ Performance: 894.9 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2426ms (2.43s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2171

âœ… ===== BATCH 19 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2427ms (2.43s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2171 ($0.0003)
âš¡ Performance: 2.1 sessions/sec
âš¡ Avg Time Per Session: 485.40ms
â±ï¸  Metadata Processing: 0ms

ğŸ“¦ ===== BATCH 20 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:12:56.269Z
ğŸ“Š Sessions in Batch: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 3
   â€¢ Locations: 2

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 3
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:12:56.269Z
ğŸ“Š Sessions to Analyze: 3

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:12:56.269Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 3,
  apiKey: 'sk-proj-...',
  promptLength: 5688,
  existingClassifications: { intents: 7, transferReasons: 3, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Customer Service, Eligibility, Live Agent, Return to work, Unknown
Existing Transfer Reason classifications: Help Offer Request, Live Agent Request, Operator Request
Existing Drop-Off Location classifications: Help Offer Prompt, Leave request number

For each session, provide the following classifications:

1. **General In...
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:12:57.719Z',
  duration: '1450ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1626,
    completion_tokens: 218,
    total_tokens: 1844,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 3,
  intentsFound: [ 'Live Agent', 'Return to work' ],
  transferCount: 3,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-0fa6fa2a-fc40-56df-ac98-a7faa658243e",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-5917e195-535d-5ad3-af86-4dc6e45e0856",
      "general_intent": "Return to work",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent after attempting to report return to work."
    },
    {
      "user_id": "u-d7c496ff-2a60-5ecc-a40a-a41a67e2343a",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1626,
  completionTokens: 218,
  totalTokens: 1844,
  cost: '$0.000250',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 1450ms (1.45s)
ğŸ“Š Sessions Returned: 3
ğŸ’° Tokens Used: 1844 ($0.0002)
âš¡ Performance: 1271.7 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 3
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 1450ms (1.45s)
ğŸ“Š Regular Sessions Processed: 3
ğŸ’° Regular Tokens Used: 1844

âœ… ===== BATCH 20 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 1450ms (1.45s)
ğŸ“Š Sessions Processed: 3/3
ğŸ’° Total Tokens: 1844 ($0.0002)
âš¡ Performance: 2.1 sessions/sec
âš¡ Avg Time Per Session: 483.33ms
â±ï¸  Metadata Processing: 0ms
[BackgroundJobQueue] Session analysis completed for job e1ecf062-ef9a-4860-a5d9-75eb3685e321-sampling-analysis, processed 98 sessions
[BackgroundJobQueue] Analysis summary generated for job e1ecf062-ef9a-4860-a5d9-75eb3685e321-sampling-analysis
[BackgroundJobQueue] Analysis completed for job e1ecf062-ef9a-4860-a5d9-75eb3685e321-sampling-analysis, processed 98 sessions
[BackgroundJobQueue] Results successfully stored in AutoAnalyzeService for analysis e1ecf062-ef9a-4860-a5d9-75eb3685e321
[BackgroundJobQueue] Analysis e1ecf062-ef9a-4860-a5d9-75eb3685e321 completed with 98 sessions
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T16:14:39.667Z",
  "dateTo": "2025-08-12T16:15:39.667Z",
  "skip": 0,
  "limit": 1
}
[fetchContainmentTypeMetadata] API Response: 1 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [ '689b687eb95843b790184da6' ]
[getSessionsMetadataForConnectionTest] Single API call succeeded with 1 sessions
::1 - - [12/Aug/2025:16:15:42 +0000] "GET /api/kore/test HTTP/1.1" 200 851 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸš€ [ParallelAutoAnalyzeRoute] Starting parallel analysis for bot ***REMOVED*** with real credentials
ğŸš€ [ParallelAutoAnalyzeService] Starting parallel analysis 52583704-4927-491d-82e4-6ee9561ebd69 with bot ***REMOVED***
ğŸš€ [ParallelAutoAnalyzeService] Using credentials: real
ğŸš€ [ParallelAutoAnalyzeRoute] Parallel analysis started: 52583704-4927-491d-82e4-6ee9561ebd69
::1 - - [12/Aug/2025:16:16:04 +0000] "POST /api/analysis/auto-analyze/parallel/start HTTP/1.1" 200 214 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:16:04 +0000] "GET /api/analysis/auto-analyze/parallel/progress/52583704-4927-491d-82e4-6ee9561ebd69 HTTP/1.1" 200 542 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:16:04 +0000] "GET /api/analysis/auto-analyze/parallel/progress/52583704-4927-491d-82e4-6ee9561ebd69 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[BackgroundJobQueue] Starting job processing after delay for job 52583704-4927-491d-82e4-6ee9561ebd69-parallel
[BackgroundJobQueue] Starting processing for job 52583704-4927-491d-82e4-6ee9561ebd69-parallel, phase: sampling
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing parallel analysis job 52583704-4927-491d-82e4-6ee9561ebd69-parallel
[BackgroundJobQueue] Processing parallel analysis for bot ***REMOVED***
[BackgroundJobQueue] Using existing ParallelAutoAnalyzeService instance for bot ***REMOVED***
[BackgroundJobQueue] Session recreated for 52583704-4927-491d-82e4-6ee9561ebd69
[ParallelAutoAnalyzeService] Running parallel analysis for 52583704-4927-491d-82e4-6ee9561ebd69
[ParallelAutoAnalyzeService] Phase 0: Starting session sampling for 52583704-4927-491d-82e4-6ee9561ebd69

ğŸ• ============ SESSION SAMPLING STARTED ============
ğŸ• [SessionSampling] Starting session sampling at 2025-08-12T16:16:05.326Z
ğŸ” [SessionDiscovery] Starting window 1/4: Initial 3-hour window
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
::1 - - [12/Aug/2025:16:16:06 +0000] "GET /api/analysis/auto-analyze/parallel/progress/52583704-4927-491d-82e4-6ee9561ebd69 HTTP/1.1" 200 715 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:16:08 +0000] "GET /api/analysis/auto-analyze/parallel/progress/52583704-4927-491d-82e4-6ee9561ebd69 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 80 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a1287849680ad9fe59e',
  '689229f9583056c6108e38fb',
  '68922914f8bee7ba6c3e67b8'
]
[fetchContainmentTypeMetadata] API Response: 139 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6a14dd27c3112087cd',
  '68922a22ef03d8ad2ec7b4ba',
  '68922a1278c1fe09a079719c'
]
::1 - - [12/Aug/2025:16:16:10 +0000] "GET /api/analysis/auto-analyze/parallel/progress/52583704-4927-491d-82e4-6ee9561ebd69 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 1338 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6d14dd27c31120888b',
  '68922a62e3804084741191d5',
  '68922a523a3160d25de144c8'
]
[getSessionsMetadata] agent API call succeeded with 1338 sessions
[getSessionsMetadata] selfService API call succeeded with 80 sessions
[getSessionsMetadata] dropOff API call succeeded with 139 sessions
Total session metadata retrieved: 1557 (parallel execution)
Creating 1557 SWTs from metadata (no messages)
Created 1557 SWT objects from metadata
âœ… [SessionDiscovery] Window 1 completed in 5504ms: found 1557 new sessions (total: 1557)
â±ï¸  TIMING: Window 1 took 5504ms (5.50s)
ğŸ¯ [SessionDiscovery] Target reached! Found 1557 sessions in 5505ms
ğŸ² [SessionSampling] Random sampling from 1557 sessions to 100 sessions

ğŸ“¬ ============ MESSAGE RETRIEVAL STARTED ============
ğŸ“¬ [MessageRetrieval] Starting message retrieval for 100 sampled sessions at 2025-08-12T16:16:10.831Z
Using new lazy loading approach to populate messages for 100 sampled sessions
Populating messages for 100 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 100 sessions from 2025-08-05T13:00:25.946Z to 2025-08-05T15:59:29.888Z at 2025-08-12T16:16:10.831Z
ğŸš€ [ConcurrentBatch] Split 100 sessions into 5 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/5] Starting: 20 sessions
[Batch 2/5] Starting: 20 sessions
[Batch 3/5] Starting: 20 sessions
[Batch 4/5] Starting: 20 sessions
[Batch 5/5] Starting: 20 sessions
[Batch 1/5] Completed in 369ms: 278 messages retrieved (1/5 done)
ğŸ“Š [BatchProgress] Reporting batch 1/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 40/100 sessions (Batch 2/5)
[Batch 2/5] Completed in 419ms: 252 messages retrieved (2/5 done)
ğŸ“Š [BatchProgress] Reporting batch 2/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 60/100 sessions (Batch 3/5)
[Batch 3/5] Completed in 439ms: 289 messages retrieved (3/5 done)
ğŸ“Š [BatchProgress] Reporting batch 3/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 80/100 sessions (Batch 4/5)
[Batch 4/5] Completed in 498ms: 245 messages retrieved (4/5 done)
ğŸ“Š [BatchProgress] Reporting batch 4/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 100/100 sessions (Batch 5/5)
[Batch 5/5] Completed in 911ms: 292 messages retrieved (5/5 done)
ğŸ“Š [BatchProgress] Reporting batch 5/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 100/100 sessions (Batch 6/5)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 912ms (0.91s)
â±ï¸  Batch Processing: 911ms (0.91s)
ğŸ“¦ Total batches: 5 (max 10 concurrent)
âœ… Successful batches: 5/5
ğŸ’¬ Total messages: 1356
ğŸ“ˆ Avg time per batch: 182ms
ğŸš€ Time per session: 9ms
ğŸ’ª Performance: 109.6 sessions/second
=======================================================

Retrieved 1356 messages for 100 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
Populated messages for 100 SWT objects
Successfully populated messages for 100 sessions using lazy loading
Applying final filtering to 100 sessions with populated messages
Final result: 99 sessions passed filtering with populated messages

ğŸ‰ ============ SESSION SAMPLING COMPLETED ============
â±ï¸  TOTAL TIME: 6426ms (6.43s)
â±ï¸  Session Discovery: 5505ms (5.50s) - 85.7% of total
â±ï¸  Message Retrieval: 921ms (0.92s) - 14.3% of total
â±ï¸  Performance: 15.4 sessions/second
ğŸ¯ Final result: 99 sessions with messages retrieved
====================================================

[StrategicDiscoveryService] Starting discovery phase with 99 total sessions
[StrategicDiscoveryService] Discovery config: {
  targetPercentage: 15,
  minSessions: 9,
  maxSessions: 14,
  diversityStrategy: {
    sessionLengths: [ 'short', 'medium', 'long' ],
    containmentTypes: [ 'agent', 'selfService', 'dropOff' ],
    timeDistribution: 'spread'
  }
}
[StrategicDiscoveryService] Selecting 14 diverse sessions from 99 total
[StrategicDiscoveryService] Session diversity groups: { short: 16, medium: 83, early: 33, middle: 33, late: 33 }
[StrategicDiscoveryService] Selected sessions by length distribution: { short: 4, medium: 10, long: 0 }
[StrategicDiscoveryService] Selected 14 sessions for discovery

ğŸ“¦ ===== BATCH 4 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:16:11.753Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 0
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:16:11.753Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:16:11.753Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6986,
  existingClassifications: { intents: 0, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.



For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and another intent, classify the intent as the other i...
::1 - - [12/Aug/2025:16:16:12 +0000] "GET /api/analysis/auto-analyze/parallel/progress/52583704-4927-491d-82e4-6ee9561ebd69 HTTP/1.1" 200 921 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:16:14 +0000] "GET /api/analysis/auto-analyze/parallel/progress/52583704-4927-491d-82e4-6ee9561ebd69 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:16:14.479Z',
  duration: '2726ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2005,
    completion_tokens: 346,
    total_tokens: 2351,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Live Agent', 'Unknown' ],
  transferCount: 3,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-99a340aa-10a8-599c-96fd-16a02fc3deaa",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak to someone about payment and was transferred to an agent."
    },
    {
      "user_id": "u-186c7475-cf74-55e3-be6c-33cdc053498a",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User attempted to track time and was guided through account verification, but no active requests found, session ended without transfer."
    },
    {
      "user_id": "u-c6917ae3-3ba5-512a-8c90-04f0de2c0aeb",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User did not provide input; session was closed by the bot."
    },
    {
      "user_id": "u-3ac33616-01c9-5481-83a5-00aeddff7a69",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted a payment and was transferred to an agent after multiple clarifications."
    },
    {
      "user_id": "u-401264d8-b9fe-5933-9655-137c96613621",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent in Spanish and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2005,
  completionTokens: 346,
  totalTokens: 2351,
  cost: '$0.000339',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2726ms (2.73s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2351 ($0.0003)
âš¡ Performance: 862.4 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2726ms (2.73s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2351

âœ… ===== BATCH 4 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2726ms (2.73s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2351 ($0.0003)
âš¡ Performance: 1.8 sessions/sec
âš¡ Avg Time Per Session: 545.20ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 1 complete: 4 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 2, reasons: 1, locations: 1, total: 4 }

ğŸ“¦ ===== BATCH 5 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:16:14.479Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 2
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:16:14.479Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:16:14.479Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6777,
  existingClassifications: { intents: 2, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Age...
::1 - - [12/Aug/2025:16:16:16 +0000] "GET /api/analysis/auto-analyze/parallel/progress/52583704-4927-491d-82e4-6ee9561ebd69 HTTP/1.1" 200 938 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:16:18.106Z',
  duration: '3627ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1924,
    completion_tokens: 337,
    total_tokens: 2261,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Live Agent', 'Claim Status' ],
  transferCount: 4,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-cc1c3ba6-3492-54fe-a3c9-58b37f53b305",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent but did not respond further."
    },
    {
      "user_id": "u-e78d1e6a-a69e-5343-abb6-f9832cb94213",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to be transferred to an agent."
    },
    {
      "user_id": "u-7bbf81c6-59d1-5db2-a884-fb85583e8e90",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User inquired about tracking time and was transferred to an agent after initial steps."
    },
    {
      "user_id": "u-c40bb5b2-f6b2-573d-ad15-67bf11bbc834",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent."
    },
    {
      "user_id": "u-f2b9603f-c182-5402-ab0c-d49422c03898",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1924,
  completionTokens: 337,
  totalTokens: 2261,
  cost: '$0.000327',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 3627ms (3.63s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2261 ($0.0003)
âš¡ Performance: 623.4 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 3627ms (3.63s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2261

âœ… ===== BATCH 5 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 3627ms (3.63s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2261 ($0.0003)
âš¡ Performance: 1.4 sessions/sec
âš¡ Avg Time Per Session: 725.40ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 2 complete: 1 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 3, reasons: 1, locations: 1, total: 5 }

ğŸ“¦ ===== BATCH 6 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:16:18.107Z
ğŸ“Š Sessions in Batch: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 4
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:16:18.107Z
ğŸ“Š Sessions to Analyze: 4

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:16:18.107Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7934,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibili...
::1 - - [12/Aug/2025:16:16:18 +0000] "GET /api/analysis/auto-analyze/parallel/progress/52583704-4927-491d-82e4-6ee9561ebd69 HTTP/1.1" 200 939 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:16:20.152Z',
  duration: '2045ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2219,
    completion_tokens: 201,
    total_tokens: 2420,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-7cbb0316-ad60-547a-9939-55528a811bcd",
      "notes": "User was silent and did not respond, leading to session transfer to a live agent."
    },
    {
      "user_id": "u-11fceefd-15bc-5447-941b-c74bb0105729",
      "notes": "User was silent and did not respond, leading to session transfer to a live agent."
    },
    {
      "user_id": "u-33aa1307-e121-5f80-9a84-e02dcdde04e1",
      "notes": "User attempted to report time off but was transferred to an agent after multiple failed attempts to verify details."
    },
    {
      "user_id": "u-760e597a-1be9-5bb5-944f-02e9d97e3cf2",
      "notes": "User wanted to update FMLA date but was transferred to an agent after difficulty verifying account details."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2219,
  completionTokens: 201,
  totalTokens: 2420,
  cost: '$0.000302',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2046ms (2.05s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2420 ($0.0003)
âš¡ Performance: 1182.8 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 4
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2046ms (2.05s)
ğŸ“Š Regular Sessions Processed: 4
ğŸ’° Regular Tokens Used: 2420

âœ… ===== BATCH 6 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2046ms (2.05s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Total Tokens: 2420 ($0.0003)
âš¡ Performance: 2.0 sessions/sec
âš¡ Avg Time Per Session: 511.50ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 3 complete: 0 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 3, reasons: 1, locations: 1, total: 5 }
[StrategicDiscoveryService] Discovery phase complete: {
  totalProcessed: 14,
  uniqueIntents: 3,
  uniqueReasons: 1,
  uniqueLocations: 1,
  discoveryRate: 0.3333333333333333
}

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T16:16:20.154Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms
[ParallelProcessingOrchestrator] Configuration for 85 sessions:
  Design: 8 streams Ã— 4 sessions = 32 per round
  Optimal: 8 streams Ã— 4 sessions = 32 per round
  Estimated Rounds: 3
[ParallelAutoAnalyzeService] Using parallel config: {
  streamCount: 8,
  sessionsPerStream: 4,
  maxSessionsPerLLMCall: 50,
  syncFrequency: 'after_each_round',
  retryAttempts: 3,
  debugLogging: false
}

ğŸš€ ============ PARALLEL PROCESSING STARTED ============
â±ï¸  Start Time: 2025-08-12T16:16:20.155Z
ğŸ“Š Total Sessions: 85

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T16:16:20.155Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms

âš™ï¸  ============ PARALLEL CONFIGURATION ============
â±ï¸  Config Time: 0ms
ğŸ”§ Stream Count: 8
ğŸ“¦ Sessions Per Stream: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per API Call: 50
ğŸ¯ Debug Logging: false

ğŸ”„ ============ ROUND 1/3 STARTED ============
â±ï¸  Round 1 Start: 2025-08-12T16:16:20.156Z
ğŸ“Š Sessions Remaining: 85
[ParallelProcessingOrchestrator] Distributed 32 sessions across 8 streams: [
  'Stream 1: 4 sessions',
  'Stream 2: 4 sessions',
  'Stream 3: 4 sessions',
  'Stream 4: 4 sessions',
  'Stream 5: 4 sessions',
  'Stream 6: 4 sessions',
  'Stream 7: 4 sessions',
  'Stream 8: 4 sessions'
]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 8

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 8 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T16:16:20.156Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:16:20.156Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 740
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6240
   â€¢ Avg Per Session: 185 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6240
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6240
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:16:20.156Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:16:20.156Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6167,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibili...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T16:16:20.156Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:16:20.156Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 821
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6321
   â€¢ Avg Per Session: 205 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6321
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6321
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:16:20.156Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:16:20.156Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6524,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibili...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T16:16:20.156Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:16:20.156Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 757
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6257
   â€¢ Avg Per Session: 189 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6257
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 1ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6257
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:16:20.157Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:16:20.157Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6197,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibili...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T16:16:20.157Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:16:20.157Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 1098
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6598
   â€¢ Avg Per Session: 275 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6598
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0011
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6598
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0011

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:16:20.157Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:16:20.157Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7795,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibili...

ğŸŒŠ ===== STREAM 5 PROCESSING START =====
â±ï¸  Stream 5 Start: 2025-08-12T16:16:20.157Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:16:20.157Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 743
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6243
   â€¢ Avg Per Session: 186 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6243
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 5) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6243
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 5: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:16:20.157Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:16:20.157Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6139,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibili...

ğŸŒŠ ===== STREAM 6 PROCESSING START =====
â±ï¸  Stream 6 Start: 2025-08-12T16:16:20.157Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:16:20.157Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 697
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6197
   â€¢ Avg Per Session: 174 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6197
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 6) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6197
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 6: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:16:20.157Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:16:20.157Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5986,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibili...

ğŸŒŠ ===== STREAM 7 PROCESSING START =====
â±ï¸  Stream 7 Start: 2025-08-12T16:16:20.157Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:16:20.157Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 728
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6228
   â€¢ Avg Per Session: 182 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6228
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 7) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6228
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 7: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:16:20.157Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:16:20.157Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6123,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibili...

ğŸŒŠ ===== STREAM 8 PROCESSING START =====
â±ï¸  Stream 8 Start: 2025-08-12T16:16:20.157Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:16:20.158Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 818
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6318
   â€¢ Avg Per Session: 205 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6318
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 8) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6318
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 8: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:16:20.158Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:16:20.158Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6540,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibili...
::1 - - [12/Aug/2025:16:16:20 +0000] "GET /api/analysis/auto-analyze/parallel/progress/52583704-4927-491d-82e4-6ee9561ebd69 HTTP/1.1" 200 1717 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:16:21.783Z',
  duration: '1625ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1869,
    completion_tokens: 195,
    total_tokens: 2064,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-3b61f568-0334-56d3-83c6-ab67eae3d6da",
      "notes": "User wanted to speak with an agent but did not provide input, resulting in transfer."
    },
    {
      "user_id": "u-592305d2-8cc5-55b5-89b2-43898efd573e",
      "notes": "User attempted to inquire about claim information but was transferred to an agent after verification issues."
    },
    {
      "user_id": "u-dc557f39-cdcc-56d8-a267-2f8015db4941",
      "notes": "User wanted to speak with an agent but did not provide input, resulting in transfer."
    },
    {
      "user_id": "u-4cd1bddc-4804-558f-a9e0-f0825f736a18",
      "notes": "User inquired about FMLA status and was transferred after verification issues."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1869,
  completionTokens: 195,
  totalTokens: 2064,
  cost: '$0.000265',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1625ms (1.63s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2064 ($0.0003)
âš¡ Performance: 1270.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1869
   â€¢ Completion Tokens: 195
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-3b61f568-0334-56d3-83c6-ab67eae3d6da: Invalid general_intent, u-3b61f568-0334-56d3-83c6-ab67eae3d6da: Invalid session_outcome, u-592305d2-8cc5-55b5-89b2-43898efd573e: Invalid general_intent, u-592305d2-8cc5-55b5-89b2-43898efd573e: Invalid session_outcome, u-dc557f39-cdcc-56d8-a267-2f8015db4941: Invalid general_intent, u-dc557f39-cdcc-56d8-a267-2f8015db4941: Invalid session_outcome, u-4cd1bddc-4804-558f-a9e0-f0825f736a18: Invalid general_intent, u-4cd1bddc-4804-558f-a9e0-f0825f736a18: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 8 Single Batch Time: 1625ms (1.63s)

âœ… ===== STREAM 8 PROCESSING COMPLETE =====
â±ï¸  Stream 8 Total Time: 1626ms (1.63s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2064 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.5 sessions/sec
âš¡ Avg Time Per Session: 406.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:16:22.124Z',
  duration: '1967ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1771,
    completion_tokens: 271,
    total_tokens: 2042,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status', 'Live Agent' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-a1961460-7749-5f35-8243-9a98a91fbb7a",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User inquired about claim status and received information without transfer."
    },
    {
      "user_id": "u-54dae05a-5dc4-5704-a1c2-d3c04780598c",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-9c8522a6-725d-56cb-a164-aab9721b4f59",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked about form details and was transferred to an agent."
    },
    {
      "user_id": "u-c459ca66-bab2-5c92-8fec-71451102c0ae",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1771,
  completionTokens: 271,
  totalTokens: 2042,
  cost: '$0.000286',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1968ms (1.97s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2042 ($0.0003)
âš¡ Performance: 1037.6 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1771
   â€¢ Completion Tokens: 271
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 3 Single Batch Time: 1968ms (1.97s)

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 1969ms (1.97s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2042 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.0 sessions/sec
âš¡ Avg Time Per Session: 492.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:16:22.229Z',
  duration: '2073ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1868,
    completion_tokens: 281,
    total_tokens: 2149,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Claim Status', 'Time Entry' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-9850247b-dfc9-5bc3-99af-37b982f2a86b",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent and was transferred."
    },
    {
      "user_id": "u-ba29892b-2ed3-5535-9112-33a3c6c5bcc0",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User inquired about leave request status and was assisted without transfer."
    },
    {
      "user_id": "u-4c5fc415-21ff-5dd7-86a1-dc62c4002f59",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent and was transferred."
    },
    {
      "user_id": "u-5f97d2a2-9f15-5e07-9e5b-11feaf820a54",
      "general_intent": "Time Entry",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1868,
  completionTokens: 281,
  totalTokens: 2149,
  cost: '$0.000299',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2073ms (2.07s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2149 ($0.0003)
âš¡ Performance: 1036.7 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1868
   â€¢ Completion Tokens: 281
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 2 Single Batch Time: 2074ms (2.07s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 2074ms (2.07s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2149 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.9 sessions/sec
âš¡ Avg Time Per Session: 518.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:16:22.275Z',
  duration: '2118ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1728,
    completion_tokens: 285,
    total_tokens: 2013,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status', 'Unknown' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-25bde93a-b323-528e-9528-1c834a8f84ef",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User reported return to work details and completed the process without transfer."
    },
    {
      "user_id": "u-dc7be4e0-0db9-5110-9c8e-567a2ac69f81",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User checked claim status and requested to speak to a live agent, resulting in transfer."
    },
    {
      "user_id": "u-51f33605-d859-5565-b440-f5a75f4aa918",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested available hours and was transferred to an agent."
    },
    {
      "user_id": "u-c191df24-6a42-5daa-9e53-dfde9a437ef3",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent about various leave and FMLA questions, resulting in transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1728,
  completionTokens: 285,
  totalTokens: 2013,
  cost: '$0.000287',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2118ms (2.12s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2013 ($0.0003)
âš¡ Performance: 950.4 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1728
   â€¢ Completion Tokens: 285
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 6 Single Batch Time: 2119ms (2.12s)

âœ… ===== STREAM 6 PROCESSING COMPLETE =====
â±ï¸  Stream 6 Total Time: 2119ms (2.12s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2013 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.9 sessions/sec
âš¡ Avg Time Per Session: 529.75ms
::1 - - [12/Aug/2025:16:16:22 +0000] "GET /api/analysis/auto-analyze/parallel/progress/52583704-4927-491d-82e4-6ee9561ebd69 HTTP/1.1" 200 1725 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:16:22.410Z',
  duration: '2253ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2203,
    completion_tokens: 269,
    total_tokens: 2472,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status', 'Live Agent', 'Leave Reporting' ],
  transferCount: 1,
  containedCount: 3
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-ca8159e6-6f27-5b28-9d2f-0d9f8614013e",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User inquired about renewing a claim and was transferred to a customer service agent."
    },
    {
      "user_id": "u-3dc6d014-3d35-5a1d-9d89-ecc1cdc95a1e",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent and was transferred."
    },
    {
      "user_id": "u-7385922d-e45b-5be6-b2d7-431f2d59cb6b",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User asked about payment, but the session was handled by the bot and ended without transfer."
    },
    {
      "user_id": "u-5ade6956-a044-5439-aa1a-7d38b3d680d7",
      "general_intent": "Leave Reporting",
      "session_outcome": "Contained",
      "notes": "User reported an absence, but the session was handled by the bot and ended without transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2203,
  completionTokens: 269,
  totalTokens: 2472,
  cost: '$0.000328',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2254ms (2.25s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2472 ($0.0003)
âš¡ Performance: 1096.7 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2203
   â€¢ Completion Tokens: 269
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 4 Single Batch Time: 2254ms (2.25s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 2254ms (2.25s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2472 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.8 sessions/sec
âš¡ Avg Time Per Session: 563.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:16:22.494Z',
  duration: '2338ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1785,
    completion_tokens: 284,
    total_tokens: 2069,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [
    'Unknown',
    'Claim Status',
    'Customer Service',
    'Speak to a Live Agent'
  ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-a0a94cf1-068b-56ad-b34d-d1996de7e5f0",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "Session involved user silence and difficulty in providing leave request information, handled by bot."
    },
    {
      "user_id": "u-ada7a4aa-0371-5a17-8f6c-0a31b88d1c2b",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested claim status and was transferred to a live agent."
    },
    {
      "user_id": "u-ccbb1b9d-f257-54ff-95bb-1df39afaddab",
      "general_intent": "Customer Service",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested customer service and was transferred to an agent."
    },
    {
      "user_id": "u-ecca3042-a6c8-5b1c-b917-730c2fdbfa57",
      "general_intent": "Speak to a Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1785,
  completionTokens: 284,
  totalTokens: 2069,
  cost: '$0.000292',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2339ms (2.34s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2069 ($0.0003)
âš¡ Performance: 884.6 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1785
   â€¢ Completion Tokens: 284
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 1 Single Batch Time: 2339ms (2.34s)
[StreamProcessingService] Discovered 2 new classifications: { intents: 2, reasons: 0, locations: 0 }

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 2339ms (2.34s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2069 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.7 sessions/sec
âš¡ Avg Time Per Session: 584.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:16:22.891Z',
  duration: '2734ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1742,
    completion_tokens: 280,
    total_tokens: 2022,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-d941d17a-6f51-50c8-9ac0-0bdc554842d8",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User sought an extension on leave but was transferred to an agent after multiple unsuccessful attempts to provide request details."
    },
    {
      "user_id": "u-6c836309-094f-581b-874c-ab94eb5591cf",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User did not provide any input, session was closed by the bot."
    },
    {
      "user_id": "u-d29eeb36-c4af-571a-915d-dfd9c658ec2d",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested customer service and was transferred to an agent after indicating a desire to speak with one."
    },
    {
      "user_id": "u-c46fbdb5-9caf-5631-b455-457951974997",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a representative and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1742,
  completionTokens: 280,
  totalTokens: 2022,
  cost: '$0.000286',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2735ms (2.73s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2022 ($0.0003)
âš¡ Performance: 739.3 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1742
   â€¢ Completion Tokens: 280
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 5 Single Batch Time: 2735ms (2.73s)

âœ… ===== STREAM 5 PROCESSING COMPLETE =====
â±ï¸  Stream 5 Total Time: 2736ms (2.74s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2022 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.5 sessions/sec
âš¡ Avg Time Per Session: 684.00ms
::1 - - [12/Aug/2025:16:16:24 +0000] "GET /api/analysis/auto-analyze/parallel/progress/52583704-4927-491d-82e4-6ee9561ebd69 HTTP/1.1" 200 1731 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:16:24.497Z',
  duration: '4340ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1753,
    completion_tokens: 230,
    total_tokens: 1983,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status', 'Live Agent' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-0c9698d5-6709-51a3-aeae-65c44a095859",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-53ac7505-d015-5839-90a9-71aec6e44e18",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-e88fafb9-c36e-5079-8f19-5bedf9173a8c",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-0a9699a8-1250-5352-9844-aa2da63aeb95",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1753,
  completionTokens: 230,
  totalTokens: 1983,
  cost: '$0.000267',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 4340ms (4.34s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1983 ($0.0003)
âš¡ Performance: 456.9 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1753
   â€¢ Completion Tokens: 230
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-0c9698d5-6709-51a3-aeae-65c44a095859: Invalid notes, u-53ac7505-d015-5839-90a9-71aec6e44e18: Invalid notes, u-e88fafb9-c36e-5079-8f19-5bedf9173a8c: Invalid notes, u-0a9699a8-1250-5352-9844-aa2da63aeb95: Invalid notes'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 7 Single Batch Time: 4341ms (4.34s)

âœ… ===== STREAM 7 PROCESSING COMPLETE =====
â±ï¸  Stream 7 Total Time: 4341ms (4.34s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1983 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.9 sessions/sec
âš¡ Avg Time Per Session: 1085.25ms
[ParallelProcessingOrchestrator] Parallel processing complete: 8/8 streams succeeded
â±ï¸  Parallel Processing Time: 4343ms (4.34s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 8 streams
[ParallelProcessingOrchestrator] Synchronization complete: 4 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 4
ğŸ“Š Total Classifications: 9

âœ… ============ ROUND 1 COMPLETED ============
â±ï¸  Round 1 Total Time: 4343ms (4.34s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 53
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 4343ms (100.0%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ”„ ============ ROUND 2/3 STARTED ============
â±ï¸  Round 2 Start: 2025-08-12T16:16:24.499Z
ğŸ“Š Sessions Remaining: 53
[ParallelProcessingOrchestrator] Distributed 32 sessions across 8 streams: [
  'Stream 1: 4 sessions',
  'Stream 2: 4 sessions',
  'Stream 3: 4 sessions',
  'Stream 4: 4 sessions',
  'Stream 5: 4 sessions',
  'Stream 6: 4 sessions',
  'Stream 7: 4 sessions',
  'Stream 8: 4 sessions'
]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 8

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 8 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T16:16:24.499Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:16:24.499Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 908
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6408
   â€¢ Avg Per Session: 227 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6408
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6408
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:16:24.500Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:16:24.500Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6990,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Customer Service, Leave Reporting, Live Agent, Speak to a Live Agent, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usua...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T16:16:24.500Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:16:24.500Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 834
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6334
   â€¢ Avg Per Session: 209 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6334
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6334
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:16:24.500Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:16:24.500Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6695,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Customer Service, Leave Reporting, Live Agent, Speak to a Live Agent, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usua...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T16:16:24.500Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:16:24.500Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 848
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6348
   â€¢ Avg Per Session: 212 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6348
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 1ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6348
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:16:24.501Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:16:24.501Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6691,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Customer Service, Leave Reporting, Live Agent, Speak to a Live Agent, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usua...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T16:16:24.501Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:16:24.501Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 773
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6273
   â€¢ Avg Per Session: 193 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6273
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6273
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:16:24.501Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:16:24.501Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6342,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Customer Service, Leave Reporting, Live Agent, Speak to a Live Agent, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usua...

ğŸŒŠ ===== STREAM 5 PROCESSING START =====
â±ï¸  Stream 5 Start: 2025-08-12T16:16:24.501Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:16:24.501Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 1021
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6521
   â€¢ Avg Per Session: 255 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6521
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 5) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6521
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 5: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:16:24.502Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:16:24.502Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7481,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Customer Service, Leave Reporting, Live Agent, Speak to a Live Agent, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usua...

ğŸŒŠ ===== STREAM 6 PROCESSING START =====
â±ï¸  Stream 6 Start: 2025-08-12T16:16:24.502Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:16:24.502Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 935
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6435
   â€¢ Avg Per Session: 234 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6435
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 6) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6435
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 6: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:16:24.502Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:16:24.502Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6947,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Customer Service, Leave Reporting, Live Agent, Speak to a Live Agent, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usua...

ğŸŒŠ ===== STREAM 7 PROCESSING START =====
â±ï¸  Stream 7 Start: 2025-08-12T16:16:24.502Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:16:24.502Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 912
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6412
   â€¢ Avg Per Session: 228 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6412
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 7) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6412
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 7: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:16:24.503Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:16:24.503Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7009,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Customer Service, Leave Reporting, Live Agent, Speak to a Live Agent, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usua...

ğŸŒŠ ===== STREAM 8 PROCESSING START =====
â±ï¸  Stream 8 Start: 2025-08-12T16:16:24.503Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:16:24.503Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 778
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6278
   â€¢ Avg Per Session: 195 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6278
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 8) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6278
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 8: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:16:24.503Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:16:24.503Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6383,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Customer Service, Leave Reporting, Live Agent, Speak to a Live Agent, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usua...
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:16:25.930Z',
  duration: '1429ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1810,
    completion_tokens: 201,
    total_tokens: 2011,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-da29f6a2-c8e9-5ec8-b224-28d9a2e72da8",
      "notes": "User wanted an exemption and an extension related to paperwork sent to the wrong doctor, then requested to speak with a live agent."
    },
    {
      "user_id": "u-2588c2f2-4f73-5dc5-b050-5357579be561",
      "notes": "User requested to speak to someone about FMLA, transferred to an agent."
    },
    {
      "user_id": "u-62529784-49c2-5080-81b3-b6bebcd04a5d",
      "notes": "User wanted to check on a claim, but did not provide claim details, session ended."
    },
    {
      "user_id": "u-f5ccdde9-de88-56f1-952f-edac85ceb84b",
      "notes": "User requested to speak with an agent, transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1810,
  completionTokens: 201,
  totalTokens: 2011,
  cost: '$0.000261',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1429ms (1.43s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2011 ($0.0003)
âš¡ Performance: 1407.3 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1810
   â€¢ Completion Tokens: 201
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-da29f6a2-c8e9-5ec8-b224-28d9a2e72da8: Invalid general_intent, u-da29f6a2-c8e9-5ec8-b224-28d9a2e72da8: Invalid session_outcome, u-2588c2f2-4f73-5dc5-b050-5357579be561: Invalid general_intent, u-2588c2f2-4f73-5dc5-b050-5357579be561: Invalid session_outcome, u-62529784-49c2-5080-81b3-b6bebcd04a5d: Invalid general_intent, u-62529784-49c2-5080-81b3-b6bebcd04a5d: Invalid session_outcome, u-f5ccdde9-de88-56f1-952f-edac85ceb84b: Invalid general_intent, u-f5ccdde9-de88-56f1-952f-edac85ceb84b: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 4 Single Batch Time: 1429ms (1.43s)

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 1429ms (1.43s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2011 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.8 sessions/sec
âš¡ Avg Time Per Session: 357.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:16:26.092Z',
  duration: '1592ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1914,
    completion_tokens: 192,
    total_tokens: 2106,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-2104e004-56c5-5443-a4cf-c035f65902bc",
      "notes": "User inquired about claim status and was prompted for a claim number."
    },
    {
      "user_id": "u-9718ce7a-efcd-5bc7-9bf7-66a2d2c21bdd",
      "notes": "User requested to speak with an agent, session was transferred to a live agent."
    },
    {
      "user_id": "u-fd7d3e52-abc8-5442-8f02-dfc372e2f17c",
      "notes": "User requested a new leave, session was transferred to an agent after initial prompts."
    },
    {
      "user_id": "u-ec01a295-3638-53c2-99cb-45b4bc004dd7",
      "notes": "User provided detailed information to submit a time entry, session was contained."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1914,
  completionTokens: 192,
  totalTokens: 2106,
  cost: '$0.000268',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1592ms (1.59s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2106 ($0.0003)
âš¡ Performance: 1322.9 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1914
   â€¢ Completion Tokens: 192
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-2104e004-56c5-5443-a4cf-c035f65902bc: Invalid general_intent, u-2104e004-56c5-5443-a4cf-c035f65902bc: Invalid session_outcome, u-9718ce7a-efcd-5bc7-9bf7-66a2d2c21bdd: Invalid general_intent, u-9718ce7a-efcd-5bc7-9bf7-66a2d2c21bdd: Invalid session_outcome, u-fd7d3e52-abc8-5442-8f02-dfc372e2f17c: Invalid general_intent, u-fd7d3e52-abc8-5442-8f02-dfc372e2f17c: Invalid session_outcome, u-ec01a295-3638-53c2-99cb-45b4bc004dd7: Invalid general_intent, u-ec01a295-3638-53c2-99cb-45b4bc004dd7: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 2 Single Batch Time: 1592ms (1.59s)

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 1593ms (1.59s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2106 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.5 sessions/sec
âš¡ Avg Time Per Session: 398.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:16:26.103Z',
  duration: '1601ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2135,
    completion_tokens: 210,
    total_tokens: 2345,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-6514d456-0aa6-52d6-a8a4-984b3508cbe0",
      "notes": "User wanted to speak with an agent but did not provide further input, resulting in session closure."
    },
    {
      "user_id": "u-abc89e36-f67e-5725-933b-1a87a3f98e2e",
      "notes": "User wanted to speak with an agent regarding FMLA, session was transferred to an agent."
    },
    {
      "user_id": "u-9bf28f74-7a5b-5b13-954c-f22485f1dcb2",
      "notes": "User provided detailed information for time entry, session was handled by bot without transfer."
    },
    {
      "user_id": "u-e09ab0c2-b331-5df2-87e8-2c81d65c8fb5",
      "notes": "User requested FMLA extension without providing necessary details, session was closed without transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2135,
  completionTokens: 210,
  totalTokens: 2345,
  cost: '$0.000298',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1602ms (1.60s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2345 ($0.0003)
âš¡ Performance: 1463.8 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2135
   â€¢ Completion Tokens: 210
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-6514d456-0aa6-52d6-a8a4-984b3508cbe0: Invalid general_intent, u-6514d456-0aa6-52d6-a8a4-984b3508cbe0: Invalid session_outcome, u-abc89e36-f67e-5725-933b-1a87a3f98e2e: Invalid general_intent, u-abc89e36-f67e-5725-933b-1a87a3f98e2e: Invalid session_outcome, u-9bf28f74-7a5b-5b13-954c-f22485f1dcb2: Invalid general_intent, u-9bf28f74-7a5b-5b13-954c-f22485f1dcb2: Invalid session_outcome, u-e09ab0c2-b331-5df2-87e8-2c81d65c8fb5: Invalid general_intent, u-e09ab0c2-b331-5df2-87e8-2c81d65c8fb5: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 5 Single Batch Time: 1602ms (1.60s)

âœ… ===== STREAM 5 PROCESSING COMPLETE =====
â±ï¸  Stream 5 Total Time: 1603ms (1.60s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2345 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.5 sessions/sec
âš¡ Avg Time Per Session: 400.75ms
::1 - - [12/Aug/2025:16:16:26 +0000] "GET /api/analysis/auto-analyze/parallel/progress/52583704-4927-491d-82e4-6ee9561ebd69 HTTP/1.1" 200 1723 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:16:26.471Z',
  duration: '1969ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1920,
    completion_tokens: 287,
    total_tokens: 2207,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Leave Reporting' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-13800289-a22d-5c86-a6ce-d4f6232cc33f",
      "general_intent": "Leave Reporting",
      "session_outcome": "Contained",
      "notes": "User inquired about FMLA deadline and expiration, but the bot did not transfer or resolve the query."
    },
    {
      "user_id": "u-c1bae55e-a686-52ab-8061-042cbe1aa179",
      "general_intent": "Leave Reporting",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative, resulting in transfer to an agent."
    },
    {
      "user_id": "u-a3fac934-5ea1-5c89-9592-516eb987e711",
      "general_intent": "Leave Reporting",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User discussed family leave denial and was transferred to an agent for assistance."
    },
    {
      "user_id": "u-9f68b0f5-4be4-5b8c-98b8-ed452f0be598",
      "general_intent": "Leave Reporting",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a representative, resulting in transfer to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1920,
  completionTokens: 287,
  totalTokens: 2207,
  cost: '$0.000307',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1969ms (1.97s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2207 ($0.0003)
âš¡ Performance: 1120.9 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1920
   â€¢ Completion Tokens: 287
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 6 Single Batch Time: 1969ms (1.97s)

âœ… ===== STREAM 6 PROCESSING COMPLETE =====
â±ï¸  Stream 6 Total Time: 1969ms (1.97s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2207 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.0 sessions/sec
âš¡ Avg Time Per Session: 492.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:16:26.472Z',
  duration: '1969ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1813,
    completion_tokens: 273,
    total_tokens: 2086,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Claim Status' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-d2c766a4-4198-5bdb-90eb-b69d0d5ffc1f",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-7ac6ccb2-b441-575f-89ef-a472a3f3b1e1",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User provided claim details and was not transferred to an agent."
    },
    {
      "user_id": "u-22bc10db-310c-595b-8eb3-77ec54aa1207",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-b144ea1b-ce0c-5230-a0d4-35ba1bdcaa59",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1813,
  completionTokens: 273,
  totalTokens: 2086,
  cost: '$0.000291',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1969ms (1.97s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2086 ($0.0003)
âš¡ Performance: 1059.4 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1813
   â€¢ Completion Tokens: 273
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 8 Single Batch Time: 1969ms (1.97s)

âœ… ===== STREAM 8 PROCESSING COMPLETE =====
â±ï¸  Stream 8 Total Time: 1969ms (1.97s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2086 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.0 sessions/sec
âš¡ Avg Time Per Session: 492.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:16:26.472Z',
  duration: '1971ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1892,
    completion_tokens: 289,
    total_tokens: 2181,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Leave Reporting' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-338a5293-c1ca-58b5-af83-a91fe5fd8cc5",
      "general_intent": "Leave Reporting",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a new claim and was transferred to an agent."
    },
    {
      "user_id": "u-cf7836e4-1933-5843-9d41-de9c452f27c2",
      "general_intent": "Leave Reporting",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak to an agent and was transferred."
    },
    {
      "user_id": "u-cdc8fc5e-fe7b-59de-a971-0a41551cef20",
      "general_intent": "Leave Reporting",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User needed help with FMLA renewal and was transferred to an agent."
    },
    {
      "user_id": "u-06b4122f-84f4-57f0-989f-330c02feecd7",
      "general_intent": "Leave Reporting",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested leave extension and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1892,
  completionTokens: 289,
  totalTokens: 2181,
  cost: '$0.000305',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1971ms (1.97s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2181 ($0.0003)
âš¡ Performance: 1106.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1892
   â€¢ Completion Tokens: 289
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 3 Single Batch Time: 1971ms (1.97s)

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 1972ms (1.97s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2181 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.0 sessions/sec
âš¡ Avg Time Per Session: 493.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:16:27.415Z',
  duration: '2915ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1984,
    completion_tokens: 293,
    total_tokens: 2277,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Leave Reporting', 'Unknown', 'Time Entry' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-d2645b9a-d2c0-5575-9f7a-1e5dd2cc0586",
      "general_intent": "Leave Reporting",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to open a new leave request and was transferred to an agent."
    },
    {
      "user_id": "u-2d23a259-8d75-5d5a-8309-5ff5832dadee",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an operator and was transferred to an agent."
    },
    {
      "user_id": "u-a3006858-f093-569d-bc9d-157aaca6f50b",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak to an agent and was transferred."
    },
    {
      "user_id": "u-4aaf3c84-6786-5018-9340-ef75ac11f620",
      "general_intent": "Time Entry",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User provided employee number, zip code, and time details; session was handled by bot."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1984,
  completionTokens: 293,
  totalTokens: 2277,
  cost: '$0.000316',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2916ms (2.92s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2277 ($0.0003)
âš¡ Performance: 780.9 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1984
   â€¢ Completion Tokens: 293
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 1 Single Batch Time: 2916ms (2.92s)

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 2917ms (2.92s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2277 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.4 sessions/sec
âš¡ Avg Time Per Session: 729.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:16:27.434Z',
  duration: '2931ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1969,
    completion_tokens: 289,
    total_tokens: 2258,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status', 'Live Agent' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-f6c53c85-1897-52ca-8a4a-4bfb2362b592",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User inquired about claim status and was transferred to an agent."
    },
    {
      "user_id": "u-bdc70a52-3c5e-532d-bb75-034eaa88731e",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked about claim status and was transferred to an agent."
    },
    {
      "user_id": "u-aec0380a-aad1-5393-9adf-03e177fad604",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-d01b5bfb-bd93-5eba-8581-c5e09b515a8a",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a representative and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1969,
  completionTokens: 289,
  totalTokens: 2258,
  cost: '$0.000312',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2933ms (2.93s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2258 ($0.0003)
âš¡ Performance: 769.9 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1969
   â€¢ Completion Tokens: 289
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 7 Single Batch Time: 2933ms (2.93s)

âœ… ===== STREAM 7 PROCESSING COMPLETE =====
â±ï¸  Stream 7 Total Time: 2933ms (2.93s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2258 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.4 sessions/sec
âš¡ Avg Time Per Session: 733.25ms
[ParallelProcessingOrchestrator] Parallel processing complete: 8/8 streams succeeded
â±ï¸  Parallel Processing Time: 2936ms (2.94s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 8 streams
[ParallelProcessingOrchestrator] Synchronization complete: 0 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 0
ğŸ“Š Total Classifications: 9

âœ… ============ ROUND 2 COMPLETED ============
â±ï¸  Round 2 Total Time: 2936ms (2.94s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 21
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 2936ms (100.0%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ”„ ============ ROUND 3/3 STARTED ============
â±ï¸  Round 3 Start: 2025-08-12T16:16:27.436Z
ğŸ“Š Sessions Remaining: 21
[ParallelProcessingOrchestrator] Distributed 21 sessions across 6 streams: [
  'Stream 1: 4 sessions',
  'Stream 2: 4 sessions',
  'Stream 3: 4 sessions',
  'Stream 4: 4 sessions',
  'Stream 5: 4 sessions',
  'Stream 6: 1 sessions'
]
â±ï¸  Session Distribution Time: 2ms
ğŸŒŠ Active Streams: 6

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 6 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T16:16:27.438Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:16:27.438Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 1001
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6501
   â€¢ Avg Per Session: 250 tokens
   â€¢ Estimation Time: 1ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6501
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 1ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6501
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:16:27.439Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:16:27.439Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7428,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Customer Service, Leave Reporting, Live Agent, Speak to a Live Agent, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usua...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T16:16:27.439Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:16:27.439Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 783
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6283
   â€¢ Avg Per Session: 196 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6283
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 1ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6283
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:16:27.440Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:16:27.440Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6333,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Customer Service, Leave Reporting, Live Agent, Speak to a Live Agent, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usua...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T16:16:27.440Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:16:27.440Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 1219
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6719
   â€¢ Avg Per Session: 305 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6719
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0011
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6719
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0011

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:16:27.440Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:16:27.440Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 8462,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Customer Service, Leave Reporting, Live Agent, Speak to a Live Agent, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usua...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T16:16:27.440Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:16:27.440Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 927
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6427
   â€¢ Avg Per Session: 232 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6427
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6427
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:16:27.441Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:16:27.441Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7060,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Customer Service, Leave Reporting, Live Agent, Speak to a Live Agent, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usua...

ğŸŒŠ ===== STREAM 5 PROCESSING START =====
â±ï¸  Stream 5 Start: 2025-08-12T16:16:27.441Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:16:27.441Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 720
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6220
   â€¢ Avg Per Session: 180 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6220
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 5) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6220
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 5: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:16:27.441Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:16:27.441Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6080,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Customer Service, Leave Reporting, Live Agent, Speak to a Live Agent, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usua...

ğŸŒŠ ===== STREAM 6 PROCESSING START =====
â±ï¸  Stream 6 Start: 2025-08-12T16:16:27.441Z
ğŸ“Š Sessions Assigned: 1
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:16:27.441Z
ğŸ“Š Sessions to Estimate: 1
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 1
   â€¢ Session Tokens: 179
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 5679
   â€¢ Avg Per Session: 179 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 5679
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0009
ğŸ“Š Recommended Batch Size: 1

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 6) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 5679
ğŸ“¦ Recommended Batch Size: 1
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0009

âš¡ Stream 6: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:16:27.441Z
ğŸ“Š Sessions to Analyze: 1
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:16:27.441Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 1,
  apiKey: 'sk-proj-...',
  promptLength: 4151,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Customer Service, Leave Reporting, Live Agent, Speak to a Live Agent, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usua...
::1 - - [12/Aug/2025:16:16:28 +0000] "GET /api/analysis/auto-analyze/parallel/progress/52583704-4927-491d-82e4-6ee9561ebd69 HTTP/1.1" 200 1527 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:16:28.567Z',
  duration: '1125ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1222,
    completion_tokens: 72,
    total_tokens: 1294,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 1,
  intentsFound: [ 'Unknown' ],
  transferCount: 1,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-1211dfed-ab69-54e2-b66c-3353656171ca",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a representative and was transferred to a live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1222,
  completionTokens: 72,
  totalTokens: 1294,
  cost: '$0.000151',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1127ms (1.13s)
ğŸ“Š Sessions Returned: 1
ğŸ’° Tokens Used: 1294 ($0.0002)
âš¡ Performance: 1148.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1222
   â€¢ Completion Tokens: 72
[SessionValidationService] Validating batch response: 1 input sessions, 1 response sessions
[SessionValidationService] Validation successful: all 1 sessions processed
[SessionValidationService] Validating batch response: 1 input sessions, 1 response sessions
[SessionValidationService] Validation successful: all 1 sessions processed
â±ï¸  Stream 6 Single Batch Time: 1127ms (1.13s)

âœ… ===== STREAM 6 PROCESSING COMPLETE =====
â±ï¸  Stream 6 Total Time: 1127ms (1.13s)
ğŸ“Š Sessions Processed: 1/1
ğŸ’° Tokens Used: 1294 ($0.0002)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.9 sessions/sec
âš¡ Avg Time Per Session: 1127.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:16:28.910Z',
  duration: '1470ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2364,
    completion_tokens: 184,
    total_tokens: 2548,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-4e8db19c-d846-548b-a018-26aa4b236bbe",
      "notes": "User successfully submitted a time entry for family member's serious health condition."
    },
    {
      "user_id": "u-be937f75-2f3b-5475-a183-6d2fd859fc76",
      "notes": "User was silent and session was transferred due to no input."
    },
    {
      "user_id": "u-dfae4a1c-64bc-55e9-9561-567b107752d0",
      "notes": "User successfully submitted a time entry for episode of incapacity."
    },
    {
      "user_id": "u-9e1996ea-0283-5ece-abd8-12b9e943c299",
      "notes": "User provided information to update date of delivery, session was transferred to an agent after user confirmation."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2364,
  completionTokens: 184,
  totalTokens: 2548,
  cost: '$0.000310',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1471ms (1.47s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2548 ($0.0003)
âš¡ Performance: 1732.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2364
   â€¢ Completion Tokens: 184
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-4e8db19c-d846-548b-a018-26aa4b236bbe: Invalid general_intent, u-4e8db19c-d846-548b-a018-26aa4b236bbe: Invalid session_outcome, u-be937f75-2f3b-5475-a183-6d2fd859fc76: Invalid general_intent, u-be937f75-2f3b-5475-a183-6d2fd859fc76: Invalid session_outcome, u-dfae4a1c-64bc-55e9-9561-567b107752d0: Invalid general_intent, u-dfae4a1c-64bc-55e9-9561-567b107752d0: Invalid session_outcome, u-9e1996ea-0283-5ece-abd8-12b9e943c299: Invalid general_intent, u-9e1996ea-0283-5ece-abd8-12b9e943c299: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 3 Single Batch Time: 1471ms (1.47s)

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 1471ms (1.47s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2548 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.7 sessions/sec
âš¡ Avg Time Per Session: 367.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:16:29.050Z',
  duration: '1609ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1728,
    completion_tokens: 227,
    total_tokens: 1955,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-0989ec9a-30d4-552d-94ff-950e54c42f24",
      "notes": "User wanted to speak with an agent about customer service, session was transferred to an agent."
    },
    {
      "user_id": "u-ee26152e-5803-58b7-9f6f-c90c9cfa00b9",
      "notes": "User wanted to speak with an agent about representative, session was transferred to an agent, but the session was closed due to no input."
    },
    {
      "user_id": "u-18ca9c73-dc40-58fa-b39f-ffdd0f82a96d",
      "notes": "User wanted to speak with an agent about representative, session was transferred to an agent, but the session was closed due to no input."
    },
    {
      "user_id": "u-f1ab3eb8-4948-5730-b1e8-8e8f45db44c0",
      "notes": "User wanted to speak with someone regarding FMLA leave, session was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1728,
  completionTokens: 227,
  totalTokens: 1955,
  cost: '$0.000264',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1610ms (1.61s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1955 ($0.0003)
âš¡ Performance: 1214.3 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1728
   â€¢ Completion Tokens: 227
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-0989ec9a-30d4-552d-94ff-950e54c42f24: Invalid general_intent, u-0989ec9a-30d4-552d-94ff-950e54c42f24: Invalid session_outcome, u-ee26152e-5803-58b7-9f6f-c90c9cfa00b9: Invalid general_intent, u-ee26152e-5803-58b7-9f6f-c90c9cfa00b9: Invalid session_outcome, u-18ca9c73-dc40-58fa-b39f-ffdd0f82a96d: Invalid general_intent, u-18ca9c73-dc40-58fa-b39f-ffdd0f82a96d: Invalid session_outcome, u-f1ab3eb8-4948-5730-b1e8-8e8f45db44c0: Invalid general_intent, u-f1ab3eb8-4948-5730-b1e8-8e8f45db44c0: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 5 Single Batch Time: 1613ms (1.61s)

âœ… ===== STREAM 5 PROCESSING COMPLETE =====
â±ï¸  Stream 5 Total Time: 1613ms (1.61s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1955 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.5 sessions/sec
âš¡ Avg Time Per Session: 403.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:16:29.449Z',
  duration: '2009ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1790,
    completion_tokens: 292,
    total_tokens: 2082,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Leave Reporting', 'Unknown' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-5919d758-9cac-5a62-824f-1aecb15a57a2",
      "general_intent": "Leave Reporting",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak to someone about FMLA leave and was transferred to an agent."
    },
    {
      "user_id": "u-92c16bcd-606b-5f1a-b39f-4c280233729b",
      "general_intent": "Leave Reporting",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent, and was transferred."
    },
    {
      "user_id": "u-68315676-f608-5c2a-af9f-b4cbc793b4fc",
      "general_intent": "Leave Reporting",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent regarding a form after an accident."
    },
    {
      "user_id": "u-3e540eba-e6cf-575c-8335-d28aae18d6d9",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted account login assistance and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1790,
  completionTokens: 292,
  totalTokens: 2082,
  cost: '$0.000296',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2010ms (2.01s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2082 ($0.0003)
âš¡ Performance: 1035.8 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1790
   â€¢ Completion Tokens: 292
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 2 Single Batch Time: 2010ms (2.01s)

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 2011ms (2.01s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2082 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.0 sessions/sec
âš¡ Avg Time Per Session: 502.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:16:29.486Z',
  duration: '2047ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2077,
    completion_tokens: 218,
    total_tokens: 2295,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Representative', 'Time Entry' ],
  transferCount: 2,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-2f64b785-5f9f-5bc0-93e8-c227ff0d2c49",
      "general_intent": "Representative",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-691da028-b59f-56dd-a191-3bb883baeb76",
      "general_intent": "Time Entry",
      "session_outcome": "Contained",
      "notes": "User successfully submitted a time entry for leave."
    },
    {
      "user_id": "u-3ceec8de-7681-5e3b-a944-a8e1e1282785",
      "general_intent": "Representative",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-b6595f56-7df0-57ed-aebb-fa35eb382174",
      "general_intent": "Time Entry",
      "session_outcome": "Contained",
      "notes": "User successfully submitted a time entry for leave."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2077,
  completionTokens: 218,
  totalTokens: 2295,
  cost: '$0.000295',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2047ms (2.05s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2295 ($0.0003)
âš¡ Performance: 1121.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2077
   â€¢ Completion Tokens: 218
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-2f64b785-5f9f-5bc0-93e8-c227ff0d2c49: Invalid notes, u-3ceec8de-7681-5e3b-a944-a8e1e1282785: Invalid notes'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 1 Single Batch Time: 2048ms (2.05s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 2049ms (2.05s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2295 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.0 sessions/sec
âš¡ Avg Time Per Session: 512.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:16:29.653Z',
  duration: '2212ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2000,
    completion_tokens: 295,
    total_tokens: 2295,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status', 'Unknown' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-c388881f-3d51-5e8a-8f8c-d1c0f1264629",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested FMLA claim status and was transferred to an agent."
    },
    {
      "user_id": "u-fe747773-8270-5745-93dc-d565565a7ed7",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak to a representative and was transferred to an agent."
    },
    {
      "user_id": "u-dae579d0-d327-5f2f-b379-c05e5f622e03",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User needed assistance with a denied FMLA request and was transferred to an agent."
    },
    {
      "user_id": "u-ea18debe-9562-5b0c-a871-40c6ab7d2bd6",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested support and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2000,
  completionTokens: 295,
  totalTokens: 2295,
  cost: '$0.000318',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2212ms (2.21s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2295 ($0.0003)
âš¡ Performance: 1037.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2000
   â€¢ Completion Tokens: 295
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 4 Single Batch Time: 2212ms (2.21s)

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 2213ms (2.21s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2295 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.8 sessions/sec
âš¡ Avg Time Per Session: 553.25ms
[ParallelProcessingOrchestrator] Parallel processing complete: 6/6 streams succeeded
â±ï¸  Parallel Processing Time: 2215ms (2.21s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 6 streams
[ParallelProcessingOrchestrator] Synchronization complete: 1 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 1
ğŸ“Š Total Classifications: 10

âœ… ============ ROUND 3 COMPLETED ============
â±ï¸  Round 3 Total Time: 2217ms (2.22s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 0
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 2ms (0.1%)
   â€¢ Parallel Processing: 2215ms (99.9%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ‰ ============ PARALLEL PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 9498ms (9.50s)
ğŸ“Š Sessions Processed: 85/85
ğŸ”„ Total Rounds: 3
ğŸŒŠ Stream Results: 22
ğŸ’° Token Usage: 46754 tokens ($0.0063)
ğŸ“ˆ Stream Utilization: 100.0%
ğŸ¯ Performance: 8.9 sessions/second
âš¡ Avg Time Per Session: 111.74ms

ğŸ“Š Stream Performance Breakdown:
   Stream 1: 4 sessions in 2339ms (884.6 tokens/sec)
   Stream 2: 4 sessions in 2074ms (1036.2 tokens/sec)
   Stream 3: 4 sessions in 1969ms (1037.1 tokens/sec)
   Stream 4: 4 sessions in 2254ms (1096.7 tokens/sec)
   Stream 5: 4 sessions in 2736ms (739.0 tokens/sec)
   Stream 6: 4 sessions in 2119ms (950.0 tokens/sec)
   Stream 7: 4 sessions in 4341ms (456.8 tokens/sec)
   Stream 8: 4 sessions in 1626ms (1269.4 tokens/sec)
   Stream 1: 4 sessions in 2917ms (780.6 tokens/sec)
   Stream 2: 4 sessions in 1593ms (1322.0 tokens/sec)
   Stream 3: 4 sessions in 1972ms (1106.0 tokens/sec)
   Stream 4: 4 sessions in 1429ms (1407.3 tokens/sec)
   Stream 5: 4 sessions in 1603ms (1462.9 tokens/sec)
   Stream 6: 4 sessions in 1969ms (1120.9 tokens/sec)
   Stream 7: 4 sessions in 2933ms (769.9 tokens/sec)
   Stream 8: 4 sessions in 1969ms (1059.4 tokens/sec)
   Stream 1: 4 sessions in 2049ms (1120.1 tokens/sec)
   Stream 2: 4 sessions in 2011ms (1035.3 tokens/sec)
   Stream 3: 4 sessions in 1471ms (1732.2 tokens/sec)
   Stream 4: 4 sessions in 2213ms (1037.1 tokens/sec)
   Stream 5: 4 sessions in 1613ms (1212.0 tokens/sec)
   Stream 6: 1 sessions in 1127ms (1148.2 tokens/sec)
[ConflictResolutionService] Starting conflict resolution for 99 sessions
[ConflictResolutionService] Found classifications: { intents: 8, reasons: 1, locations: 1 }
[ConflictResolutionService] Calling LLM for conflict resolution with model gpt-4.1-nano
ğŸ”§ Conflict Resolution Prompt Preview: You are reviewing classifications from parallel analysis streams. Identify any semantic duplicates and choose the canonical version for each group.

**Instructions:**
1. Look for classifications that refer to the same concept but use different wording
2. For each group of duplicates, choose the most...
::1 - - [12/Aug/2025:16:16:30 +0000] "GET /api/analysis/auto-analyze/parallel/progress/52583704-4927-491d-82e4-6ee9561ebd69 HTTP/1.1" 200 1539 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:16:32 +0000] "GET /api/analysis/auto-analyze/parallel/progress/52583704-4927-491d-82e4-6ee9561ebd69 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[ConflictResolutionService] LLM conflict resolution complete: { intents: 7, reasons: 1, locations: 1, tokens: 768, cost: 0.0001161 }
ğŸ”§ Conflict Resolution Response: {
  "generalIntents": [
    {
      "canonical": "Claim Status Inquiry",
      "aliases": [
        "Claim Status"
      ]
    },
    {
      "canonical": "Customer Support Service",
      "aliases": [
        "Customer Service"
      ]
    },
    {
      "canonical": "Leave Reporting",
      "aliases": [
        "Leave Reporting"
      ]
    },
    {
      "canonical": "Live Agent Transfer",
      "aliases": [
        "Live Agent",
        "Transfer to Human",
        "Speak to a Live Agent"
      ]
    },
    {
      "canonical": "Customer Representative",
      "aliases": [
        "Representative"
      ]
    },
    {
      "canonical": "Time Entry",
      "aliases": [
        "Time Entry"
      ]
    },
    {
      "canonical": "Unknown",
      "aliases": [
        "Unknown"
      ]
    }
  ],
  "transferReasons": [
    {
      "canonical": "Live Agent Request",
      "aliases": [
        "Live Agent Request"
      ]
    }
  ],
  "dropOffLocations": [
    {
      "canonical": "Help Offer Prompt",
      "aliases": [
        "Help Offer Prompt"
      ]
    }
  ]
}
[ConflictResolutionService] Applying resolutions to 99 sessions
[ConflictResolutionService] Applied 40 classification mappings across 99 sessions
[ConflictResolutionService] Identified 1 potential conflict groups
[ConflictResolutionService] Conflict resolution complete in 2936ms: { conflictsFound: 1, conflictsResolved: 9, canonicalMappings: 11 }
[ParallelAutoAnalyzeService] Using real analysis summary service
::1 - - [12/Aug/2025:16:16:34 +0000] "GET /api/analysis/auto-analyze/parallel/progress/52583704-4927-491d-82e4-6ee9561ebd69 HTTP/1.1" 200 1621 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:16:36 +0000] "GET /api/analysis/auto-analyze/parallel/progress/52583704-4927-491d-82e4-6ee9561ebd69 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:16:38 +0000] "GET /api/analysis/auto-analyze/parallel/progress/52583704-4927-491d-82e4-6ee9561ebd69 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:16:40 +0000] "GET /api/analysis/auto-analyze/parallel/progress/52583704-4927-491d-82e4-6ee9561ebd69 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:16:42 +0000] "GET /api/analysis/auto-analyze/parallel/progress/52583704-4927-491d-82e4-6ee9561ebd69 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:16:44 +0000] "GET /api/analysis/auto-analyze/parallel/progress/52583704-4927-491d-82e4-6ee9561ebd69 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:16:46 +0000] "GET /api/analysis/auto-analyze/parallel/progress/52583704-4927-491d-82e4-6ee9561ebd69 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:16:48 +0000] "GET /api/analysis/auto-analyze/parallel/progress/52583704-4927-491d-82e4-6ee9561ebd69 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[ParallelAutoAnalyzeService] Parallel analysis 52583704-4927-491d-82e4-6ee9561ebd69 completed successfully
[BackgroundJobQueue] Updated job progress to final state: complete
[BackgroundJobQueue] Parallel analysis job 52583704-4927-491d-82e4-6ee9561ebd69-parallel completed successfully
::1 - - [12/Aug/2025:16:16:50 +0000] "GET /api/analysis/auto-analyze/parallel/progress/52583704-4927-491d-82e4-6ee9561ebd69 HTTP/1.1" 200 1661 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:16:50 +0000] "GET /api/analysis/auto-analyze/parallel/results/52583704-4927-491d-82e4-6ee9561ebd69 HTTP/1.1" 200 720534 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T16:18:20.841Z",
  "dateTo": "2025-08-12T16:19:20.841Z",
  "skip": 0,
  "limit": 1
}
[fetchContainmentTypeMetadata] API Response: 1 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [ '689b695ee11e897de60472ef' ]
[getSessionsMetadataForConnectionTest] Single API call succeeded with 1 sessions
::1 - - [12/Aug/2025:16:19:23 +0000] "GET /api/kore/test HTTP/1.1" 200 851 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[Direct API] Fetching real Kore.ai sessions from 2025-08-05T16:19:24.352Z to 2025-08-12T16:19:24.352Z for User Bot st-90549... (limit=50)
Retrieving sessions from 2025-08-05T16:19:24.352Z to 2025-08-12T16:19:24.352Z (limit=50), populateMessages=true...
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T16:19:24.352Z",
  "dateTo": "2025-08-12T16:19:24.352Z",
  "limit": 50
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T16:19:24.352Z",
  "dateTo": "2025-08-12T16:19:24.352Z",
  "skip": 0,
  "limit": 50
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T16:19:24.352Z",
  "dateTo": "2025-08-12T16:19:24.352Z",
  "skip": 0,
  "limit": 50
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T16:19:24.352Z",
  "dateTo": "2025-08-12T16:19:24.352Z",
  "skip": 0,
  "limit": 50
}
::1 - - [12/Aug/2025:16:19:25 +0000] "GET /api/analysis/sessions?limit=50 HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 50 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b69889516e359d07b585f',
  '689b6986bf7ccd3cf0f6bec8',
  '689b6981995362de8def2385'
]
[fetchContainmentTypeMetadata] API Response: 50 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b64449516e359d07aa002',
  '689b643eb1f082150b5210a9',
  '689b641b5f04b9bca7b28c3e'
]
[fetchContainmentTypeMetadata] API Response: 50 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b695ee11e897de60472ef',
  '689b6959dcfd96eb5e75ed0c',
  '689b694b05a45fff890502c7'
]
[getSessionsMetadata] agent API call succeeded with 50 sessions
[getSessionsMetadata] selfService API call succeeded with 50 sessions
[getSessionsMetadata] dropOff API call succeeded with 50 sessions
Total session metadata retrieved: 150 (parallel execution)
Retrieved 150 session metadata objects
Creating 150 SWTs from metadata (no messages)
Created 150 SWT objects from metadata
Populating messages for all sessions (legacy behavior)
Populating messages for 150 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 150 sessions from 2025-08-12T15:06:51.250Z to 2025-08-12T16:19:23.153Z at 2025-08-12T16:19:33.270Z
ğŸš€ [ConcurrentBatch] Split 150 sessions into 8 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/8] Starting: 20 sessions
[Batch 2/8] Starting: 20 sessions
[Batch 3/8] Starting: 20 sessions
[Batch 4/8] Starting: 20 sessions
[Batch 5/8] Starting: 20 sessions
[Batch 6/8] Starting: 20 sessions
[Batch 7/8] Starting: 20 sessions
[Batch 8/8] Starting: 10 sessions
[Batch 3/8] Completed in 220ms: 195 messages retrieved (1/8 done)
[Batch 2/8] Completed in 223ms: 208 messages retrieved (2/8 done)
[Batch 1/8] Completed in 242ms: 201 messages retrieved (3/8 done)
[Batch 6/8] Completed in 481ms: 227 messages retrieved (4/8 done)
[Batch 4/8] Completed in 513ms: 314 messages retrieved (5/8 done)
[Batch 8/8] Completed in 529ms: 122 messages retrieved (6/8 done)
[Batch 7/8] Completed in 582ms: 205 messages retrieved (7/8 done)
[Batch 5/8] Completed in 743ms: 413 messages retrieved (8/8 done)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 743ms (0.74s)
â±ï¸  Batch Processing: 743ms (0.74s)
ğŸ“¦ Total batches: 8 (max 10 concurrent)
âœ… Successful batches: 8/8
ğŸ’¬ Total messages: 1885
ğŸ“ˆ Avg time per batch: 93ms
ğŸš€ Time per session: 5ms
ğŸ’ª Performance: 201.9 sessions/second
=======================================================

Retrieved 1885 messages for 150 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
Populated messages for 150 SWT objects
Generated 150 SWT objects in 9668ms using layered architecture
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T16:18:47.221Z",
  "dateTo": "2025-08-12T16:19:47.221Z",
  "skip": 0,
  "limit": 1
}
[fetchContainmentTypeMetadata] API Response: 1 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [ '689b6977946228cfd44c4b25' ]
[getSessionsMetadataForConnectionTest] Single API call succeeded with 1 sessions
::1 - - [12/Aug/2025:16:19:49 +0000] "GET /api/kore/test HTTP/1.1" 200 851 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[Direct API] Fetching real Kore.ai sessions from 2025-08-05T16:19:50.560Z to 2025-08-12T16:19:50.560Z for User Bot st-90549... (limit=50)
Retrieving sessions from 2025-08-05T16:19:50.560Z to 2025-08-12T16:19:50.560Z (limit=50), populateMessages=true...
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T16:19:50.560Z",
  "dateTo": "2025-08-12T16:19:50.560Z",
  "limit": 50
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T16:19:50.560Z",
  "dateTo": "2025-08-12T16:19:50.560Z",
  "skip": 0,
  "limit": 50
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T16:19:50.560Z",
  "dateTo": "2025-08-12T16:19:50.560Z",
  "skip": 0,
  "limit": 50
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T16:19:50.560Z",
  "dateTo": "2025-08-12T16:19:50.560Z",
  "skip": 0,
  "limit": 50
}
::1 - - [12/Aug/2025:16:19:51 +0000] "GET /api/analysis/sessions?limit=50 HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[Direct API] Fetching real Kore.ai sessions from 2025-08-05T16:19:51.380Z to 2025-08-12T16:19:51.380Z for User Bot st-90549... (limit=50)
Retrieving sessions from 2025-08-05T16:19:51.380Z to 2025-08-12T16:19:51.380Z (limit=50), populateMessages=true...
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T16:19:51.380Z",
  "dateTo": "2025-08-12T16:19:51.380Z",
  "limit": 50
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T16:19:51.380Z",
  "dateTo": "2025-08-12T16:19:51.380Z",
  "skip": 0,
  "limit": 50
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T16:19:51.380Z",
  "dateTo": "2025-08-12T16:19:51.380Z",
  "skip": 0,
  "limit": 50
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T16:19:51.380Z",
  "dateTo": "2025-08-12T16:19:51.380Z",
  "skip": 0,
  "limit": 50
}
::1 - - [12/Aug/2025:16:19:51 +0000] "GET /api/analysis/sessions?limit=50 HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 50 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b6977946228cfd44c4b25',
  '689b69673360bd076e15b567',
  '689b695ee11e897de60472ef'
]
[fetchContainmentTypeMetadata] API Response: 50 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b699a025fed00985f011d',
  '689b6998296df1d830cd0292',
  '689b6995144f8feea17f0293'
]
[fetchContainmentTypeMetadata] API Response: 50 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b64449516e359d07aa002',
  '689b643eb1f082150b5210a9',
  '689b641b5f04b9bca7b28c3e'
]
[getSessionsMetadata] agent API call succeeded with 50 sessions
[getSessionsMetadata] selfService API call succeeded with 50 sessions
[getSessionsMetadata] dropOff API call succeeded with 50 sessions
Total session metadata retrieved: 150 (parallel execution)
Retrieved 150 session metadata objects
Creating 150 SWTs from metadata (no messages)
Created 150 SWT objects from metadata
Populating messages for all sessions (legacy behavior)
Populating messages for 150 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 150 sessions from 2025-08-12T15:06:51.250Z to 2025-08-12T16:19:49.785Z at 2025-08-12T16:19:53.293Z
ğŸš€ [ConcurrentBatch] Split 150 sessions into 8 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/8] Starting: 20 sessions
[Batch 2/8] Starting: 20 sessions
[Batch 3/8] Starting: 20 sessions
[Batch 4/8] Starting: 20 sessions
[Batch 5/8] Starting: 20 sessions
[Batch 6/8] Starting: 20 sessions
[Batch 7/8] Starting: 20 sessions
[Batch 8/8] Starting: 10 sessions
[Batch 3/8] Completed in 191ms: 174 messages retrieved (1/8 done)
[Batch 2/8] Completed in 209ms: 210 messages retrieved (2/8 done)
[Batch 1/8] Completed in 213ms: 207 messages retrieved (3/8 done)
[Batch 7/8] Completed in 370ms: 205 messages retrieved (4/8 done)
[Batch 8/8] Completed in 417ms: 122 messages retrieved (5/8 done)
[Batch 6/8] Completed in 466ms: 227 messages retrieved (6/8 done)
[Batch 4/8] Completed in 573ms: 330 messages retrieved (7/8 done)
[Batch 5/8] Completed in 637ms: 369 messages retrieved (8/8 done)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 637ms (0.64s)
â±ï¸  Batch Processing: 637ms (0.64s)
ğŸ“¦ Total batches: 8 (max 10 concurrent)
âœ… Successful batches: 8/8
ğŸ’¬ Total messages: 1844
ğŸ“ˆ Avg time per batch: 80ms
ğŸš€ Time per session: 4ms
ğŸ’ª Performance: 235.5 sessions/second
=======================================================

Retrieved 1844 messages for 150 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
Populated messages for 150 SWT objects
Generated 150 SWT objects in 3378ms using layered architecture
[fetchContainmentTypeMetadata] API Response: 50 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b699a025fed00985f011d',
  '689b6998296df1d830cd0292',
  '689b6995144f8feea17f0293'
]
[fetchContainmentTypeMetadata] API Response: 50 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b6977946228cfd44c4b25',
  '689b69673360bd076e15b567',
  '689b695ee11e897de60472ef'
]
[fetchContainmentTypeMetadata] API Response: 50 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b64449516e359d07aa002',
  '689b643eb1f082150b5210a9',
  '689b641b5f04b9bca7b28c3e'
]
[getSessionsMetadata] agent API call succeeded with 50 sessions
[getSessionsMetadata] selfService API call succeeded with 50 sessions
[getSessionsMetadata] dropOff API call succeeded with 50 sessions
Total session metadata retrieved: 150 (parallel execution)
Retrieved 150 session metadata objects
Creating 150 SWTs from metadata (no messages)
Created 150 SWT objects from metadata
Populating messages for all sessions (legacy behavior)
Populating messages for 150 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 150 sessions from 2025-08-12T15:06:51.250Z to 2025-08-12T16:19:49.785Z at 2025-08-12T16:19:54.105Z
ğŸš€ [ConcurrentBatch] Split 150 sessions into 8 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/8] Starting: 20 sessions
[Batch 2/8] Starting: 20 sessions
[Batch 3/8] Starting: 20 sessions
[Batch 4/8] Starting: 20 sessions
[Batch 5/8] Starting: 20 sessions
[Batch 6/8] Starting: 20 sessions
[Batch 7/8] Starting: 20 sessions
[Batch 8/8] Starting: 10 sessions
[Batch 8/8] Completed in 207ms: 122 messages retrieved (1/8 done)
[Batch 3/8] Completed in 209ms: 174 messages retrieved (2/8 done)
[Batch 2/8] Completed in 218ms: 216 messages retrieved (3/8 done)
[Batch 1/8] Completed in 240ms: 214 messages retrieved (4/8 done)
[Batch 7/8] Completed in 308ms: 205 messages retrieved (5/8 done)
[Batch 4/8] Completed in 314ms: 330 messages retrieved (6/8 done)
[Batch 6/8] Completed in 317ms: 227 messages retrieved (7/8 done)
[Batch 5/8] Completed in 325ms: 369 messages retrieved (8/8 done)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 325ms (0.33s)
â±ï¸  Batch Processing: 325ms (0.33s)
ğŸ“¦ Total batches: 8 (max 10 concurrent)
âœ… Successful batches: 8/8
ğŸ’¬ Total messages: 1857
ğŸ“ˆ Avg time per batch: 41ms
ğŸš€ Time per session: 2ms
ğŸ’ª Performance: 461.5 sessions/second
=======================================================

Retrieved 1857 messages for 150 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
Populated messages for 150 SWT objects
Generated 150 SWT objects in 3057ms using layered architecture
ğŸš€ [ParallelAutoAnalyzeRoute] Starting parallel analysis for bot ***REMOVED*** with real credentials
ğŸš€ [ParallelAutoAnalyzeService] Starting parallel analysis 3913454c-67c8-4323-8ea6-8130bec8e988 with bot ***REMOVED***
ğŸš€ [ParallelAutoAnalyzeService] Using credentials: real
ğŸš€ [ParallelAutoAnalyzeRoute] Parallel analysis started: 3913454c-67c8-4323-8ea6-8130bec8e988
::1 - - [12/Aug/2025:16:19:55 +0000] "POST /api/analysis/auto-analyze/parallel/start HTTP/1.1" 200 214 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:19:55 +0000] "GET /api/analysis/auto-analyze/parallel/progress/3913454c-67c8-4323-8ea6-8130bec8e988 HTTP/1.1" 200 541 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:19:55 +0000] "GET /api/analysis/auto-analyze/parallel/progress/3913454c-67c8-4323-8ea6-8130bec8e988 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[BackgroundJobQueue] Starting job processing after delay for job 3913454c-67c8-4323-8ea6-8130bec8e988-parallel
[BackgroundJobQueue] Starting processing for job 3913454c-67c8-4323-8ea6-8130bec8e988-parallel, phase: sampling
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing parallel analysis job 3913454c-67c8-4323-8ea6-8130bec8e988-parallel
[BackgroundJobQueue] Processing parallel analysis for bot ***REMOVED***
[BackgroundJobQueue] Using existing ParallelAutoAnalyzeService instance for bot ***REMOVED***
[BackgroundJobQueue] Session recreated for 3913454c-67c8-4323-8ea6-8130bec8e988
[ParallelAutoAnalyzeService] Running parallel analysis for 3913454c-67c8-4323-8ea6-8130bec8e988
[ParallelAutoAnalyzeService] Phase 0: Starting session sampling for 3913454c-67c8-4323-8ea6-8130bec8e988

ğŸ• ============ SESSION SAMPLING STARTED ============
ğŸ• [SessionSampling] Starting session sampling at 2025-08-12T16:19:56.316Z
ğŸ” [SessionDiscovery] Starting window 1/4: Initial 3-hour window
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
::1 - - [12/Aug/2025:16:19:57 +0000] "GET /api/analysis/auto-analyze/parallel/progress/3913454c-67c8-4323-8ea6-8130bec8e988 HTTP/1.1" 200 713 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 139 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6a14dd27c3112087cd',
  '68922a22ef03d8ad2ec7b4ba',
  '68922a1278c1fe09a079719c'
]
[fetchContainmentTypeMetadata] API Response: 80 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a1287849680ad9fe59e',
  '689229f9583056c6108e38fb',
  '68922914f8bee7ba6c3e67b8'
]
[fetchContainmentTypeMetadata] API Response: 1338 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6d14dd27c31120888b',
  '68922a62e3804084741191d5',
  '68922a523a3160d25de144c8'
]
[getSessionsMetadata] agent API call succeeded with 1338 sessions
[getSessionsMetadata] selfService API call succeeded with 80 sessions
[getSessionsMetadata] dropOff API call succeeded with 139 sessions
Total session metadata retrieved: 1557 (parallel execution)
Creating 1557 SWTs from metadata (no messages)
Created 1557 SWT objects from metadata
âœ… [SessionDiscovery] Window 1 completed in 4717ms: found 1557 new sessions (total: 1557)
â±ï¸  TIMING: Window 1 took 4717ms (4.72s)
ğŸ¯ [SessionDiscovery] Target reached! Found 1557 sessions in 4717ms
ğŸ² [SessionSampling] Random sampling from 1557 sessions to 10 sessions

ğŸ“¬ ============ MESSAGE RETRIEVAL STARTED ============
ğŸ“¬ [MessageRetrieval] Starting message retrieval for 10 sampled sessions at 2025-08-12T16:20:01.033Z
Using new lazy loading approach to populate messages for 10 sampled sessions
Populating messages for 10 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 10 sessions from 2025-08-05T13:42:13.267Z to 2025-08-05T15:53:46.455Z at 2025-08-12T16:20:01.033Z
ğŸ”„ [KoreAPI] Using single API call for 10 sessions (â‰¤20)
âœ… [KoreAPI] Single call completed in 383ms: 121 messages
Retrieved 121 messages for 10 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
Populated messages for 10 SWT objects
Successfully populated messages for 10 sessions using lazy loading
Applying final filtering to 10 sessions with populated messages
Final result: 10 sessions passed filtering with populated messages

ğŸ‰ ============ SESSION SAMPLING COMPLETED ============
â±ï¸  TOTAL TIME: 5101ms (5.10s)
â±ï¸  Session Discovery: 4717ms (4.72s) - 92.5% of total
â±ï¸  Message Retrieval: 384ms (0.38s) - 7.5% of total
â±ï¸  Performance: 2.0 sessions/second
ğŸ¯ Final result: 10 sessions with messages retrieved
====================================================

[StrategicDiscoveryService] Starting discovery phase with 10 total sessions
[StrategicDiscoveryService] Discovery config: {
  targetPercentage: 15,
  minSessions: 5,
  maxSessions: 5,
  diversityStrategy: {
    sessionLengths: [ 'short', 'medium', 'long' ],
    containmentTypes: [ 'agent', 'selfService', 'dropOff' ],
    timeDistribution: 'spread'
  }
}
[StrategicDiscoveryService] Selecting 5 diverse sessions from 10 total
[StrategicDiscoveryService] Session diversity groups: { short: 5, medium: 5, early: 3, middle: 3, late: 4 }
[StrategicDiscoveryService] Selected sessions by length distribution: { short: 3, medium: 2, long: 0 }
[StrategicDiscoveryService] Selected 5 sessions for discovery

ğŸ“¦ ===== BATCH 7 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:20:01.417Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 0
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:20:01.417Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:20:01.418Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6249,
  existingClassifications: { intents: 0, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.



For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and another intent, classify the intent as the other i...
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:20:03.699Z',
  duration: '2281ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1807,
    completion_tokens: 287,
    total_tokens: 2094,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Claim Status' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-df5d2530-0de6-559d-95db-db27b52249a4",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-6a1a9fc3-bdbb-59a4-9a81-f00a4822c553",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-df5d2530-0de6-559d-95db-db27b52249a4",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-dd74491d-613d-5f59-be9d-8d591794e911",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-ba29892b-2ed3-5535-9112-33a3c6c5bcc0",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1807,
  completionTokens: 287,
  totalTokens: 2094,
  cost: '$0.000295',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2282ms (2.28s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2094 ($0.0003)
âš¡ Performance: 917.6 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 4
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2282ms (2.28s)
ğŸ“Š Regular Sessions Processed: 4
ğŸ’° Regular Tokens Used: 2094

âœ… ===== BATCH 7 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2282ms (2.28s)
ğŸ“Š Sessions Processed: 4/5
ğŸ’° Total Tokens: 2094 ($0.0003)
âš¡ Performance: 1.8 sessions/sec
âš¡ Avg Time Per Session: 570.50ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 1 complete: 3 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 1, reasons: 1, locations: 1, total: 3 }
[StrategicDiscoveryService] Discovery phase complete: {
  totalProcessed: 4,
  uniqueIntents: 1,
  uniqueReasons: 1,
  uniqueLocations: 1,
  discoveryRate: 0.2
}

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T16:20:03.700Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms
[ParallelProcessingOrchestrator] Configuration for 6 sessions:
  Design: 8 streams Ã— 4 sessions = 32 per round
  Optimal: 2 streams Ã— 3 sessions = 6 per round
  Estimated Rounds: 1
[ParallelAutoAnalyzeService] Using parallel config: {
  streamCount: 2,
  sessionsPerStream: 3,
  maxSessionsPerLLMCall: 50,
  syncFrequency: 'after_each_round',
  retryAttempts: 3,
  debugLogging: false
}

ğŸš€ ============ PARALLEL PROCESSING STARTED ============
â±ï¸  Start Time: 2025-08-12T16:20:03.700Z
ğŸ“Š Total Sessions: 6

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T16:20:03.700Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms

âš™ï¸  ============ PARALLEL CONFIGURATION ============
â±ï¸  Config Time: 0ms
ğŸ”§ Stream Count: 2
ğŸ“¦ Sessions Per Stream: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per API Call: 50
ğŸ¯ Debug Logging: false

ğŸ”„ ============ ROUND 1/1 STARTED ============
â±ï¸  Round 1 Start: 2025-08-12T16:20:03.700Z
ğŸ“Š Sessions Remaining: 6
[ParallelProcessingOrchestrator] Distributed 6 sessions across 2 streams: [ 'Stream 1: 3 sessions', 'Stream 2: 3 sessions' ]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 2

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 2 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T16:20:03.700Z
ğŸ“Š Sessions Assigned: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:20:03.700Z
ğŸ“Š Sessions to Estimate: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 3
   â€¢ Session Tokens: 524
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6024
   â€¢ Avg Per Session: 175 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6024
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 3

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6024
ğŸ“¦ Recommended Batch Size: 3
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:20:03.701Z
ğŸ“Š Sessions to Analyze: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 1
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:20:03.701Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 3,
  apiKey: 'sk-proj-...',
  promptLength: 5293,
  existingClassifications: { intents: 1, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "P...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T16:20:03.701Z
ğŸ“Š Sessions Assigned: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:20:03.701Z
ğŸ“Š Sessions to Estimate: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 3
   â€¢ Session Tokens: 743
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6243
   â€¢ Avg Per Session: 248 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6243
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 3

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6243
ğŸ“¦ Recommended Batch Size: 3
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:20:03.701Z
ğŸ“Š Sessions to Analyze: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 1
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:20:03.701Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 3,
  apiKey: 'sk-proj-...',
  promptLength: 6303,
  existingClassifications: { intents: 1, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "P...
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:20:05.752Z',
  duration: '2051ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1544,
    completion_tokens: 227,
    total_tokens: 1771,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 3,
  intentsFound: [ 'Live Agent' ],
  transferCount: 3,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-569381e4-050c-50c9-beac-9da84fddbf50",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred."
    },
    {
      "user_id": "u-a5fb424b-8e25-5e25-b07d-0998e9b0cd51",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User expressed desire to speak to an agent and was transferred."
    },
    {
      "user_id": "u-30b3737f-8f3a-5e90-b33a-65fea102bc35",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred, but session was closed due to no input."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1544,
  completionTokens: 227,
  totalTokens: 1771,
  cost: '$0.000245',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2051ms (2.05s)
ğŸ“Š Sessions Returned: 3
ğŸ’° Tokens Used: 1771 ($0.0002)
âš¡ Performance: 863.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1544
   â€¢ Completion Tokens: 227
[SessionValidationService] Validating batch response: 3 input sessions, 3 response sessions
[SessionValidationService] Validation successful: all 3 sessions processed
[SessionValidationService] Validating batch response: 3 input sessions, 3 response sessions
[SessionValidationService] Validation successful: all 3 sessions processed
â±ï¸  Stream 1 Single Batch Time: 2052ms (2.05s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 2052ms (2.05s)
ğŸ“Š Sessions Processed: 3/3
ğŸ’° Tokens Used: 1771 ($0.0002)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.5 sessions/sec
âš¡ Avg Time Per Session: 684.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:20:06.041Z',
  duration: '2340ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1809,
    completion_tokens: 213,
    total_tokens: 2022,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 3,
  intentsFound: [ 'Live Agent', 'Claim Status' ],
  transferCount: 2,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-4898b204-9214-5313-8558-0f0d865ef097",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative and was transferred to an agent."
    },
    {
      "user_id": "u-69366f69-e835-5f64-8ab3-36292d5b0825",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested customer service and was transferred to an agent."
    },
    {
      "user_id": "u-d5778127-5e94-5784-b18e-0863031a45fe",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User attempted to access claim information but was not transferred; session was handled by bot."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1809,
  completionTokens: 213,
  totalTokens: 2022,
  cost: '$0.000266',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2340ms (2.34s)
ğŸ“Š Sessions Returned: 3
ğŸ’° Tokens Used: 2022 ($0.0003)
âš¡ Performance: 864.1 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1809
   â€¢ Completion Tokens: 213
[SessionValidationService] Validating batch response: 3 input sessions, 3 response sessions
[SessionValidationService] Validation successful: all 3 sessions processed
[SessionValidationService] Validating batch response: 3 input sessions, 3 response sessions
[SessionValidationService] Validation successful: all 3 sessions processed
â±ï¸  Stream 2 Single Batch Time: 2340ms (2.34s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 2340ms (2.34s)
ğŸ“Š Sessions Processed: 3/3
ğŸ’° Tokens Used: 2022 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.3 sessions/sec
âš¡ Avg Time Per Session: 780.00ms
[ParallelProcessingOrchestrator] Parallel processing complete: 2/2 streams succeeded
â±ï¸  Parallel Processing Time: 2341ms (2.34s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 2 streams
[ParallelProcessingOrchestrator] Synchronization complete: 1 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 1
ğŸ“Š Total Classifications: 4

âœ… ============ ROUND 1 COMPLETED ============
â±ï¸  Round 1 Total Time: 2341ms (2.34s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 0
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 2341ms (100.0%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ‰ ============ PARALLEL PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 2341ms (2.34s)
ğŸ“Š Sessions Processed: 6/6
ğŸ”„ Total Rounds: 1
ğŸŒŠ Stream Results: 2
ğŸ’° Token Usage: 3793 tokens ($0.0005)
ğŸ“ˆ Stream Utilization: 100.0%
ğŸ¯ Performance: 2.6 sessions/second
âš¡ Avg Time Per Session: 390.17ms

ğŸ“Š Stream Performance Breakdown:
   Stream 1: 3 sessions in 2052ms (863.1 tokens/sec)
   Stream 2: 3 sessions in 2340ms (864.1 tokens/sec)
[ConflictResolutionService] Starting conflict resolution for 10 sessions
[ConflictResolutionService] Found classifications: { intents: 2, reasons: 1, locations: 1 }
[ConflictResolutionService] No conflicts detected, skipping resolution
[ParallelAutoAnalyzeService] Using real analysis summary service
[ParallelAutoAnalyzeService] Parallel analysis 3913454c-67c8-4323-8ea6-8130bec8e988 completed successfully
[BackgroundJobQueue] Updated job progress to final state: complete
[BackgroundJobQueue] Parallel analysis job 3913454c-67c8-4323-8ea6-8130bec8e988-parallel completed successfully
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T16:19:22.872Z",
  "dateTo": "2025-08-12T16:20:22.872Z",
  "skip": 0,
  "limit": 1
}
[fetchContainmentTypeMetadata] API Response: 1 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [ '689b698d04e17fb1eb5153b1' ]
[getSessionsMetadataForConnectionTest] Single API call succeeded with 1 sessions
::1 - - [12/Aug/2025:16:20:25 +0000] "GET /api/kore/test HTTP/1.1" 200 851 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[Direct API] Fetching real Kore.ai sessions from 2025-08-05T16:20:26.269Z to 2025-08-12T16:20:26.269Z for User Bot st-90549... (limit=50)
Retrieving sessions from 2025-08-05T16:20:26.269Z to 2025-08-12T16:20:26.269Z (limit=50), populateMessages=true...
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T16:20:26.269Z",
  "dateTo": "2025-08-12T16:20:26.269Z",
  "limit": 50
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T16:20:26.269Z",
  "dateTo": "2025-08-12T16:20:26.269Z",
  "skip": 0,
  "limit": 50
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T16:20:26.269Z",
  "dateTo": "2025-08-12T16:20:26.269Z",
  "skip": 0,
  "limit": 50
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T16:20:26.269Z",
  "dateTo": "2025-08-12T16:20:26.269Z",
  "skip": 0,
  "limit": 50
}
::1 - - [12/Aug/2025:16:20:27 +0000] "GET /api/analysis/sessions?limit=50 HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 50 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b698d04e17fb1eb5153b1',
  '689b69889516e359d07b585f',
  '689b6981995362de8def2385'
]
[fetchContainmentTypeMetadata] API Response: 50 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b69c63d161a6761544a8d',
  '689b69bbb95843b790187ad5',
  '689b69b5695380b63c46ee3b'
]
[fetchContainmentTypeMetadata] API Response: 50 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b64c69fa3aff653c80423',
  '689b64449516e359d07aa002',
  '689b643eb1f082150b5210a9'
]
[getSessionsMetadata] agent API call succeeded with 50 sessions
[getSessionsMetadata] selfService API call succeeded with 50 sessions
[getSessionsMetadata] dropOff API call succeeded with 50 sessions
Total session metadata retrieved: 150 (parallel execution)
Retrieved 150 session metadata objects
Creating 150 SWTs from metadata (no messages)
Created 150 SWT objects from metadata
Populating messages for all sessions (legacy behavior)
Populating messages for 150 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 150 sessions from 2025-08-12T15:07:33.238Z to 2025-08-12T16:20:24.680Z at 2025-08-12T16:20:29.195Z
ğŸš€ [ConcurrentBatch] Split 150 sessions into 8 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/8] Starting: 20 sessions
[Batch 2/8] Starting: 20 sessions
[Batch 3/8] Starting: 20 sessions
[Batch 4/8] Starting: 20 sessions
[Batch 5/8] Starting: 20 sessions
[Batch 6/8] Starting: 20 sessions
[Batch 7/8] Starting: 20 sessions
[Batch 8/8] Starting: 10 sessions
[Batch 3/8] Completed in 206ms: 196 messages retrieved (1/8 done)
[Batch 1/8] Completed in 287ms: 264 messages retrieved (2/8 done)
[Batch 2/8] Completed in 296ms: 222 messages retrieved (3/8 done)
[Batch 6/8] Completed in 412ms: 216 messages retrieved (4/8 done)
[Batch 7/8] Completed in 438ms: 198 messages retrieved (5/8 done)
[Batch 8/8] Completed in 494ms: 144 messages retrieved (6/8 done)
[Batch 5/8] Completed in 654ms: 429 messages retrieved (7/8 done)
[Batch 4/8] Completed in 772ms: 321 messages retrieved (8/8 done)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 772ms (0.77s)
â±ï¸  Batch Processing: 772ms (0.77s)
ğŸ“¦ Total batches: 8 (max 10 concurrent)
âœ… Successful batches: 8/8
ğŸ’¬ Total messages: 1990
ğŸ“ˆ Avg time per batch: 97ms
ğŸš€ Time per session: 5ms
ğŸ’ª Performance: 194.3 sessions/second
=======================================================

Retrieved 1990 messages for 150 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
Populated messages for 150 SWT objects
Generated 150 SWT objects in 3710ms using layered architecture
ğŸš€ [ParallelAutoAnalyzeRoute] Starting parallel analysis for bot ***REMOVED*** with real credentials
ğŸš€ [ParallelAutoAnalyzeService] Starting parallel analysis 50e2b675-3b20-4f9f-9609-ba284c1cdb17 with bot ***REMOVED***
ğŸš€ [ParallelAutoAnalyzeService] Using credentials: real
ğŸš€ [ParallelAutoAnalyzeRoute] Parallel analysis started: 50e2b675-3b20-4f9f-9609-ba284c1cdb17
::1 - - [12/Aug/2025:16:20:45 +0000] "POST /api/analysis/auto-analyze/parallel/start HTTP/1.1" 200 214 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:20:45 +0000] "GET /api/analysis/auto-analyze/parallel/progress/50e2b675-3b20-4f9f-9609-ba284c1cdb17 HTTP/1.1" 200 542 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:20:45 +0000] "GET /api/analysis/auto-analyze/parallel/progress/50e2b675-3b20-4f9f-9609-ba284c1cdb17 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[BackgroundJobQueue] Starting job processing after delay for job 50e2b675-3b20-4f9f-9609-ba284c1cdb17-parallel
[BackgroundJobQueue] Starting processing for job 50e2b675-3b20-4f9f-9609-ba284c1cdb17-parallel, phase: sampling
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing parallel analysis job 50e2b675-3b20-4f9f-9609-ba284c1cdb17-parallel
[BackgroundJobQueue] Processing parallel analysis for bot ***REMOVED***
[BackgroundJobQueue] Using existing ParallelAutoAnalyzeService instance for bot ***REMOVED***
[BackgroundJobQueue] Session recreated for 50e2b675-3b20-4f9f-9609-ba284c1cdb17
[ParallelAutoAnalyzeService] Running parallel analysis for 50e2b675-3b20-4f9f-9609-ba284c1cdb17
[ParallelAutoAnalyzeService] Phase 0: Starting session sampling for 50e2b675-3b20-4f9f-9609-ba284c1cdb17

ğŸ• ============ SESSION SAMPLING STARTED ============
ğŸ• [SessionSampling] Starting session sampling at 2025-08-12T16:20:46.287Z
ğŸ” [SessionDiscovery] Starting window 1/4: Initial 3-hour window
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
::1 - - [12/Aug/2025:16:20:47 +0000] "GET /api/analysis/auto-analyze/parallel/progress/50e2b675-3b20-4f9f-9609-ba284c1cdb17 HTTP/1.1" 200 715 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 80 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a1287849680ad9fe59e',
  '689229f9583056c6108e38fb',
  '68922914f8bee7ba6c3e67b8'
]
[fetchContainmentTypeMetadata] API Response: 139 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6a14dd27c3112087cd',
  '68922a22ef03d8ad2ec7b4ba',
  '68922a1278c1fe09a079719c'
]
::1 - - [12/Aug/2025:16:20:49 +0000] "GET /api/analysis/auto-analyze/parallel/progress/50e2b675-3b20-4f9f-9609-ba284c1cdb17 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 1338 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6d14dd27c31120888b',
  '68922a62e3804084741191d5',
  '68922a523a3160d25de144c8'
]
[getSessionsMetadata] agent API call succeeded with 1338 sessions
[getSessionsMetadata] selfService API call succeeded with 80 sessions
[getSessionsMetadata] dropOff API call succeeded with 139 sessions
Total session metadata retrieved: 1557 (parallel execution)
Creating 1557 SWTs from metadata (no messages)
Created 1557 SWT objects from metadata
âœ… [SessionDiscovery] Window 1 completed in 4546ms: found 1557 new sessions (total: 1557)
â±ï¸  TIMING: Window 1 took 4546ms (4.55s)
ğŸ¯ [SessionDiscovery] Target reached! Found 1557 sessions in 4546ms
ğŸ² [SessionSampling] Random sampling from 1557 sessions to 100 sessions

ğŸ“¬ ============ MESSAGE RETRIEVAL STARTED ============
ğŸ“¬ [MessageRetrieval] Starting message retrieval for 100 sampled sessions at 2025-08-12T16:20:50.834Z
Using new lazy loading approach to populate messages for 100 sampled sessions
Populating messages for 100 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 100 sessions from 2025-08-05T13:00:21.370Z to 2025-08-05T15:57:30.784Z at 2025-08-12T16:20:50.834Z
ğŸš€ [ConcurrentBatch] Split 100 sessions into 5 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/5] Starting: 20 sessions
[Batch 2/5] Starting: 20 sessions
[Batch 3/5] Starting: 20 sessions
[Batch 4/5] Starting: 20 sessions
[Batch 5/5] Starting: 20 sessions
[Batch 2/5] Completed in 366ms: 228 messages retrieved (1/5 done)
ğŸ“Š [BatchProgress] Reporting batch 1/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 40/100 sessions (Batch 2/5)
[Batch 1/5] Completed in 396ms: 214 messages retrieved (2/5 done)
ğŸ“Š [BatchProgress] Reporting batch 2/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 60/100 sessions (Batch 3/5)
[Batch 3/5] Completed in 450ms: 277 messages retrieved (3/5 done)
ğŸ“Š [BatchProgress] Reporting batch 3/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 80/100 sessions (Batch 4/5)
::1 - - [12/Aug/2025:16:20:51 +0000] "GET /api/analysis/auto-analyze/parallel/progress/50e2b675-3b20-4f9f-9609-ba284c1cdb17 HTTP/1.1" 200 815 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[Batch 4/5] Completed in 530ms: 221 messages retrieved (4/5 done)
ğŸ“Š [BatchProgress] Reporting batch 4/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 100/100 sessions (Batch 5/5)
[Batch 5/5] Completed in 613ms: 258 messages retrieved (5/5 done)
ğŸ“Š [BatchProgress] Reporting batch 5/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 100/100 sessions (Batch 6/5)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 613ms (0.61s)
â±ï¸  Batch Processing: 613ms (0.61s)
ğŸ“¦ Total batches: 5 (max 10 concurrent)
âœ… Successful batches: 5/5
ğŸ’¬ Total messages: 1198
ğŸ“ˆ Avg time per batch: 123ms
ğŸš€ Time per session: 6ms
ğŸ’ª Performance: 163.1 sessions/second
=======================================================

Retrieved 1198 messages for 100 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "<speak><prosody rate="-20%"></prosody></speak>
" (bot)
ğŸ§¼ SWTService: Filtered out message: "<speak><prosody rate="-20%"></prosody></speak>
" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
Populated messages for 100 SWT objects
Successfully populated messages for 100 sessions using lazy loading
Applying final filtering to 100 sessions with populated messages
Final result: 98 sessions passed filtering with populated messages

ğŸ‰ ============ SESSION SAMPLING COMPLETED ============
â±ï¸  TOTAL TIME: 5167ms (5.17s)
â±ï¸  Session Discovery: 4546ms (4.55s) - 88.0% of total
â±ï¸  Message Retrieval: 620ms (0.62s) - 12.0% of total
â±ï¸  Performance: 19.0 sessions/second
ğŸ¯ Final result: 98 sessions with messages retrieved
====================================================

[StrategicDiscoveryService] Starting discovery phase with 98 total sessions
[StrategicDiscoveryService] Discovery config: {
  targetPercentage: 15,
  minSessions: 9,
  maxSessions: 14,
  diversityStrategy: {
    sessionLengths: [ 'short', 'medium', 'long' ],
    containmentTypes: [ 'agent', 'selfService', 'dropOff' ],
    timeDistribution: 'spread'
  }
}
[StrategicDiscoveryService] Selecting 14 diverse sessions from 98 total
[StrategicDiscoveryService] Session diversity groups: { short: 24, medium: 74, early: 32, middle: 32, late: 34 }
[StrategicDiscoveryService] Selected sessions by length distribution: { short: 4, medium: 10, long: 0 }
[StrategicDiscoveryService] Selected 14 sessions for discovery

ğŸ“¦ ===== BATCH 8 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:20:51.455Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 0
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:20:51.455Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:20:51.455Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6714,
  existingClassifications: { intents: 0, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.



For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and another intent, classify the intent as the other i...
::1 - - [12/Aug/2025:16:20:53 +0000] "GET /api/analysis/auto-analyze/parallel/progress/50e2b675-3b20-4f9f-9609-ba284c1cdb17 HTTP/1.1" 200 921 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:20:54.081Z',
  duration: '2626ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1934,
    completion_tokens: 370,
    total_tokens: 2304,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Unknown' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-27f79c5f-bd80-5bc6-bd26-75b99734b16b",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with a representative, session transferred to live agent."
    },
    {
      "user_id": "u-814c0b21-be9d-5731-8ca1-f3f8eddef7cf",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with a representative, session transferred to live agent."
    },
    {
      "user_id": "u-18c41c8d-d820-5ec9-aa61-42518ff12695",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to update an SLA leave, session transferred to live agent."
    },
    {
      "user_id": "u-f422c254-18d9-56bf-bd30-1dc329091c59",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to request a medical leave, session transferred to live agent."
    },
    {
      "user_id": "u-3b4b1bcb-2ae5-5f9b-8b87-5a02617afa03",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to be absent for three days, session transferred to live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1934,
  completionTokens: 370,
  totalTokens: 2304,
  cost: '$0.000341',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2626ms (2.63s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2304 ($0.0003)
âš¡ Performance: 877.4 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2626ms (2.63s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2304

âœ… ===== BATCH 8 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2627ms (2.63s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2304 ($0.0003)
âš¡ Performance: 1.9 sessions/sec
âš¡ Avg Time Per Session: 525.40ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 1 complete: 3 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 1, reasons: 1, locations: 1, total: 3 }

ğŸ“¦ ===== BATCH 9 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:20:54.082Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 1
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:20:54.082Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:20:54.082Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7089,
  existingClassifications: { intents: 1, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provid...
::1 - - [12/Aug/2025:16:20:55 +0000] "GET /api/analysis/auto-analyze/parallel/progress/50e2b675-3b20-4f9f-9609-ba284c1cdb17 HTTP/1.1" 200 939 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:20:56.487Z',
  duration: '2405ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2035,
    completion_tokens: 362,
    total_tokens: 2397,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Unknown', 'Report new leave', 'Report time' ],
  transferCount: 3,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-f3c64b0b-7170-57cc-8bde-c34b9f23cfce",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and did not respond, leading to transfer to a live agent."
    },
    {
      "user_id": "u-d7c8ac85-9565-521f-bf5e-03b91b7855ce",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent, resulting in transfer."
    },
    {
      "user_id": "u-d95e2dad-08f5-5f1f-931a-3d57fdb5494c",
      "general_intent": "Report new leave",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User attempted to report a new leave and encountered issues, session was not transferred."
    },
    {
      "user_id": "u-ed3e45c9-7f49-5dbd-925d-836547cac3bd",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a representative, leading to transfer."
    },
    {
      "user_id": "u-45d4e4e2-23d8-5c36-b487-1a8c3c0efb02",
      "general_intent": "Report time",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User tried to report time but lacked necessary info, session was not transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2035,
  completionTokens: 362,
  totalTokens: 2397,
  cost: '$0.000348',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2405ms (2.40s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2397 ($0.0003)
âš¡ Performance: 996.7 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2406ms (2.41s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2397

âœ… ===== BATCH 9 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2406ms (2.41s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2397 ($0.0003)
âš¡ Performance: 2.1 sessions/sec
âš¡ Avg Time Per Session: 481.20ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 2 complete: 2 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 3, reasons: 1, locations: 1, total: 5 }

ğŸ“¦ ===== BATCH 10 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:20:56.488Z
ğŸ“Š Sessions in Batch: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 4
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:20:56.488Z
ğŸ“Š Sessions to Analyze: 4

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:20:56.488Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6087,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Report new leave, Report time, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Elig...
::1 - - [12/Aug/2025:16:20:57 +0000] "GET /api/analysis/auto-analyze/parallel/progress/50e2b675-3b20-4f9f-9609-ba284c1cdb17 HTTP/1.1" 200 939 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:20:58.352Z',
  duration: '1863ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1751,
    completion_tokens: 239,
    total_tokens: 1990,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown', 'Leave Request' ],
  transferCount: 1,
  containedCount: 3
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-c54ac274-bf09-54b0-9e14-b3937c9d60df",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User was silent and session was closed without interaction."
    },
    {
      "user_id": "u-583c7f73-871c-58a0-a8c6-c5d8f2647356",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User did not provide input; session was closed."
    },
    {
      "user_id": "u-5f135adb-065b-59bf-bc7d-4afa34e20c42",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to open a leave request; session was transferred to a live agent."
    },
    {
      "user_id": "u-679899c2-4146-5a48-9bbd-a7065c494323",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User did not respond; session was closed."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1751,
  completionTokens: 239,
  totalTokens: 1990,
  cost: '$0.000271',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 1864ms (1.86s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1990 ($0.0003)
âš¡ Performance: 1067.6 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 1ms
ğŸ“Š Final Session Results: 4
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 1865ms (1.86s)
ğŸ“Š Regular Sessions Processed: 4
ğŸ’° Regular Tokens Used: 1990

âœ… ===== BATCH 10 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 1865ms (1.86s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Total Tokens: 1990 ($0.0003)
âš¡ Performance: 2.1 sessions/sec
âš¡ Avg Time Per Session: 466.25ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 3 complete: 1 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 4, reasons: 1, locations: 1, total: 6 }
[StrategicDiscoveryService] Discovery phase complete: {
  totalProcessed: 14,
  uniqueIntents: 4,
  uniqueReasons: 1,
  uniqueLocations: 1,
  discoveryRate: 0.4
}

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T16:20:58.353Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms
[ParallelProcessingOrchestrator] Configuration for 84 sessions:
  Design: 8 streams Ã— 4 sessions = 32 per round
  Optimal: 8 streams Ã— 4 sessions = 32 per round
  Estimated Rounds: 3
[ParallelAutoAnalyzeService] Using parallel config: {
  streamCount: 8,
  sessionsPerStream: 4,
  maxSessionsPerLLMCall: 50,
  syncFrequency: 'after_each_round',
  retryAttempts: 3,
  debugLogging: false
}

ğŸš€ ============ PARALLEL PROCESSING STARTED ============
â±ï¸  Start Time: 2025-08-12T16:20:58.354Z
ğŸ“Š Total Sessions: 84

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T16:20:58.354Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms

âš™ï¸  ============ PARALLEL CONFIGURATION ============
â±ï¸  Config Time: 0ms
ğŸ”§ Stream Count: 8
ğŸ“¦ Sessions Per Stream: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per API Call: 50
ğŸ¯ Debug Logging: false

ğŸ”„ ============ ROUND 1/3 STARTED ============
â±ï¸  Round 1 Start: 2025-08-12T16:20:58.354Z
ğŸ“Š Sessions Remaining: 84
[ParallelProcessingOrchestrator] Distributed 32 sessions across 8 streams: [
  'Stream 1: 4 sessions',
  'Stream 2: 4 sessions',
  'Stream 3: 4 sessions',
  'Stream 4: 4 sessions',
  'Stream 5: 4 sessions',
  'Stream 6: 4 sessions',
  'Stream 7: 4 sessions',
  'Stream 8: 4 sessions'
]
â±ï¸  Session Distribution Time: 1ms
ğŸŒŠ Active Streams: 8

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 8 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T16:20:58.355Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:20:58.355Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 696
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6196
   â€¢ Avg Per Session: 174 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6196
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6196
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:20:58.355Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:20:58.355Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5903,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Leave Request, Report new leave, Report time, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T16:20:58.355Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:20:58.355Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 717
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6217
   â€¢ Avg Per Session: 179 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6217
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6217
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:20:58.356Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:20:58.356Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6017,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Leave Request, Report new leave, Report time, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T16:20:58.356Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:20:58.356Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 958
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6458
   â€¢ Avg Per Session: 240 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6458
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6458
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:20:58.356Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:20:58.356Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7174,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Leave Request, Report new leave, Report time, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T16:20:58.356Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:20:58.356Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 628
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6128
   â€¢ Avg Per Session: 157 tokens
   â€¢ Estimation Time: 1ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6128
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 1ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6128
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:20:58.357Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:20:58.357Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5639,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Leave Request, Report new leave, Report time, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "...

ğŸŒŠ ===== STREAM 5 PROCESSING START =====
â±ï¸  Stream 5 Start: 2025-08-12T16:20:58.357Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:20:58.357Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 889
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6389
   â€¢ Avg Per Session: 222 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6389
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 5) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6389
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 5: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:20:58.357Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:20:58.357Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6844,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Leave Request, Report new leave, Report time, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "...

ğŸŒŠ ===== STREAM 6 PROCESSING START =====
â±ï¸  Stream 6 Start: 2025-08-12T16:20:58.357Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:20:58.357Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 766
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6266
   â€¢ Avg Per Session: 192 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6266
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 6) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6266
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 6: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:20:58.358Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:20:58.358Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6295,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Leave Request, Report new leave, Report time, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "...

ğŸŒŠ ===== STREAM 7 PROCESSING START =====
â±ï¸  Stream 7 Start: 2025-08-12T16:20:58.358Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:20:58.358Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 751
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6251
   â€¢ Avg Per Session: 188 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6251
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 7) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6251
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 7: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:20:58.358Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:20:58.358Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6162,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Leave Request, Report new leave, Report time, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "...

ğŸŒŠ ===== STREAM 8 PROCESSING START =====
â±ï¸  Stream 8 Start: 2025-08-12T16:20:58.358Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:20:58.358Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 689
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6189
   â€¢ Avg Per Session: 172 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6189
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 8) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6189
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 8: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:20:58.358Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:20:58.358Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5918,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Leave Request, Report new leave, Report time, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "...
::1 - - [12/Aug/2025:16:20:59 +0000] "GET /api/analysis/auto-analyze/parallel/progress/50e2b675-3b20-4f9f-9609-ba284c1cdb17 HTTP/1.1" 200 1702 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:21:00.212Z',
  duration: '1856ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2022,
    completion_tokens: 197,
    total_tokens: 2219,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-f487a17e-9e55-5d05-829d-0e6a25f8feab",
      "notes": "User provided leave request details and successfully submitted a time entry, session ended without transfer."
    },
    {
      "user_id": "u-95240753-180a-5885-9758-2df7f668dcec",
      "notes": "User requested to speak with an agent, session transferred to live agent."
    },
    {
      "user_id": "u-1da68389-6b58-5f96-99b0-f293cdb6d560",
      "notes": "User attempted to report time but was transferred to customer service due to issue with leave request status."
    },
    {
      "user_id": "u-b55f88d0-ad9e-551e-87d8-d33d98e2e36c",
      "notes": "User requested to speak with an agent, session transferred to live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2022,
  completionTokens: 197,
  totalTokens: 2219,
  cost: '$0.000281',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1857ms (1.86s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2219 ($0.0003)
âš¡ Performance: 1194.9 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2022
   â€¢ Completion Tokens: 197
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-f487a17e-9e55-5d05-829d-0e6a25f8feab: Invalid general_intent, u-f487a17e-9e55-5d05-829d-0e6a25f8feab: Invalid session_outcome, u-95240753-180a-5885-9758-2df7f668dcec: Invalid general_intent, u-95240753-180a-5885-9758-2df7f668dcec: Invalid session_outcome, u-1da68389-6b58-5f96-99b0-f293cdb6d560: Invalid general_intent, u-1da68389-6b58-5f96-99b0-f293cdb6d560: Invalid session_outcome, u-b55f88d0-ad9e-551e-87d8-d33d98e2e36c: Invalid general_intent, u-b55f88d0-ad9e-551e-87d8-d33d98e2e36c: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 3 Single Batch Time: 1858ms (1.86s)

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 1858ms (1.86s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2219 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.2 sessions/sec
âš¡ Avg Time Per Session: 464.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:21:00.317Z',
  duration: '1960ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1935,
    completion_tokens: 241,
    total_tokens: 2176,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Customer Service', 'Check time', 'Operator', 'Claim status' ],
  transferCount: 2,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-890a85a0-ba52-5e31-8337-385a42ab386e",
      "general_intent": "Customer Service",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-be6907b2-ff40-55dc-9a97-8fd80421407b",
      "general_intent": "Check time",
      "session_outcome": "Contained",
      "notes": "User successfully submitted a time entry after providing leave request number, zip code, date, hours, and reason."
    },
    {
      "user_id": "u-ef1d57b2-d6e6-54e0-a3d1-e496a21654f4",
      "general_intent": "Operator",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-ae2bdaaf-b0fd-53da-85db-2f393ef68805",
      "general_intent": "Claim status",
      "session_outcome": "Contained",
      "notes": "User provided leave request number, zip code, and received leave request status."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1935,
  completionTokens: 241,
  totalTokens: 2176,
  cost: '$0.000290',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1961ms (1.96s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2176 ($0.0003)
âš¡ Performance: 1109.6 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1935
   â€¢ Completion Tokens: 241
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-890a85a0-ba52-5e31-8337-385a42ab386e: Invalid notes, u-ef1d57b2-d6e6-54e0-a3d1-e496a21654f4: Invalid notes'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 5 Single Batch Time: 1961ms (1.96s)
[StreamProcessingService] Discovered 4 new classifications: { intents: 4, reasons: 0, locations: 0 }

âœ… ===== STREAM 5 PROCESSING COMPLETE =====
â±ï¸  Stream 5 Total Time: 1962ms (1.96s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2176 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.0 sessions/sec
âš¡ Avg Time Per Session: 490.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:21:00.570Z',
  duration: '2212ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1703,
    completion_tokens: 283,
    total_tokens: 1986,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Leave Request', 'Report new leave', 'Report time' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-ae901242-6161-5e12-9bd4-30db720ad814",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with a representative and was transferred to an agent."
    },
    {
      "user_id": "u-443b963d-fee6-5afa-a24e-dd4109cc89ba",
      "general_intent": "Report new leave",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to take a leave and was transferred to an agent."
    },
    {
      "user_id": "u-e09ab0c2-b331-5df2-87e8-2c81d65c8fb5",
      "general_intent": "Report time",
      "session_outcome": "Contained",
      "notes": "User inquired about extension of FMLA leave but did not complete the process."
    },
    {
      "user_id": "u-90fdae86-db8a-5c5a-8da2-50afff7a00e4",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1703,
  completionTokens: 283,
  totalTokens: 1986,
  cost: '$0.000284',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2212ms (2.21s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1986 ($0.0003)
âš¡ Performance: 897.8 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1703
   â€¢ Completion Tokens: 283
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 8 Single Batch Time: 2213ms (2.21s)

âœ… ===== STREAM 8 PROCESSING COMPLETE =====
â±ï¸  Stream 8 Total Time: 2213ms (2.21s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1986 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.8 sessions/sec
âš¡ Avg Time Per Session: 553.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:21:00.671Z',
  duration: '2316ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1682,
    completion_tokens: 296,
    total_tokens: 1978,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Leave Request' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-09dbf4ee-1d7b-5d36-8af8-bd806e99f551",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak to someone in absent management and was transferred to an agent."
    },
    {
      "user_id": "u-bc766dae-8806-5700-abe0-287636671691",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred to an agent."
    },
    {
      "user_id": "u-5c928ed7-7d61-55e5-aef5-5be592f2d7a4",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative in Spanish and was transferred to an agent."
    },
    {
      "user_id": "u-bd119e77-c6c7-51ab-9c96-3e442946edc5",
      "general_intent": "Leave Request",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User did not provide any input and session was closed by the bot."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1682,
  completionTokens: 296,
  totalTokens: 1978,
  cost: '$0.000287',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2316ms (2.32s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1978 ($0.0003)
âš¡ Performance: 854.1 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1682
   â€¢ Completion Tokens: 296
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 1 Single Batch Time: 2316ms (2.32s)

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 2316ms (2.32s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1978 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.7 sessions/sec
âš¡ Avg Time Per Session: 579.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:21:00.686Z',
  duration: '2328ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1809,
    completion_tokens: 301,
    total_tokens: 2110,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-4f56f3d7-6876-5dbf-8784-c77a59680500",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to change FMLA details but was transferred to an agent after failed record matching."
    },
    {
      "user_id": "u-6d2aa459-5524-5dda-ad1a-8508029f3688",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested agent, but no further input was received before transfer."
    },
    {
      "user_id": "u-06b553ed-51f4-5a8c-83e6-a3dbce521c86",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent, session transferred after no further input."
    },
    {
      "user_id": "u-c820d38a-6ba7-5469-9a4a-66272e867d88",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User indicated desire for a representative, session transferred after no further input."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1809,
  completionTokens: 301,
  totalTokens: 2110,
  cost: '$0.000301',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2328ms (2.33s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2110 ($0.0003)
âš¡ Performance: 906.4 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1809
   â€¢ Completion Tokens: 301
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 6 Single Batch Time: 2329ms (2.33s)

âœ… ===== STREAM 6 PROCESSING COMPLETE =====
â±ï¸  Stream 6 Total Time: 2330ms (2.33s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2110 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.7 sessions/sec
âš¡ Avg Time Per Session: 582.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:21:00.769Z',
  duration: '2412ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1636,
    completion_tokens: 296,
    total_tokens: 1932,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Leave Request', 'Unknown' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-add9bd3a-bad8-5dba-9eb4-b51a590bc803",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was calling about FMLA and was transferred to a live agent for a new leave request."
    },
    {
      "user_id": "u-695d0850-5820-5472-aaad-3c331b0c2dc9",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak to a representative about leave, and was transferred to an agent."
    },
    {
      "user_id": "u-be84e5ec-7cfa-5ef0-87b4-1d82ae62db35",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "Session ended without user input, no transfer occurred."
    },
    {
      "user_id": "u-937af4f5-a2c0-55da-ba54-cf3b10fbd668",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with a representative about leave and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1636,
  completionTokens: 296,
  totalTokens: 1932,
  cost: '$0.000282',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2412ms (2.41s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1932 ($0.0003)
âš¡ Performance: 801.0 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1636
   â€¢ Completion Tokens: 296
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 4 Single Batch Time: 2413ms (2.41s)

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 2414ms (2.41s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1932 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.7 sessions/sec
âš¡ Avg Time Per Session: 603.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:21:00.970Z',
  duration: '2612ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1752,
    completion_tokens: 299,
    total_tokens: 2051,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-c01ac970-eda7-5053-8d9e-973e7818c4c2",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an operator but did not specify a reason, and the session was transferred to an agent."
    },
    {
      "user_id": "u-af051590-5163-501f-8dee-cd86a2b93a51",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a person, leading to transfer to an agent."
    },
    {
      "user_id": "u-595d45f6-736b-5660-a69f-022aab6a7650",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User said 'Customer service', resulting in transfer to an agent."
    },
    {
      "user_id": "u-96618d9f-871d-5b97-aa75-a0b14ffa7026",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User simply said 'Agent', leading to transfer to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1752,
  completionTokens: 299,
  totalTokens: 2051,
  cost: '$0.000295',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2612ms (2.61s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2051 ($0.0003)
âš¡ Performance: 785.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1752
   â€¢ Completion Tokens: 299
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 7 Single Batch Time: 2612ms (2.61s)

âœ… ===== STREAM 7 PROCESSING COMPLETE =====
â±ï¸  Stream 7 Total Time: 2612ms (2.61s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2051 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.5 sessions/sec
âš¡ Avg Time Per Session: 653.00ms
::1 - - [12/Aug/2025:16:21:01 +0000] "GET /api/analysis/auto-analyze/parallel/progress/50e2b675-3b20-4f9f-9609-ba284c1cdb17 HTTP/1.1" 200 1716 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:21:02.076Z',
  duration: '3720ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1720,
    completion_tokens: 287,
    total_tokens: 2007,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-4a336580-e5bd-551a-aaec-2606589cc831",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-9cb316de-3773-59c4-9d13-20d7d0ea0f2c",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-69880613-bf26-562f-93a9-60671a6a1dd4",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-f9e44c90-29a4-5f40-bb5b-d33a7cef6027",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1720,
  completionTokens: 287,
  totalTokens: 2007,
  cost: '$0.000287',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 3721ms (3.72s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2007 ($0.0003)
âš¡ Performance: 539.4 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1720
   â€¢ Completion Tokens: 287
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 2 Single Batch Time: 3721ms (3.72s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 3722ms (3.72s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2007 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.1 sessions/sec
âš¡ Avg Time Per Session: 930.50ms
[ParallelProcessingOrchestrator] Parallel processing complete: 8/8 streams succeeded
â±ï¸  Parallel Processing Time: 3722ms (3.72s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 8 streams
[ParallelProcessingOrchestrator] Synchronization complete: 5 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 5
ğŸ“Š Total Classifications: 11

âœ… ============ ROUND 1 COMPLETED ============
â±ï¸  Round 1 Total Time: 3724ms (3.72s)
â±ï¸  Session Cleanup Time: 1ms
ğŸ“Š Sessions Remaining: 52
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 1ms (0.0%)
   â€¢ Parallel Processing: 3722ms (99.9%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 1ms (0.0%)

ğŸ”„ ============ ROUND 2/3 STARTED ============
â±ï¸  Round 2 Start: 2025-08-12T16:21:02.078Z
ğŸ“Š Sessions Remaining: 52
[ParallelProcessingOrchestrator] Distributed 32 sessions across 8 streams: [
  'Stream 1: 4 sessions',
  'Stream 2: 4 sessions',
  'Stream 3: 4 sessions',
  'Stream 4: 4 sessions',
  'Stream 5: 4 sessions',
  'Stream 6: 4 sessions',
  'Stream 7: 4 sessions',
  'Stream 8: 4 sessions'
]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 8

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 8 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T16:21:02.078Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:21:02.078Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 777
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6277
   â€¢ Avg Per Session: 194 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6277
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6277
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:21:02.078Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 9
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:21:02.078Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6396,
  existingClassifications: { intents: 9, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Check time, Claim status, Customer Service, Leave Request, Live Agent, Operator, Report new leave, Report time, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to ...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T16:21:02.079Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:21:02.079Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 1270
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6770
   â€¢ Avg Per Session: 318 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6770
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0011
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6770
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0011

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:21:02.079Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 9
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:21:02.079Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 8607,
  existingClassifications: { intents: 9, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Check time, Claim status, Customer Service, Leave Request, Live Agent, Operator, Report new leave, Report time, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to ...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T16:21:02.079Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:21:02.079Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 796
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6296
   â€¢ Avg Per Session: 199 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6296
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6296
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:21:02.079Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 9
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:21:02.080Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6590,
  existingClassifications: { intents: 9, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Check time, Claim status, Customer Service, Leave Request, Live Agent, Operator, Report new leave, Report time, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to ...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T16:21:02.080Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:21:02.080Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 655
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6155
   â€¢ Avg Per Session: 164 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6155
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6155
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:21:02.080Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 9
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:21:02.080Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5800,
  existingClassifications: { intents: 9, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Check time, Claim status, Customer Service, Leave Request, Live Agent, Operator, Report new leave, Report time, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to ...

ğŸŒŠ ===== STREAM 5 PROCESSING START =====
â±ï¸  Stream 5 Start: 2025-08-12T16:21:02.080Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:21:02.080Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 703
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6203
   â€¢ Avg Per Session: 176 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6203
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 5) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6203
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 5: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:21:02.080Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 9
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:21:02.080Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6033,
  existingClassifications: { intents: 9, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Check time, Claim status, Customer Service, Leave Request, Live Agent, Operator, Report new leave, Report time, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to ...

ğŸŒŠ ===== STREAM 6 PROCESSING START =====
â±ï¸  Stream 6 Start: 2025-08-12T16:21:02.081Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:21:02.081Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 714
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6214
   â€¢ Avg Per Session: 179 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6214
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 6) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6214
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 6: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:21:02.081Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 9
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:21:02.081Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6114,
  existingClassifications: { intents: 9, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Check time, Claim status, Customer Service, Leave Request, Live Agent, Operator, Report new leave, Report time, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to ...

ğŸŒŠ ===== STREAM 7 PROCESSING START =====
â±ï¸  Stream 7 Start: 2025-08-12T16:21:02.081Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:21:02.081Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 660
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6160
   â€¢ Avg Per Session: 165 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6160
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 7) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6160
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 7: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:21:02.081Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 9
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:21:02.081Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5854,
  existingClassifications: { intents: 9, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Check time, Claim status, Customer Service, Leave Request, Live Agent, Operator, Report new leave, Report time, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to ...

ğŸŒŠ ===== STREAM 8 PROCESSING START =====
â±ï¸  Stream 8 Start: 2025-08-12T16:21:02.081Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:21:02.081Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 905
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6405
   â€¢ Avg Per Session: 226 tokens
   â€¢ Estimation Time: 1ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6405
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 1ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 8) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6405
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 8: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:21:02.082Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 9
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:21:02.082Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6961,
  existingClassifications: { intents: 9, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Check time, Claim status, Customer Service, Leave Request, Live Agent, Operator, Report new leave, Report time, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to ...
::1 - - [12/Aug/2025:16:21:03 +0000] "GET /api/analysis/auto-analyze/parallel/progress/50e2b675-3b20-4f9f-9609-ba284c1cdb17 HTTP/1.1" 200 1702 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:21:03.960Z',
  duration: '1881ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2377,
    completion_tokens: 201,
    total_tokens: 2578,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-ab63427a-5402-51fa-87f1-0abf957e8c68",
      "notes": "User attempted to verify leave request and was transferred after multiple inputs without providing sufficient info."
    },
    {
      "user_id": "u-dffd0b5a-995b-5391-b69c-c4559a77db1f",
      "notes": "User requested to speak with an agent in Spanish; session was transferred to an agent."
    },
    {
      "user_id": "u-4afcdc47-ea22-5b55-8b0b-cb0a30779ddb",
      "notes": "User inquired about FMLA, attempted to request leave, but was transferred after no active request found."
    },
    {
      "user_id": "u-0da25c7f-d70d-5033-bfe9-8a31d6f12ac6",
      "notes": "User requested customer service; session was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2377,
  completionTokens: 201,
  totalTokens: 2578,
  cost: '$0.000318',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1881ms (1.88s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2578 ($0.0003)
âš¡ Performance: 1370.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2377
   â€¢ Completion Tokens: 201
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-ab63427a-5402-51fa-87f1-0abf957e8c68: Invalid general_intent, u-ab63427a-5402-51fa-87f1-0abf957e8c68: Invalid session_outcome, u-dffd0b5a-995b-5391-b69c-c4559a77db1f: Invalid general_intent, u-dffd0b5a-995b-5391-b69c-c4559a77db1f: Invalid session_outcome, u-4afcdc47-ea22-5b55-8b0b-cb0a30779ddb: Invalid general_intent, u-4afcdc47-ea22-5b55-8b0b-cb0a30779ddb: Invalid session_outcome, u-0da25c7f-d70d-5033-bfe9-8a31d6f12ac6: Invalid general_intent, u-0da25c7f-d70d-5033-bfe9-8a31d6f12ac6: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 2 Single Batch Time: 1882ms (1.88s)

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 1882ms (1.88s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2578 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.1 sessions/sec
âš¡ Avg Time Per Session: 470.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:21:03.982Z',
  duration: '1902ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1816,
    completion_tokens: 188,
    total_tokens: 2004,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-03910a6d-e22e-5a98-8d54-00a94bb46fa8",
      "notes": "User requested leave request information and was transferred to an agent for benefit deduction assistance."
    },
    {
      "user_id": "u-dc557f39-cdcc-56d8-a267-2f8015db4941",
      "notes": "User requested to speak with an operator and was transferred to an agent."
    },
    {
      "user_id": "u-ed3373a6-3b15-561a-a86c-b5ab0c2601e4",
      "notes": "User asked about estimated leave dates and was transferred to an agent for new leave requests."
    },
    {
      "user_id": "u-35ac4c19-9a73-5d58-b07a-189fcef05f10",
      "notes": "User requested operator and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1816,
  completionTokens: 188,
  totalTokens: 2004,
  cost: '$0.000257',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1904ms (1.90s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2004 ($0.0003)
âš¡ Performance: 1052.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1816
   â€¢ Completion Tokens: 188
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-03910a6d-e22e-5a98-8d54-00a94bb46fa8: Invalid general_intent, u-03910a6d-e22e-5a98-8d54-00a94bb46fa8: Invalid session_outcome, u-dc557f39-cdcc-56d8-a267-2f8015db4941: Invalid general_intent, u-dc557f39-cdcc-56d8-a267-2f8015db4941: Invalid session_outcome, u-ed3373a6-3b15-561a-a86c-b5ab0c2601e4: Invalid general_intent, u-ed3373a6-3b15-561a-a86c-b5ab0c2601e4: Invalid session_outcome, u-35ac4c19-9a73-5d58-b07a-189fcef05f10: Invalid general_intent, u-35ac4c19-9a73-5d58-b07a-189fcef05f10: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 1 Single Batch Time: 1904ms (1.90s)

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 1904ms (1.90s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2004 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.1 sessions/sec
âš¡ Avg Time Per Session: 476.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:21:04.494Z',
  duration: '2413ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1750,
    completion_tokens: 293,
    total_tokens: 2043,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Leave Request', 'Unknown', 'Customer Service' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-5b1caa0f-2eb8-54bd-94fe-e5fcda70d15a",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an operator and was transferred."
    },
    {
      "user_id": "u-fa0eb39e-a680-5b90-8cba-05dfce275c71",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent and was transferred."
    },
    {
      "user_id": "u-4ae9b8c5-e32d-5e70-8506-e5284ccb5cbb",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User repeatedly asked to speak to an operator, leading to transfer."
    },
    {
      "user_id": "u-7481b906-77e6-5567-87e4-a41ea5483043",
      "general_intent": "Customer Service",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked about FMLA certification and was transferred to a live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1750,
  completionTokens: 293,
  totalTokens: 2043,
  cost: '$0.000292',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2413ms (2.41s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2043 ($0.0003)
âš¡ Performance: 846.7 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1750
   â€¢ Completion Tokens: 293
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 6 Single Batch Time: 2413ms (2.41s)

âœ… ===== STREAM 6 PROCESSING COMPLETE =====
â±ï¸  Stream 6 Total Time: 2413ms (2.41s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2043 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.7 sessions/sec
âš¡ Avg Time Per Session: 603.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:21:04.589Z',
  duration: '2508ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1687,
    completion_tokens: 259,
    total_tokens: 1946,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown', 'Leave Request' ],
  transferCount: 2,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-b985c8aa-cd15-5b47-a74f-6b660623e703",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User was unclear about their request and did not request a transfer."
    },
    {
      "user_id": "u-a9fadc3c-cd79-5884-933b-935fffb2d26b",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an operator and was transferred to an agent."
    },
    {
      "user_id": "u-b60675b8-f2c1-5e6a-97fc-22245089cd18",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and was transferred to an agent after initial prompts."
    },
    {
      "user_id": "u-f7533efe-9431-568a-bd21-f17a3ebf8d66",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User requested a representative but did not proceed to a transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1687,
  completionTokens: 259,
  totalTokens: 1946,
  cost: '$0.000272',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2508ms (2.51s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1946 ($0.0003)
âš¡ Performance: 775.9 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1687
   â€¢ Completion Tokens: 259
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 7 Single Batch Time: 2509ms (2.51s)

âœ… ===== STREAM 7 PROCESSING COMPLETE =====
â±ï¸  Stream 7 Total Time: 2509ms (2.51s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1946 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.6 sessions/sec
âš¡ Avg Time Per Session: 627.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:21:04.616Z',
  duration: '2534ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1961,
    completion_tokens: 306,
    total_tokens: 2267,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Time Entry', 'Claim Status', 'Leave Request' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-89eaa7c7-8aa9-5eab-ad2e-ee14eb96c976",
      "general_intent": "Time Entry",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to access time entry and was transferred to a live agent after multiple input issues."
    },
    {
      "user_id": "u-5f17c02b-e486-52bb-af15-815d7fa7f584",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to start a new claim and was transferred to a live agent."
    },
    {
      "user_id": "u-3f925c9e-8b27-5db4-8a30-2568d6129af3",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User inquired about family leave and was transferred to a live agent."
    },
    {
      "user_id": "u-9f56081b-1b8a-530c-b851-314f1dac3c50",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked to speak to someone about leave request and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1961,
  completionTokens: 306,
  totalTokens: 2267,
  cost: '$0.000319',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2534ms (2.53s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2267 ($0.0003)
âš¡ Performance: 894.6 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1961
   â€¢ Completion Tokens: 306
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 8 Single Batch Time: 2534ms (2.53s)
[StreamProcessingService] Discovered 2 new classifications: { intents: 2, reasons: 0, locations: 0 }

âœ… ===== STREAM 8 PROCESSING COMPLETE =====
â±ï¸  Stream 8 Total Time: 2536ms (2.54s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2267 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.6 sessions/sec
âš¡ Avg Time Per Session: 634.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:21:04.797Z',
  duration: '2717ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1671,
    completion_tokens: 271,
    total_tokens: 1942,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown', 'Leave Request' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-1a63b7b9-358b-5043-9f7d-6ee26a68bef3",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "Session was closed without user input."
    },
    {
      "user_id": "u-49ab7048-cb90-5739-aa2a-4d9e9447f6bd",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-b1afd683-6d37-5a4c-92e1-70ea51ab11eb",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-38a82550-24aa-5dd9-a406-fbc91e9e31f2",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1671,
  completionTokens: 271,
  totalTokens: 1942,
  cost: '$0.000275',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2718ms (2.72s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1942 ($0.0003)
âš¡ Performance: 714.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1671
   â€¢ Completion Tokens: 271
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 4 Single Batch Time: 2718ms (2.72s)

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 2718ms (2.72s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1942 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.5 sessions/sec
âš¡ Avg Time Per Session: 679.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:21:04.841Z',
  duration: '2760ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1728,
    completion_tokens: 295,
    total_tokens: 2023,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Leave Request', 'Customer Service' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-9f68b0f5-4be4-5b8c-98b8-ed452f0be598",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-8560afe0-af9e-50b9-b5fe-5d94d9cb05f8",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User indicated silence and was transferred to an agent for leave request assistance."
    },
    {
      "user_id": "u-47c37255-0e49-5754-a0de-f1dabc352edc",
      "general_intent": "Customer Service",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested customer service and was transferred to an agent."
    },
    {
      "user_id": "u-7efad988-d2ef-5e98-9c13-df9cdac36c0c",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1728,
  completionTokens: 295,
  totalTokens: 2023,
  cost: '$0.000291',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2761ms (2.76s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2023 ($0.0003)
âš¡ Performance: 732.7 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1728
   â€¢ Completion Tokens: 295
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 5 Single Batch Time: 2762ms (2.76s)

âœ… ===== STREAM 5 PROCESSING COMPLETE =====
â±ï¸  Stream 5 Total Time: 2762ms (2.76s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2023 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.4 sessions/sec
âš¡ Avg Time Per Session: 690.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:21:04.950Z',
  duration: '2870ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1880,
    completion_tokens: 298,
    total_tokens: 2178,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Leave Request', 'Unknown', 'Claim Status' ],
  transferCount: 2,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-08ccb388-87ee-5cd3-b401-a8d893c50dae",
      "general_intent": "Leave Request",
      "session_outcome": "Contained",
      "notes": "The user attempted to report a leave request and was guided to find their leave request number, but the session was not transferred to an agent."
    },
    {
      "user_id": "u-b7afdec1-75b0-514e-89e8-f8d9140002b0",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "The user attempted to log on to the site, and the session was transferred to a live agent."
    },
    {
      "user_id": "u-566b7c4c-f9ec-566c-a619-08cc9dcb4601",
      "general_intent": "Leave Request",
      "session_outcome": "Contained",
      "notes": "The user tried to request a leave, but the session was not transferred to an agent due to repeated input issues."
    },
    {
      "user_id": "u-837c909b-3429-53b9-84f1-86249bb3668f",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "The user requested claim status, and the session was transferred to a live agent after failed input."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1880,
  completionTokens: 298,
  totalTokens: 2178,
  cost: '$0.000307',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2872ms (2.87s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2178 ($0.0003)
âš¡ Performance: 758.4 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1880
   â€¢ Completion Tokens: 298
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 3 Single Batch Time: 2872ms (2.87s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 2872ms (2.87s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2178 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.4 sessions/sec
âš¡ Avg Time Per Session: 718.00ms
[ParallelProcessingOrchestrator] Parallel processing complete: 8/8 streams succeeded
â±ï¸  Parallel Processing Time: 2874ms (2.87s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 8 streams
[ParallelProcessingOrchestrator] Synchronization complete: 2 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 2
ğŸ“Š Total Classifications: 13

âœ… ============ ROUND 2 COMPLETED ============
â±ï¸  Round 2 Total Time: 2874ms (2.87s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 20
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 2874ms (100.0%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ”„ ============ ROUND 3/3 STARTED ============
â±ï¸  Round 3 Start: 2025-08-12T16:21:04.952Z
ğŸ“Š Sessions Remaining: 20
[ParallelProcessingOrchestrator] Distributed 20 sessions across 5 streams: [
  'Stream 1: 4 sessions',
  'Stream 2: 4 sessions',
  'Stream 3: 4 sessions',
  'Stream 4: 4 sessions',
  'Stream 5: 4 sessions'
]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 5

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 5 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T16:21:04.952Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:21:04.952Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 696
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6196
   â€¢ Avg Per Session: 174 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6196
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6196
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:21:04.953Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 11
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:21:04.953Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6059,
  existingClassifications: { intents: 11, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Check time, Claim Status, Claim status, Customer Service, Leave Request, Live Agent, Operator, Report new leave, Report time, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: W...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T16:21:04.953Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:21:04.953Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 856
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6356
   â€¢ Avg Per Session: 214 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6356
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6356
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:21:04.954Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 11
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:21:04.954Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6848,
  existingClassifications: { intents: 11, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Check time, Claim Status, Claim status, Customer Service, Leave Request, Live Agent, Operator, Report new leave, Report time, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: W...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T16:21:04.954Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:21:04.954Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 821
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6321
   â€¢ Avg Per Session: 205 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6321
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6321
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:21:04.954Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 11
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:21:04.954Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6702,
  existingClassifications: { intents: 11, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Check time, Claim Status, Claim status, Customer Service, Leave Request, Live Agent, Operator, Report new leave, Report time, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: W...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T16:21:04.954Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:21:04.954Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 728
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6228
   â€¢ Avg Per Session: 182 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6228
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6228
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:21:04.955Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 11
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:21:04.955Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6224,
  existingClassifications: { intents: 11, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Check time, Claim Status, Claim status, Customer Service, Leave Request, Live Agent, Operator, Report new leave, Report time, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: W...

ğŸŒŠ ===== STREAM 5 PROCESSING START =====
â±ï¸  Stream 5 Start: 2025-08-12T16:21:04.955Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:21:04.955Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 813
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6313
   â€¢ Avg Per Session: 203 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6313
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 5) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6313
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 5: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:21:04.955Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 11
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:21:04.955Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6634,
  existingClassifications: { intents: 11, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Check time, Claim Status, Claim status, Customer Service, Leave Request, Live Agent, Operator, Report new leave, Report time, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: W...
::1 - - [12/Aug/2025:16:21:05 +0000] "GET /api/analysis/auto-analyze/parallel/progress/50e2b675-3b20-4f9f-9609-ba284c1cdb17 HTTP/1.1" 200 1417 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:21:06.930Z',
  duration: '1976ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1917,
    completion_tokens: 255,
    total_tokens: 2172,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Leave Request', 'Unknown' ],
  transferCount: 1,
  containedCount: 3
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-17504f01-538c-5d3f-94f4-8f14e2dee97b",
      "general_intent": "Leave Request",
      "session_outcome": "Contained",
      "notes": "User attempted to add time on a leave but did not have the leave request number and was unable to verify account details."
    },
    {
      "user_id": "u-e76e8344-8237-5eab-a823-3c66840bd0a5",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative, and the session was transferred to an agent."
    },
    {
      "user_id": "u-3a287dd3-fa9c-5280-b930-75d82c378aaa",
      "general_intent": "Leave Request",
      "session_outcome": "Contained",
      "notes": "User provided leave request details and successfully completed the return to work process."
    },
    {
      "user_id": "u-55655004-4b2a-5a72-a822-48d129ba8236",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "Session ended without user input."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1917,
  completionTokens: 255,
  totalTokens: 2172,
  cost: '$0.000294',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1977ms (1.98s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2172 ($0.0003)
âš¡ Performance: 1098.6 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1917
   â€¢ Completion Tokens: 255
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 3 Single Batch Time: 1977ms (1.98s)

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 1977ms (1.98s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2172 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.0 sessions/sec
âš¡ Avg Time Per Session: 494.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:21:07.090Z',
  duration: '2137ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1732,
    completion_tokens: 276,
    total_tokens: 2008,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Customer Service', 'Claim Status', 'Unknown' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-b9ec360d-34fe-591c-a76d-4d890dd29073",
      "general_intent": "Customer Service",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent and was transferred."
    },
    {
      "user_id": "u-3966a782-7523-5f67-a423-42c0d7e2b5f7",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User inquired about claim status and was not transferred to an agent."
    },
    {
      "user_id": "u-19472037-1001-52e3-83f7-0ea9c51fb9b5",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to start a new claim and was transferred to an agent."
    },
    {
      "user_id": "u-13d601bf-3345-5814-a476-1deb050a9e91",
      "general_intent": "Customer Service",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1732,
  completionTokens: 276,
  totalTokens: 2008,
  cost: '$0.000284',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2138ms (2.14s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2008 ($0.0003)
âš¡ Performance: 939.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1732
   â€¢ Completion Tokens: 276
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 1 Single Batch Time: 2138ms (2.14s)

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 2139ms (2.14s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2008 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.9 sessions/sec
âš¡ Avg Time Per Session: 534.75ms
::1 - - [12/Aug/2025:16:21:07 +0000] "GET /api/analysis/auto-analyze/parallel/progress/50e2b675-3b20-4f9f-9609-ba284c1cdb17 HTTP/1.1" 200 1421 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:21:07.372Z',
  duration: '2417ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1901,
    completion_tokens: 318,
    total_tokens: 2219,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status', 'Unknown', 'Leave Request' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-0d3a4e33-fd87-5515-874f-1cf12d728996",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User inquired about claim status and verified account details, leading to a leave request status update."
    },
    {
      "user_id": "u-c093c84d-997e-51a1-bc90-36b3c34c3945",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked about a FMLA claim, was verified, and then transferred to an agent for further assistance."
    },
    {
      "user_id": "u-5c0b0e0d-ffea-50ba-841b-c74c02b702f3",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and then indicated intent to open a new leave request, resulting in transfer to an agent."
    },
    {
      "user_id": "u-a4f4ec85-2d80-5f4c-8d6f-730961f8bea8",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to file for leave but did not have the leave request number, leading to transfer to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1901,
  completionTokens: 318,
  totalTokens: 2219,
  cost: '$0.000317',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2417ms (2.42s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2219 ($0.0003)
âš¡ Performance: 918.1 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1901
   â€¢ Completion Tokens: 318
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 5 Single Batch Time: 2418ms (2.42s)

âœ… ===== STREAM 5 PROCESSING COMPLETE =====
â±ï¸  Stream 5 Total Time: 2418ms (2.42s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2219 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.7 sessions/sec
âš¡ Avg Time Per Session: 604.50ms
::1 - - [12/Aug/2025:16:21:09 +0000] "GET /api/analysis/auto-analyze/parallel/progress/50e2b675-3b20-4f9f-9609-ba284c1cdb17 HTTP/1.1" 200 1423 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:21:11.124Z',
  duration: '6170ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1954,
    completion_tokens: 276,
    total_tokens: 2230,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Leave Request', 'Claim Status', 'Unknown' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-ee2f350a-14a6-590a-ad0f-4d62ab486804",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and did not respond, leading to transfer to an agent."
    },
    {
      "user_id": "u-2d3ad2e2-42db-5786-9f8b-67ac59481ae9",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User provided claim details and received status update without transfer."
    },
    {
      "user_id": "u-72442738-170c-5b36-b3f0-b95490fdfc1a",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and did not respond, leading to transfer to an agent."
    },
    {
      "user_id": "u-d11f2582-b1ad-532b-abd2-0803e859a455",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to register and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1954,
  completionTokens: 276,
  totalTokens: 2230,
  cost: '$0.000306',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 6171ms (6.17s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2230 ($0.0003)
âš¡ Performance: 361.4 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1954
   â€¢ Completion Tokens: 276
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 2 Single Batch Time: 6171ms (6.17s)

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 6172ms (6.17s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2230 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1543.00ms
::1 - - [12/Aug/2025:16:21:11 +0000] "GET /api/analysis/auto-analyze/parallel/progress/50e2b675-3b20-4f9f-9609-ba284c1cdb17 HTTP/1.1" 200 1425 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:21:13 +0000] "GET /api/analysis/auto-analyze/parallel/progress/50e2b675-3b20-4f9f-9609-ba284c1cdb17 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:21:15 +0000] "GET /api/analysis/auto-analyze/parallel/progress/50e2b675-3b20-4f9f-9609-ba284c1cdb17 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:21:17 +0000] "GET /api/analysis/auto-analyze/parallel/progress/50e2b675-3b20-4f9f-9609-ba284c1cdb17 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:21:17.969Z',
  duration: '13014ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1781,
    completion_tokens: 292,
    total_tokens: 2073,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Leave Request' ],
  transferCount: 2,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-18507077-7e9a-581b-9e03-bc04989c32c4",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred to an agent."
    },
    {
      "user_id": "u-942076a5-97b6-508c-a0db-23e06838540b",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak to someone and was transferred to an agent."
    },
    {
      "user_id": "u-48f6883d-646c-5a2e-a589-c83f433f33d7",
      "general_intent": "Leave Request",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User inquired about a claim extension, verified account, and was transferred to an agent after no further input."
    },
    {
      "user_id": "u-25bde93a-b323-528e-9528-1c834a8f84ef",
      "general_intent": "Leave Request",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User reported return to work, verified account, and successfully submitted the request without transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1781,
  completionTokens: 292,
  totalTokens: 2073,
  cost: '$0.000295',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 13014ms (13.01s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2073 ($0.0003)
âš¡ Performance: 159.3 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1781
   â€¢ Completion Tokens: 292
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 4 Single Batch Time: 13014ms (13.01s)

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 13015ms (13.02s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2073 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.3 sessions/sec
âš¡ Avg Time Per Session: 3253.75ms
[ParallelProcessingOrchestrator] Parallel processing complete: 5/5 streams succeeded
â±ï¸  Parallel Processing Time: 13018ms (13.02s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 5 streams
[ParallelProcessingOrchestrator] Synchronization complete: 0 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 0
ğŸ“Š Total Classifications: 13

âœ… ============ ROUND 3 COMPLETED ============
â±ï¸  Round 3 Total Time: 13018ms (13.02s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 0
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 13018ms (100.0%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ‰ ============ PARALLEL PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 19616ms (19.62s)
ğŸ“Š Sessions Processed: 84/84
ğŸ”„ Total Rounds: 3
ğŸŒŠ Stream Results: 21
ğŸ’° Token Usage: 44142 tokens ($0.0061)
ğŸ“ˆ Stream Utilization: 100.0%
ğŸ¯ Performance: 4.3 sessions/second
âš¡ Avg Time Per Session: 233.52ms

ğŸ“Š Stream Performance Breakdown:
   Stream 1: 4 sessions in 2316ms (854.1 tokens/sec)
   Stream 2: 4 sessions in 3722ms (539.2 tokens/sec)
   Stream 3: 4 sessions in 1858ms (1194.3 tokens/sec)
   Stream 4: 4 sessions in 2414ms (800.3 tokens/sec)
   Stream 5: 4 sessions in 1962ms (1109.1 tokens/sec)
   Stream 6: 4 sessions in 2330ms (905.6 tokens/sec)
   Stream 7: 4 sessions in 2612ms (785.2 tokens/sec)
   Stream 8: 4 sessions in 2213ms (897.4 tokens/sec)
   Stream 1: 4 sessions in 1904ms (1052.5 tokens/sec)
   Stream 2: 4 sessions in 1882ms (1369.8 tokens/sec)
   Stream 3: 4 sessions in 2872ms (758.4 tokens/sec)
   Stream 4: 4 sessions in 2718ms (714.5 tokens/sec)
   Stream 5: 4 sessions in 2762ms (732.4 tokens/sec)
   Stream 6: 4 sessions in 2413ms (846.7 tokens/sec)
   Stream 7: 4 sessions in 2509ms (775.6 tokens/sec)
   Stream 8: 4 sessions in 2536ms (893.9 tokens/sec)
   Stream 1: 4 sessions in 2139ms (938.8 tokens/sec)
   Stream 2: 4 sessions in 6172ms (361.3 tokens/sec)
   Stream 3: 4 sessions in 1977ms (1098.6 tokens/sec)
   Stream 4: 4 sessions in 13015ms (159.3 tokens/sec)
   Stream 5: 4 sessions in 2418ms (917.7 tokens/sec)
[ConflictResolutionService] Starting conflict resolution for 98 sessions
[ConflictResolutionService] Found classifications: { intents: 11, reasons: 1, locations: 1 }
[ConflictResolutionService] Calling LLM for conflict resolution with model gpt-4.1-nano
ğŸ”§ Conflict Resolution Prompt Preview: You are reviewing classifications from parallel analysis streams. Identify any semantic duplicates and choose the canonical version for each group.

**Instructions:**
1. Look for classifications that refer to the same concept but use different wording
2. For each group of duplicates, choose the most...
::1 - - [12/Aug/2025:16:21:19 +0000] "GET /api/analysis/auto-analyze/parallel/progress/50e2b675-3b20-4f9f-9609-ba284c1cdb17 HTTP/1.1" 200 1427 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[ConflictResolutionService] LLM conflict resolution complete: { intents: 9, reasons: 1, locations: 1, tokens: 808, cost: 0.0001273 }
ğŸ”§ Conflict Resolution Response: {
  "generalIntents": [
    {
      "canonical": "Check Time Inquiry",
      "aliases": [
        "Check time"
      ]
    },
    {
      "canonical": "Claim Status Inquiry",
      "aliases": [
        "Claim Status",
        "Claim status"
      ]
    },
    {
      "canonical": "Customer Service Assistance",
      "aliases": [
        "Customer Service"
      ]
    },
    {
      "canonical": "Leave Request Submission",
      "aliases": [
        "Leave Request"
      ]
    },
    {
      "canonical": "Live Agent Transfer",
      "aliases": [
        "Live Agent"
      ]
    },
    {
      "canonical": "Operator Assistance",
      "aliases": [
        "Operator"
      ]
    },
    {
      "canonical": "Leave Report Submission",
      "aliases": [
        "Report new leave"
      ]
    },
    {
      "canonical": "Time Entry Reporting",
      "aliases": [
        "Report time",
        "Time Entry"
      ]
    },
    {
      "canonical": "Unknown Inquiry",
      "aliases": [
        "Unknown"
      ]
    }
  ],
  "transferReasons": [
    {
      "canonical": "Live Agent Request",
      "aliases": [
        "Live Agent Request"
      ]
    }
  ],
  "dropOffLocations": [
    {
      "canonical": "Help Offer Prompt",
      "aliases": [
        "Help Offer Prompt"
      ]
    }
  ]
}
[ConflictResolutionService] Applying resolutions to 98 sessions
[ConflictResolutionService] Applied 98 classification mappings across 98 sessions
[ConflictResolutionService] Identified 2 potential conflict groups
[ConflictResolutionService] Conflict resolution complete in 2646ms: { conflictsFound: 2, conflictsResolved: 11, canonicalMappings: 13 }
[ParallelAutoAnalyzeService] Using real analysis summary service
::1 - - [12/Aug/2025:16:21:21 +0000] "GET /api/analysis/auto-analyze/parallel/progress/50e2b675-3b20-4f9f-9609-ba284c1cdb17 HTTP/1.1" 200 1510 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:21:23 +0000] "GET /api/analysis/auto-analyze/parallel/progress/50e2b675-3b20-4f9f-9609-ba284c1cdb17 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:21:25 +0000] "GET /api/analysis/auto-analyze/parallel/progress/50e2b675-3b20-4f9f-9609-ba284c1cdb17 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:21:27 +0000] "GET /api/analysis/auto-analyze/parallel/progress/50e2b675-3b20-4f9f-9609-ba284c1cdb17 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:21:29 +0000] "GET /api/analysis/auto-analyze/parallel/progress/50e2b675-3b20-4f9f-9609-ba284c1cdb17 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:21:31 +0000] "GET /api/analysis/auto-analyze/parallel/progress/50e2b675-3b20-4f9f-9609-ba284c1cdb17 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:21:33 +0000] "GET /api/analysis/auto-analyze/parallel/progress/50e2b675-3b20-4f9f-9609-ba284c1cdb17 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:21:35 +0000] "GET /api/analysis/auto-analyze/parallel/progress/50e2b675-3b20-4f9f-9609-ba284c1cdb17 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:21:37 +0000] "GET /api/analysis/auto-analyze/parallel/progress/50e2b675-3b20-4f9f-9609-ba284c1cdb17 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:21:39 +0000] "GET /api/analysis/auto-analyze/parallel/progress/50e2b675-3b20-4f9f-9609-ba284c1cdb17 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[ParallelAutoAnalyzeService] Parallel analysis 50e2b675-3b20-4f9f-9609-ba284c1cdb17 completed successfully
[BackgroundJobQueue] Updated job progress to final state: complete
[BackgroundJobQueue] Parallel analysis job 50e2b675-3b20-4f9f-9609-ba284c1cdb17-parallel completed successfully
::1 - - [12/Aug/2025:16:21:41 +0000] "GET /api/analysis/auto-analyze/parallel/progress/50e2b675-3b20-4f9f-9609-ba284c1cdb17 HTTP/1.1" 200 1550 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:21:41 +0000] "GET /api/analysis/auto-analyze/parallel/results/50e2b675-3b20-4f9f-9609-ba284c1cdb17 HTTP/1.1" 200 655561 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T16:26:47.998Z",
  "dateTo": "2025-08-12T16:27:47.998Z",
  "skip": 0,
  "limit": 1
}
::1 - - [12/Aug/2025:16:27:52 +0000] "GET /api/kore/test HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 1 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [ '689b6b52b110c33d69850579' ]
[getSessionsMetadataForConnectionTest] Single API call succeeded with 1 sessions
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T16:30:55.374Z",
  "dateTo": "2025-08-12T16:31:55.374Z",
  "skip": 0,
  "limit": 1
}
[fetchContainmentTypeMetadata] API Response: 0 agent sessions received
[getSessionsMetadataForConnectionTest] Single API call succeeded with 0 sessions
::1 - - [12/Aug/2025:16:31:59 +0000] "GET /api/kore/test HTTP/1.1" 200 299 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸš€ [ParallelAutoAnalyzeRoute] Starting parallel analysis for bot ***REMOVED*** with real credentials
ğŸš€ [ParallelAutoAnalyzeService] Starting parallel analysis 0e17cda9-7c0d-45c6-81b3-a26d2e3afe15 with bot ***REMOVED***
ğŸš€ [ParallelAutoAnalyzeService] Using credentials: real
ğŸš€ [ParallelAutoAnalyzeRoute] Parallel analysis started: 0e17cda9-7c0d-45c6-81b3-a26d2e3afe15
::1 - - [12/Aug/2025:16:32:17 +0000] "POST /api/analysis/auto-analyze/parallel/start HTTP/1.1" 200 214 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:32:17 +0000] "GET /api/analysis/auto-analyze/parallel/progress/0e17cda9-7c0d-45c6-81b3-a26d2e3afe15 HTTP/1.1" 200 542 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:32:17 +0000] "GET /api/analysis/auto-analyze/parallel/progress/0e17cda9-7c0d-45c6-81b3-a26d2e3afe15 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[BackgroundJobQueue] Starting job processing after delay for job 0e17cda9-7c0d-45c6-81b3-a26d2e3afe15-parallel
[BackgroundJobQueue] Starting processing for job 0e17cda9-7c0d-45c6-81b3-a26d2e3afe15-parallel, phase: sampling
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing parallel analysis job 0e17cda9-7c0d-45c6-81b3-a26d2e3afe15-parallel
[BackgroundJobQueue] Processing parallel analysis for bot ***REMOVED***
[BackgroundJobQueue] Using existing ParallelAutoAnalyzeService instance for bot ***REMOVED***
[BackgroundJobQueue] Session recreated for 0e17cda9-7c0d-45c6-81b3-a26d2e3afe15
[ParallelAutoAnalyzeService] Running parallel analysis for 0e17cda9-7c0d-45c6-81b3-a26d2e3afe15
[ParallelAutoAnalyzeService] Phase 0: Starting session sampling for 0e17cda9-7c0d-45c6-81b3-a26d2e3afe15

ğŸ• ============ SESSION SAMPLING STARTED ============
ğŸ• [SessionSampling] Starting session sampling at 2025-08-12T16:32:18.848Z
ğŸ” [SessionDiscovery] Starting window 1/4: Initial 3-hour window
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
::1 - - [12/Aug/2025:16:32:19 +0000] "GET /api/analysis/auto-analyze/parallel/progress/0e17cda9-7c0d-45c6-81b3-a26d2e3afe15 HTTP/1.1" 200 715 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 80 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a1287849680ad9fe59e',
  '689229f9583056c6108e38fb',
  '68922914f8bee7ba6c3e67b8'
]
[fetchContainmentTypeMetadata] API Response: 139 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6a14dd27c3112087cd',
  '68922a22ef03d8ad2ec7b4ba',
  '68922a1278c1fe09a079719c'
]
::1 - - [12/Aug/2025:16:32:21 +0000] "GET /api/analysis/auto-analyze/parallel/progress/0e17cda9-7c0d-45c6-81b3-a26d2e3afe15 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:32:23 +0000] "GET /api/analysis/auto-analyze/parallel/progress/0e17cda9-7c0d-45c6-81b3-a26d2e3afe15 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 1338 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6d14dd27c31120888b',
  '68922a62e3804084741191d5',
  '68922a523a3160d25de144c8'
]
[getSessionsMetadata] agent API call succeeded with 1338 sessions
[getSessionsMetadata] selfService API call succeeded with 80 sessions
[getSessionsMetadata] dropOff API call succeeded with 139 sessions
Total session metadata retrieved: 1557 (parallel execution)
Creating 1557 SWTs from metadata (no messages)
Created 1557 SWT objects from metadata
âœ… [SessionDiscovery] Window 1 completed in 6104ms: found 1557 new sessions (total: 1557)
â±ï¸  TIMING: Window 1 took 6104ms (6.10s)
ğŸ¯ [SessionDiscovery] Target reached! Found 1557 sessions in 6104ms
ğŸ² [SessionSampling] Random sampling from 1557 sessions to 100 sessions

ğŸ“¬ ============ MESSAGE RETRIEVAL STARTED ============
ğŸ“¬ [MessageRetrieval] Starting message retrieval for 100 sampled sessions at 2025-08-12T16:32:24.952Z
Using new lazy loading approach to populate messages for 100 sampled sessions
Populating messages for 100 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 100 sessions from 2025-08-05T13:01:05.701Z to 2025-08-05T15:59:17.388Z at 2025-08-12T16:32:24.953Z
ğŸš€ [ConcurrentBatch] Split 100 sessions into 5 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/5] Starting: 20 sessions
[Batch 2/5] Starting: 20 sessions
[Batch 3/5] Starting: 20 sessions
[Batch 4/5] Starting: 20 sessions
[Batch 5/5] Starting: 20 sessions
[Batch 3/5] Completed in 351ms: 214 messages retrieved (1/5 done)
ğŸ“Š [BatchProgress] Reporting batch 1/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 40/100 sessions (Batch 2/5)
[Batch 1/5] Completed in 380ms: 249 messages retrieved (2/5 done)
ğŸ“Š [BatchProgress] Reporting batch 2/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 60/100 sessions (Batch 3/5)
[Batch 2/5] Completed in 429ms: 263 messages retrieved (3/5 done)
ğŸ“Š [BatchProgress] Reporting batch 3/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 80/100 sessions (Batch 4/5)
[Batch 4/5] Completed in 607ms: 273 messages retrieved (4/5 done)
ğŸ“Š [BatchProgress] Reporting batch 4/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 100/100 sessions (Batch 5/5)
[Batch 5/5] Completed in 705ms: 303 messages retrieved (5/5 done)
ğŸ“Š [BatchProgress] Reporting batch 5/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 100/100 sessions (Batch 6/5)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 705ms (0.70s)
â±ï¸  Batch Processing: 705ms (0.70s)
ğŸ“¦ Total batches: 5 (max 10 concurrent)
âœ… Successful batches: 5/5
ğŸ’¬ Total messages: 1302
ğŸ“ˆ Avg time per batch: 141ms
ğŸš€ Time per session: 7ms
ğŸ’ª Performance: 141.8 sessions/second
=======================================================

Retrieved 1302 messages for 100 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
Populated messages for 100 SWT objects
Successfully populated messages for 100 sessions using lazy loading
Applying final filtering to 100 sessions with populated messages
Final result: 99 sessions passed filtering with populated messages

ğŸ‰ ============ SESSION SAMPLING COMPLETED ============
â±ï¸  TOTAL TIME: 6815ms (6.82s)
â±ï¸  Session Discovery: 6104ms (6.10s) - 89.6% of total
â±ï¸  Message Retrieval: 711ms (0.71s) - 10.4% of total
â±ï¸  Performance: 14.5 sessions/second
ğŸ¯ Final result: 99 sessions with messages retrieved
====================================================

[StrategicDiscoveryService] Starting discovery phase with 99 total sessions
[StrategicDiscoveryService] Discovery config: {
  targetPercentage: 15,
  minSessions: 9,
  maxSessions: 14,
  diversityStrategy: {
    sessionLengths: [ 'short', 'medium', 'long' ],
    containmentTypes: [ 'agent', 'selfService', 'dropOff' ],
    timeDistribution: 'spread'
  }
}
[StrategicDiscoveryService] Selecting 14 diverse sessions from 99 total
[StrategicDiscoveryService] Session diversity groups: { short: 31, medium: 68, early: 33, middle: 33, late: 33 }
[StrategicDiscoveryService] Selected sessions by length distribution: { short: 6, medium: 8, long: 0 }
[StrategicDiscoveryService] Selected 14 sessions for discovery

ğŸ“¦ ===== BATCH 11 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:32:25.664Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 0
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:32:25.664Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:32:25.664Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6406,
  existingClassifications: { intents: 0, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.



For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and another intent, classify the intent as the other i...
::1 - - [12/Aug/2025:16:32:25 +0000] "GET /api/analysis/auto-analyze/parallel/progress/0e17cda9-7c0d-45c6-81b3-a26d2e3afe15 HTTP/1.1" 200 921 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:32:27 +0000] "GET /api/analysis/auto-analyze/parallel/progress/0e17cda9-7c0d-45c6-81b3-a26d2e3afe15 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:32:28.788Z',
  duration: '3124ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1864,
    completion_tokens: 385,
    total_tokens: 2249,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Unknown', 'Question about leave request' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-1cb3e4ec-a55b-55ec-91cf-d6fbcb19ca65",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak to someone about an FMLA form, session was transferred to an agent."
    },
    {
      "user_id": "u-a9fadc3c-cd79-5884-933b-935fffb2d26b",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an operator, session was transferred to an agent."
    },
    {
      "user_id": "u-40ab5c5d-3955-5eec-9fd8-27cca44e4640",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with a representative, session was transferred to an agent."
    },
    {
      "user_id": "u-8f6c7fec-77f4-5896-88b3-764f20adfe9c",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User provided leave request number, but was unable to proceed, session transferred to an agent."
    },
    {
      "user_id": "u-ba29892b-2ed3-5535-9112-33a3c6c5bcc0",
      "general_intent": "Question about leave request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked about leave request, session was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1864,
  completionTokens: 385,
  totalTokens: 2249,
  cost: '$0.000340',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 3125ms (3.13s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2249 ($0.0003)
âš¡ Performance: 719.7 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 3125ms (3.13s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2249

âœ… ===== BATCH 11 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 3125ms (3.13s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2249 ($0.0003)
âš¡ Performance: 1.6 sessions/sec
âš¡ Avg Time Per Session: 625.00ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 1 complete: 4 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 2, reasons: 1, locations: 1, total: 4 }

ğŸ“¦ ===== BATCH 12 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:32:28.789Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 2
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:32:28.789Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:32:28.789Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6404,
  existingClassifications: { intents: 2, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Question about leave request, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligi...
::1 - - [12/Aug/2025:16:32:29 +0000] "GET /api/analysis/auto-analyze/parallel/progress/0e17cda9-7c0d-45c6-81b3-a26d2e3afe15 HTTP/1.1" 200 938 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:32:31.440Z',
  duration: '2651ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1839,
    completion_tokens: 356,
    total_tokens: 2195,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Unknown', 'Claim status', 'Question about leave request' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-fe82cb15-3319-598d-99c2-2bc6a944d833",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted portal login assistance and was transferred to a live agent."
    },
    {
      "user_id": "u-bfd01b9c-5b15-53ef-9bbd-d3d676ae75df",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-6904f438-c3ff-5395-b502-2b9224dd8679",
      "general_intent": "Claim status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User provided claim details and was transferred to an agent."
    },
    {
      "user_id": "u-add9bd3a-bad8-5dba-9eb4-b51a590bc803",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User discussed FMLA and was transferred to a live agent."
    },
    {
      "user_id": "u-8375a5b5-fb93-54fd-b586-f61f5e5b296e",
      "general_intent": "Question about leave request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent about leave request."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1839,
  completionTokens: 356,
  totalTokens: 2195,
  cost: '$0.000326',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2652ms (2.65s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2195 ($0.0003)
âš¡ Performance: 827.7 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2652ms (2.65s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2195

âœ… ===== BATCH 12 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2652ms (2.65s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2195 ($0.0003)
âš¡ Performance: 1.9 sessions/sec
âš¡ Avg Time Per Session: 530.40ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 2 complete: 1 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 3, reasons: 1, locations: 1, total: 5 }

ğŸ“¦ ===== BATCH 13 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:32:31.442Z
ğŸ“Š Sessions in Batch: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 4
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:32:31.442Z
ğŸ“Š Sessions to Analyze: 4

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:32:31.442Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7854,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim status, Question about leave request, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Bi...
::1 - - [12/Aug/2025:16:32:31 +0000] "GET /api/analysis/auto-analyze/parallel/progress/0e17cda9-7c0d-45c6-81b3-a26d2e3afe15 HTTP/1.1" 200 939 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:32:33 +0000] "GET /api/analysis/auto-analyze/parallel/progress/0e17cda9-7c0d-45c6-81b3-a26d2e3afe15 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:32:35.690Z',
  duration: '4248ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2222,
    completion_tokens: 229,
    total_tokens: 2451,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status', 'Live Agent', 'Unknown' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-1b820ea7-cee4-5b57-9d00-605916606b93",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-f487a17e-9e55-5d05-829d-0e6a25f8feab",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": ""
    },
    {
      "user_id": "u-16f01507-1160-5322-aa3c-fb4b3b7413a9",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-17504f01-538c-5d3f-94f4-8f14e2dee97b",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2222,
  completionTokens: 229,
  totalTokens: 2451,
  cost: '$0.000314',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 4249ms (4.25s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2451 ($0.0003)
âš¡ Performance: 576.8 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 4
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 4249ms (4.25s)
ğŸ“Š Regular Sessions Processed: 4
ğŸ’° Regular Tokens Used: 2451

âœ… ===== BATCH 13 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 4250ms (4.25s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Total Tokens: 2451 ($0.0003)
âš¡ Performance: 0.9 sessions/sec
âš¡ Avg Time Per Session: 1062.50ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 3 complete: 2 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 5, reasons: 1, locations: 1, total: 7 }
[StrategicDiscoveryService] Discovery phase complete: {
  totalProcessed: 14,
  uniqueIntents: 5,
  uniqueReasons: 1,
  uniqueLocations: 1,
  discoveryRate: 0.4666666666666667
}

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T16:32:35.692Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms
[ParallelProcessingOrchestrator] Configuration for 85 sessions:
  Design: 8 streams Ã— 4 sessions = 32 per round
  Optimal: 8 streams Ã— 4 sessions = 32 per round
  Estimated Rounds: 3
[ParallelAutoAnalyzeService] Using parallel config: {
  streamCount: 8,
  sessionsPerStream: 4,
  maxSessionsPerLLMCall: 50,
  syncFrequency: 'after_each_round',
  retryAttempts: 3,
  debugLogging: false
}

ğŸš€ ============ PARALLEL PROCESSING STARTED ============
â±ï¸  Start Time: 2025-08-12T16:32:35.693Z
ğŸ“Š Total Sessions: 85

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T16:32:35.693Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms

âš™ï¸  ============ PARALLEL CONFIGURATION ============
â±ï¸  Config Time: 0ms
ğŸ”§ Stream Count: 8
ğŸ“¦ Sessions Per Stream: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per API Call: 50
ğŸ¯ Debug Logging: false

ğŸ”„ ============ ROUND 1/3 STARTED ============
â±ï¸  Round 1 Start: 2025-08-12T16:32:35.693Z
ğŸ“Š Sessions Remaining: 85
[ParallelProcessingOrchestrator] Distributed 32 sessions across 8 streams: [
  'Stream 1: 4 sessions',
  'Stream 2: 4 sessions',
  'Stream 3: 4 sessions',
  'Stream 4: 4 sessions',
  'Stream 5: 4 sessions',
  'Stream 6: 4 sessions',
  'Stream 7: 4 sessions',
  'Stream 8: 4 sessions'
]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 8

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 8 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T16:32:35.693Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:32:35.693Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 837
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6337
   â€¢ Avg Per Session: 209 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6337
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6337
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:32:35.693Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:32:35.694Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6620,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Live Agent, Question about leave request, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common exa...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T16:32:35.694Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:32:35.694Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 759
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6259
   â€¢ Avg Per Session: 190 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6259
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6259
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:32:35.694Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:32:35.694Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6328,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Live Agent, Question about leave request, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common exa...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T16:32:35.694Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:32:35.694Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 788
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6288
   â€¢ Avg Per Session: 197 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6288
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6288
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:32:35.694Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:32:35.694Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6462,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Live Agent, Question about leave request, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common exa...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T16:32:35.694Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:32:35.695Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 736
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6236
   â€¢ Avg Per Session: 184 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6236
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6236
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:32:35.695Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:32:35.695Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6187,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Live Agent, Question about leave request, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common exa...

ğŸŒŠ ===== STREAM 5 PROCESSING START =====
â±ï¸  Stream 5 Start: 2025-08-12T16:32:35.695Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:32:35.695Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 992
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6492
   â€¢ Avg Per Session: 248 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6492
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 5) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6492
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 5: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:32:35.695Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:32:35.695Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7377,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Live Agent, Question about leave request, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common exa...

ğŸŒŠ ===== STREAM 6 PROCESSING START =====
â±ï¸  Stream 6 Start: 2025-08-12T16:32:35.695Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:32:35.695Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 723
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6223
   â€¢ Avg Per Session: 181 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6223
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 6) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6223
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 6: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:32:35.696Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:32:35.696Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6101,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Live Agent, Question about leave request, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common exa...

ğŸŒŠ ===== STREAM 7 PROCESSING START =====
â±ï¸  Stream 7 Start: 2025-08-12T16:32:35.696Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:32:35.696Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 649
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6149
   â€¢ Avg Per Session: 162 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6149
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 7) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6149
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 7: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:32:35.696Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:32:35.696Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5797,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Live Agent, Question about leave request, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common exa...

ğŸŒŠ ===== STREAM 8 PROCESSING START =====
â±ï¸  Stream 8 Start: 2025-08-12T16:32:35.696Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:32:35.696Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 710
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6210
   â€¢ Avg Per Session: 178 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6210
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 8) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6210
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 8: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:32:35.696Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:32:35.696Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6021,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Live Agent, Question about leave request, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common exa...
::1 - - [12/Aug/2025:16:32:35 +0000] "GET /api/analysis/auto-analyze/parallel/progress/0e17cda9-7c0d-45c6-81b3-a26d2e3afe15 HTTP/1.1" 200 1717 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:32:37.240Z',
  duration: '1545ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2085,
    completion_tokens: 188,
    total_tokens: 2273,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-9db65bb4-abb4-5f7f-97de-b2932a1cd106",
      "notes": "User wanted IT support and was transferred to an agent."
    },
    {
      "user_id": "u-5f50487d-35f7-59e6-8a7d-3552721d3947",
      "notes": "User inquired about paperwork, was transferred to an agent after multiple clarifications."
    },
    {
      "user_id": "u-b654f81d-301d-5421-8514-c16379457a1c",
      "notes": "User verified leave request details and was transferred to an agent for further assistance."
    },
    {
      "user_id": "u-65de5019-27a8-5788-a16c-833401f7b785",
      "notes": "User asked about FMLA, was transferred to an agent for renewal assistance."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2085,
  completionTokens: 188,
  totalTokens: 2273,
  cost: '$0.000284',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1546ms (1.55s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2273 ($0.0003)
âš¡ Performance: 1470.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2085
   â€¢ Completion Tokens: 188
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-9db65bb4-abb4-5f7f-97de-b2932a1cd106: Invalid general_intent, u-9db65bb4-abb4-5f7f-97de-b2932a1cd106: Invalid session_outcome, u-5f50487d-35f7-59e6-8a7d-3552721d3947: Invalid general_intent, u-5f50487d-35f7-59e6-8a7d-3552721d3947: Invalid session_outcome, u-b654f81d-301d-5421-8514-c16379457a1c: Invalid general_intent, u-b654f81d-301d-5421-8514-c16379457a1c: Invalid session_outcome, u-65de5019-27a8-5788-a16c-833401f7b785: Invalid general_intent, u-65de5019-27a8-5788-a16c-833401f7b785: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 5 Single Batch Time: 1546ms (1.55s)

âœ… ===== STREAM 5 PROCESSING COMPLETE =====
â±ï¸  Stream 5 Total Time: 1546ms (1.55s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2273 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.6 sessions/sec
âš¡ Avg Time Per Session: 386.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:32:37.377Z',
  duration: '1682ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1771,
    completion_tokens: 231,
    total_tokens: 2002,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [
    'Claim',
    'Question about leave request',
    'Unknown',
    'Update claim status'
  ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-73eb7a58-99a9-5085-b473-50e8ddc35a13",
      "general_intent": "Claim",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-d1c209d4-4174-5330-9fa4-67369fc21de4",
      "general_intent": "Question about leave request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-1dd19dc4-dc07-5d8d-94c9-00073d90ae6a",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": ""
    },
    {
      "user_id": "u-710b0571-5b4b-553c-b981-4ab62c4b7c4a",
      "general_intent": "Update claim status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1771,
  completionTokens: 231,
  totalTokens: 2002,
  cost: '$0.000270',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1683ms (1.68s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2002 ($0.0003)
âš¡ Performance: 1189.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1771
   â€¢ Completion Tokens: 231
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-73eb7a58-99a9-5085-b473-50e8ddc35a13: Invalid notes, u-d1c209d4-4174-5330-9fa4-67369fc21de4: Invalid notes, u-1dd19dc4-dc07-5d8d-94c9-00073d90ae6a: Invalid notes, u-710b0571-5b4b-553c-b981-4ab62c4b7c4a: Invalid notes'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 4 Single Batch Time: 1683ms (1.68s)
[StreamProcessingService] Discovered 2 new classifications: { intents: 2, reasons: 0, locations: 0 }

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 1684ms (1.68s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2002 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.4 sessions/sec
âš¡ Avg Time Per Session: 421.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:32:37.426Z',
  duration: '1732ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1849,
    completion_tokens: 236,
    total_tokens: 2085,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Leave Request', 'Unknown', 'Claim Status' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-afe49426-bc8f-59cb-8f7d-41caafb7e4dc",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-890a85a0-ba52-5e31-8337-385a42ab386e",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-f2a0383b-17cd-5a98-990d-5fdba0077086",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-fa5967dd-1fe8-512b-a895-0c3e78d1e37f",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User inquired about claim status and attempted to verify details, but was unable to complete the process."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1849,
  completionTokens: 236,
  totalTokens: 2085,
  cost: '$0.000279',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1732ms (1.73s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2085 ($0.0003)
âš¡ Performance: 1203.8 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1849
   â€¢ Completion Tokens: 236
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-afe49426-bc8f-59cb-8f7d-41caafb7e4dc: Invalid notes, u-890a85a0-ba52-5e31-8337-385a42ab386e: Invalid notes, u-f2a0383b-17cd-5a98-990d-5fdba0077086: Invalid notes'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 3 Single Batch Time: 1733ms (1.73s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 1733ms (1.73s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2085 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.3 sessions/sec
âš¡ Avg Time Per Session: 433.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:32:37.557Z',
  duration: '1861ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1742,
    completion_tokens: 258,
    total_tokens: 2000,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Unknown' ],
  transferCount: 2,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-e1d9a63c-9298-58d7-a2c0-707dac00e634",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent and was transferred."
    },
    {
      "user_id": "u-9e7555f0-e014-5921-a47f-45e5af817ca2",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User provided claim and leave request info but did not complete the transfer process."
    },
    {
      "user_id": "u-ea01724b-62d5-58a0-a7be-90c38b8be681",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested customer service and was transferred to an agent."
    },
    {
      "user_id": "u-a6c2ecd9-e003-5092-96c9-efd870e71a8a",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User was silent and did not complete the session."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1742,
  completionTokens: 258,
  totalTokens: 2000,
  cost: '$0.000277',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1861ms (1.86s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2000 ($0.0003)
âš¡ Performance: 1074.7 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1742
   â€¢ Completion Tokens: 258
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 6 Single Batch Time: 1862ms (1.86s)

âœ… ===== STREAM 6 PROCESSING COMPLETE =====
â±ï¸  Stream 6 Total Time: 1863ms (1.86s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2000 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.1 sessions/sec
âš¡ Avg Time Per Session: 465.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:32:37.684Z',
  duration: '1990ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1875,
    completion_tokens: 297,
    total_tokens: 2172,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown', 'Claim status', 'Live Agent' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-d38e1cfe-1404-533b-b2b9-ea12af6e54ae",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent regarding leave request and FMLA questions."
    },
    {
      "user_id": "u-ea813842-eff8-53a4-b6d6-bd87e95ce9cb",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User inquired about FMLA papers and was transferred to an agent for leave request assistance."
    },
    {
      "user_id": "u-e08924c4-137c-5be1-98df-578bce24869b",
      "general_intent": "Claim status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User provided claim details and was transferred to an agent for further assistance."
    },
    {
      "user_id": "u-6514d456-0aa6-52d6-a8a4-984b3508cbe0",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1875,
  completionTokens: 297,
  totalTokens: 2172,
  cost: '$0.000306',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1992ms (1.99s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2172 ($0.0003)
âš¡ Performance: 1090.4 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1875
   â€¢ Completion Tokens: 297
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 1 Single Batch Time: 1992ms (1.99s)

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 1992ms (1.99s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2172 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.0 sessions/sec
âš¡ Avg Time Per Session: 498.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:32:37.710Z',
  duration: '2014ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1667,
    completion_tokens: 285,
    total_tokens: 1952,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status', 'Live Agent', 'Unknown' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-bbe5e080-66b9-528b-afab-0f75bdbe8119",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User initiated a claim request and was transferred to an agent."
    },
    {
      "user_id": "u-df1ed592-2472-5bfd-beab-b279a1403022",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred to an agent."
    },
    {
      "user_id": "u-3ccd4175-c809-5d5a-84fb-c35b8a629042",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User checked claim status and was transferred to an agent."
    },
    {
      "user_id": "u-f3c64b0b-7170-57cc-8bde-c34b9f23cfce",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and transferred to an agent after no input."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1667,
  completionTokens: 285,
  totalTokens: 1952,
  cost: '$0.000281',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2014ms (2.01s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1952 ($0.0003)
âš¡ Performance: 969.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1667
   â€¢ Completion Tokens: 285
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 7 Single Batch Time: 2014ms (2.01s)

âœ… ===== STREAM 7 PROCESSING COMPLETE =====
â±ï¸  Stream 7 Total Time: 2014ms (2.01s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1952 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.0 sessions/sec
âš¡ Avg Time Per Session: 503.50ms
::1 - - [12/Aug/2025:16:32:37 +0000] "GET /api/analysis/auto-analyze/parallel/progress/0e17cda9-7c0d-45c6-81b3-a26d2e3afe15 HTTP/1.1" 200 1729 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:32:38.565Z',
  duration: '2869ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1720,
    completion_tokens: 290,
    total_tokens: 2010,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-1e335903-d482-5092-aebf-1c3765fca936",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an operator and was transferred to an agent."
    },
    {
      "user_id": "u-f1c66492-b166-51c7-8c56-9d91f62551e2",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a representative and was transferred to an agent."
    },
    {
      "user_id": "u-f49ff565-7e3b-5d8a-afb5-6f2318aa26b7",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked to speak to a representative and was transferred to an agent."
    },
    {
      "user_id": "u-81d20619-f7ea-5471-8497-b517cfe87002",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a representative and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1720,
  completionTokens: 290,
  totalTokens: 2010,
  cost: '$0.000288',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2870ms (2.87s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2010 ($0.0003)
âš¡ Performance: 700.3 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1720
   â€¢ Completion Tokens: 290
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 8 Single Batch Time: 2870ms (2.87s)

âœ… ===== STREAM 8 PROCESSING COMPLETE =====
â±ï¸  Stream 8 Total Time: 2870ms (2.87s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2010 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.4 sessions/sec
âš¡ Avg Time Per Session: 717.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:32:39.131Z',
  duration: '3437ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1815,
    completion_tokens: 307,
    total_tokens: 2122,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Leave Request' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-443b963d-fee6-5afa-a24e-dd4109cc89ba",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a leave of absence and was transferred to a live agent."
    },
    {
      "user_id": "u-d40b94f1-6fd5-5542-9c12-c2a4a27df698",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak to a representative and was transferred to an agent."
    },
    {
      "user_id": "u-c07f0c36-ebfe-5e9e-96ac-7a8abbcbb9ab",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to file a new FMLA leave request and was transferred to an agent."
    },
    {
      "user_id": "u-ada7a4aa-0371-5a17-8f6c-0a31b88d1c2b",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User checked claim status and requested a representative, then was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1815,
  completionTokens: 307,
  totalTokens: 2122,
  cost: '$0.000304',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 3438ms (3.44s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2122 ($0.0003)
âš¡ Performance: 617.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1815
   â€¢ Completion Tokens: 307
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 2 Single Batch Time: 3438ms (3.44s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 3438ms (3.44s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2122 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.2 sessions/sec
âš¡ Avg Time Per Session: 859.50ms
[ParallelProcessingOrchestrator] Parallel processing complete: 8/8 streams succeeded
â±ï¸  Parallel Processing Time: 3439ms (3.44s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 8 streams
[ParallelProcessingOrchestrator] Synchronization complete: 3 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 3
ğŸ“Š Total Classifications: 10

âœ… ============ ROUND 1 COMPLETED ============
â±ï¸  Round 1 Total Time: 3439ms (3.44s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 53
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 3439ms (100.0%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ”„ ============ ROUND 2/3 STARTED ============
â±ï¸  Round 2 Start: 2025-08-12T16:32:39.132Z
ğŸ“Š Sessions Remaining: 53
[ParallelProcessingOrchestrator] Distributed 32 sessions across 8 streams: [
  'Stream 1: 4 sessions',
  'Stream 2: 4 sessions',
  'Stream 3: 4 sessions',
  'Stream 4: 4 sessions',
  'Stream 5: 4 sessions',
  'Stream 6: 4 sessions',
  'Stream 7: 4 sessions',
  'Stream 8: 4 sessions'
]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 8

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 8 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T16:32:39.132Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:32:39.132Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 900
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6400
   â€¢ Avg Per Session: 225 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6400
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6400
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:32:39.132Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 8
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:32:39.132Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6993,
  existingClassifications: { intents: 8, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim, Claim Status, Claim status, Leave Request, Live Agent, Question about leave request, Unknown, Update claim status
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T16:32:39.132Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:32:39.133Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 723
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6223
   â€¢ Avg Per Session: 181 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6223
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6223
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:32:39.133Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 8
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:32:39.133Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6118,
  existingClassifications: { intents: 8, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim, Claim Status, Claim status, Leave Request, Live Agent, Question about leave request, Unknown, Update claim status
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T16:32:39.133Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:32:39.133Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 948
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6448
   â€¢ Avg Per Session: 237 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6448
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6448
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:32:39.133Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 8
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:32:39.133Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7165,
  existingClassifications: { intents: 8, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim, Claim Status, Claim status, Leave Request, Live Agent, Question about leave request, Unknown, Update claim status
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T16:32:39.133Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:32:39.133Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 651
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6151
   â€¢ Avg Per Session: 163 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6151
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6151
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:32:39.133Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 8
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:32:39.133Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5819,
  existingClassifications: { intents: 8, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim, Claim Status, Claim status, Leave Request, Live Agent, Question about leave request, Unknown, Update claim status
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to...

ğŸŒŠ ===== STREAM 5 PROCESSING START =====
â±ï¸  Stream 5 Start: 2025-08-12T16:32:39.133Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:32:39.133Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 949
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6449
   â€¢ Avg Per Session: 237 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6449
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 5) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6449
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 5: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:32:39.133Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 8
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:32:39.134Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7063,
  existingClassifications: { intents: 8, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim, Claim Status, Claim status, Leave Request, Live Agent, Question about leave request, Unknown, Update claim status
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to...

ğŸŒŠ ===== STREAM 6 PROCESSING START =====
â±ï¸  Stream 6 Start: 2025-08-12T16:32:39.134Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:32:39.134Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 651
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6151
   â€¢ Avg Per Session: 163 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6151
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 6) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6151
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 6: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:32:39.134Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 8
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:32:39.134Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5813,
  existingClassifications: { intents: 8, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim, Claim Status, Claim status, Leave Request, Live Agent, Question about leave request, Unknown, Update claim status
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to...

ğŸŒŠ ===== STREAM 7 PROCESSING START =====
â±ï¸  Stream 7 Start: 2025-08-12T16:32:39.134Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:32:39.134Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 882
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6382
   â€¢ Avg Per Session: 221 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6382
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 7) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6382
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 7: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:32:39.134Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 8
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:32:39.134Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6932,
  existingClassifications: { intents: 8, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim, Claim Status, Claim status, Leave Request, Live Agent, Question about leave request, Unknown, Update claim status
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to...

ğŸŒŠ ===== STREAM 8 PROCESSING START =====
â±ï¸  Stream 8 Start: 2025-08-12T16:32:39.134Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:32:39.134Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 922
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6422
   â€¢ Avg Per Session: 231 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6422
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 8) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6422
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 8: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:32:39.134Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 8
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:32:39.134Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7070,
  existingClassifications: { intents: 8, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim, Claim Status, Claim status, Leave Request, Live Agent, Question about leave request, Unknown, Update claim status
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to...
::1 - - [12/Aug/2025:16:32:39 +0000] "GET /api/analysis/auto-analyze/parallel/progress/0e17cda9-7c0d-45c6-81b3-a26d2e3afe15 HTTP/1.1" 200 1717 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:32:40.853Z',
  duration: '1721ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1976,
    completion_tokens: 186,
    total_tokens: 2162,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-14fe36a6-c3f0-54e5-8bb5-41bbfc978f0e",
      "notes": "User needed to update FMLA and was transferred to an agent after verification."
    },
    {
      "user_id": "u-dfae4a1c-64bc-55e9-9561-567b107752d0",
      "notes": "User reported an absence and submitted a time entry without transfer."
    },
    {
      "user_id": "u-519bdca8-2d1f-59d7-a125-ed05c63271a5",
      "notes": "User could not access account and was transferred to an agent."
    },
    {
      "user_id": "u-897fc911-1563-514f-aef3-2bf5446b3e3f",
      "notes": "User asked about FMLA and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1976,
  completionTokens: 186,
  totalTokens: 2162,
  cost: '$0.000272',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1721ms (1.72s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2162 ($0.0003)
âš¡ Performance: 1256.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1976
   â€¢ Completion Tokens: 186
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-14fe36a6-c3f0-54e5-8bb5-41bbfc978f0e: Invalid general_intent, u-14fe36a6-c3f0-54e5-8bb5-41bbfc978f0e: Invalid session_outcome, u-dfae4a1c-64bc-55e9-9561-567b107752d0: Invalid general_intent, u-dfae4a1c-64bc-55e9-9561-567b107752d0: Invalid session_outcome, u-519bdca8-2d1f-59d7-a125-ed05c63271a5: Invalid general_intent, u-519bdca8-2d1f-59d7-a125-ed05c63271a5: Invalid session_outcome, u-897fc911-1563-514f-aef3-2bf5446b3e3f: Invalid general_intent, u-897fc911-1563-514f-aef3-2bf5446b3e3f: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 1 Single Batch Time: 1722ms (1.72s)

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 1722ms (1.72s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2162 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.3 sessions/sec
âš¡ Avg Time Per Session: 430.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:32:40.868Z',
  duration: '1734ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1983,
    completion_tokens: 208,
    total_tokens: 2191,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-de5a6c4d-ff89-5e1a-834b-3a1e29b987b7",
      "notes": "User wanted to speak with an agent regarding leave of absence and FMLA leave, session was transferred to an agent."
    },
    {
      "user_id": "u-58becbd0-894a-5eeb-b179-c5410e721f48",
      "notes": "User provided leave request details and confirmed submission of time entry, no transfer occurred."
    },
    {
      "user_id": "u-c60120f3-32b0-54f9-9faf-07bda3299ecb",
      "notes": "User requested a leave form, session was transferred to an agent."
    },
    {
      "user_id": "u-5f97d2a2-9f15-5e07-9e5b-11feaf820a54",
      "notes": "User attempted to check time entry but was transferred to an agent after an unsuccessful attempt."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1983,
  completionTokens: 208,
  totalTokens: 2191,
  cost: '$0.000282',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1734ms (1.73s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2191 ($0.0003)
âš¡ Performance: 1263.6 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1983
   â€¢ Completion Tokens: 208
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-de5a6c4d-ff89-5e1a-834b-3a1e29b987b7: Invalid general_intent, u-de5a6c4d-ff89-5e1a-834b-3a1e29b987b7: Invalid session_outcome, u-58becbd0-894a-5eeb-b179-c5410e721f48: Invalid general_intent, u-58becbd0-894a-5eeb-b179-c5410e721f48: Invalid session_outcome, u-c60120f3-32b0-54f9-9faf-07bda3299ecb: Invalid general_intent, u-c60120f3-32b0-54f9-9faf-07bda3299ecb: Invalid session_outcome, u-5f97d2a2-9f15-5e07-9e5b-11feaf820a54: Invalid general_intent, u-5f97d2a2-9f15-5e07-9e5b-11feaf820a54: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 7 Single Batch Time: 1735ms (1.74s)

âœ… ===== STREAM 7 PROCESSING COMPLETE =====
â±ï¸  Stream 7 Total Time: 1735ms (1.74s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2191 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.3 sessions/sec
âš¡ Avg Time Per Session: 433.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:32:40.901Z',
  duration: '1768ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1748,
    completion_tokens: 191,
    total_tokens: 1939,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-de3db11f-27d1-5377-857d-8cc49d427165",
      "notes": "User wanted to speak with an agent, session was transferred to a live agent."
    },
    {
      "user_id": "u-2eb5c812-7237-5c28-8b56-c8849f28b249",
      "notes": "User wanted to speak with an agent, session was transferred to a live agent."
    },
    {
      "user_id": "u-e90a4f58-47af-576f-90ce-699b5ac0d765",
      "notes": "User asked for a representative, session was transferred to a live agent."
    },
    {
      "user_id": "u-16b00de8-3c10-5106-8cdf-453d7e505188",
      "notes": "User asked to talk to a representative, session was transferred to a live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1748,
  completionTokens: 191,
  totalTokens: 1939,
  cost: '$0.000251',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1768ms (1.77s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1939 ($0.0003)
âš¡ Performance: 1096.7 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1748
   â€¢ Completion Tokens: 191
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-de3db11f-27d1-5377-857d-8cc49d427165: Invalid general_intent, u-de3db11f-27d1-5377-857d-8cc49d427165: Invalid session_outcome, u-2eb5c812-7237-5c28-8b56-c8849f28b249: Invalid general_intent, u-2eb5c812-7237-5c28-8b56-c8849f28b249: Invalid session_outcome, u-e90a4f58-47af-576f-90ce-699b5ac0d765: Invalid general_intent, u-e90a4f58-47af-576f-90ce-699b5ac0d765: Invalid session_outcome, u-16b00de8-3c10-5106-8cdf-453d7e505188: Invalid general_intent, u-16b00de8-3c10-5106-8cdf-453d7e505188: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 2 Single Batch Time: 1768ms (1.77s)

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 1769ms (1.77s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1939 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.3 sessions/sec
âš¡ Avg Time Per Session: 442.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:32:40.953Z',
  duration: '1819ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1942,
    completion_tokens: 205,
    total_tokens: 2147,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-f95e3438-8716-5204-852a-371b2ff8fa67",
      "notes": "User wanted to speak with an agent but did not provide further input, session was transferred to an agent."
    },
    {
      "user_id": "u-41864219-53c5-5cca-ab71-5a00283cc528",
      "notes": "User wanted to speak with an agent but did not provide further input, session was transferred to an agent."
    },
    {
      "user_id": "u-fecf9ac7-1faf-58bf-aa42-ac13f7648eba",
      "notes": "User wanted to speak with an agent but did not provide further input, session was transferred to an agent."
    },
    {
      "user_id": "u-b51a7229-ed0b-5e5e-8666-e557994d6559",
      "notes": "User wanted to speak with an agent but did not provide further input, session was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1942,
  completionTokens: 205,
  totalTokens: 2147,
  cost: '$0.000276',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1821ms (1.82s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2147 ($0.0003)
âš¡ Performance: 1179.0 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1942
   â€¢ Completion Tokens: 205
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-f95e3438-8716-5204-852a-371b2ff8fa67: Invalid general_intent, u-f95e3438-8716-5204-852a-371b2ff8fa67: Invalid session_outcome, u-41864219-53c5-5cca-ab71-5a00283cc528: Invalid general_intent, u-41864219-53c5-5cca-ab71-5a00283cc528: Invalid session_outcome, u-fecf9ac7-1faf-58bf-aa42-ac13f7648eba: Invalid general_intent, u-fecf9ac7-1faf-58bf-aa42-ac13f7648eba: Invalid session_outcome, u-b51a7229-ed0b-5e5e-8666-e557994d6559: Invalid general_intent, u-b51a7229-ed0b-5e5e-8666-e557994d6559: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 5 Single Batch Time: 1821ms (1.82s)

âœ… ===== STREAM 5 PROCESSING COMPLETE =====
â±ï¸  Stream 5 Total Time: 1821ms (1.82s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2147 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.2 sessions/sec
âš¡ Avg Time Per Session: 455.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:32:41.365Z',
  duration: '2232ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2005,
    completion_tokens: 279,
    total_tokens: 2284,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'FMLA', 'Claim' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-fe747773-8270-5745-93dc-d565565a7ed7",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak to a representative and was transferred to an agent."
    },
    {
      "user_id": "u-473f29f5-8d8f-5b7f-a545-d59424a3255b",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested an agent and was transferred to a live agent."
    },
    {
      "user_id": "u-498e5dee-c7f0-580a-b19a-254785a09fe0",
      "general_intent": "FMLA",
      "session_outcome": "Contained",
      "notes": "User inquired about FMLA leave, verified account, and checked leave request status."
    },
    {
      "user_id": "u-04126375-8cb9-58a1-a092-22fb7e81b088",
      "general_intent": "Claim",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to file a claim but was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2005,
  completionTokens: 279,
  totalTokens: 2284,
  cost: '$0.000312',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2233ms (2.23s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2284 ($0.0003)
âš¡ Performance: 1022.8 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2005
   â€¢ Completion Tokens: 279
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 3 Single Batch Time: 2233ms (2.23s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 2234ms (2.23s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2284 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.8 sessions/sec
âš¡ Avg Time Per Session: 558.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:32:41.511Z',
  duration: '2378ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1676,
    completion_tokens: 289,
    total_tokens: 1965,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Leave Request', 'Claim' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-658c97ec-4558-58dd-b360-671da6c71d81",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User indicated intent to open a new leave request and was transferred to an agent."
    },
    {
      "user_id": "u-966e8602-8333-5912-98c3-84af7b57e8df",
      "general_intent": "Claim",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User expressed intent to file a claim but was transferred to an agent."
    },
    {
      "user_id": "u-e09ab0c2-b331-5df2-87e8-2c81d65c8fb5",
      "general_intent": "Leave Request",
      "session_outcome": "Contained",
      "notes": "User wanted an extension on FMLA but did not provide enough information, session was not transferred."
    },
    {
      "user_id": "u-ac9b48a6-2566-5b66-a4e1-ceedce20d8df",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1676,
  completionTokens: 289,
  totalTokens: 1965,
  cost: '$0.000283',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2378ms (2.38s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1965 ($0.0003)
âš¡ Performance: 826.3 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1676
   â€¢ Completion Tokens: 289
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 4 Single Batch Time: 2378ms (2.38s)

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 2378ms (2.38s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1965 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.7 sessions/sec
âš¡ Avg Time Per Session: 594.50ms
::1 - - [12/Aug/2025:16:32:41 +0000] "GET /api/analysis/auto-analyze/parallel/progress/0e17cda9-7c0d-45c6-81b3-a26d2e3afe15 HTTP/1.1" 200 1729 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:32:41.950Z',
  duration: '2816ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1667,
    completion_tokens: 183,
    total_tokens: 1850,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-1211dfed-ab69-54e2-b66c-3353656171ca",
      "notes": "User wanted to speak with an agent, session was transferred to a live agent."
    },
    {
      "user_id": "u-967d5044-b514-5a96-ab2f-629612faf474",
      "notes": "User requested leave, session was not transferred and was handled by bot."
    },
    {
      "user_id": "u-096ea020-27b8-5ecd-9d66-2884c67be145",
      "notes": "User wanted to apply for FMLA, session was transferred to a live agent."
    },
    {
      "user_id": "u-9055287b-bcfb-5439-94a0-f4e23f982edf",
      "notes": "User wanted to speak with an agent, session was transferred to a live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1667,
  completionTokens: 183,
  totalTokens: 1850,
  cost: '$0.000240',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2816ms (2.82s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1850 ($0.0002)
âš¡ Performance: 657.0 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1667
   â€¢ Completion Tokens: 183
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-1211dfed-ab69-54e2-b66c-3353656171ca: Invalid general_intent, u-1211dfed-ab69-54e2-b66c-3353656171ca: Invalid session_outcome, u-967d5044-b514-5a96-ab2f-629612faf474: Invalid general_intent, u-967d5044-b514-5a96-ab2f-629612faf474: Invalid session_outcome, u-096ea020-27b8-5ecd-9d66-2884c67be145: Invalid general_intent, u-096ea020-27b8-5ecd-9d66-2884c67be145: Invalid session_outcome, u-9055287b-bcfb-5439-94a0-f4e23f982edf: Invalid general_intent, u-9055287b-bcfb-5439-94a0-f4e23f982edf: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 6 Single Batch Time: 2816ms (2.82s)

âœ… ===== STREAM 6 PROCESSING COMPLETE =====
â±ï¸  Stream 6 Total Time: 2816ms (2.82s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1850 ($0.0002)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.4 sessions/sec
âš¡ Avg Time Per Session: 704.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:32:42.051Z',
  duration: '2917ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2002,
    completion_tokens: 292,
    total_tokens: 2294,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Leave Request' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-97a12900-df8f-5585-916f-fdbcbae04087",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent regarding FMLA leave questions."
    },
    {
      "user_id": "u-cf0885b3-390b-59b2-9444-365ea9ff1aa5",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent about questions related to leave requests."
    },
    {
      "user_id": "u-583c7f73-871c-58a0-a8c6-c5d8f2647356",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent about starting the process for FMLA paperwork."
    },
    {
      "user_id": "u-06d38663-c3ec-53a1-a667-d0b653968c50",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2002,
  completionTokens: 292,
  totalTokens: 2294,
  cost: '$0.000317',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2918ms (2.92s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2294 ($0.0003)
âš¡ Performance: 786.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2002
   â€¢ Completion Tokens: 292
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 8 Single Batch Time: 2918ms (2.92s)

âœ… ===== STREAM 8 PROCESSING COMPLETE =====
â±ï¸  Stream 8 Total Time: 2918ms (2.92s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2294 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.4 sessions/sec
âš¡ Avg Time Per Session: 729.50ms
[ParallelProcessingOrchestrator] Parallel processing complete: 8/8 streams succeeded
â±ï¸  Parallel Processing Time: 2920ms (2.92s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 8 streams
[ParallelProcessingOrchestrator] Synchronization complete: 1 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 1
ğŸ“Š Total Classifications: 11

âœ… ============ ROUND 2 COMPLETED ============
â±ï¸  Round 2 Total Time: 2920ms (2.92s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 21
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 2920ms (100.0%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ”„ ============ ROUND 3/3 STARTED ============
â±ï¸  Round 3 Start: 2025-08-12T16:32:42.052Z
ğŸ“Š Sessions Remaining: 21
[ParallelProcessingOrchestrator] Distributed 21 sessions across 6 streams: [
  'Stream 1: 4 sessions',
  'Stream 2: 4 sessions',
  'Stream 3: 4 sessions',
  'Stream 4: 4 sessions',
  'Stream 5: 4 sessions',
  'Stream 6: 1 sessions'
]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 6

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 6 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T16:32:42.052Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:32:42.052Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 854
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6354
   â€¢ Avg Per Session: 214 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6354
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6354
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:32:42.052Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 9
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:32:42.052Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6754,
  existingClassifications: { intents: 9, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim, Claim Status, Claim status, FMLA, Leave Request, Live Agent, Question about leave request, Unknown, Update claim status
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is try...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T16:32:42.052Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:32:42.052Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 941
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6441
   â€¢ Avg Per Session: 235 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6441
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6441
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:32:42.052Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 9
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:32:42.052Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7155,
  existingClassifications: { intents: 9, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim, Claim Status, Claim status, FMLA, Leave Request, Live Agent, Question about leave request, Unknown, Update claim status
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is try...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T16:32:42.052Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:32:42.052Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 668
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6168
   â€¢ Avg Per Session: 167 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6168
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6168
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:32:42.052Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 9
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:32:42.052Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5877,
  existingClassifications: { intents: 9, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim, Claim Status, Claim status, FMLA, Leave Request, Live Agent, Question about leave request, Unknown, Update claim status
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is try...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T16:32:42.053Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:32:42.053Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 1184
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6684
   â€¢ Avg Per Session: 296 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6684
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0011
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6684
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0011

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:32:42.053Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 9
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:32:42.053Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 8271,
  existingClassifications: { intents: 9, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim, Claim Status, Claim status, FMLA, Leave Request, Live Agent, Question about leave request, Unknown, Update claim status
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is try...

ğŸŒŠ ===== STREAM 5 PROCESSING START =====
â±ï¸  Stream 5 Start: 2025-08-12T16:32:42.053Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:32:42.053Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 1002
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6502
   â€¢ Avg Per Session: 251 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6502
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 5) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6502
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 5: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:32:42.053Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 9
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:32:42.053Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7406,
  existingClassifications: { intents: 9, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim, Claim Status, Claim status, FMLA, Leave Request, Live Agent, Question about leave request, Unknown, Update claim status
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is try...

ğŸŒŠ ===== STREAM 6 PROCESSING START =====
â±ï¸  Stream 6 Start: 2025-08-12T16:32:42.053Z
ğŸ“Š Sessions Assigned: 1
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:32:42.053Z
ğŸ“Š Sessions to Estimate: 1
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 1
   â€¢ Session Tokens: 134
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 5634
   â€¢ Avg Per Session: 134 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 5634
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0009
ğŸ“Š Recommended Batch Size: 1

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 6) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 5634
ğŸ“¦ Recommended Batch Size: 1
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0009

âš¡ Stream 6: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:32:42.053Z
ğŸ“Š Sessions to Analyze: 1
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 9
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:32:42.053Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 1,
  apiKey: 'sk-proj-...',
  promptLength: 3980,
  existingClassifications: { intents: 9, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim, Claim Status, Claim status, FMLA, Leave Request, Live Agent, Question about leave request, Unknown, Update claim status
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is try...
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:32:42.990Z',
  duration: '937ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1183,
    completion_tokens: 80,
    total_tokens: 1263,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 1,
  intentsFound: [ 'Leave Request' ],
  transferCount: 1,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-53ac7505-d015-5839-90a9-71aec6e44e18",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to file a claim but was transferred to an agent for leave request assistance."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1183,
  completionTokens: 80,
  totalTokens: 1263,
  cost: '$0.000150',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 938ms (0.94s)
ğŸ“Š Sessions Returned: 1
ğŸ’° Tokens Used: 1263 ($0.0002)
âš¡ Performance: 1346.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1183
   â€¢ Completion Tokens: 80
[SessionValidationService] Validating batch response: 1 input sessions, 1 response sessions
[SessionValidationService] Validation successful: all 1 sessions processed
[SessionValidationService] Validating batch response: 1 input sessions, 1 response sessions
[SessionValidationService] Validation successful: all 1 sessions processed
â±ï¸  Stream 6 Single Batch Time: 938ms (0.94s)

âœ… ===== STREAM 6 PROCESSING COMPLETE =====
â±ï¸  Stream 6 Total Time: 938ms (0.94s)
ğŸ“Š Sessions Processed: 1/1
ğŸ’° Tokens Used: 1263 ($0.0002)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.1 sessions/sec
âš¡ Avg Time Per Session: 938.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:32:43.536Z',
  duration: '1483ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2070,
    completion_tokens: 196,
    total_tokens: 2266,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-b2c85c77-c45b-5b21-9f25-96c909eef0ee",
      "notes": "User wanted to speak with a representative and was transferred to an agent."
    },
    {
      "user_id": "u-8e43ae42-cf37-5610-a6f5-473f200be9f4",
      "notes": "User wanted to speak with an agent and was transferred to an agent."
    },
    {
      "user_id": "u-8f14dc6b-d4f1-5b65-bb19-2d1e9f609422",
      "notes": "User requested leave of absence and was transferred to an agent for assistance."
    },
    {
      "user_id": "u-95a2e057-a55b-5cf5-b091-7fac3318d907",
      "notes": "User provided details about a leave request and successfully submitted a time entry, ending the session without transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2070,
  completionTokens: 196,
  totalTokens: 2266,
  cost: '$0.000285',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1483ms (1.48s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2266 ($0.0003)
âš¡ Performance: 1528.0 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2070
   â€¢ Completion Tokens: 196
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-b2c85c77-c45b-5b21-9f25-96c909eef0ee: Invalid general_intent, u-b2c85c77-c45b-5b21-9f25-96c909eef0ee: Invalid session_outcome, u-8e43ae42-cf37-5610-a6f5-473f200be9f4: Invalid general_intent, u-8e43ae42-cf37-5610-a6f5-473f200be9f4: Invalid session_outcome, u-8f14dc6b-d4f1-5b65-bb19-2d1e9f609422: Invalid general_intent, u-8f14dc6b-d4f1-5b65-bb19-2d1e9f609422: Invalid session_outcome, u-95a2e057-a55b-5cf5-b091-7fac3318d907: Invalid general_intent, u-95a2e057-a55b-5cf5-b091-7fac3318d907: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 5 Single Batch Time: 1483ms (1.48s)

âœ… ===== STREAM 5 PROCESSING COMPLETE =====
â±ï¸  Stream 5 Total Time: 1483ms (1.48s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2266 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.7 sessions/sec
âš¡ Avg Time Per Session: 370.75ms
::1 - - [12/Aug/2025:16:32:43 +0000] "GET /api/analysis/auto-analyze/parallel/progress/0e17cda9-7c0d-45c6-81b3-a26d2e3afe15 HTTP/1.1" 200 1531 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:32:43.982Z',
  duration: '1930ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2026,
    completion_tokens: 209,
    total_tokens: 2235,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-7142eab7-a13a-575f-8e6b-120a99b87df5",
      "notes": "User attempted to access leave request information and was transferred to an agent when requesting to open a new leave request."
    },
    {
      "user_id": "u-0afcbb17-d319-5547-a823-7022e4105f1b",
      "notes": "User wanted to report a return to work date and was transferred to an agent when unable to do so due to leave request status."
    },
    {
      "user_id": "u-8126563b-e494-55d5-9511-40288ef17b49",
      "notes": "User asked for claim help, was prompted for leave request number, and was transferred to an agent."
    },
    {
      "user_id": "u-8921d8e3-285c-5008-a087-9cb991c7462e",
      "notes": "User wanted to file a claim and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2026,
  completionTokens: 209,
  totalTokens: 2235,
  cost: '$0.000286',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1931ms (1.93s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2235 ($0.0003)
âš¡ Performance: 1157.4 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2026
   â€¢ Completion Tokens: 209
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-7142eab7-a13a-575f-8e6b-120a99b87df5: Invalid general_intent, u-7142eab7-a13a-575f-8e6b-120a99b87df5: Invalid session_outcome, u-0afcbb17-d319-5547-a823-7022e4105f1b: Invalid general_intent, u-0afcbb17-d319-5547-a823-7022e4105f1b: Invalid session_outcome, u-8126563b-e494-55d5-9511-40288ef17b49: Invalid general_intent, u-8126563b-e494-55d5-9511-40288ef17b49: Invalid session_outcome, u-8921d8e3-285c-5008-a087-9cb991c7462e: Invalid general_intent, u-8921d8e3-285c-5008-a087-9cb991c7462e: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 2 Single Batch Time: 1931ms (1.93s)

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 1931ms (1.93s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2235 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.1 sessions/sec
âš¡ Avg Time Per Session: 482.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:32:44.140Z',
  duration: '2087ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2285,
    completion_tokens: 285,
    total_tokens: 2570,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Time Entry', 'Question about leave request', 'Leave Request' ],
  transferCount: 2,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-5add6d4d-2cc4-59bd-bd1e-ebdf5cb8fa83",
      "general_intent": "Time Entry",
      "session_outcome": "Contained",
      "notes": "User provided details for submitting a time entry for leave due to treatment, which was successfully submitted."
    },
    {
      "user_id": "u-89c952e4-2057-5483-9001-ae326ccb454e",
      "general_intent": "Time Entry",
      "session_outcome": "Contained",
      "notes": "User provided details for submitting a time entry for leave due to an episode of incapacity, which was successfully submitted."
    },
    {
      "user_id": "u-bca92f2e-07af-5056-9729-2fcceab578d7",
      "general_intent": "Question about leave request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent regarding leave request."
    },
    {
      "user_id": "u-2c88bfee-7fbf-5580-9a65-a9ee258e2096",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to initiate a new FMLA leave request and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2285,
  completionTokens: 285,
  totalTokens: 2570,
  cost: '$0.000343',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2087ms (2.09s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2570 ($0.0003)
âš¡ Performance: 1231.4 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2285
   â€¢ Completion Tokens: 285
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 4 Single Batch Time: 2087ms (2.09s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 2087ms (2.09s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2570 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.9 sessions/sec
âš¡ Avg Time Per Session: 521.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:32:44.195Z',
  duration: '2143ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1913,
    completion_tokens: 291,
    total_tokens: 2204,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'FMLA', 'Leave Request', 'Live Agent' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-2be80988-5360-5c39-9a99-d3b6b05b8012",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User inquired about receiving paperwork for FMLA and was transferred to an agent."
    },
    {
      "user_id": "u-b002faaf-a675-5cc4-8530-b30f4d7d81a6",
      "general_intent": "Leave Request",
      "session_outcome": "Contained",
      "notes": "User provided leave request number, employee number, zip code, and details about time absence, successfully submitting a time entry."
    },
    {
      "user_id": "u-4dc39776-d3bc-5b7d-8138-8c713fe673fb",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-046312a9-e331-5d87-91bf-18f55f78202e",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1913,
  completionTokens: 291,
  totalTokens: 2204,
  cost: '$0.000308',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2143ms (2.14s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2204 ($0.0003)
âš¡ Performance: 1028.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1913
   â€¢ Completion Tokens: 291
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 1 Single Batch Time: 2143ms (2.14s)

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 2143ms (2.14s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2204 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.9 sessions/sec
âš¡ Avg Time Per Session: 535.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:32:44.211Z',
  duration: '2158ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1697,
    completion_tokens: 276,
    total_tokens: 1973,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Leave Request', 'Unknown', 'FMLA' ],
  transferCount: 2,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-f1dde317-1248-5dbb8729-23ba27a0d6b1",
      "general_intent": "Leave Request",
      "session_outcome": "Contained",
      "notes": "User was silent and did not specify further, session was not transferred."
    },
    {
      "user_id": "u-fe00876b-298c-5ee5-bc06-072a4b980dbf",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User was very upset and ended the call without further interaction, session was not transferred."
    },
    {
      "user_id": "u-c939b308-1500-5251-b017-2d572d3a2ecd",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to change FMLA dates and requested to speak with an agent, session was transferred."
    },
    {
      "user_id": "u-55a1e1d4-d19f-5ca3-8658-3ef9f38695f3",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and requested help, session was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1697,
  completionTokens: 276,
  totalTokens: 1973,
  cost: '$0.000280',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2159ms (2.16s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1973 ($0.0003)
âš¡ Performance: 913.8 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1697
   â€¢ Completion Tokens: 276
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 1,
  errors: 1,
  details: [
    'Unexpected sessions in response: u-f1dde317-1248-5dbb8729-23ba27a0d6b1'
  ]
}
[Stream 3] 1 sessions missing, attempting retries

ğŸ”„ ===== RETRY 1/3 (Stream 3) =====
â±ï¸  Retry Start: 2025-08-12T16:32:44.211Z
ğŸ“Š Missing Sessions: 1

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:32:44.211Z
ğŸ“Š Sessions to Analyze: 1
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 9
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:32:44.211Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 1,
  apiKey: 'sk-proj-...',
  promptLength: 3876,
  existingClassifications: { intents: 9, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim, Claim Status, Claim status, FMLA, Leave Request, Live Agent, Question about leave request, Unknown, Update claim status
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is try...
::1 - - [12/Aug/2025:16:32:45 +0000] "GET /api/analysis/auto-analyze/parallel/progress/0e17cda9-7c0d-45c6-81b3-a26d2e3afe15 HTTP/1.1" 200 1537 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:32:46.206Z',
  duration: '1995ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1166,
    completion_tokens: 67,
    total_tokens: 1233,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 1,
  intentsFound: [ 'Leave Request' ],
  transferCount: 0,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-f1dde317-1248-5dbb-8729-23ba27a0d6b1",
      "general_intent": "Leave Request",
      "session_outcome": "Contained",
      "notes": "Bot asked if user was calling to open a new leave request after user was silent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1166,
  completionTokens: 67,
  totalTokens: 1233,
  cost: '$0.000143',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1995ms (2.00s)
ğŸ“Š Sessions Returned: 1
ğŸ’° Tokens Used: 1233 ($0.0001)
âš¡ Performance: 618.0 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1166
   â€¢ Completion Tokens: 67
[SessionValidationService] Validating batch response: 1 input sessions, 1 response sessions
[SessionValidationService] Validation successful: all 1 sessions processed
[SessionValidationService] Merging 3 original + 1 retry results
[SessionValidationService] Merge complete: 4 total sessions
âœ… Stream 3 Retry 1 Results:
   â€¢ Processed: 1 sessions
   â€¢ Still Missing: 0 sessions
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 3 Single Batch Time: 4156ms (4.16s)

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 4156ms (4.16s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 3206 ($0.0004)
ğŸ”„ Retry Attempts: 1
ğŸ¯ Performance: 1.0 sessions/sec
âš¡ Avg Time Per Session: 1039.00ms
[ParallelProcessingOrchestrator] Parallel processing complete: 6/6 streams succeeded
â±ï¸  Parallel Processing Time: 4156ms (4.16s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 6 streams
[ParallelProcessingOrchestrator] Synchronization complete: 1 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 1
ğŸ“Š Total Classifications: 12

âœ… ============ ROUND 3 COMPLETED ============
â±ï¸  Round 3 Total Time: 4156ms (4.16s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 0
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 4156ms (100.0%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ‰ ============ PARALLEL PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 10515ms (10.52s)
ğŸ“Š Sessions Processed: 85/85
ğŸ”„ Total Rounds: 3
ğŸŒŠ Stream Results: 22
ğŸ’° Token Usage: 47192 tokens ($0.0063)
ğŸ“ˆ Stream Utilization: 100.0%
ğŸ¯ Performance: 8.1 sessions/second
âš¡ Avg Time Per Session: 123.71ms

ğŸ“Š Stream Performance Breakdown:
   Stream 1: 4 sessions in 1992ms (1090.4 tokens/sec)
   Stream 2: 4 sessions in 3438ms (617.2 tokens/sec)
   Stream 3: 4 sessions in 1733ms (1203.1 tokens/sec)
   Stream 4: 4 sessions in 1684ms (1188.8 tokens/sec)
   Stream 5: 4 sessions in 1546ms (1470.2 tokens/sec)
   Stream 6: 4 sessions in 1863ms (1073.5 tokens/sec)
   Stream 7: 4 sessions in 2014ms (969.2 tokens/sec)
   Stream 8: 4 sessions in 2870ms (700.3 tokens/sec)
   Stream 1: 4 sessions in 1722ms (1255.5 tokens/sec)
   Stream 2: 4 sessions in 1769ms (1096.1 tokens/sec)
   Stream 3: 4 sessions in 2234ms (1022.4 tokens/sec)
   Stream 4: 4 sessions in 2378ms (826.3 tokens/sec)
   Stream 5: 4 sessions in 1821ms (1179.0 tokens/sec)
   Stream 6: 4 sessions in 2816ms (657.0 tokens/sec)
   Stream 7: 4 sessions in 1735ms (1262.8 tokens/sec)
   Stream 8: 4 sessions in 2918ms (786.2 tokens/sec)
   Stream 1: 4 sessions in 2143ms (1028.5 tokens/sec)
   Stream 2: 4 sessions in 1931ms (1157.4 tokens/sec)
   Stream 3: 4 sessions in 4156ms (771.4 tokens/sec)
   Stream 4: 4 sessions in 2087ms (1231.4 tokens/sec)
   Stream 5: 4 sessions in 1483ms (1528.0 tokens/sec)
   Stream 6: 1 sessions in 938ms (1346.5 tokens/sec)
[ConflictResolutionService] Starting conflict resolution for 99 sessions
[ConflictResolutionService] Found classifications: { intents: 10, reasons: 1, locations: 1 }
[ConflictResolutionService] Calling LLM for conflict resolution with model gpt-4.1-nano
ğŸ”§ Conflict Resolution Prompt Preview: You are reviewing classifications from parallel analysis streams. Identify any semantic duplicates and choose the canonical version for each group.

**Instructions:**
1. Look for classifications that refer to the same concept but use different wording
2. For each group of duplicates, choose the most...
::1 - - [12/Aug/2025:16:32:47 +0000] "GET /api/analysis/auto-analyze/parallel/progress/0e17cda9-7c0d-45c6-81b3-a26d2e3afe15 HTTP/1.1" 200 1539 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[ConflictResolutionService] LLM conflict resolution complete: { intents: 6, reasons: 1, locations: 1, tokens: 777, cost: 0.0001158 }
ğŸ”§ Conflict Resolution Response: {
  "generalIntents": [
    {
      "canonical": "Claim Inquiry",
      "aliases": [
        "Claim",
        "Claim Status",
        "Claim status",
        "Update claim status"
      ]
    },
    {
      "canonical": "Leave Request Inquiry",
      "aliases": [
        "Leave Request",
        "Question about leave request"
      ]
    },
    {
      "canonical": "FMLA Inquiry",
      "aliases": [
        "FMLA"
      ]
    },
    {
      "canonical": "Time Entry",
      "aliases": [
        "Time Entry"
      ]
    },
    {
      "canonical": "Unknown",
      "aliases": [
        "Unknown"
      ]
    },
    {
      "canonical": "Live Agent Support",
      "aliases": [
        "Live Agent"
      ]
    }
  ],
  "transferReasons": [
    {
      "canonical": "Customer Support Request",
      "aliases": [
        "Live Agent Request"
      ]
    }
  ],
  "dropOffLocations": [
    {
      "canonical": "Help Offer Prompt",
      "aliases": [
        "Help Offer Prompt"
      ]
    }
  ]
}
[ConflictResolutionService] Applying resolutions to 99 sessions
[ConflictResolutionService] Applied 102 classification mappings across 99 sessions
[ConflictResolutionService] Identified 2 potential conflict groups
[ConflictResolutionService] Conflict resolution complete in 1983ms: { conflictsFound: 2, conflictsResolved: 8, canonicalMappings: 12 }
[ParallelAutoAnalyzeService] Using real analysis summary service
::1 - - [12/Aug/2025:16:32:49 +0000] "GET /api/analysis/auto-analyze/parallel/progress/0e17cda9-7c0d-45c6-81b3-a26d2e3afe15 HTTP/1.1" 200 1621 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:32:51 +0000] "GET /api/analysis/auto-analyze/parallel/progress/0e17cda9-7c0d-45c6-81b3-a26d2e3afe15 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:32:53 +0000] "GET /api/analysis/auto-analyze/parallel/progress/0e17cda9-7c0d-45c6-81b3-a26d2e3afe15 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:32:55 +0000] "GET /api/analysis/auto-analyze/parallel/progress/0e17cda9-7c0d-45c6-81b3-a26d2e3afe15 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:32:57 +0000] "GET /api/analysis/auto-analyze/parallel/progress/0e17cda9-7c0d-45c6-81b3-a26d2e3afe15 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:32:59 +0000] "GET /api/analysis/auto-analyze/parallel/progress/0e17cda9-7c0d-45c6-81b3-a26d2e3afe15 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:33:01 +0000] "GET /api/analysis/auto-analyze/parallel/progress/0e17cda9-7c0d-45c6-81b3-a26d2e3afe15 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:33:03 +0000] "GET /api/analysis/auto-analyze/parallel/progress/0e17cda9-7c0d-45c6-81b3-a26d2e3afe15 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:33:05 +0000] "GET /api/analysis/auto-analyze/parallel/progress/0e17cda9-7c0d-45c6-81b3-a26d2e3afe15 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[ParallelAutoAnalyzeService] Parallel analysis 0e17cda9-7c0d-45c6-81b3-a26d2e3afe15 completed successfully
[BackgroundJobQueue] Updated job progress to final state: complete
[BackgroundJobQueue] Parallel analysis job 0e17cda9-7c0d-45c6-81b3-a26d2e3afe15-parallel completed successfully
::1 - - [12/Aug/2025:16:33:07 +0000] "GET /api/analysis/auto-analyze/parallel/progress/0e17cda9-7c0d-45c6-81b3-a26d2e3afe15 HTTP/1.1" 200 1661 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:33:07 +0000] "GET /api/analysis/auto-analyze/parallel/results/0e17cda9-7c0d-45c6-81b3-a26d2e3afe15 HTTP/1.1" 200 699272 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T16:41:41.061Z",
  "dateTo": "2025-08-12T16:42:41.061Z",
  "skip": 0,
  "limit": 1
}
[fetchContainmentTypeMetadata] API Response: 1 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [ '689b6ec86ebd43e3e632d19c' ]
[getSessionsMetadataForConnectionTest] Single API call succeeded with 1 sessions
::1 - - [12/Aug/2025:16:42:44 +0000] "GET /api/kore/test HTTP/1.1" 200 851 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸš€ [ParallelAutoAnalyzeRoute] Starting parallel analysis for bot ***REMOVED*** with real credentials
ğŸš€ [ParallelAutoAnalyzeService] Starting parallel analysis c296fa3c-a256-48b7-9b42-59a6b04dbdad with bot ***REMOVED***
ğŸš€ [ParallelAutoAnalyzeService] Using credentials: real
ğŸš€ [ParallelAutoAnalyzeRoute] Parallel analysis started: c296fa3c-a256-48b7-9b42-59a6b04dbdad
::1 - - [12/Aug/2025:16:42:49 +0000] "POST /api/analysis/auto-analyze/parallel/start HTTP/1.1" 200 214 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:42:49 +0000] "GET /api/analysis/auto-analyze/parallel/progress/c296fa3c-a256-48b7-9b42-59a6b04dbdad HTTP/1.1" 200 540 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:42:49 +0000] "GET /api/analysis/auto-analyze/parallel/progress/c296fa3c-a256-48b7-9b42-59a6b04dbdad HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[BackgroundJobQueue] Starting job processing after delay for job c296fa3c-a256-48b7-9b42-59a6b04dbdad-parallel
[BackgroundJobQueue] Starting processing for job c296fa3c-a256-48b7-9b42-59a6b04dbdad-parallel, phase: sampling
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing parallel analysis job c296fa3c-a256-48b7-9b42-59a6b04dbdad-parallel
[BackgroundJobQueue] Processing parallel analysis for bot ***REMOVED***
[BackgroundJobQueue] Using existing ParallelAutoAnalyzeService instance for bot ***REMOVED***
[BackgroundJobQueue] Session recreated for c296fa3c-a256-48b7-9b42-59a6b04dbdad
[ParallelAutoAnalyzeService] Running parallel analysis for c296fa3c-a256-48b7-9b42-59a6b04dbdad
[ParallelAutoAnalyzeService] Phase 0: Starting session sampling for c296fa3c-a256-48b7-9b42-59a6b04dbdad

ğŸ• ============ SESSION SAMPLING STARTED ============
ğŸ• [SessionSampling] Starting session sampling at 2025-08-12T16:42:50.303Z
ğŸ” [SessionDiscovery] Starting window 1/4: Initial 3-hour window
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
::1 - - [12/Aug/2025:16:42:51 +0000] "GET /api/analysis/auto-analyze/parallel/progress/c296fa3c-a256-48b7-9b42-59a6b04dbdad HTTP/1.1" 200 711 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:42:53 +0000] "GET /api/analysis/auto-analyze/parallel/progress/c296fa3c-a256-48b7-9b42-59a6b04dbdad HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 80 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a1287849680ad9fe59e',
  '689229f9583056c6108e38fb',
  '68922914f8bee7ba6c3e67b8'
]
[fetchContainmentTypeMetadata] API Response: 139 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6a14dd27c3112087cd',
  '68922a22ef03d8ad2ec7b4ba',
  '68922a1278c1fe09a079719c'
]
::1 - - [12/Aug/2025:16:42:55 +0000] "GET /api/analysis/auto-analyze/parallel/progress/c296fa3c-a256-48b7-9b42-59a6b04dbdad HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 1338 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6d14dd27c31120888b',
  '68922a62e3804084741191d5',
  '68922a523a3160d25de144c8'
]
[getSessionsMetadata] agent API call succeeded with 1338 sessions
[getSessionsMetadata] selfService API call succeeded with 80 sessions
[getSessionsMetadata] dropOff API call succeeded with 139 sessions
Total session metadata retrieved: 1557 (parallel execution)
Creating 1557 SWTs from metadata (no messages)
Created 1557 SWT objects from metadata
âœ… [SessionDiscovery] Window 1 completed in 5312ms: found 1557 new sessions (total: 1557)
â±ï¸  TIMING: Window 1 took 5312ms (5.31s)
ğŸ¯ [SessionDiscovery] Target reached! Found 1557 sessions in 5312ms
ğŸ² [SessionSampling] Random sampling from 1557 sessions to 5 sessions

ğŸ“¬ ============ MESSAGE RETRIEVAL STARTED ============
ğŸ“¬ [MessageRetrieval] Starting message retrieval for 5 sampled sessions at 2025-08-12T16:42:55.616Z
Using new lazy loading approach to populate messages for 5 sampled sessions
Populating messages for 5 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 5 sessions from 2025-08-05T13:11:23.179Z to 2025-08-05T15:16:06.166Z at 2025-08-12T16:42:55.616Z
ğŸ”„ [KoreAPI] Using single API call for 5 sessions (â‰¤20)
âœ… [KoreAPI] Single call completed in 178ms: 57 messages
Retrieved 57 messages for 5 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
Populated messages for 5 SWT objects
Successfully populated messages for 5 sessions using lazy loading
Applying final filtering to 5 sessions with populated messages
Final result: 5 sessions passed filtering with populated messages

ğŸ‰ ============ SESSION SAMPLING COMPLETED ============
â±ï¸  TOTAL TIME: 5492ms (5.49s)
â±ï¸  Session Discovery: 5312ms (5.31s) - 96.7% of total
â±ï¸  Message Retrieval: 180ms (0.18s) - 3.3% of total
â±ï¸  Performance: 0.9 sessions/second
ğŸ¯ Final result: 5 sessions with messages retrieved
====================================================

[StrategicDiscoveryService] Starting discovery phase with 5 total sessions
[StrategicDiscoveryService] Discovery config: {
  targetPercentage: 15,
  minSessions: 5,
  maxSessions: 5,
  diversityStrategy: {
    sessionLengths: [ 'short', 'medium', 'long' ],
    containmentTypes: [ 'agent', 'selfService', 'dropOff' ],
    timeDistribution: 'spread'
  }
}
[StrategicDiscoveryService] Selecting 5 diverse sessions from 5 total
[StrategicDiscoveryService] Selected 5 sessions for discovery

ğŸ“¦ ===== BATCH 14 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:42:55.795Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 0
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:42:55.795Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:42:55.796Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6515,
  existingClassifications: { intents: 0, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.



For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and another intent, classify the intent as the other i...
::1 - - [12/Aug/2025:16:42:57 +0000] "GET /api/analysis/auto-analyze/parallel/progress/c296fa3c-a256-48b7-9b42-59a6b04dbdad HTTP/1.1" 200 816 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:42:59.129Z',
  duration: '3333ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1904,
    completion_tokens: 283,
    total_tokens: 2187,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Unknown', 'Time entry' ],
  transferCount: 3,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-34d87a6e-c6da-53cf-8a6e-7357f5d8a785",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-b002faaf-a675-5cc4-8530-b30f4d7d81a6",
      "general_intent": "Time entry",
      "session_outcome": "Contained",
      "notes": "User verified account details and successfully submitted a time entry."
    },
    {
      "user_id": "u-86069c83-e34c-5530-aa75-4fd93b8fb21c",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User was silent and did not provide input; session was closed."
    },
    {
      "user_id": "u-aefdd380-ada3-5e11-bb64-fb4e49982de5",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-b5036189-a7c4-5aab-92d1-ceda7591af82",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1904,
  completionTokens: 283,
  totalTokens: 2187,
  cost: '$0.000304',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 3334ms (3.33s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2187 ($0.0003)
âš¡ Performance: 656.0 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 3334ms (3.33s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2187

âœ… ===== BATCH 14 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 3334ms (3.33s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2187 ($0.0003)
âš¡ Performance: 1.5 sessions/sec
âš¡ Avg Time Per Session: 666.80ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 1 complete: 4 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 2, reasons: 1, locations: 1, total: 4 }
[StrategicDiscoveryService] Discovery phase complete: {
  totalProcessed: 5,
  uniqueIntents: 2,
  uniqueReasons: 1,
  uniqueLocations: 1,
  discoveryRate: 0.26666666666666666
}

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T16:42:59.130Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms
[ParallelProcessingOrchestrator] Configuration for 0 sessions:
  Design: 8 streams Ã— 4 sessions = 32 per round
  Optimal: 1 streams Ã— 0 sessions = 0 per round
  Estimated Rounds: NaN
[ParallelAutoAnalyzeService] Using parallel config: {
  streamCount: 1,
  sessionsPerStream: 0,
  maxSessionsPerLLMCall: 50,
  syncFrequency: 'after_each_round',
  retryAttempts: 3,
  debugLogging: false
}

ğŸš€ ============ PARALLEL PROCESSING STARTED ============
â±ï¸  Start Time: 2025-08-12T16:42:59.130Z
ğŸ“Š Total Sessions: 0

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T16:42:59.130Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms

âš™ï¸  ============ PARALLEL CONFIGURATION ============
â±ï¸  Config Time: 0ms
ğŸ”§ Stream Count: 1
ğŸ“¦ Sessions Per Stream: 0
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per API Call: 50
ğŸ¯ Debug Logging: false

ğŸ‰ ============ PARALLEL PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 0ms (0.00s)
ğŸ“Š Sessions Processed: 0/0
ğŸ”„ Total Rounds: 0
ğŸŒŠ Stream Results: 0
ğŸ’° Token Usage: 0 tokens ($0.0000)
ğŸ“ˆ Stream Utilization: 0.0%
ğŸ¯ Performance: NaN sessions/second
âš¡ Avg Time Per Session: NaNms

ğŸ“Š Stream Performance Breakdown:
[ConflictResolutionService] Starting conflict resolution for 5 sessions
[ConflictResolutionService] Found classifications: { intents: 2, reasons: 1, locations: 1 }
[ConflictResolutionService] No conflicts detected, skipping resolution
[ParallelAutoAnalyzeService] Using real analysis summary service
::1 - - [12/Aug/2025:16:42:59 +0000] "GET /api/analysis/auto-analyze/parallel/progress/c296fa3c-a256-48b7-9b42-59a6b04dbdad HTTP/1.1" 200 935 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:43:01 +0000] "GET /api/analysis/auto-analyze/parallel/progress/c296fa3c-a256-48b7-9b42-59a6b04dbdad HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:43:03 +0000] "GET /api/analysis/auto-analyze/parallel/progress/c296fa3c-a256-48b7-9b42-59a6b04dbdad HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:43:05 +0000] "GET /api/analysis/auto-analyze/parallel/progress/c296fa3c-a256-48b7-9b42-59a6b04dbdad HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:43:07 +0000] "GET /api/analysis/auto-analyze/parallel/progress/c296fa3c-a256-48b7-9b42-59a6b04dbdad HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:43:09 +0000] "GET /api/analysis/auto-analyze/parallel/progress/c296fa3c-a256-48b7-9b42-59a6b04dbdad HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:43:11 +0000] "GET /api/analysis/auto-analyze/parallel/progress/c296fa3c-a256-48b7-9b42-59a6b04dbdad HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:43:13 +0000] "GET /api/analysis/auto-analyze/parallel/progress/c296fa3c-a256-48b7-9b42-59a6b04dbdad HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[ParallelAutoAnalyzeService] Parallel analysis c296fa3c-a256-48b7-9b42-59a6b04dbdad completed successfully
[BackgroundJobQueue] Updated job progress to final state: complete
[BackgroundJobQueue] Parallel analysis job c296fa3c-a256-48b7-9b42-59a6b04dbdad-parallel completed successfully
::1 - - [12/Aug/2025:16:43:15 +0000] "GET /api/analysis/auto-analyze/parallel/progress/c296fa3c-a256-48b7-9b42-59a6b04dbdad HTTP/1.1" 200 974 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:43:15 +0000] "GET /api/analysis/auto-analyze/parallel/results/c296fa3c-a256-48b7-9b42-59a6b04dbdad HTTP/1.1" 200 35777 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
12:46:44 PM [tsx] change in ./src/services/backgroundJobQueue.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T16:46:42.424Z",
  "dateTo": "2025-08-12T16:47:42.424Z",
  "skip": 0,
  "limit": 1
}
[fetchContainmentTypeMetadata] API Response: 1 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [ '689b70088b529fd4faafe2fb' ]
[getSessionsMetadataForConnectionTest] Single API call succeeded with 1 sessions
::1 - - [12/Aug/2025:16:47:45 +0000] "GET /api/kore/test HTTP/1.1" 200 851 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[Direct API] Fetching real Kore.ai sessions from 2025-08-05T16:47:46.179Z to 2025-08-12T16:47:46.179Z for User Bot st-90549... (limit=50)
Retrieving sessions from 2025-08-05T16:47:46.179Z to 2025-08-12T16:47:46.179Z (limit=50), populateMessages=true...
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T16:47:46.179Z",
  "dateTo": "2025-08-12T16:47:46.179Z",
  "limit": 50
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T16:47:46.179Z",
  "dateTo": "2025-08-12T16:47:46.179Z",
  "skip": 0,
  "limit": 50
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T16:47:46.179Z",
  "dateTo": "2025-08-12T16:47:46.179Z",
  "skip": 0,
  "limit": 50
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T16:47:46.179Z",
  "dateTo": "2025-08-12T16:47:46.179Z",
  "skip": 0,
  "limit": 50
}
::1 - - [12/Aug/2025:16:47:46 +0000] "GET /api/analysis/sessions?limit=50 HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 50 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b702905a45fff8905ef21',
  '689b6fef3360bd076e169921',
  '689b6fd90cef90d203028bf0'
]
[fetchContainmentTypeMetadata] API Response: 50 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b6b62f4e07e53775771df',
  '689b6b29a672546ebf5589e5',
  '689b6a969dd6aafc5d9309c5'
]
[fetchContainmentTypeMetadata] API Response: 50 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b700e8c094d6aa01dd57a',
  '689b70088b529fd4faafe2fb',
  '689b700004e268eb7c17d203'
]
[getSessionsMetadata] agent API call succeeded with 50 sessions
[getSessionsMetadata] selfService API call succeeded with 50 sessions
[getSessionsMetadata] dropOff API call succeeded with 50 sessions
Total session metadata retrieved: 150 (parallel execution)
Retrieved 150 session metadata objects
Creating 150 SWTs from metadata (no messages)
Created 150 SWT objects from metadata
Populating messages for all sessions (legacy behavior)
Populating messages for 150 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 150 sessions from 2025-08-12T15:27:42.917Z to 2025-08-12T16:47:47.264Z at 2025-08-12T16:47:54.166Z
ğŸš€ [ConcurrentBatch] Split 150 sessions into 8 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/8] Starting: 20 sessions
[Batch 2/8] Starting: 20 sessions
[Batch 3/8] Starting: 20 sessions
[Batch 4/8] Starting: 20 sessions
[Batch 5/8] Starting: 20 sessions
[Batch 6/8] Starting: 20 sessions
[Batch 7/8] Starting: 20 sessions
[Batch 8/8] Starting: 10 sessions
[Batch 1/8] Completed in 208ms: 217 messages retrieved (1/8 done)
[Batch 3/8] Completed in 211ms: 244 messages retrieved (2/8 done)
[Batch 2/8] Completed in 242ms: 262 messages retrieved (3/8 done)
[Batch 8/8] Completed in 395ms: 101 messages retrieved (4/8 done)
[Batch 7/8] Completed in 579ms: 208 messages retrieved (5/8 done)
[Batch 6/8] Completed in 618ms: 265 messages retrieved (6/8 done)
[Batch 4/8] Completed in 638ms: 328 messages retrieved (7/8 done)
[Batch 5/8] Completed in 767ms: 444 messages retrieved (8/8 done)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 768ms (0.77s)
â±ï¸  Batch Processing: 768ms (0.77s)
ğŸ“¦ Total batches: 8 (max 10 concurrent)
âœ… Successful batches: 8/8
ğŸ’¬ Total messages: 2069
ğŸ“ˆ Avg time per batch: 96ms
ğŸš€ Time per session: 5ms
ğŸ’ª Performance: 195.3 sessions/second
=======================================================

Retrieved 2069 messages for 150 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
Populated messages for 150 SWT objects
Generated 150 SWT objects in 8776ms using layered architecture
ğŸš€ [ParallelAutoAnalyzeRoute] Starting parallel analysis for bot ***REMOVED*** with real credentials
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
ğŸ­ ServiceFactory: Creating OpenAI service (type: real)
ğŸš€ [ParallelAutoAnalyzeService] Starting parallel analysis 3c88b8e1-926f-4b7b-a86a-ce0150f3af46 with bot ***REMOVED***
ğŸš€ [ParallelAutoAnalyzeService] Using credentials: real
ğŸš€ [ParallelAutoAnalyzeRoute] Parallel analysis started: 3c88b8e1-926f-4b7b-a86a-ce0150f3af46
::1 - - [12/Aug/2025:16:48:04 +0000] "POST /api/analysis/auto-analyze/parallel/start HTTP/1.1" 200 214 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:48:04 +0000] "GET /api/analysis/auto-analyze/parallel/progress/3c88b8e1-926f-4b7b-a86a-ce0150f3af46 HTTP/1.1" 200 541 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:48:04 +0000] "GET /api/analysis/auto-analyze/parallel/progress/3c88b8e1-926f-4b7b-a86a-ce0150f3af46 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[BackgroundJobQueue] Starting job processing after delay for job 3c88b8e1-926f-4b7b-a86a-ce0150f3af46-parallel
[BackgroundJobQueue] Starting processing for job 3c88b8e1-926f-4b7b-a86a-ce0150f3af46-parallel, phase: sampling
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing parallel analysis job 3c88b8e1-926f-4b7b-a86a-ce0150f3af46-parallel
[BackgroundJobQueue] Processing parallel analysis for bot ***REMOVED***
[BackgroundJobQueue] Using existing ParallelAutoAnalyzeService instance for bot ***REMOVED***
[BackgroundJobQueue] Session recreated for 3c88b8e1-926f-4b7b-a86a-ce0150f3af46
[ParallelAutoAnalyzeService] Running parallel analysis for 3c88b8e1-926f-4b7b-a86a-ce0150f3af46
[ParallelAutoAnalyzeService] Phase 0: Starting session sampling for 3c88b8e1-926f-4b7b-a86a-ce0150f3af46

ğŸ• ============ SESSION SAMPLING STARTED ============
ğŸ• [SessionSampling] Starting session sampling at 2025-08-12T16:48:05.718Z
ğŸ” [SessionDiscovery] Starting window 1/4: Initial 3-hour window
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
::1 - - [12/Aug/2025:16:48:06 +0000] "GET /api/analysis/auto-analyze/parallel/progress/3c88b8e1-926f-4b7b-a86a-ce0150f3af46 HTTP/1.1" 200 713 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:48:08 +0000] "GET /api/analysis/auto-analyze/parallel/progress/3c88b8e1-926f-4b7b-a86a-ce0150f3af46 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:48:10 +0000] "GET /api/analysis/auto-analyze/parallel/progress/3c88b8e1-926f-4b7b-a86a-ce0150f3af46 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 80 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a1287849680ad9fe59e',
  '689229f9583056c6108e38fb',
  '68922914f8bee7ba6c3e67b8'
]
[fetchContainmentTypeMetadata] API Response: 139 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6a14dd27c3112087cd',
  '68922a22ef03d8ad2ec7b4ba',
  '68922a1278c1fe09a079719c'
]
::1 - - [12/Aug/2025:16:48:12 +0000] "GET /api/analysis/auto-analyze/parallel/progress/3c88b8e1-926f-4b7b-a86a-ce0150f3af46 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 1338 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6d14dd27c31120888b',
  '68922a62e3804084741191d5',
  '68922a523a3160d25de144c8'
]
[getSessionsMetadata] agent API call succeeded with 1338 sessions
[getSessionsMetadata] selfService API call succeeded with 80 sessions
[getSessionsMetadata] dropOff API call succeeded with 139 sessions
Total session metadata retrieved: 1557 (parallel execution)
Creating 1557 SWTs from metadata (no messages)
Created 1557 SWT objects from metadata
âœ… [SessionDiscovery] Window 1 completed in 8914ms: found 1557 new sessions (total: 1557)
â±ï¸  TIMING: Window 1 took 8914ms (8.91s)
ğŸ¯ [SessionDiscovery] Target reached! Found 1557 sessions in 8914ms
ğŸ² [SessionSampling] Random sampling from 1557 sessions to 10 sessions

ğŸ“¬ ============ MESSAGE RETRIEVAL STARTED ============
ğŸ“¬ [MessageRetrieval] Starting message retrieval for 10 sampled sessions at 2025-08-12T16:48:14.634Z
Using new lazy loading approach to populate messages for 10 sampled sessions
Populating messages for 10 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 10 sessions from 2025-08-05T13:05:29.941Z to 2025-08-05T15:42:06.764Z at 2025-08-12T16:48:14.634Z
ğŸ”„ [KoreAPI] Using single API call for 10 sessions (â‰¤20)
::1 - - [12/Aug/2025:16:48:14 +0000] "GET /api/analysis/auto-analyze/parallel/progress/3c88b8e1-926f-4b7b-a86a-ce0150f3af46 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… [KoreAPI] Single call completed in 265ms: 118 messages
Retrieved 118 messages for 10 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
Populated messages for 10 SWT objects
Successfully populated messages for 10 sessions using lazy loading
Applying final filtering to 10 sessions with populated messages
Final result: 9 sessions passed filtering with populated messages

ğŸ‰ ============ SESSION SAMPLING COMPLETED ============
â±ï¸  TOTAL TIME: 9183ms (9.18s)
â±ï¸  Session Discovery: 8914ms (8.91s) - 97.1% of total
â±ï¸  Message Retrieval: 267ms (0.27s) - 2.9% of total
â±ï¸  Performance: 1.0 sessions/second
ğŸ¯ Final result: 9 sessions with messages retrieved
====================================================

[StrategicDiscoveryService] Starting discovery phase with 9 total sessions
[StrategicDiscoveryService] Discovery config: {
  targetPercentage: 15,
  minSessions: 5,
  maxSessions: 5,
  diversityStrategy: {
    sessionLengths: [ 'short', 'medium', 'long' ],
    containmentTypes: [ 'agent', 'selfService', 'dropOff' ],
    timeDistribution: 'spread'
  }
}
[StrategicDiscoveryService] Selecting 5 diverse sessions from 9 total
[StrategicDiscoveryService] Session diversity groups: { short: 3, medium: 6, early: 3, middle: 3, late: 3 }
[StrategicDiscoveryService] Selected sessions by length distribution: { short: 2, medium: 3, long: 0 }
[StrategicDiscoveryService] Selected 5 sessions for discovery

ğŸ“¦ ===== BATCH 1 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:48:14.904Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 0
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:48:14.905Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:48:14.907Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6448,
  existingClassifications: { intents: 0, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.



For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and another intent, classify the intent as the other i...
::1 - - [12/Aug/2025:16:48:16 +0000] "GET /api/analysis/auto-analyze/parallel/progress/3c88b8e1-926f-4b7b-a86a-ce0150f3af46 HTTP/1.1" 200 818 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:48:18.627Z',
  duration: '3720ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1862,
    completion_tokens: 373,
    total_tokens: 2235,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Claim Status', 'Unknown' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-dd74491d-613d-5f59-be9d-8d591794e911",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a customer service agent and was transferred."
    },
    {
      "user_id": "u-86ef7ec2-8e90-5530-9e8b-e66c412ddd9d",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User expressed difficulty understanding and requested to speak with an agent, resulting in transfer."
    },
    {
      "user_id": "u-ef5b5dae-3b0c-5ef5-bd3a-08e33f5ac481",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative and was transferred to an agent."
    },
    {
      "user_id": "u-dd74491d-613d-5f59-be9d-8d591794e911",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a customer service agent and was transferred."
    },
    {
      "user_id": "u-86ef7ec2-8e90-5530-9e8b-e66c412ddd9d",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User expressed difficulty understanding and requested to speak with an agent, resulting in transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1862,
  completionTokens: 373,
  totalTokens: 2235,
  cost: '$0.000335',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 3723ms (3.72s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2235 ($0.0003)
âš¡ Performance: 600.3 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 3
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 3724ms (3.72s)
ğŸ“Š Regular Sessions Processed: 3
ğŸ’° Regular Tokens Used: 2235

âœ… ===== BATCH 1 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 3724ms (3.72s)
ğŸ“Š Sessions Processed: 3/5
ğŸ’° Total Tokens: 2235 ($0.0003)
âš¡ Performance: 0.8 sessions/sec
âš¡ Avg Time Per Session: 1241.33ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 1 complete: 4 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 2, reasons: 1, locations: 1, total: 4 }
[StrategicDiscoveryService] Discovery phase complete: {
  totalProcessed: 3,
  uniqueIntents: 2,
  uniqueReasons: 1,
  uniqueLocations: 1,
  discoveryRate: 0.26666666666666666
}

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T16:48:18.629Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms
[ParallelProcessingOrchestrator] Configuration for 6 sessions:
  Design: 8 streams Ã— 4 sessions = 32 per round
  Optimal: 2 streams Ã— 3 sessions = 6 per round
  Estimated Rounds: 1
[ParallelAutoAnalyzeService] Using parallel config: {
  streamCount: 2,
  sessionsPerStream: 3,
  maxSessionsPerLLMCall: 50,
  syncFrequency: 'after_each_round',
  retryAttempts: 3,
  debugLogging: false
}

ğŸš€ ============ PARALLEL PROCESSING STARTED ============
â±ï¸  Start Time: 2025-08-12T16:48:18.655Z
ğŸ“Š Total Sessions: 6

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T16:48:18.655Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms

âš™ï¸  ============ PARALLEL CONFIGURATION ============
â±ï¸  Config Time: 0ms
ğŸ”§ Stream Count: 2
ğŸ“¦ Sessions Per Stream: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per API Call: 50
ğŸ¯ Debug Logging: false

ğŸ”„ ============ ROUND 1/1 STARTED ============
â±ï¸  Round 1 Start: 2025-08-12T16:48:18.656Z
ğŸ“Š Sessions Remaining: 6
[ParallelProcessingOrchestrator] Distributed 6 sessions across 2 streams: [ 'Stream 1: 3 sessions', 'Stream 2: 3 sessions' ]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 2

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 2 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T16:48:18.656Z
ğŸ“Š Sessions Assigned: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:48:18.656Z
ğŸ“Š Sessions to Estimate: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 3
   â€¢ Session Tokens: 492
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 5992
   â€¢ Avg Per Session: 164 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 5992
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 3

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 5992
ğŸ“¦ Recommended Batch Size: 3
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:48:18.657Z
ğŸ“Š Sessions to Analyze: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 2
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:48:18.657Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 3,
  apiKey: 'sk-proj-...',
  promptLength: 5182,
  existingClassifications: { intents: 2, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live A...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T16:48:18.657Z
ğŸ“Š Sessions Assigned: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:48:18.657Z
ğŸ“Š Sessions to Estimate: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 3
   â€¢ Session Tokens: 723
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6223
   â€¢ Avg Per Session: 241 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6223
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 3

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6223
ğŸ“¦ Recommended Batch Size: 3
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:48:18.657Z
ğŸ“Š Sessions to Analyze: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 2
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:48:18.657Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 3,
  apiKey: 'sk-proj-...',
  promptLength: 6292,
  existingClassifications: { intents: 2, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live A...
::1 - - [12/Aug/2025:16:48:18 +0000] "GET /api/analysis/auto-analyze/parallel/progress/3c88b8e1-926f-4b7b-a86a-ce0150f3af46 HTTP/1.1" 200 1045 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:48:20.686Z',
  duration: '2029ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1507,
    completion_tokens: 197,
    total_tokens: 1704,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 3,
  intentsFound: [ 'Claim Status', 'Unknown' ],
  transferCount: 1,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-32ab19e7-ce34-548d-8c64-7f859460d05c",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User inquired about leave request status but did not get transferred to an agent."
    },
    {
      "user_id": "u-b21c8307-121c-55db-81ca-f72ebd160b91",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a customer service representative and was transferred to an agent."
    },
    {
      "user_id": "u-bf8a4ab3-f5ae-55ae-8000-ba2b159a1ab7",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User provided claim number and zip code but was not transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1507,
  completionTokens: 197,
  totalTokens: 1704,
  cost: '$0.000230',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2029ms (2.03s)
ğŸ“Š Sessions Returned: 3
ğŸ’° Tokens Used: 1704 ($0.0002)
âš¡ Performance: 839.8 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1507
   â€¢ Completion Tokens: 197
[SessionValidationService] Validating batch response: 3 input sessions, 3 response sessions
[SessionValidationService] Validation successful: all 3 sessions processed
[SessionValidationService] Validating batch response: 3 input sessions, 3 response sessions
[SessionValidationService] Validation successful: all 3 sessions processed
â±ï¸  Stream 1 Single Batch Time: 2031ms (2.03s)

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 2032ms (2.03s)
ğŸ“Š Sessions Processed: 3/3
ğŸ’° Tokens Used: 1704 ($0.0002)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.5 sessions/sec
âš¡ Avg Time Per Session: 677.33ms
::1 - - [12/Aug/2025:16:48:20 +0000] "GET /api/analysis/auto-analyze/parallel/progress/3c88b8e1-926f-4b7b-a86a-ce0150f3af46 HTTP/1.1" 200 1047 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:48:20.814Z',
  duration: '2157ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1795,
    completion_tokens: 204,
    total_tokens: 1999,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 3,
  intentsFound: [ 'Claim Status', 'Live Agent' ],
  transferCount: 1,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-36a7dd7a-22df-5fb5-bfe9-779d952709a0",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User inquired about claim status, verified account details, and received information without transfer."
    },
    {
      "user_id": "u-186c7475-cf74-55e3-be6c-33cdc053498a",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User asked to track time, verified account details, but no active leave requests found, session ended without transfer."
    },
    {
      "user_id": "u-acedbd25-2b13-52e2-8a01-613e84bc888a",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent, session transferred to live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1795,
  completionTokens: 204,
  totalTokens: 1999,
  cost: '$0.000261',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2157ms (2.16s)
ğŸ“Š Sessions Returned: 3
ğŸ’° Tokens Used: 1999 ($0.0003)
âš¡ Performance: 926.8 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1795
   â€¢ Completion Tokens: 204
[SessionValidationService] Validating batch response: 3 input sessions, 3 response sessions
[SessionValidationService] Validation successful: all 3 sessions processed
[SessionValidationService] Validating batch response: 3 input sessions, 3 response sessions
[SessionValidationService] Validation successful: all 3 sessions processed
â±ï¸  Stream 2 Single Batch Time: 2158ms (2.16s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 2158ms (2.16s)
ğŸ“Š Sessions Processed: 3/3
ğŸ’° Tokens Used: 1999 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.4 sessions/sec
âš¡ Avg Time Per Session: 719.33ms
[ParallelProcessingOrchestrator] Parallel processing complete: 2/2 streams succeeded
â±ï¸  Parallel Processing Time: 2160ms (2.16s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 2 streams
[ParallelProcessingOrchestrator] Synchronization complete: 1 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 1
ğŸ“Š Total Classifications: 5

âœ… ============ ROUND 1 COMPLETED ============
â±ï¸  Round 1 Total Time: 2160ms (2.16s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 0
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 2160ms (100.0%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ‰ ============ PARALLEL PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 2161ms (2.16s)
ğŸ“Š Sessions Processed: 6/6
ğŸ”„ Total Rounds: 1
ğŸŒŠ Stream Results: 2
ğŸ’° Token Usage: 3703 tokens ($0.0005)
ğŸ“ˆ Stream Utilization: 100.0%
ğŸ¯ Performance: 2.8 sessions/second
âš¡ Avg Time Per Session: 360.17ms

ğŸ“Š Stream Performance Breakdown:
   Stream 1: 3 sessions in 2032ms (838.6 tokens/sec)
   Stream 2: 3 sessions in 2158ms (926.3 tokens/sec)
[ConflictResolutionService] Starting conflict resolution for 9 sessions
[ConflictResolutionService] Found classifications: { intents: 3, reasons: 1, locations: 1 }
[ConflictResolutionService] No conflicts detected, skipping resolution
[ParallelAutoAnalyzeService] Using real analysis summary service
::1 - - [12/Aug/2025:16:48:22 +0000] "GET /api/analysis/auto-analyze/parallel/progress/3c88b8e1-926f-4b7b-a86a-ce0150f3af46 HTTP/1.1" 200 1130 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:48:24 +0000] "GET /api/analysis/auto-analyze/parallel/progress/3c88b8e1-926f-4b7b-a86a-ce0150f3af46 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:48:26 +0000] "GET /api/analysis/auto-analyze/parallel/progress/3c88b8e1-926f-4b7b-a86a-ce0150f3af46 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:48:28 +0000] "GET /api/analysis/auto-analyze/parallel/progress/3c88b8e1-926f-4b7b-a86a-ce0150f3af46 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:48:30 +0000] "GET /api/analysis/auto-analyze/parallel/progress/3c88b8e1-926f-4b7b-a86a-ce0150f3af46 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:48:32 +0000] "GET /api/analysis/auto-analyze/parallel/progress/3c88b8e1-926f-4b7b-a86a-ce0150f3af46 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:48:34 +0000] "GET /api/analysis/auto-analyze/parallel/progress/3c88b8e1-926f-4b7b-a86a-ce0150f3af46 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:48:36 +0000] "GET /api/analysis/auto-analyze/parallel/progress/3c88b8e1-926f-4b7b-a86a-ce0150f3af46 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[ParallelAutoAnalyzeService] Parallel analysis 3c88b8e1-926f-4b7b-a86a-ce0150f3af46 completed successfully
[BackgroundJobQueue] Updated job progress to final state: complete
[BackgroundJobQueue] Parallel analysis job 3c88b8e1-926f-4b7b-a86a-ce0150f3af46-parallel completed successfully
::1 - - [12/Aug/2025:16:48:38 +0000] "GET /api/analysis/auto-analyze/parallel/progress/3c88b8e1-926f-4b7b-a86a-ce0150f3af46 HTTP/1.1" 200 1169 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:48:38 +0000] "GET /api/analysis/auto-analyze/parallel/results/3c88b8e1-926f-4b7b-a86a-ce0150f3af46 HTTP/1.1" 200 64818 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
12:49:29 PM [tsx] change in ./src/services/parallelAutoAnalyzeService.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
12:49:37 PM [tsx] change in ./src/services/parallelAutoAnalyzeService.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
12:51:02 PM [tsx] change in ./src/services/parallelAutoAnalyzeService.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
12:51:07 PM [tsx] change in ./src/services/parallelAutoAnalyzeService.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
12:51:10 PM [tsx] change in ./src/services/parallelAutoAnalyzeService.ts Restarting...
cnode:internal/modules/run_main:105
    triggerUncaughtException(
    ^

Error: Transform failed with 1 error:
/Users/kengrafals/workspace/xobcat/backend/src/services/parallelAutoAnalyzeService.ts:318:10: ERROR: "await" can only be used inside an "async" function
    at failureErrorWithLog (/Users/kengrafals/workspace/xobcat/node_modules/esbuild/lib/main.js:1467:15)
    at /Users/kengrafals/workspace/xobcat/node_modules/esbuild/lib/main.js:736:50
    at responseCallbacks.<computed> (/Users/kengrafals/workspace/xobcat/node_modules/esbuild/lib/main.js:603:9)
    at handleIncomingPacket (/Users/kengrafals/workspace/xobcat/node_modules/esbuild/lib/main.js:658:12)
    at Socket.readFromStdout (/Users/kengrafals/workspace/xobcat/node_modules/esbuild/lib/main.js:581:7)
    at Socket.emit (node:events:507:28)
    at addChunk (node:internal/streams/readable:559:12)
    at readableAddChunkPushByteMode (node:internal/streams/readable:510:3)
    at Readable.push (node:internal/streams/readable:390:5)
    at Pipe.onStreamRead (node:internal/stream_base_commons:189:23) {
  name: 'TransformError'
}

Node.js v24.4.1
12:51:16 PM [tsx] change in ./src/services/parallelAutoAnalyzeService.ts Rerunning...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
12:51:20 PM [tsx] change in ./src/services/parallelAutoAnalyzeService.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
12:51:25 PM [tsx] change in ./src/services/parallelAutoAnalyzeService.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
12:51:30 PM [tsx] change in ./src/services/parallelAutoAnalyzeService.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
12:51:47 PM [tsx] change in ./src/services/parallelAutoAnalyzeService.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
12:51:52 PM [tsx] change in ./src/services/parallelAutoAnalyzeService.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T16:51:30.854Z",
  "dateTo": "2025-08-12T16:52:30.854Z",
  "skip": 0,
  "limit": 1
}
[fetchContainmentTypeMetadata] API Response: 0 agent sessions received
[getSessionsMetadataForConnectionTest] Single API call succeeded with 0 sessions
::1 - - [12/Aug/2025:16:52:33 +0000] "GET /api/kore/test HTTP/1.1" 200 299 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[Direct API] Fetching real Kore.ai sessions from 2025-08-05T16:52:34.502Z to 2025-08-12T16:52:34.502Z for User Bot st-90549... (limit=50)
Retrieving sessions from 2025-08-05T16:52:34.502Z to 2025-08-12T16:52:34.502Z (limit=50), populateMessages=true...
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T16:52:34.502Z",
  "dateTo": "2025-08-12T16:52:34.502Z",
  "limit": 50
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T16:52:34.502Z",
  "dateTo": "2025-08-12T16:52:34.502Z",
  "skip": 0,
  "limit": 50
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T16:52:34.502Z",
  "dateTo": "2025-08-12T16:52:34.502Z",
  "skip": 0,
  "limit": 50
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T16:52:34.502Z",
  "dateTo": "2025-08-12T16:52:34.502Z",
  "skip": 0,
  "limit": 50
}
::1 - - [12/Aug/2025:16:52:35 +0000] "GET /api/analysis/sessions?limit=50 HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 50 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b712fd1c995239927d2e8',
  '689b710e8c094d6aa01dfa1a',
  '689b70fa224c97ecf1354383'
]
[fetchContainmentTypeMetadata] API Response: 50 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b714832b94a1c3f1e791b',
  '689b714432b94a1c3f1e788a',
  '689b713e224c97ecf1354c23'
]
[fetchContainmentTypeMetadata] API Response: 50 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b6c4f618775e3b376cade',
  '689b6c4705a45fff89056641',
  '689b6bc9995362de8def70e0'
]
[getSessionsMetadata] agent API call succeeded with 50 sessions
[getSessionsMetadata] selfService API call succeeded with 50 sessions
[getSessionsMetadata] dropOff API call succeeded with 50 sessions
Total session metadata retrieved: 150 (parallel execution)
Retrieved 150 session metadata objects
Creating 150 SWTs from metadata (no messages)
Created 150 SWT objects from metadata
Populating messages for all sessions (legacy behavior)
Populating messages for 150 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 150 sessions from 2025-08-12T15:37:08.988Z to 2025-08-12T16:52:31.429Z at 2025-08-12T16:52:37.532Z
ğŸš€ [ConcurrentBatch] Split 150 sessions into 8 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/8] Starting: 20 sessions
[Batch 2/8] Starting: 20 sessions
[Batch 3/8] Starting: 20 sessions
[Batch 4/8] Starting: 20 sessions
[Batch 5/8] Starting: 20 sessions
[Batch 6/8] Starting: 20 sessions
[Batch 7/8] Starting: 20 sessions
[Batch 8/8] Starting: 10 sessions
[Batch 3/8] Completed in 274ms: 192 messages retrieved (1/8 done)
[Batch 1/8] Completed in 278ms: 182 messages retrieved (2/8 done)
[Batch 2/8] Completed in 358ms: 274 messages retrieved (3/8 done)
[Batch 8/8] Completed in 540ms: 120 messages retrieved (4/8 done)
[Batch 7/8] Completed in 543ms: 212 messages retrieved (5/8 done)
[Batch 6/8] Completed in 565ms: 259 messages retrieved (6/8 done)
[Batch 4/8] Completed in 582ms: 303 messages retrieved (7/8 done)
[Batch 5/8] Completed in 641ms: 474 messages retrieved (8/8 done)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 642ms (0.64s)
â±ï¸  Batch Processing: 642ms (0.64s)
ğŸ“¦ Total batches: 8 (max 10 concurrent)
âœ… Successful batches: 8/8
ğŸ’¬ Total messages: 2016
ğŸ“ˆ Avg time per batch: 80ms
ğŸš€ Time per session: 4ms
ğŸ’ª Performance: 233.6 sessions/second
=======================================================

Retrieved 2016 messages for 150 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
Populated messages for 150 SWT objects
Generated 150 SWT objects in 3697ms using layered architecture
ğŸš€ [ParallelAutoAnalyzeRoute] Starting parallel analysis for bot ***REMOVED*** with real credentials
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
ğŸ­ ServiceFactory: Creating OpenAI service (type: real)
ğŸš€ [ParallelAutoAnalyzeService] Starting parallel analysis ff658da6-879a-495e-b048-d5f28152e758 with bot ***REMOVED***
ğŸš€ [ParallelAutoAnalyzeService] Using credentials: real
ğŸš€ [ParallelAutoAnalyzeRoute] Parallel analysis started: ff658da6-879a-495e-b048-d5f28152e758
::1 - - [12/Aug/2025:16:52:53 +0000] "POST /api/analysis/auto-analyze/parallel/start HTTP/1.1" 200 214 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:52:53 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ff658da6-879a-495e-b048-d5f28152e758 HTTP/1.1" 200 541 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:52:53 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ff658da6-879a-495e-b048-d5f28152e758 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[BackgroundJobQueue] Starting job processing after delay for job ff658da6-879a-495e-b048-d5f28152e758-parallel
[BackgroundJobQueue] Starting processing for job ff658da6-879a-495e-b048-d5f28152e758-parallel, phase: sampling
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing parallel analysis job ff658da6-879a-495e-b048-d5f28152e758-parallel
[BackgroundJobQueue] Processing parallel analysis for bot ***REMOVED***
[BackgroundJobQueue] Using existing ParallelAutoAnalyzeService instance for bot ***REMOVED***
[BackgroundJobQueue] Session recreated for ff658da6-879a-495e-b048-d5f28152e758
[ParallelAutoAnalyzeService] Running parallel analysis for ff658da6-879a-495e-b048-d5f28152e758
[ParallelAutoAnalyzeService] Phase 0: Starting session sampling for ff658da6-879a-495e-b048-d5f28152e758

ğŸ• ============ SESSION SAMPLING STARTED ============
ğŸ• [SessionSampling] Starting session sampling at 2025-08-12T16:52:54.140Z
ğŸ” [SessionDiscovery] Starting window 1/4: Initial 3-hour window
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
::1 - - [12/Aug/2025:16:52:55 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ff658da6-879a-495e-b048-d5f28152e758 HTTP/1.1" 200 717 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 80 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a1287849680ad9fe59e',
  '689229f9583056c6108e38fb',
  '68922914f8bee7ba6c3e67b8'
]
::1 - - [12/Aug/2025:16:52:57 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ff658da6-879a-495e-b048-d5f28152e758 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 139 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6a14dd27c3112087cd',
  '68922a22ef03d8ad2ec7b4ba',
  '68922a1278c1fe09a079719c'
]
::1 - - [12/Aug/2025:16:52:59 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ff658da6-879a-495e-b048-d5f28152e758 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 1338 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6d14dd27c31120888b',
  '68922a62e3804084741191d5',
  '68922a523a3160d25de144c8'
]
[getSessionsMetadata] agent API call succeeded with 1338 sessions
[getSessionsMetadata] selfService API call succeeded with 80 sessions
[getSessionsMetadata] dropOff API call succeeded with 139 sessions
Total session metadata retrieved: 1557 (parallel execution)
Creating 1557 SWTs from metadata (no messages)
Created 1557 SWT objects from metadata
âœ… [SessionDiscovery] Window 1 completed in 5214ms: found 1557 new sessions (total: 1557)
â±ï¸  TIMING: Window 1 took 5214ms (5.21s)
ğŸ¯ [SessionDiscovery] Target reached! Found 1557 sessions in 5214ms
ğŸ² [SessionSampling] Random sampling from 1557 sessions to 10 sessions

ğŸ“¬ ============ MESSAGE RETRIEVAL STARTED ============
ğŸ“¬ [MessageRetrieval] Starting message retrieval for 10 sampled sessions at 2025-08-12T16:52:59.356Z
Using new lazy loading approach to populate messages for 10 sampled sessions
Populating messages for 10 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 10 sessions from 2025-08-05T13:08:24.947Z to 2025-08-05T15:47:02.019Z at 2025-08-12T16:52:59.356Z
ğŸ”„ [KoreAPI] Using single API call for 10 sessions (â‰¤20)
âœ… [KoreAPI] Single call completed in 264ms: 173 messages
Retrieved 173 messages for 10 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
Populated messages for 10 SWT objects
Successfully populated messages for 10 sessions using lazy loading
Applying final filtering to 10 sessions with populated messages
Final result: 10 sessions passed filtering with populated messages

ğŸ‰ ============ SESSION SAMPLING COMPLETED ============
â±ï¸  TOTAL TIME: 5482ms (5.48s)
â±ï¸  Session Discovery: 5214ms (5.21s) - 95.1% of total
â±ï¸  Message Retrieval: 266ms (0.27s) - 4.9% of total
â±ï¸  Performance: 1.8 sessions/second
ğŸ¯ Final result: 10 sessions with messages retrieved
====================================================

[StrategicDiscoveryService] Starting discovery phase with 10 total sessions
[StrategicDiscoveryService] Discovery config: {
  targetPercentage: 15,
  minSessions: 5,
  maxSessions: 5,
  diversityStrategy: {
    sessionLengths: [ 'short', 'medium', 'long' ],
    containmentTypes: [ 'agent', 'selfService', 'dropOff' ],
    timeDistribution: 'spread'
  }
}
[StrategicDiscoveryService] Selecting 5 diverse sessions from 10 total
[StrategicDiscoveryService] Session diversity groups: { short: 2, medium: 8, early: 3, middle: 3, late: 4 }
[StrategicDiscoveryService] Selected sessions by length distribution: { short: 1, medium: 4, long: 0 }
[StrategicDiscoveryService] Selected 5 sessions for discovery

ğŸ“¦ ===== BATCH 1 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:52:59.625Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 0
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:52:59.625Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:52:59.627Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6645,
  existingClassifications: { intents: 0, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.



For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and another intent, classify the intent as the other i...
::1 - - [12/Aug/2025:16:53:01 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ff658da6-879a-495e-b048-d5f28152e758 HTTP/1.1" 200 830 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:53:02.319Z',
  duration: '2692ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1929,
    completion_tokens: 311,
    total_tokens: 2240,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Live Agent', 'Claim Status' ],
  transferCount: 4,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-54f5a053-95f2-5a42-a0ab-5a5c24683dba",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-63dbe6d5-df46-5b0e-a36b-3aa4a085d066",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-80867886-805b-54c0-81a8-1677faf789e1",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-d3a50416-0065-5e99-832f-3bfc7534c4a7",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-535698ce-fd9c-5d6d-8a90-4aa41f681e29",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User inquired about claim status, provided claim number and zip code, but was transferred to an agent after multiple unsuccessful attempts to get specific information."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1929,
  completionTokens: 311,
  totalTokens: 2240,
  cost: '$0.000317',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2695ms (2.69s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2240 ($0.0003)
âš¡ Performance: 831.2 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2695ms (2.69s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2240

âœ… ===== BATCH 1 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2696ms (2.70s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2240 ($0.0003)
âš¡ Performance: 1.9 sessions/sec
âš¡ Avg Time Per Session: 539.20ms
â±ï¸  Metadata Processing: 1ms
[StrategicDiscoveryService] Batch 1 complete: 4 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 2, reasons: 1, locations: 1, total: 4 }
[StrategicDiscoveryService] Discovery phase complete: {
  totalProcessed: 5,
  uniqueIntents: 2,
  uniqueReasons: 1,
  uniqueLocations: 1,
  discoveryRate: 0.26666666666666666
}

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T16:53:02.322Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms
[ParallelProcessingOrchestrator] Configuration for 5 sessions:
  Design: 8 streams Ã— 4 sessions = 32 per round
  Optimal: 2 streams Ã— 3 sessions = 6 per round
  Estimated Rounds: 1
[ParallelAutoAnalyzeService] Using parallel config: {
  streamCount: 2,
  sessionsPerStream: 3,
  maxSessionsPerLLMCall: 50,
  syncFrequency: 'after_each_round',
  retryAttempts: 3,
  debugLogging: false
}

ğŸš€ ============ PARALLEL PROCESSING STARTED ============
â±ï¸  Start Time: 2025-08-12T16:53:02.335Z
ğŸ“Š Total Sessions: 5

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T16:53:02.335Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms

âš™ï¸  ============ PARALLEL CONFIGURATION ============
â±ï¸  Config Time: 0ms
ğŸ”§ Stream Count: 2
ğŸ“¦ Sessions Per Stream: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per API Call: 50
ğŸ¯ Debug Logging: false

ğŸ”„ ============ ROUND 1/1 STARTED ============
â±ï¸  Round 1 Start: 2025-08-12T16:53:02.335Z
ğŸ“Š Sessions Remaining: 5
[ParallelProcessingOrchestrator] Distributed 5 sessions across 2 streams: [ 'Stream 1: 3 sessions', 'Stream 2: 2 sessions' ]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 2

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 2 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T16:53:02.336Z
ğŸ“Š Sessions Assigned: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:53:02.336Z
ğŸ“Š Sessions to Estimate: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 3
   â€¢ Session Tokens: 704
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6204
   â€¢ Avg Per Session: 235 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6204
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 3

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 1ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6204
ğŸ“¦ Recommended Batch Size: 3
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:53:02.337Z
ğŸ“Š Sessions to Analyze: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 2
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:53:02.338Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 3,
  apiKey: 'sk-proj-...',
  promptLength: 6096,
  existingClassifications: { intents: 2, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Liv...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T16:53:02.338Z
ğŸ“Š Sessions Assigned: 2
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T16:53:02.338Z
ğŸ“Š Sessions to Estimate: 2
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 2
   â€¢ Session Tokens: 1005
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6505
   â€¢ Avg Per Session: 503 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6505
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 2

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6505
ğŸ“¦ Recommended Batch Size: 2
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T16:53:02.338Z
ğŸ“Š Sessions to Analyze: 2
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 2
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:53:02.338Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 2,
  apiKey: 'sk-proj-...',
  promptLength: 7669,
  existingClassifications: { intents: 2, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Liv...
::1 - - [12/Aug/2025:16:53:03 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ff658da6-879a-495e-b048-d5f28152e758 HTTP/1.1" 200 1054 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:53:03.675Z',
  duration: '1337ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2104,
    completion_tokens: 117,
    total_tokens: 2221,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 2,
  intentsFound: [ 'Unknown' ],
  transferCount: 0,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-5add6d4d-2cc4-59bd-bd1e-ebdf5cb8fa83",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "Handled time entry for leave request with verification and correction process."
    },
    {
      "user_id": "u-b9fdf33d-ffa8-5c34-9bea-981aceea8caa",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "Handled time entry for leave request with verification and correction process."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2104,
  completionTokens: 117,
  totalTokens: 2221,
  cost: '$0.000257',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1338ms (1.34s)
ğŸ“Š Sessions Returned: 2
ğŸ’° Tokens Used: 2221 ($0.0003)
âš¡ Performance: 1659.9 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2104
   â€¢ Completion Tokens: 117
[SessionValidationService] Validating batch response: 2 input sessions, 2 response sessions
[SessionValidationService] Validation successful: all 2 sessions processed
[SessionValidationService] Validating batch response: 2 input sessions, 2 response sessions
[SessionValidationService] Validation successful: all 2 sessions processed
â±ï¸  Stream 2 Single Batch Time: 1339ms (1.34s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 1340ms (1.34s)
ğŸ“Š Sessions Processed: 2/2
ğŸ’° Tokens Used: 2221 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.5 sessions/sec
âš¡ Avg Time Per Session: 670.00ms
::1 - - [12/Aug/2025:16:53:05 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ff658da6-879a-495e-b048-d5f28152e758 HTTP/1.1" 200 1056 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:53:05.996Z',
  duration: '3658ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1709,
    completion_tokens: 231,
    total_tokens: 1940,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 3,
  intentsFound: [ 'Claim Status', 'Live Agent', 'FMLA' ],
  transferCount: 3,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-31c2d162-4e6b-5b7c-9e7d-c0dc18c8a089",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak to an agent after checking claim status and was transferred."
    },
    {
      "user_id": "u-642429c9-095d-5d4b-9cc9-229d840af30d",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-182ffbd2-c02e-509e-8a67-9f5b7f315019",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked about FMLA and was transferred when needing further assistance."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1709,
  completionTokens: 231,
  totalTokens: 1940,
  cost: '$0.000263',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 3660ms (3.66s)
ğŸ“Š Sessions Returned: 3
ğŸ’° Tokens Used: 1940 ($0.0003)
âš¡ Performance: 530.1 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1709
   â€¢ Completion Tokens: 231
[SessionValidationService] Validating batch response: 3 input sessions, 3 response sessions
[SessionValidationService] Validation successful: all 3 sessions processed
[SessionValidationService] Validating batch response: 3 input sessions, 3 response sessions
[SessionValidationService] Validation successful: all 3 sessions processed
â±ï¸  Stream 1 Single Batch Time: 3660ms (3.66s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 3661ms (3.66s)
ğŸ“Š Sessions Processed: 3/3
ğŸ’° Tokens Used: 1940 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.8 sessions/sec
âš¡ Avg Time Per Session: 1220.33ms
[ParallelProcessingOrchestrator] Parallel processing complete: 2/2 streams succeeded
â±ï¸  Parallel Processing Time: 3662ms (3.66s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 2 streams
[ParallelProcessingOrchestrator] Synchronization complete: 2 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 1ms
ğŸ†• New Classifications: 2
ğŸ“Š Total Classifications: 6

âœ… ============ ROUND 1 COMPLETED ============
â±ï¸  Round 1 Total Time: 3663ms (3.66s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 0
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 3662ms (100.0%)
   â€¢ Synchronization: 1ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ‰ ============ PARALLEL PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 3664ms (3.66s)
ğŸ“Š Sessions Processed: 5/5
ğŸ”„ Total Rounds: 1
ğŸŒŠ Stream Results: 2
ğŸ’° Token Usage: 4161 tokens ($0.0005)
ğŸ“ˆ Stream Utilization: 100.0%
ğŸ¯ Performance: 1.4 sessions/second
âš¡ Avg Time Per Session: 732.80ms

ğŸ“Š Stream Performance Breakdown:
   Stream 1: 3 sessions in 3661ms (529.9 tokens/sec)
   Stream 2: 2 sessions in 1340ms (1657.5 tokens/sec)
[ConflictResolutionService] Starting conflict resolution for 10 sessions
[ConflictResolutionService] Found classifications: { intents: 4, reasons: 1, locations: 1 }
[ConflictResolutionService] No conflicts detected, skipping resolution
[ParallelAutoAnalyzeService] Using real analysis summary service
::1 - - [12/Aug/2025:16:53:07 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ff658da6-879a-495e-b048-d5f28152e758 HTTP/1.1" 200 1163 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:53:09 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ff658da6-879a-495e-b048-d5f28152e758 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:53:11 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ff658da6-879a-495e-b048-d5f28152e758 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:53:13 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ff658da6-879a-495e-b048-d5f28152e758 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:53:15 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ff658da6-879a-495e-b048-d5f28152e758 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:53:17 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ff658da6-879a-495e-b048-d5f28152e758 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:53:19 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ff658da6-879a-495e-b048-d5f28152e758 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:53:21 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ff658da6-879a-495e-b048-d5f28152e758 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[ParallelAutoAnalyzeService] Parallel analysis ff658da6-879a-495e-b048-d5f28152e758 completed successfully
[BackgroundJobQueue] Updated job progress to final state: complete
[BackgroundJobQueue] Parallel analysis job ff658da6-879a-495e-b048-d5f28152e758-parallel completed successfully
::1 - - [12/Aug/2025:16:53:23 +0000] "GET /api/analysis/auto-analyze/parallel/progress/ff658da6-879a-495e-b048-d5f28152e758 HTTP/1.1" 200 1175 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:53:23 +0000] "GET /api/analysis/auto-analyze/parallel/results/ff658da6-879a-495e-b048-d5f28152e758 HTTP/1.1" 200 90972 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T16:55:40.532Z",
  "dateTo": "2025-08-12T16:56:40.532Z",
  "skip": 0,
  "limit": 1
}
[fetchContainmentTypeMetadata] API Response: 1 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [ '689b72109516e359d07c8488' ]
[getSessionsMetadataForConnectionTest] Single API call succeeded with 1 sessions
::1 - - [12/Aug/2025:16:56:43 +0000] "GET /api/kore/test HTTP/1.1" 200 851 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[Direct API] Fetching real Kore.ai sessions from 2025-08-05T16:56:44.183Z to 2025-08-12T16:56:44.183Z for User Bot st-90549... (limit=50)
Retrieving sessions from 2025-08-05T16:56:44.183Z to 2025-08-12T16:56:44.183Z (limit=50), populateMessages=true...
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T16:56:44.183Z",
  "dateTo": "2025-08-12T16:56:44.183Z",
  "limit": 50
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T16:56:44.183Z",
  "dateTo": "2025-08-12T16:56:44.183Z",
  "skip": 0,
  "limit": 50
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T16:56:44.183Z",
  "dateTo": "2025-08-12T16:56:44.183Z",
  "skip": 0,
  "limit": 50
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T16:56:44.183Z",
  "dateTo": "2025-08-12T16:56:44.183Z",
  "skip": 0,
  "limit": 50
}
::1 - - [12/Aug/2025:16:56:44 +0000] "GET /api/analysis/sessions?limit=50 HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 50 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b72110989a8bc72a41d01',
  '689b72109516e359d07c8488',
  '689b72073f6da016cf82f2e6'
]
[fetchContainmentTypeMetadata] API Response: 50 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b6e28b12946428596c9fd',
  '689b6e271dffa49ef371d432',
  '689b6d8be6e30b33f5be298d'
]
[fetchContainmentTypeMetadata] API Response: 50 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b723d0a261bd4437474ea',
  '689b723de11e897de605ab32',
  '689b7232f54cdbf3def1ceff'
]
[getSessionsMetadata] agent API call succeeded with 50 sessions
[getSessionsMetadata] selfService API call succeeded with 50 sessions
[getSessionsMetadata] dropOff API call succeeded with 50 sessions
Total session metadata retrieved: 150 (parallel execution)
Retrieved 150 session metadata objects
Creating 150 SWTs from metadata (no messages)
Created 150 SWT objects from metadata
Populating messages for all sessions (legacy behavior)
Populating messages for 150 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 150 sessions from 2025-08-12T15:47:46.114Z to 2025-08-12T16:56:47.396Z at 2025-08-12T16:56:52.451Z
ğŸš€ [ConcurrentBatch] Split 150 sessions into 8 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/8] Starting: 20 sessions
[Batch 2/8] Starting: 20 sessions
[Batch 3/8] Starting: 20 sessions
[Batch 4/8] Starting: 20 sessions
[Batch 5/8] Starting: 20 sessions
[Batch 6/8] Starting: 20 sessions
[Batch 7/8] Starting: 20 sessions
[Batch 8/8] Starting: 10 sessions
[Batch 3/8] Completed in 367ms: 153 messages retrieved (1/8 done)
[Batch 2/8] Completed in 377ms: 263 messages retrieved (2/8 done)
[Batch 1/8] Completed in 379ms: 233 messages retrieved (3/8 done)
[Batch 8/8] Completed in 423ms: 127 messages retrieved (4/8 done)
[Batch 5/8] Completed in 600ms: 467 messages retrieved (5/8 done)
[Batch 7/8] Completed in 679ms: 188 messages retrieved (6/8 done)
[Batch 6/8] Completed in 742ms: 277 messages retrieved (7/8 done)
[Batch 4/8] Completed in 759ms: 306 messages retrieved (8/8 done)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 760ms (0.76s)
â±ï¸  Batch Processing: 760ms (0.76s)
ğŸ“¦ Total batches: 8 (max 10 concurrent)
âœ… Successful batches: 8/8
ğŸ’¬ Total messages: 2014
ğŸ“ˆ Avg time per batch: 95ms
ğŸš€ Time per session: 5ms
ğŸ’ª Performance: 197.4 sessions/second
=======================================================

Retrieved 2014 messages for 150 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
Populated messages for 150 SWT objects
Generated 150 SWT objects in 9037ms using layered architecture
ğŸš€ [ParallelAutoAnalyzeRoute] Starting parallel analysis for bot ***REMOVED*** with real credentials
ğŸš€ [ParallelAutoAnalyzeService] Starting parallel analysis 483d5da8-317a-4aa1-a5e7-3e735474a670 with bot ***REMOVED***
ğŸš€ [ParallelAutoAnalyzeService] Using credentials: real
ğŸš€ [ParallelAutoAnalyzeRoute] Parallel analysis started: 483d5da8-317a-4aa1-a5e7-3e735474a670
::1 - - [12/Aug/2025:16:57:02 +0000] "POST /api/analysis/auto-analyze/parallel/start HTTP/1.1" 200 214 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:57:02 +0000] "GET /api/analysis/auto-analyze/parallel/progress/483d5da8-317a-4aa1-a5e7-3e735474a670 HTTP/1.1" 200 540 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:57:02 +0000] "GET /api/analysis/auto-analyze/parallel/progress/483d5da8-317a-4aa1-a5e7-3e735474a670 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[BackgroundJobQueue] Starting job processing after delay for job 483d5da8-317a-4aa1-a5e7-3e735474a670-parallel
[BackgroundJobQueue] Starting processing for job 483d5da8-317a-4aa1-a5e7-3e735474a670-parallel, phase: sampling
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing parallel analysis job 483d5da8-317a-4aa1-a5e7-3e735474a670-parallel
[BackgroundJobQueue] Processing parallel analysis for bot ***REMOVED***
[BackgroundJobQueue] Using existing ParallelAutoAnalyzeService instance for bot ***REMOVED***
[BackgroundJobQueue] Session recreated for 483d5da8-317a-4aa1-a5e7-3e735474a670
[ParallelAutoAnalyzeService] Running parallel analysis for 483d5da8-317a-4aa1-a5e7-3e735474a670
[ParallelAutoAnalyzeService] Phase 0: Starting session sampling for 483d5da8-317a-4aa1-a5e7-3e735474a670

ğŸ• ============ SESSION SAMPLING STARTED ============
ğŸ• [SessionSampling] Starting session sampling at 2025-08-12T16:57:03.672Z
ğŸ” [SessionDiscovery] Starting window 1/4: Initial 3-hour window
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
::1 - - [12/Aug/2025:16:57:04 +0000] "GET /api/analysis/auto-analyze/parallel/progress/483d5da8-317a-4aa1-a5e7-3e735474a670 HTTP/1.1" 200 715 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:57:06 +0000] "GET /api/analysis/auto-analyze/parallel/progress/483d5da8-317a-4aa1-a5e7-3e735474a670 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 80 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a1287849680ad9fe59e',
  '689229f9583056c6108e38fb',
  '68922914f8bee7ba6c3e67b8'
]
[fetchContainmentTypeMetadata] API Response: 139 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6a14dd27c3112087cd',
  '68922a22ef03d8ad2ec7b4ba',
  '68922a1278c1fe09a079719c'
]
::1 - - [12/Aug/2025:16:57:08 +0000] "GET /api/analysis/auto-analyze/parallel/progress/483d5da8-317a-4aa1-a5e7-3e735474a670 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 1338 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6d14dd27c31120888b',
  '68922a62e3804084741191d5',
  '68922a523a3160d25de144c8'
]
[getSessionsMetadata] agent API call succeeded with 1338 sessions
[getSessionsMetadata] selfService API call succeeded with 80 sessions
[getSessionsMetadata] dropOff API call succeeded with 139 sessions
Total session metadata retrieved: 1557 (parallel execution)
Creating 1557 SWTs from metadata (no messages)
Created 1557 SWT objects from metadata
âœ… [SessionDiscovery] Window 1 completed in 5679ms: found 1557 new sessions (total: 1557)
â±ï¸  TIMING: Window 1 took 5679ms (5.68s)
ğŸ¯ [SessionDiscovery] Target reached! Found 1557 sessions in 5680ms
ğŸ² [SessionSampling] Random sampling from 1557 sessions to 5 sessions

ğŸ“¬ ============ MESSAGE RETRIEVAL STARTED ============
ğŸ“¬ [MessageRetrieval] Starting message retrieval for 5 sampled sessions at 2025-08-12T16:57:09.353Z
Using new lazy loading approach to populate messages for 5 sampled sessions
Populating messages for 5 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 5 sessions from 2025-08-05T13:13:05.372Z to 2025-08-05T15:06:19.339Z at 2025-08-12T16:57:09.353Z
ğŸ”„ [KoreAPI] Using single API call for 5 sessions (â‰¤20)
âœ… [KoreAPI] Single call completed in 197ms: 73 messages
Retrieved 73 messages for 5 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
Populated messages for 5 SWT objects
Successfully populated messages for 5 sessions using lazy loading
Applying final filtering to 5 sessions with populated messages
Final result: 5 sessions passed filtering with populated messages

ğŸ‰ ============ SESSION SAMPLING COMPLETED ============
â±ï¸  TOTAL TIME: 5879ms (5.88s)
â±ï¸  Session Discovery: 5680ms (5.68s) - 96.6% of total
â±ï¸  Message Retrieval: 198ms (0.20s) - 3.4% of total
â±ï¸  Performance: 0.9 sessions/second
ğŸ¯ Final result: 5 sessions with messages retrieved
====================================================

[StrategicDiscoveryService] Starting discovery phase with 5 total sessions
[StrategicDiscoveryService] Discovery config: {
  targetPercentage: 15,
  minSessions: 5,
  maxSessions: 5,
  diversityStrategy: {
    sessionLengths: [ 'short', 'medium', 'long' ],
    containmentTypes: [ 'agent', 'selfService', 'dropOff' ],
    timeDistribution: 'spread'
  }
}
[StrategicDiscoveryService] Selecting 5 diverse sessions from 5 total
[StrategicDiscoveryService] Selected 5 sessions for discovery

ğŸ“¦ ===== BATCH 2 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T16:57:09.551Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 0
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T16:57:09.551Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T16:57:09.552Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6790,
  existingClassifications: { intents: 0, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.



For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and another intent, classify the intent as the other i...
::1 - - [12/Aug/2025:16:57:10 +0000] "GET /api/analysis/auto-analyze/parallel/progress/483d5da8-317a-4aa1-a5e7-3e735474a670 HTTP/1.1" 200 827 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:57:12 +0000] "GET /api/analysis/auto-analyze/parallel/progress/483d5da8-317a-4aa1-a5e7-3e735474a670 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T16:57:14.225Z',
  duration: '4673ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1975,
    completion_tokens: 249,
    total_tokens: 2224,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-f10dad0e-9c79-558a-9021-7ef6b81969de",
      "notes": "User attempted to report time off but did not provide input, leading to transfer to a live agent."
    },
    {
      "user_id": "u-2db0e173-29c3-55da-b67c-75eb37670165",
      "notes": "User provided partial information for time entry but was unable to complete the process, leading to transfer to a live agent."
    },
    {
      "user_id": "u-e2297561-a114-5e38-995a-0f82f19fd77c",
      "notes": "User requested to speak with a representative, resulting in transfer to a live agent."
    },
    {
      "user_id": "u-78eae2bb-2884-5aa5-b541-f5c7697b4425",
      "notes": "User was unable to provide leave request number, leading to transfer to a live agent."
    },
    {
      "user_id": "u-0a40fb72-2dad-50cf-8a90-dce202d77233",
      "notes": "User expressed intent to file a claim, resulting in transfer to a live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1975,
  completionTokens: 249,
  totalTokens: 2224,
  cost: '$0.000297',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 4675ms (4.67s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2224 ($0.0003)
âš¡ Performance: 475.7 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 1ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 4676ms (4.68s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2224

âœ… ===== BATCH 2 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 4676ms (4.68s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2224 ($0.0003)
âš¡ Performance: 1.1 sessions/sec
âš¡ Avg Time Per Session: 935.20ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 1 complete: 1 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 1, reasons: 0, locations: 0, total: 1 }
[StrategicDiscoveryService] Discovery phase complete: {
  totalProcessed: 5,
  uniqueIntents: 1,
  uniqueReasons: 0,
  uniqueLocations: 0,
  discoveryRate: 0.06666666666666667
}

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T16:57:14.227Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms
[ParallelProcessingOrchestrator] Configuration for 0 sessions:
  Design: 8 streams Ã— 4 sessions = 32 per round
  Optimal: 1 streams Ã— 0 sessions = 0 per round
  Estimated Rounds: NaN
[ParallelAutoAnalyzeService] Using parallel config: {
  streamCount: 1,
  sessionsPerStream: 0,
  maxSessionsPerLLMCall: 50,
  syncFrequency: 'after_each_round',
  retryAttempts: 3,
  debugLogging: false
}

ğŸš€ ============ PARALLEL PROCESSING STARTED ============
â±ï¸  Start Time: 2025-08-12T16:57:14.228Z
ğŸ“Š Total Sessions: 0

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T16:57:14.228Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms

âš™ï¸  ============ PARALLEL CONFIGURATION ============
â±ï¸  Config Time: 0ms
ğŸ”§ Stream Count: 1
ğŸ“¦ Sessions Per Stream: 0
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per API Call: 50
ğŸ¯ Debug Logging: false

ğŸ‰ ============ PARALLEL PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 0ms (0.00s)
ğŸ“Š Sessions Processed: 0/0
ğŸ”„ Total Rounds: 0
ğŸŒŠ Stream Results: 0
ğŸ’° Token Usage: 0 tokens ($0.0000)
ğŸ“ˆ Stream Utilization: 0.0%
ğŸ¯ Performance: NaN sessions/second
âš¡ Avg Time Per Session: NaNms

ğŸ“Š Stream Performance Breakdown:
[ConflictResolutionService] Starting conflict resolution for 5 sessions
[ConflictResolutionService] Found classifications: { intents: 1, reasons: 0, locations: 0 }
[ConflictResolutionService] No conflicts detected, skipping resolution
[ParallelAutoAnalyzeService] Using real analysis summary service
::1 - - [12/Aug/2025:16:57:14 +0000] "GET /api/analysis/auto-analyze/parallel/progress/483d5da8-317a-4aa1-a5e7-3e735474a670 HTTP/1.1" 200 957 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:57:16 +0000] "GET /api/analysis/auto-analyze/parallel/progress/483d5da8-317a-4aa1-a5e7-3e735474a670 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:57:18 +0000] "GET /api/analysis/auto-analyze/parallel/progress/483d5da8-317a-4aa1-a5e7-3e735474a670 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:57:20 +0000] "GET /api/analysis/auto-analyze/parallel/progress/483d5da8-317a-4aa1-a5e7-3e735474a670 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:57:22 +0000] "GET /api/analysis/auto-analyze/parallel/progress/483d5da8-317a-4aa1-a5e7-3e735474a670 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:57:24 +0000] "GET /api/analysis/auto-analyze/parallel/progress/483d5da8-317a-4aa1-a5e7-3e735474a670 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:57:26 +0000] "GET /api/analysis/auto-analyze/parallel/progress/483d5da8-317a-4aa1-a5e7-3e735474a670 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:57:28 +0000] "GET /api/analysis/auto-analyze/parallel/progress/483d5da8-317a-4aa1-a5e7-3e735474a670 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:57:30 +0000] "GET /api/analysis/auto-analyze/parallel/progress/483d5da8-317a-4aa1-a5e7-3e735474a670 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:57:32 +0000] "GET /api/analysis/auto-analyze/parallel/progress/483d5da8-317a-4aa1-a5e7-3e735474a670 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[ParallelAutoAnalyzeService] Parallel analysis 483d5da8-317a-4aa1-a5e7-3e735474a670 completed successfully
[BackgroundJobQueue] Updated job progress to final state: complete
[BackgroundJobQueue] Parallel analysis job 483d5da8-317a-4aa1-a5e7-3e735474a670-parallel completed successfully
::1 - - [12/Aug/2025:16:57:34 +0000] "GET /api/analysis/auto-analyze/parallel/progress/483d5da8-317a-4aa1-a5e7-3e735474a670 HTTP/1.1" 200 981 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:16:57:34 +0000] "GET /api/analysis/auto-analyze/parallel/results/483d5da8-317a-4aa1-a5e7-3e735474a670 HTTP/1.1" 200 41921 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T17:00:08.538Z",
  "dateTo": "2025-08-12T17:01:08.538Z",
  "skip": 0,
  "limit": 1
}
::1 - - [12/Aug/2025:17:01:12 +0000] "GET /api/kore/test HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[getSessionsMetadataForConnectionTest] Connection test failed: Error: Connection test timeout after 10000ms
    at Timeout._onTimeout (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:491:33)
    at listOnTimeout (node:internal/timers:608:17)
    at process.processTimers (node:internal/timers:543:7)
Kore.ai API connection test failed: Error: Connection test timeout after 10000ms
    at Timeout._onTimeout (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:491:33)
    at listOnTimeout (node:internal/timers:608:17)
    at process.processTimers (node:internal/timers:543:7)
[fetchContainmentTypeMetadata] API Response: 1 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [ '689b73223360bd076e1706ed' ]
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T17:00:43.608Z",
  "dateTo": "2025-08-12T17:01:43.608Z",
  "skip": 0,
  "limit": 1
}
[fetchContainmentTypeMetadata] API Response: 1 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [ '689b7359759df740254d1b48' ]
[getSessionsMetadataForConnectionTest] Single API call succeeded with 1 sessions
::1 - - [12/Aug/2025:17:01:46 +0000] "GET /api/kore/test HTTP/1.1" 200 851 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[Direct API] Fetching real Kore.ai sessions from 2025-08-05T17:01:47.254Z to 2025-08-12T17:01:47.254Z for User Bot st-90549... (limit=50)
Retrieving sessions from 2025-08-05T17:01:47.254Z to 2025-08-12T17:01:47.254Z (limit=50), populateMessages=true...
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T17:01:47.254Z",
  "dateTo": "2025-08-12T17:01:47.254Z",
  "limit": 50
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T17:01:47.254Z",
  "dateTo": "2025-08-12T17:01:47.254Z",
  "skip": 0,
  "limit": 50
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T17:01:47.254Z",
  "dateTo": "2025-08-12T17:01:47.254Z",
  "skip": 0,
  "limit": 50
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T17:01:47.254Z",
  "dateTo": "2025-08-12T17:01:47.254Z",
  "skip": 0,
  "limit": 50
}
::1 - - [12/Aug/2025:17:01:47 +0000] "GET /api/analysis/sessions?limit=50 HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 50 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b7359759df740254d1b48',
  '689b73513d161a6761559d8d',
  '689b733e05a45fff89065709'
]
[fetchContainmentTypeMetadata] API Response: 50 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b737505a45fff89065d95',
  '689b737404e17fb1eb52ae99',
  '689b736d8ee3c38f17a7b95b'
]
[fetchContainmentTypeMetadata] API Response: 50 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b6f421cf7bdce60f849f6',
  '689b6e5f8ee3c38f17a70039',
  '689b6e28b12946428596c9fd'
]
[getSessionsMetadata] agent API call succeeded with 50 sessions
[getSessionsMetadata] selfService API call succeeded with 50 sessions
[getSessionsMetadata] dropOff API call succeeded with 50 sessions
Total session metadata retrieved: 150 (parallel execution)
Retrieved 150 session metadata objects
Creating 150 SWTs from metadata (no messages)
Created 150 SWT objects from metadata
Populating messages for all sessions (legacy behavior)
Populating messages for 150 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 150 sessions from 2025-08-12T15:49:39.626Z to 2025-08-12T17:01:46.627Z at 2025-08-12T17:01:50.028Z
ğŸš€ [ConcurrentBatch] Split 150 sessions into 8 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/8] Starting: 20 sessions
[Batch 2/8] Starting: 20 sessions
[Batch 3/8] Starting: 20 sessions
[Batch 4/8] Starting: 20 sessions
[Batch 5/8] Starting: 20 sessions
[Batch 6/8] Starting: 20 sessions
[Batch 7/8] Starting: 20 sessions
[Batch 8/8] Starting: 10 sessions
[Batch 3/8] Completed in 259ms: 172 messages retrieved (1/8 done)
[Batch 1/8] Completed in 344ms: 179 messages retrieved (2/8 done)
[Batch 2/8] Completed in 452ms: 243 messages retrieved (3/8 done)
[Batch 8/8] Completed in 487ms: 113 messages retrieved (4/8 done)
[Batch 6/8] Completed in 491ms: 240 messages retrieved (5/8 done)
[Batch 7/8] Completed in 494ms: 237 messages retrieved (6/8 done)
[Batch 4/8] Completed in 499ms: 237 messages retrieved (7/8 done)
[Batch 5/8] Completed in 723ms: 500 messages retrieved (8/8 done)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 724ms (0.72s)
â±ï¸  Batch Processing: 723ms (0.72s)
ğŸ“¦ Total batches: 8 (max 10 concurrent)
âœ… Successful batches: 8/8
ğŸ’¬ Total messages: 1921
ğŸ“ˆ Avg time per batch: 90ms
ğŸš€ Time per session: 5ms
ğŸ’ª Performance: 207.2 sessions/second
=======================================================

Retrieved 1921 messages for 150 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
Populated messages for 150 SWT objects
Generated 150 SWT objects in 3507ms using layered architecture
ğŸš€ [ParallelAutoAnalyzeRoute] Starting parallel analysis for bot ***REMOVED*** with real credentials
ğŸš€ [ParallelAutoAnalyzeService] Starting parallel analysis 9bca8d52-50ef-4527-b3fd-115db8c75919 with bot ***REMOVED***
ğŸš€ [ParallelAutoAnalyzeService] Using credentials: real
ğŸš€ [ParallelAutoAnalyzeRoute] Parallel analysis started: 9bca8d52-50ef-4527-b3fd-115db8c75919
::1 - - [12/Aug/2025:17:02:05 +0000] "POST /api/analysis/auto-analyze/parallel/start HTTP/1.1" 200 214 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:02:05 +0000] "GET /api/analysis/auto-analyze/parallel/progress/9bca8d52-50ef-4527-b3fd-115db8c75919 HTTP/1.1" 200 542 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:02:05 +0000] "GET /api/analysis/auto-analyze/parallel/progress/9bca8d52-50ef-4527-b3fd-115db8c75919 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[BackgroundJobQueue] Starting job processing after delay for job 9bca8d52-50ef-4527-b3fd-115db8c75919-parallel
[BackgroundJobQueue] Starting processing for job 9bca8d52-50ef-4527-b3fd-115db8c75919-parallel, phase: sampling
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing parallel analysis job 9bca8d52-50ef-4527-b3fd-115db8c75919-parallel
[BackgroundJobQueue] Processing parallel analysis for bot ***REMOVED***
[BackgroundJobQueue] Using existing ParallelAutoAnalyzeService instance for bot ***REMOVED***
[BackgroundJobQueue] Session recreated for 9bca8d52-50ef-4527-b3fd-115db8c75919
[ParallelAutoAnalyzeService] Running parallel analysis for 9bca8d52-50ef-4527-b3fd-115db8c75919
[ParallelAutoAnalyzeService] Phase 0: Starting session sampling for 9bca8d52-50ef-4527-b3fd-115db8c75919

ğŸ• ============ SESSION SAMPLING STARTED ============
ğŸ• [SessionSampling] Starting session sampling at 2025-08-12T17:02:06.890Z
ğŸ” [SessionDiscovery] Starting window 1/4: Initial 3-hour window
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
::1 - - [12/Aug/2025:17:02:07 +0000] "GET /api/analysis/auto-analyze/parallel/progress/9bca8d52-50ef-4527-b3fd-115db8c75919 HTTP/1.1" 200 719 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 80 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a1287849680ad9fe59e',
  '689229f9583056c6108e38fb',
  '68922914f8bee7ba6c3e67b8'
]
::1 - - [12/Aug/2025:17:02:09 +0000] "GET /api/analysis/auto-analyze/parallel/progress/9bca8d52-50ef-4527-b3fd-115db8c75919 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 139 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6a14dd27c3112087cd',
  '68922a22ef03d8ad2ec7b4ba',
  '68922a1278c1fe09a079719c'
]
::1 - - [12/Aug/2025:17:02:11 +0000] "GET /api/analysis/auto-analyze/parallel/progress/9bca8d52-50ef-4527-b3fd-115db8c75919 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 1338 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6d14dd27c31120888b',
  '68922a62e3804084741191d5',
  '68922a523a3160d25de144c8'
]
[getSessionsMetadata] agent API call succeeded with 1338 sessions
[getSessionsMetadata] selfService API call succeeded with 80 sessions
[getSessionsMetadata] dropOff API call succeeded with 139 sessions
Total session metadata retrieved: 1557 (parallel execution)
Creating 1557 SWTs from metadata (no messages)
Created 1557 SWT objects from metadata
âœ… [SessionDiscovery] Window 1 completed in 5203ms: found 1557 new sessions (total: 1557)
â±ï¸  TIMING: Window 1 took 5203ms (5.20s)
ğŸ¯ [SessionDiscovery] Target reached! Found 1557 sessions in 5204ms
ğŸ² [SessionSampling] Random sampling from 1557 sessions to 100 sessions

ğŸ“¬ ============ MESSAGE RETRIEVAL STARTED ============
ğŸ“¬ [MessageRetrieval] Starting message retrieval for 100 sampled sessions at 2025-08-12T17:02:12.095Z
Using new lazy loading approach to populate messages for 100 sampled sessions
Populating messages for 100 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 100 sessions from 2025-08-05T13:02:53.254Z to 2025-08-05T15:59:47.016Z at 2025-08-12T17:02:12.096Z
ğŸš€ [ConcurrentBatch] Split 100 sessions into 5 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/5] Starting: 20 sessions
[Batch 2/5] Starting: 20 sessions
[Batch 3/5] Starting: 20 sessions
[Batch 4/5] Starting: 20 sessions
[Batch 5/5] Starting: 20 sessions
[Batch 1/5] Completed in 360ms: 237 messages retrieved (1/5 done)
ğŸ“Š [BatchProgress] Reporting batch 1/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 40/100 sessions (Batch 2/5)
[Batch 2/5] Completed in 471ms: 286 messages retrieved (2/5 done)
ğŸ“Š [BatchProgress] Reporting batch 2/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 60/100 sessions (Batch 3/5)
[Batch 3/5] Completed in 555ms: 326 messages retrieved (3/5 done)
ğŸ“Š [BatchProgress] Reporting batch 3/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 80/100 sessions (Batch 4/5)
[Batch 4/5] Completed in 562ms: 202 messages retrieved (4/5 done)
ğŸ“Š [BatchProgress] Reporting batch 4/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 100/100 sessions (Batch 5/5)
[Batch 5/5] Completed in 608ms: 217 messages retrieved (5/5 done)
ğŸ“Š [BatchProgress] Reporting batch 5/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 100/100 sessions (Batch 6/5)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 608ms (0.61s)
â±ï¸  Batch Processing: 608ms (0.61s)
ğŸ“¦ Total batches: 5 (max 10 concurrent)
âœ… Successful batches: 5/5
ğŸ’¬ Total messages: 1268
ğŸ“ˆ Avg time per batch: 122ms
ğŸš€ Time per session: 6ms
ğŸ’ª Performance: 164.5 sessions/second
=======================================================

Retrieved 1268 messages for 100 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
Populated messages for 100 SWT objects
Successfully populated messages for 100 sessions using lazy loading
Applying final filtering to 100 sessions with populated messages
Final result: 99 sessions passed filtering with populated messages

ğŸ‰ ============ SESSION SAMPLING COMPLETED ============
â±ï¸  TOTAL TIME: 5819ms (5.82s)
â±ï¸  Session Discovery: 5204ms (5.20s) - 89.4% of total
â±ï¸  Message Retrieval: 614ms (0.61s) - 10.6% of total
â±ï¸  Performance: 17.0 sessions/second
ğŸ¯ Final result: 99 sessions with messages retrieved
====================================================

[StrategicDiscoveryService] Starting discovery phase with 99 total sessions
[StrategicDiscoveryService] Discovery config: {
  targetPercentage: 15,
  minSessions: 9,
  maxSessions: 14,
  diversityStrategy: {
    sessionLengths: [ 'short', 'medium', 'long' ],
    containmentTypes: [ 'agent', 'selfService', 'dropOff' ],
    timeDistribution: 'spread'
  }
}
[StrategicDiscoveryService] Selecting 14 diverse sessions from 99 total
[StrategicDiscoveryService] Session diversity groups: { short: 29, medium: 69, long: 1, early: 33, middle: 33, late: 33 }
[StrategicDiscoveryService] Selected sessions by length distribution: { short: 4, medium: 9, long: 1 }
[StrategicDiscoveryService] Selected 14 sessions for discovery

ğŸ“¦ ===== BATCH 3 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T17:02:12.710Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 0
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T17:02:12.710Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:02:12.711Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6407,
  existingClassifications: { intents: 0, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.



For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and another intent, classify the intent as the other i...
::1 - - [12/Aug/2025:17:02:13 +0000] "GET /api/analysis/auto-analyze/parallel/progress/9bca8d52-50ef-4527-b3fd-115db8c75919 HTTP/1.1" 200 932 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:02:15 +0000] "GET /api/analysis/auto-analyze/parallel/progress/9bca8d52-50ef-4527-b3fd-115db8c75919 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:02:17.964Z',
  duration: '5253ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1854,
    completion_tokens: 364,
    total_tokens: 2218,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Unknown', 'Claim status' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-4c5fc415-21ff-5dd7-86a1-dc62c4002f59",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak to someone but did not provide further details."
    },
    {
      "user_id": "u-7e18204f-f922-5c06-970f-e38d7996d039",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested agent but did not specify the reason."
    },
    {
      "user_id": "u-486516ab-3c5c-5694-a9fe-6e098e64b961",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked to talk to someone at direct time but did not specify the reason."
    },
    {
      "user_id": "u-bf8a4ab3-f5ae-55ae-8000-ba2b159a1ab7",
      "general_intent": "Claim status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User provided claim number and zip code, then was transferred to an agent."
    },
    {
      "user_id": "u-8918a80e-1731-5535-ac5a-190c35f884c8",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a representative, then was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1854,
  completionTokens: 364,
  totalTokens: 2218,
  cost: '$0.000331',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 5255ms (5.25s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2218 ($0.0003)
âš¡ Performance: 422.1 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 1ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 5256ms (5.26s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2218

âœ… ===== BATCH 3 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 5256ms (5.26s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2218 ($0.0003)
âš¡ Performance: 1.0 sessions/sec
âš¡ Avg Time Per Session: 1051.20ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 1 complete: 4 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 2, reasons: 1, locations: 1, total: 4 }

ğŸ“¦ ===== BATCH 4 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T17:02:17.966Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 2
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T17:02:17.966Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:02:17.966Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6979,
  existingClassifications: { intents: 2, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim status, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live A...
::1 - - [12/Aug/2025:17:02:17 +0000] "GET /api/analysis/auto-analyze/parallel/progress/9bca8d52-50ef-4527-b3fd-115db8c75919 HTTP/1.1" 200 949 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:02:19 +0000] "GET /api/analysis/auto-analyze/parallel/progress/9bca8d52-50ef-4527-b3fd-115db8c75919 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:02:21 +0000] "GET /api/analysis/auto-analyze/parallel/progress/9bca8d52-50ef-4527-b3fd-115db8c75919 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:02:21.971Z',
  duration: '4005ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2005,
    completion_tokens: 383,
    total_tokens: 2388,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Claim Status', 'Unknown' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-dc0fc431-39bd-5277-bdc7-d884a570adc3",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to confirm leave request date and was transferred to an agent."
    },
    {
      "user_id": "u-173dd7ee-4bae-5495-b390-c95776cb4a17",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with a representative about a fax number and was transferred to an agent."
    },
    {
      "user_id": "u-12daa5f5-7cd9-5a3e-9532-4797abedb5c9",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with Linda Stout and was transferred to an agent."
    },
    {
      "user_id": "u-eb5f4f48-1f88-5d44-85e5-866af37d23dc",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked to speak to someone regarding status and was transferred to an agent."
    },
    {
      "user_id": "u-cfb7f7b1-be81-5c2c-8d1c-9a66869ad4d0",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent, then asked to report jury duty, and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2005,
  completionTokens: 383,
  totalTokens: 2388,
  cost: '$0.000354',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 4005ms (4.00s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2388 ($0.0004)
âš¡ Performance: 596.3 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 4006ms (4.01s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2388

âœ… ===== BATCH 4 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 4006ms (4.01s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2388 ($0.0004)
âš¡ Performance: 1.2 sessions/sec
âš¡ Avg Time Per Session: 801.20ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 2 complete: 1 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 3, reasons: 1, locations: 1, total: 5 }

ğŸ“¦ ===== BATCH 5 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T17:02:21.972Z
ğŸ“Š Sessions in Batch: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 4
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T17:02:21.972Z
ğŸ“Š Sessions to Analyze: 4

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:02:21.975Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 8994,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibi...
::1 - - [12/Aug/2025:17:02:23 +0000] "GET /api/analysis/auto-analyze/parallel/progress/9bca8d52-50ef-4527-b3fd-115db8c75919 HTTP/1.1" 200 950 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:02:25.696Z',
  duration: '3720ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2500,
    completion_tokens: 279,
    total_tokens: 2779,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status', 'Live Agent' ],
  transferCount: 2,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-5f42f78c-0cef-534a-9e8e-b8b7962ee692",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User was navigating time entry for leave request and did not request transfer to an agent."
    },
    {
      "user_id": "u-fe558fcb-fc70-5e53-a5f8-b0375d082f05",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative, resulting in transfer to an agent."
    },
    {
      "user_id": "u-56fec388-dbe1-52a2-a644-0a4e9d3dc604",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User attempted to check remaining hours but was transferred to an agent after failing to provide leave request details."
    },
    {
      "user_id": "u-feb3f7d5-0b52-5fb2-baf5-1359e399f9cd",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent, resulting in transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2500,
  completionTokens: 279,
  totalTokens: 2779,
  cost: '$0.000362',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 3725ms (3.73s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2779 ($0.0004)
âš¡ Performance: 746.0 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 4
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 3725ms (3.73s)
ğŸ“Š Regular Sessions Processed: 4
ğŸ’° Regular Tokens Used: 2779

âœ… ===== BATCH 5 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 3725ms (3.73s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Total Tokens: 2779 ($0.0004)
âš¡ Performance: 1.1 sessions/sec
âš¡ Avg Time Per Session: 931.25ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 3 complete: 1 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 4, reasons: 1, locations: 1, total: 6 }
[StrategicDiscoveryService] Discovery phase complete: {
  totalProcessed: 14,
  uniqueIntents: 4,
  uniqueReasons: 1,
  uniqueLocations: 1,
  discoveryRate: 0.4
}

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T17:02:25.698Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms
[ParallelProcessingOrchestrator] Configuration for 85 sessions:
  Design: 8 streams Ã— 4 sessions = 32 per round
  Optimal: 8 streams Ã— 4 sessions = 32 per round
  Estimated Rounds: 3
[ParallelAutoAnalyzeService] Using parallel config: {
  streamCount: 8,
  sessionsPerStream: 4,
  maxSessionsPerLLMCall: 50,
  syncFrequency: 'after_each_round',
  retryAttempts: 3,
  debugLogging: false
}

ğŸš€ ============ PARALLEL PROCESSING STARTED ============
â±ï¸  Start Time: 2025-08-12T17:02:25.699Z
ğŸ“Š Total Sessions: 85

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T17:02:25.699Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms

âš™ï¸  ============ PARALLEL CONFIGURATION ============
â±ï¸  Config Time: 0ms
ğŸ”§ Stream Count: 8
ğŸ“¦ Sessions Per Stream: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per API Call: 50
ğŸ¯ Debug Logging: false

ğŸ”„ ============ ROUND 1/3 STARTED ============
â±ï¸  Round 1 Start: 2025-08-12T17:02:25.699Z
ğŸ“Š Sessions Remaining: 85
[ParallelProcessingOrchestrator] Distributed 32 sessions across 8 streams: [
  'Stream 1: 4 sessions',
  'Stream 2: 4 sessions',
  'Stream 3: 4 sessions',
  'Stream 4: 4 sessions',
  'Stream 5: 4 sessions',
  'Stream 6: 4 sessions',
  'Stream 7: 4 sessions',
  'Stream 8: 4 sessions'
]
â±ï¸  Session Distribution Time: 1ms
ğŸŒŠ Active Streams: 8

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 8 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T17:02:25.700Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:02:25.701Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 747
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6247
   â€¢ Avg Per Session: 187 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6247
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6247
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:02:25.701Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:02:25.702Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6222,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billin...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T17:02:25.702Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:02:25.702Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 653
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6153
   â€¢ Avg Per Session: 163 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6153
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6153
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:02:25.702Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:02:25.702Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5748,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billin...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T17:02:25.702Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:02:25.702Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 660
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6160
   â€¢ Avg Per Session: 165 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6160
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 1ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6160
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:02:25.703Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:02:25.703Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5784,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billin...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T17:02:25.703Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:02:25.703Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 885
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6385
   â€¢ Avg Per Session: 221 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6385
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 1ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6385
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:02:25.704Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:02:25.704Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6828,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billin...

ğŸŒŠ ===== STREAM 5 PROCESSING START =====
â±ï¸  Stream 5 Start: 2025-08-12T17:02:25.704Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:02:25.704Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 696
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6196
   â€¢ Avg Per Session: 174 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6196
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 5) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6196
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 5: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:02:25.704Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:02:25.704Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5895,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billin...

ğŸŒŠ ===== STREAM 6 PROCESSING START =====
â±ï¸  Stream 6 Start: 2025-08-12T17:02:25.705Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:02:25.705Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 859
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6359
   â€¢ Avg Per Session: 215 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6359
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 6) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6359
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 6: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:02:25.705Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:02:25.705Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6742,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billin...

ğŸŒŠ ===== STREAM 7 PROCESSING START =====
â±ï¸  Stream 7 Start: 2025-08-12T17:02:25.705Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:02:25.705Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 630
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6130
   â€¢ Avg Per Session: 158 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6130
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 7) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6130
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 7: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:02:25.705Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:02:25.705Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5658,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billin...

ğŸŒŠ ===== STREAM 8 PROCESSING START =====
â±ï¸  Stream 8 Start: 2025-08-12T17:02:25.705Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:02:25.705Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 962
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6462
   â€¢ Avg Per Session: 241 tokens
   â€¢ Estimation Time: 1ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6462
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 1ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 8) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6462
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 8: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:02:25.706Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:02:25.706Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7249,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billin...
::1 - - [12/Aug/2025:17:02:25 +0000] "GET /api/analysis/auto-analyze/parallel/progress/9bca8d52-50ef-4527-b3fd-115db8c75919 HTTP/1.1" 200 1710 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:02:27 +0000] "GET /api/analysis/auto-analyze/parallel/progress/9bca8d52-50ef-4527-b3fd-115db8c75919 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:02:28.430Z',
  duration: '2725ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1680,
    completion_tokens: 226,
    total_tokens: 1906,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status', 'Live Agent' ],
  transferCount: 2,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-afe49426-bc8f-59cb-8f7d-41caafb7e4dc",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-6ca9ff29-83b0-5d00-8455-3e8f335f1a4e",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": ""
    },
    {
      "user_id": "u-d2c766a4-4198-5bdb-90eb-b69d0d5ffc1f",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-a891f1b6-ee40-5f50-829a-2a98b7f34762",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": ""
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1680,
  completionTokens: 226,
  totalTokens: 1906,
  cost: '$0.000258',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2726ms (2.73s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1906 ($0.0003)
âš¡ Performance: 699.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1680
   â€¢ Completion Tokens: 226
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-afe49426-bc8f-59cb-8f7d-41caafb7e4dc: Invalid notes, u-6ca9ff29-83b0-5d00-8455-3e8f335f1a4e: Invalid notes, u-d2c766a4-4198-5bdb-90eb-b69d0d5ffc1f: Invalid notes, u-a891f1b6-ee40-5f50-829a-2a98b7f34762: Invalid notes'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 5 Single Batch Time: 2728ms (2.73s)

âœ… ===== STREAM 5 PROCESSING COMPLETE =====
â±ï¸  Stream 5 Total Time: 2728ms (2.73s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1906 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.5 sessions/sec
âš¡ Avg Time Per Session: 682.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:02:28.939Z',
  duration: '3235ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1935,
    completion_tokens: 276,
    total_tokens: 2211,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown', 'Live Agent' ],
  transferCount: 2,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-1dd19dc4-dc07-5d8d-94c9-00073d90ae6a",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "Session ended without user input, no transfer or specific intent identified."
    },
    {
      "user_id": "u-d6c25e65-0980-5ecf-9f22-9e7faf5dda31",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User sought assistance with updating FMLA and was transferred to a live agent."
    },
    {
      "user_id": "u-186c7475-cf74-55e3-be6c-33cdc053498a",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User attempted to track time but did not have active leave requests; session ended without transfer."
    },
    {
      "user_id": "u-e48dbf90-737f-5e3d-bd79-0c9c742fc8c3",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred to a live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1935,
  completionTokens: 276,
  totalTokens: 2211,
  cost: '$0.000304',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 3236ms (3.24s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2211 ($0.0003)
âš¡ Performance: 683.3 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1935
   â€¢ Completion Tokens: 276
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 4 Single Batch Time: 3236ms (3.24s)

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 3237ms (3.24s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2211 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.2 sessions/sec
âš¡ Avg Time Per Session: 809.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:02:29.279Z',
  duration: '3576ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1668,
    completion_tokens: 291,
    total_tokens: 1959,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Claim Status' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-61545ab9-aa39-585f-94b8-d36f3774765e",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-98f165c6-00ce-531f-b76e-b85c0a90d696",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred, session ended after no input."
    },
    {
      "user_id": "u-a9626a1d-21e3-5524-9fab-7ea940ff1618",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked to make a claim, was transferred to an agent."
    },
    {
      "user_id": "u-3cf89b7b-28da-5cbc-8d86-f1205521705e",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1668,
  completionTokens: 291,
  totalTokens: 1959,
  cost: '$0.000283',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 3576ms (3.58s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1959 ($0.0003)
âš¡ Performance: 547.8 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1668
   â€¢ Completion Tokens: 291
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 3 Single Batch Time: 3577ms (3.58s)

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 3578ms (3.58s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1959 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.1 sessions/sec
âš¡ Avg Time Per Session: 894.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:02:29.426Z',
  duration: '3718ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2065,
    completion_tokens: 312,
    total_tokens: 2377,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown', 'Live Agent' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-3131cd1f-22f8-50c3-8fe6-8d20265a4d08",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to get leave status but was transferred to a live agent after multiple failed attempts to provide information."
    },
    {
      "user_id": "u-43a7da62-4ff0-5861-905b-bb12fdac635f",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a new leave request and was transferred to a live agent for assistance."
    },
    {
      "user_id": "u-ae2165f1-21f0-5cfb-8dc4-ac5e96cc7afc",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User reported time but was transferred to a live agent after unsuccessful attempts to verify details."
    },
    {
      "user_id": "u-7b049bb1-230d-5659-a88d-3a1d7afe5998",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred accordingly."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2065,
  completionTokens: 312,
  totalTokens: 2377,
  cost: '$0.000331',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 3721ms (3.72s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2377 ($0.0003)
âš¡ Performance: 638.8 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2065
   â€¢ Completion Tokens: 312
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 8 Single Batch Time: 3721ms (3.72s)

âœ… ===== STREAM 8 PROCESSING COMPLETE =====
â±ï¸  Stream 8 Total Time: 3722ms (3.72s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2377 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.1 sessions/sec
âš¡ Avg Time Per Session: 930.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:02:29.464Z',
  duration: '3762ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1652,
    completion_tokens: 280,
    total_tokens: 1932,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Claim Status', 'Unknown', 'Leave of Absence' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-6fcef7dc-b12d-5865-8e5f-a3cf893b772e",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-3f1cfaa1-2e1f-5568-80ce-52dd7ea55630",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User attempted to inquire about maternity leave but did not provide further details or input."
    },
    {
      "user_id": "u-70cea903-7919-577d-96eb-9e08d13cedc7",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and was transferred to an agent after no input."
    },
    {
      "user_id": "u-9d637f90-17ab-5282-86c1-504b54002788",
      "general_intent": "Leave of Absence",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested leave of absence and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1652,
  completionTokens: 280,
  totalTokens: 1932,
  cost: '$0.000277',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 3762ms (3.76s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1932 ($0.0003)
âš¡ Performance: 513.6 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1652
   â€¢ Completion Tokens: 280
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 2 Single Batch Time: 3762ms (3.76s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 3762ms (3.76s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1932 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.1 sessions/sec
âš¡ Avg Time Per Session: 940.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:02:29.560Z',
  duration: '3858ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1774,
    completion_tokens: 307,
    total_tokens: 2081,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown', 'FMLA leave' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-e423eb80-3c71-512b-82b2-d61d7ebf275a",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was seeking help with a leave request but was unable to provide necessary information and was transferred to an agent."
    },
    {
      "user_id": "u-3a020de4-f067-5a2b-9539-76193bde453c",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to file FMLA papers but did not respond to transfer prompt and was transferred to an agent."
    },
    {
      "user_id": "u-3428b9d5-b664-51b1-a590-536149789a0a",
      "general_intent": "FMLA leave",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User provided leave request details and was transferred to an agent for further assistance."
    },
    {
      "user_id": "u-be95aceb-876e-590d-ad80-c672b854dc56",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1774,
  completionTokens: 307,
  totalTokens: 2081,
  cost: '$0.000300',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 3861ms (3.86s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2081 ($0.0003)
âš¡ Performance: 539.0 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1774
   â€¢ Completion Tokens: 307
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 1 Single Batch Time: 3861ms (3.86s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 3862ms (3.86s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2081 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.0 sessions/sec
âš¡ Avg Time Per Session: 965.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:02:29.581Z',
  duration: '3876ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1926,
    completion_tokens: 229,
    total_tokens: 2155,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status', 'Time Entry', 'Live Agent' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-f8982ac7-a3b8-59ea-ae7d-b3ae27368b49",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-b6c8cf4b-0c23-5849-964d-5b5a8337f1e3",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-efb861cd-edf8-530d-875e-4a8ad29dfa62",
      "general_intent": "Time Entry",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": ""
    },
    {
      "user_id": "u-29329b41-cfc1-5c19-bd5e-9fbbfde1bcb4",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1926,
  completionTokens: 229,
  totalTokens: 2155,
  cost: '$0.000284',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 3876ms (3.88s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2155 ($0.0003)
âš¡ Performance: 556.0 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1926
   â€¢ Completion Tokens: 229
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-f8982ac7-a3b8-59ea-ae7d-b3ae27368b49: Invalid notes, u-b6c8cf4b-0c23-5849-964d-5b5a8337f1e3: Invalid notes, u-efb861cd-edf8-530d-875e-4a8ad29dfa62: Invalid notes, u-29329b41-cfc1-5c19-bd5e-9fbbfde1bcb4: Invalid notes'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 6 Single Batch Time: 3877ms (3.88s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 6 PROCESSING COMPLETE =====
â±ï¸  Stream 6 Total Time: 3877ms (3.88s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2155 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.0 sessions/sec
âš¡ Avg Time Per Session: 969.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:02:29.950Z',
  duration: '4245ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1637,
    completion_tokens: 288,
    total_tokens: 1925,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Claim Status', 'Report Time' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-30342e26-d14c-5c12-95dc-da2f8fc4f5b0",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-41864219-53c5-5cca-ab71-5a00283cc528",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested customer service and was transferred to an agent."
    },
    {
      "user_id": "u-7034345e-9323-5b95-a776-6e05758dcb41",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to file a new claim and was transferred to an agent."
    },
    {
      "user_id": "u-e88fafb9-c36e-5079-8f19-5bedf9173a8c",
      "general_intent": "Report Time",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to report time but was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1637,
  completionTokens: 288,
  totalTokens: 1925,
  cost: '$0.000279',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 4245ms (4.25s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1925 ($0.0003)
âš¡ Performance: 453.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1637
   â€¢ Completion Tokens: 288
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 7 Single Batch Time: 4246ms (4.25s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 7 PROCESSING COMPLETE =====
â±ï¸  Stream 7 Total Time: 4246ms (4.25s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1925 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.9 sessions/sec
âš¡ Avg Time Per Session: 1061.50ms
[ParallelProcessingOrchestrator] Parallel processing complete: 8/8 streams succeeded
â±ï¸  Parallel Processing Time: 4251ms (4.25s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 8 streams
[ParallelProcessingOrchestrator] Synchronization complete: 4 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 4
ğŸ“Š Total Classifications: 10

âœ… ============ ROUND 1 COMPLETED ============
â±ï¸  Round 1 Total Time: 4253ms (4.25s)
â±ï¸  Session Cleanup Time: 1ms
ğŸ“Š Sessions Remaining: 53
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 1ms (0.0%)
   â€¢ Parallel Processing: 4251ms (100.0%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 1ms (0.0%)

ğŸ”„ ============ ROUND 2/3 STARTED ============
â±ï¸  Round 2 Start: 2025-08-12T17:02:29.952Z
ğŸ“Š Sessions Remaining: 53
[ParallelProcessingOrchestrator] Distributed 32 sessions across 8 streams: [
  'Stream 1: 4 sessions',
  'Stream 2: 4 sessions',
  'Stream 3: 4 sessions',
  'Stream 4: 4 sessions',
  'Stream 5: 4 sessions',
  'Stream 6: 4 sessions',
  'Stream 7: 4 sessions',
  'Stream 8: 4 sessions'
]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 8

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 8 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T17:02:29.952Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:02:29.952Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 940
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6440
   â€¢ Avg Per Session: 235 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6440
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6440
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:02:29.952Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 8
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:02:29.953Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7145,
  existingClassifications: { intents: 8, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, FMLA leave, Leave of Absence, Live Agent, Report Time, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usual...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T17:02:29.953Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:02:29.953Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 1260
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6760
   â€¢ Avg Per Session: 315 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6760
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0011
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6760
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0011

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:02:29.953Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 8
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:02:29.953Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 8629,
  existingClassifications: { intents: 8, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, FMLA leave, Leave of Absence, Live Agent, Report Time, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usual...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T17:02:29.953Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:02:29.953Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 818
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6318
   â€¢ Avg Per Session: 205 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6318
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6318
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:02:29.954Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 8
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:02:29.954Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6585,
  existingClassifications: { intents: 8, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, FMLA leave, Leave of Absence, Live Agent, Report Time, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usual...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T17:02:29.954Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:02:29.954Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 827
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6327
   â€¢ Avg Per Session: 207 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6327
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6327
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:02:29.954Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 8
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:02:29.954Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6631,
  existingClassifications: { intents: 8, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, FMLA leave, Leave of Absence, Live Agent, Report Time, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usual...

ğŸŒŠ ===== STREAM 5 PROCESSING START =====
â±ï¸  Stream 5 Start: 2025-08-12T17:02:29.954Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:02:29.954Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 667
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6167
   â€¢ Avg Per Session: 167 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6167
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 5) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6167
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 5: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:02:29.954Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 8
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:02:29.955Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5853,
  existingClassifications: { intents: 8, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, FMLA leave, Leave of Absence, Live Agent, Report Time, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usual...

ğŸŒŠ ===== STREAM 6 PROCESSING START =====
â±ï¸  Stream 6 Start: 2025-08-12T17:02:29.955Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:02:29.955Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 700
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6200
   â€¢ Avg Per Session: 175 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6200
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 6) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6200
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 6: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:02:29.955Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 8
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:02:29.955Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6027,
  existingClassifications: { intents: 8, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, FMLA leave, Leave of Absence, Live Agent, Report Time, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usual...

ğŸŒŠ ===== STREAM 7 PROCESSING START =====
â±ï¸  Stream 7 Start: 2025-08-12T17:02:29.955Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:02:29.955Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 652
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6152
   â€¢ Avg Per Session: 163 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6152
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 7) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6152
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 7: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:02:29.955Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 8
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:02:29.955Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5799,
  existingClassifications: { intents: 8, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, FMLA leave, Leave of Absence, Live Agent, Report Time, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usual...

ğŸŒŠ ===== STREAM 8 PROCESSING START =====
â±ï¸  Stream 8 Start: 2025-08-12T17:02:29.955Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:02:29.955Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 849
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6349
   â€¢ Avg Per Session: 212 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6349
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 1ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 8) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6349
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 8: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:02:29.956Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 8
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:02:29.956Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6725,
  existingClassifications: { intents: 8, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, FMLA leave, Leave of Absence, Live Agent, Report Time, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usual...
::1 - - [12/Aug/2025:17:02:29 +0000] "GET /api/analysis/auto-analyze/parallel/progress/9bca8d52-50ef-4527-b3fd-115db8c75919 HTTP/1.1" 200 1710 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:02:31 +0000] "GET /api/analysis/auto-analyze/parallel/progress/9bca8d52-50ef-4527-b3fd-115db8c75919 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:02:32.150Z',
  duration: '2194ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1904,
    completion_tokens: 204,
    total_tokens: 2108,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-22bc10db-310c-595b-8eb3-77ec54aa1207",
      "notes": "User wanted to speak with an agent but did not provide input, resulting in session closure."
    },
    {
      "user_id": "u-4000bdd6-06fa-574f-b9fb-0fed09e752cf",
      "notes": "User attempted to call with a fax number, but did not provide further input, leading to session closure."
    },
    {
      "user_id": "u-b3d05227-3bfb-5570-838d-534379ff2663",
      "notes": "User wanted to speak with an agent; session was transferred to an agent."
    },
    {
      "user_id": "u-5963eb00-fc3e-5583-9f1c-578b7f1dc3b6",
      "notes": "User was trying to verify leave request details; session was transferred to an agent after failed attempts to get information."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1904,
  completionTokens: 204,
  totalTokens: 2108,
  cost: '$0.000272',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2194ms (2.19s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2108 ($0.0003)
âš¡ Performance: 960.8 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1904
   â€¢ Completion Tokens: 204
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-22bc10db-310c-595b-8eb3-77ec54aa1207: Invalid general_intent, u-22bc10db-310c-595b-8eb3-77ec54aa1207: Invalid session_outcome, u-4000bdd6-06fa-574f-b9fb-0fed09e752cf: Invalid general_intent, u-4000bdd6-06fa-574f-b9fb-0fed09e752cf: Invalid session_outcome, u-b3d05227-3bfb-5570-838d-534379ff2663: Invalid general_intent, u-b3d05227-3bfb-5570-838d-534379ff2663: Invalid session_outcome, u-5963eb00-fc3e-5583-9f1c-578b7f1dc3b6: Invalid general_intent, u-5963eb00-fc3e-5583-9f1c-578b7f1dc3b6: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 8 Single Batch Time: 2195ms (2.19s)

âœ… ===== STREAM 8 PROCESSING COMPLETE =====
â±ï¸  Stream 8 Total Time: 2196ms (2.20s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2108 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.8 sessions/sec
âš¡ Avg Time Per Session: 549.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:02:32.278Z',
  duration: '2325ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2014,
    completion_tokens: 220,
    total_tokens: 2234,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-14892cce-0b34-5f79-84ea-adbc915c78ff",
      "notes": "User wanted to speak to a representative about a letter received in the mail and was transferred to an agent."
    },
    {
      "user_id": "u-1271a3bf-fc5a-5237-bf15-67f6b06a016b",
      "notes": "User wanted to see if paperwork was received for return to work and requested to speak to an agent, resulting in a transfer."
    },
    {
      "user_id": "u-b51737c3-b249-5af7-a28b-e7bb78833734",
      "notes": "User attempted to provide leave request details but was unable, and was transferred to an agent after multiple failed attempts."
    },
    {
      "user_id": "u-cf991cfd-0eb3-52b6-9aa1-d2f9ca686aa9",
      "notes": "User was asked questions but was silent, then requested to speak to a customer service advocate, leading to a transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2014,
  completionTokens: 220,
  totalTokens: 2234,
  cost: '$0.000289',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2326ms (2.33s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2234 ($0.0003)
âš¡ Performance: 960.4 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2014
   â€¢ Completion Tokens: 220
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-14892cce-0b34-5f79-84ea-adbc915c78ff: Invalid general_intent, u-14892cce-0b34-5f79-84ea-adbc915c78ff: Invalid session_outcome, u-1271a3bf-fc5a-5237-bf15-67f6b06a016b: Invalid general_intent, u-1271a3bf-fc5a-5237-bf15-67f6b06a016b: Invalid session_outcome, u-b51737c3-b249-5af7-a28b-e7bb78833734: Invalid general_intent, u-b51737c3-b249-5af7-a28b-e7bb78833734: Invalid session_outcome, u-cf991cfd-0eb3-52b6-9aa1-d2f9ca686aa9: Invalid general_intent, u-cf991cfd-0eb3-52b6-9aa1-d2f9ca686aa9: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 1 Single Batch Time: 2327ms (2.33s)

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 2327ms (2.33s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2234 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.7 sessions/sec
âš¡ Avg Time Per Session: 581.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:02:32.561Z',
  duration: '2608ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2412,
    completion_tokens: 198,
    total_tokens: 2610,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-ab63427a-5402-51fa-87f1-0abf957e8c68",
      "notes": "User attempted to verify leave request and report time but hung up after providing employee number, resulting in transfer to a live agent."
    },
    {
      "user_id": "u-12ddc522-bd83-515d-ab38-faa7376b4cec",
      "notes": "User reported a time entry for absence, confirmed details, but transferred after incorrect date input."
    },
    {
      "user_id": "u-41af0814-e0dc-5703-9874-fe68f12dfadc",
      "notes": "User attempted to get claim status or speak to an agent but was transferred to an agent after initial inputs."
    },
    {
      "user_id": "u-37e03063-afef-5250-90e4-c28bb573f455",
      "notes": "User requested to speak to an agent, session transferred after initial prompt."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2412,
  completionTokens: 198,
  totalTokens: 2610,
  cost: '$0.000320',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2608ms (2.61s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2610 ($0.0003)
âš¡ Performance: 1000.8 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2412
   â€¢ Completion Tokens: 198
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-ab63427a-5402-51fa-87f1-0abf957e8c68: Invalid general_intent, u-ab63427a-5402-51fa-87f1-0abf957e8c68: Invalid session_outcome, u-12ddc522-bd83-515d-ab38-faa7376b4cec: Invalid general_intent, u-12ddc522-bd83-515d-ab38-faa7376b4cec: Invalid session_outcome, u-41af0814-e0dc-5703-9874-fe68f12dfadc: Invalid general_intent, u-41af0814-e0dc-5703-9874-fe68f12dfadc: Invalid session_outcome, u-37e03063-afef-5250-90e4-c28bb573f455: Invalid general_intent, u-37e03063-afef-5250-90e4-c28bb573f455: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 2 Single Batch Time: 2608ms (2.61s)

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 2608ms (2.61s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2610 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.5 sessions/sec
âš¡ Avg Time Per Session: 652.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:02:32.597Z',
  duration: '2643ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1887,
    completion_tokens: 208,
    total_tokens: 2095,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-a6caebae-ea8e-5c9c-bef0-7af6938b990c",
      "notes": "User wanted to speak with an agent, session was transferred to a live agent."
    },
    {
      "user_id": "u-1cb3e4ec-a55b-55ec-91cf-d6fbcb19ca65",
      "notes": "User wanted to speak with an agent, session was transferred to a live agent."
    },
    {
      "user_id": "u-351cedfb-9d1d-5b65-bbf1-5ace5870ed2f",
      "notes": "User inquired about time entry, bot attempted to assist but user did not have a leave request number."
    },
    {
      "user_id": "u-336964cc-89d8-5f7d-8752-594032bb16c8",
      "notes": "User provided claim and return to work details, but no transfer to an agent occurred; session was handled by bot."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1887,
  completionTokens: 208,
  totalTokens: 2095,
  cost: '$0.000272',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2643ms (2.64s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2095 ($0.0003)
âš¡ Performance: 792.7 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1887
   â€¢ Completion Tokens: 208
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-a6caebae-ea8e-5c9c-bef0-7af6938b990c: Invalid general_intent, u-a6caebae-ea8e-5c9c-bef0-7af6938b990c: Invalid session_outcome, u-1cb3e4ec-a55b-55ec-91cf-d6fbcb19ca65: Invalid general_intent, u-1cb3e4ec-a55b-55ec-91cf-d6fbcb19ca65: Invalid session_outcome, u-351cedfb-9d1d-5b65-bbf1-5ace5870ed2f: Invalid general_intent, u-351cedfb-9d1d-5b65-bbf1-5ace5870ed2f: Invalid session_outcome, u-336964cc-89d8-5f7d-8752-594032bb16c8: Invalid general_intent, u-336964cc-89d8-5f7d-8752-594032bb16c8: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 3 Single Batch Time: 2643ms (2.64s)

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 2644ms (2.64s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2095 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.5 sessions/sec
âš¡ Avg Time Per Session: 661.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:02:32.610Z',
  duration: '2655ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1737,
    completion_tokens: 202,
    total_tokens: 1939,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-13c0b0b3-e128-53a5-a06a-9fdaed19524c",
      "notes": "User wanted customer service but did not specify the reason, and was transferred to an agent after some confusion."
    },
    {
      "user_id": "u-62d9d468-db8d-506d-b346-8b28ea086b77",
      "notes": "User requested to talk about a claim and was transferred to an agent."
    },
    {
      "user_id": "u-3f48cbe1-1f8f-5e2a-8a85-c22b43e243de",
      "notes": "User asked about FMLA paperwork and was transferred to an agent."
    },
    {
      "user_id": "u-6249e06f-2c21-5664-b3fa-43e674f00f55",
      "notes": "User inquired about claim status and was transferred to an agent after providing claim details."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1737,
  completionTokens: 202,
  totalTokens: 1939,
  cost: '$0.000255',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2655ms (2.65s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1939 ($0.0003)
âš¡ Performance: 730.3 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1737
   â€¢ Completion Tokens: 202
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-13c0b0b3-e128-53a5-a06a-9fdaed19524c: Invalid general_intent, u-13c0b0b3-e128-53a5-a06a-9fdaed19524c: Invalid session_outcome, u-62d9d468-db8d-506d-b346-8b28ea086b77: Invalid general_intent, u-62d9d468-db8d-506d-b346-8b28ea086b77: Invalid session_outcome, u-3f48cbe1-1f8f-5e2a-8a85-c22b43e243de: Invalid general_intent, u-3f48cbe1-1f8f-5e2a-8a85-c22b43e243de: Invalid session_outcome, u-6249e06f-2c21-5664-b3fa-43e674f00f55: Invalid general_intent, u-6249e06f-2c21-5664-b3fa-43e674f00f55: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 6 Single Batch Time: 2656ms (2.66s)

âœ… ===== STREAM 6 PROCESSING COMPLETE =====
â±ï¸  Stream 6 Total Time: 2656ms (2.66s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1939 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.5 sessions/sec
âš¡ Avg Time Per Session: 664.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:02:32.867Z',
  duration: '2912ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1684,
    completion_tokens: 279,
    total_tokens: 1963,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Leave of Absence' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-5c0b0e0d-ffea-50ba-841b-c74c02b702f3",
      "general_intent": "Leave of Absence",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and was transferred to an agent for leave request assistance."
    },
    {
      "user_id": "u-1841b6a9-7ee9-52cf-9e63-0100836efa87",
      "general_intent": "Leave of Absence",
      "session_outcome": "Contained",
      "notes": "User was silent and session was closed due to no input."
    },
    {
      "user_id": "u-af29062d-77e3-57f4-b7bb-d5328c2ab867",
      "general_intent": "Leave of Absence",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested agent, session transferred."
    },
    {
      "user_id": "u-4eea5186-a7a0-5eb6-9542-85eb9f0bae60",
      "general_intent": "Leave of Absence",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested agent, session transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1684,
  completionTokens: 279,
  totalTokens: 1963,
  cost: '$0.000280',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2912ms (2.91s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1963 ($0.0003)
âš¡ Performance: 674.1 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1684
   â€¢ Completion Tokens: 279
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 7 Single Batch Time: 2912ms (2.91s)

âœ… ===== STREAM 7 PROCESSING COMPLETE =====
â±ï¸  Stream 7 Total Time: 2912ms (2.91s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1963 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.4 sessions/sec
âš¡ Avg Time Per Session: 728.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:02:32.988Z',
  duration: '3034ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1903,
    completion_tokens: 292,
    total_tokens: 2195,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status', 'Leave of Absence' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-74d21e4c-4e47-5ab6-93ff-72d6a9b2be50",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to start a new claim and was transferred to an agent."
    },
    {
      "user_id": "u-1abc4cf8-17fc-5fcb-a9bd-9bcc8b06d14e",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted claim paperwork and was transferred to an agent."
    },
    {
      "user_id": "u-403bae97-df2d-530a-909d-0f8a67aa8e00",
      "general_intent": "Leave of Absence",
      "session_outcome": "Contained",
      "notes": "User checked leave request status and asked about adding to it, but no transfer occurred."
    },
    {
      "user_id": "u-42bc83ad-4850-5f70-a135-dc698ab12113",
      "general_intent": "Leave of Absence",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak to a representative about leave, transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1903,
  completionTokens: 292,
  totalTokens: 2195,
  cost: '$0.000307',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 3034ms (3.03s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2195 ($0.0003)
âš¡ Performance: 723.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1903
   â€¢ Completion Tokens: 292
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 4 Single Batch Time: 3034ms (3.03s)

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 3034ms (3.03s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2195 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.3 sessions/sec
âš¡ Avg Time Per Session: 758.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:02:33.319Z',
  duration: '3364ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1682,
    completion_tokens: 286,
    total_tokens: 1968,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Unknown' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-890a85a0-ba52-5e31-8337-385a42ab386e",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-a36e9fc1-dc0a-5437-817b-8bf0eba3c648",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-32aa6ce6-e23c-5a0c-a845-1b43e62b315c",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested password reset and was transferred to an agent."
    },
    {
      "user_id": "u-54dae05a-5dc4-5704-a1c2-d3c04780598c",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1682,
  completionTokens: 286,
  totalTokens: 1968,
  cost: '$0.000283',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 3365ms (3.37s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1968 ($0.0003)
âš¡ Performance: 584.8 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1682
   â€¢ Completion Tokens: 286
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 5 Single Batch Time: 3365ms (3.37s)

âœ… ===== STREAM 5 PROCESSING COMPLETE =====
â±ï¸  Stream 5 Total Time: 3365ms (3.37s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1968 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.2 sessions/sec
âš¡ Avg Time Per Session: 841.25ms
[ParallelProcessingOrchestrator] Parallel processing complete: 8/8 streams succeeded
â±ï¸  Parallel Processing Time: 3368ms (3.37s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 8 streams
[ParallelProcessingOrchestrator] Synchronization complete: 0 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 0
ğŸ“Š Total Classifications: 10

âœ… ============ ROUND 2 COMPLETED ============
â±ï¸  Round 2 Total Time: 3368ms (3.37s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 21
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 3368ms (100.0%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ”„ ============ ROUND 3/3 STARTED ============
â±ï¸  Round 3 Start: 2025-08-12T17:02:33.320Z
ğŸ“Š Sessions Remaining: 21
[ParallelProcessingOrchestrator] Distributed 21 sessions across 6 streams: [
  'Stream 1: 4 sessions',
  'Stream 2: 4 sessions',
  'Stream 3: 4 sessions',
  'Stream 4: 4 sessions',
  'Stream 5: 4 sessions',
  'Stream 6: 1 sessions'
]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 6

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 6 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T17:02:33.320Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:02:33.320Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 726
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6226
   â€¢ Avg Per Session: 182 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6226
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6226
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:02:33.320Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 8
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:02:33.321Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6107,
  existingClassifications: { intents: 8, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, FMLA leave, Leave of Absence, Live Agent, Report Time, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usual...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T17:02:33.321Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:02:33.321Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 868
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6368
   â€¢ Avg Per Session: 217 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6368
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6368
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:02:33.321Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 8
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:02:33.321Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6821,
  existingClassifications: { intents: 8, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, FMLA leave, Leave of Absence, Live Agent, Report Time, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usual...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T17:02:33.321Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:02:33.321Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 761
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6261
   â€¢ Avg Per Session: 190 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6261
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6261
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:02:33.321Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 8
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:02:33.322Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6242,
  existingClassifications: { intents: 8, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, FMLA leave, Leave of Absence, Live Agent, Report Time, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usual...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T17:02:33.322Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:02:33.322Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 907
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6407
   â€¢ Avg Per Session: 227 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6407
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6407
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:02:33.322Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 8
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:02:33.322Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6952,
  existingClassifications: { intents: 8, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, FMLA leave, Leave of Absence, Live Agent, Report Time, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usual...

ğŸŒŠ ===== STREAM 5 PROCESSING START =====
â±ï¸  Stream 5 Start: 2025-08-12T17:02:33.322Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:02:33.322Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 693
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6193
   â€¢ Avg Per Session: 173 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6193
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 5) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6193
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 5: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:02:33.322Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 8
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:02:33.322Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5976,
  existingClassifications: { intents: 8, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, FMLA leave, Leave of Absence, Live Agent, Report Time, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usual...

ğŸŒŠ ===== STREAM 6 PROCESSING START =====
â±ï¸  Stream 6 Start: 2025-08-12T17:02:33.322Z
ğŸ“Š Sessions Assigned: 1
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:02:33.323Z
ğŸ“Š Sessions to Estimate: 1
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 1
   â€¢ Session Tokens: 181
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 5681
   â€¢ Avg Per Session: 181 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 5681
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0009
ğŸ“Š Recommended Batch Size: 1

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 6) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 5681
ğŸ“¦ Recommended Batch Size: 1
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0009

âš¡ Stream 6: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:02:33.323Z
ğŸ“Š Sessions to Analyze: 1
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 8
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:02:33.323Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 1,
  apiKey: 'sk-proj-...',
  promptLength: 4157,
  existingClassifications: { intents: 8, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, FMLA leave, Leave of Absence, Live Agent, Report Time, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usual...
::1 - - [12/Aug/2025:17:02:33 +0000] "GET /api/analysis/auto-analyze/parallel/progress/9bca8d52-50ef-4527-b3fd-115db8c75919 HTTP/1.1" 200 1520 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:02:34.348Z',
  duration: '1025ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1234,
    completion_tokens: 80,
    total_tokens: 1314,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 1,
  intentsFound: [ 'Leave of Absence' ],
  transferCount: 1,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-fbbc5ff4-ebc4-5b61-9f11-af2e63dc4e26",
      "general_intent": "Leave of Absence",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a live agent, session was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1234,
  completionTokens: 80,
  totalTokens: 1314,
  cost: '$0.000155',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1025ms (1.02s)
ğŸ“Š Sessions Returned: 1
ğŸ’° Tokens Used: 1314 ($0.0002)
âš¡ Performance: 1282.0 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1234
   â€¢ Completion Tokens: 80
[SessionValidationService] Validating batch response: 1 input sessions, 1 response sessions
[SessionValidationService] Validation successful: all 1 sessions processed
[SessionValidationService] Validating batch response: 1 input sessions, 1 response sessions
[SessionValidationService] Validation successful: all 1 sessions processed
â±ï¸  Stream 6 Single Batch Time: 1026ms (1.03s)

âœ… ===== STREAM 6 PROCESSING COMPLETE =====
â±ï¸  Stream 6 Total Time: 1027ms (1.03s)
ğŸ“Š Sessions Processed: 1/1
ğŸ’° Tokens Used: 1314 ($0.0002)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.0 sessions/sec
âš¡ Avg Time Per Session: 1027.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:02:35.862Z',
  duration: '2540ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1976,
    completion_tokens: 185,
    total_tokens: 2161,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-ed64c08d-dc63-59ff-b026-a681a76a8306",
      "notes": "User wanted customer service and was transferred to an agent."
    },
    {
      "user_id": "u-fb03cc4b-00eb-569f-b079-aab2ee118a52",
      "notes": "User attempted to provide information but was transferred to an agent after multiple failed attempts to identify themselves."
    },
    {
      "user_id": "u-b36cc8dc-5a3e-5548-8a1c-917130856581",
      "notes": "User wanted customer service and was transferred to an agent."
    },
    {
      "user_id": "u-abc89e36-f67e-5725-933b-1a87a3f98e2e",
      "notes": "User asked about FMLA and requested to speak to an agent, resulting in transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1976,
  completionTokens: 185,
  totalTokens: 2161,
  cost: '$0.000272',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2541ms (2.54s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2161 ($0.0003)
âš¡ Performance: 850.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1976
   â€¢ Completion Tokens: 185
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-ed64c08d-dc63-59ff-b026-a681a76a8306: Invalid general_intent, u-ed64c08d-dc63-59ff-b026-a681a76a8306: Invalid session_outcome, u-fb03cc4b-00eb-569f-b079-aab2ee118a52: Invalid general_intent, u-fb03cc4b-00eb-569f-b079-aab2ee118a52: Invalid session_outcome, u-b36cc8dc-5a3e-5548-8a1c-917130856581: Invalid general_intent, u-b36cc8dc-5a3e-5548-8a1c-917130856581: Invalid session_outcome, u-abc89e36-f67e-5725-933b-1a87a3f98e2e: Invalid general_intent, u-abc89e36-f67e-5725-933b-1a87a3f98e2e: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 4 Single Batch Time: 2541ms (2.54s)

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 2541ms (2.54s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2161 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.6 sessions/sec
âš¡ Avg Time Per Session: 635.25ms
::1 - - [12/Aug/2025:17:02:35 +0000] "GET /api/analysis/auto-analyze/parallel/progress/9bca8d52-50ef-4527-b3fd-115db8c75919 HTTP/1.1" 200 1524 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:02:36.802Z',
  duration: '3480ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1704,
    completion_tokens: 279,
    total_tokens: 1983,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Customer Service', 'Claim Status' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-c3680942-77b9-5c73-8d1e-43daedcd55e6",
      "general_intent": "Customer Service",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent and was transferred."
    },
    {
      "user_id": "u-17ba5430-d8df-565a-b09e-92323482fa8b",
      "general_intent": "Customer Service",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent and was transferred."
    },
    {
      "user_id": "u-0a40fb72-2dad-50cf-8a90-dce202d77233",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent regarding filing a claim and was transferred."
    },
    {
      "user_id": "u-536258a1-e64f-5a6d-a217-644fb3ce7214",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User attempted to check claim status but did not provide enough information, session was not transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1704,
  completionTokens: 279,
  totalTokens: 1983,
  cost: '$0.000282',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 3480ms (3.48s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1983 ($0.0003)
âš¡ Performance: 569.8 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1704
   â€¢ Completion Tokens: 279
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 5 Single Batch Time: 3481ms (3.48s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 5 PROCESSING COMPLETE =====
â±ï¸  Stream 5 Total Time: 3481ms (3.48s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1983 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.1 sessions/sec
âš¡ Avg Time Per Session: 870.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:02:37.067Z',
  duration: '3746ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1750,
    completion_tokens: 299,
    total_tokens: 2049,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Leave of Absence' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-e977e2cf-fab1-55e1-ac68-2ca1d70e1d5c",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-48f4a31f-236a-5794-9d03-40a9cfc780c3",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-99f9a726-5450-5a1c-95ed-39ff882b7c97",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-da7db518-a59d-58a1-84de-a178b0542b3b",
      "general_intent": "Leave of Absence",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak to a representative about FMLA leave change and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1750,
  completionTokens: 299,
  totalTokens: 2049,
  cost: '$0.000295',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 3747ms (3.75s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2049 ($0.0003)
âš¡ Performance: 546.8 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1750
   â€¢ Completion Tokens: 299
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 1 Single Batch Time: 3747ms (3.75s)

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 3747ms (3.75s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2049 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.1 sessions/sec
âš¡ Avg Time Per Session: 936.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:02:37.216Z',
  duration: '3895ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1947,
    completion_tokens: 213,
    total_tokens: 2160,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-be84e5ec-7cfa-5ef0-87b4-1d82ae62db35",
      "notes": "Session ended without user input, conversation closed by bot."
    },
    {
      "user_id": "u-e517b678-55f8-5dbf-bb59-f0076e5d406d",
      "notes": "User attempted to report leave status but was transferred to a live agent after multiple prompts, session ended with transfer."
    },
    {
      "user_id": "u-5035766f-c388-5cd0-bd5d-d1640658a3d6",
      "notes": "User inquired about setting up FMLA, then was transferred to a live agent after multiple prompts, session ended with transfer."
    },
    {
      "user_id": "u-83edce9f-e127-5739-a5a3-ea4cdaa39ee1",
      "notes": "User asked about claim status, verified account, and confirmed leave request details, session was handled by bot without transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1947,
  completionTokens: 213,
  totalTokens: 2160,
  cost: '$0.000280',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 3895ms (3.90s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2160 ($0.0003)
âš¡ Performance: 554.6 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1947
   â€¢ Completion Tokens: 213
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-be84e5ec-7cfa-5ef0-87b4-1d82ae62db35: Invalid general_intent, u-be84e5ec-7cfa-5ef0-87b4-1d82ae62db35: Invalid session_outcome, u-e517b678-55f8-5dbf-bb59-f0076e5d406d: Invalid general_intent, u-e517b678-55f8-5dbf-bb59-f0076e5d406d: Invalid session_outcome, u-5035766f-c388-5cd0-bd5d-d1640658a3d6: Invalid general_intent, u-5035766f-c388-5cd0-bd5d-d1640658a3d6: Invalid session_outcome, u-83edce9f-e127-5739-a5a3-ea4cdaa39ee1: Invalid general_intent, u-83edce9f-e127-5739-a5a3-ea4cdaa39ee1: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 2 Single Batch Time: 3895ms (3.90s)

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 3895ms (3.90s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2160 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.0 sessions/sec
âš¡ Avg Time Per Session: 973.75ms
::1 - - [12/Aug/2025:17:02:37 +0000] "GET /api/analysis/auto-analyze/parallel/progress/9bca8d52-50ef-4527-b3fd-115db8c75919 HTTP/1.1" 200 1530 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:02:38.116Z',
  duration: '4794ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1774,
    completion_tokens: 294,
    total_tokens: 2068,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-73b27b1b-97d0-5c34-bdd8-c0a6c28268c1",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an operator and was transferred to an agent."
    },
    {
      "user_id": "u-ebdfb9d2-11b8-59bd-9a01-b43c63a4726a",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-a790edf1-df48-5b27-b67e-631267b53e6c",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-2dd1a0a5-f940-55f6-a8ef-9aed2395052e",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested customer service and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1774,
  completionTokens: 294,
  totalTokens: 2068,
  cost: '$0.000295',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 4796ms (4.80s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2068 ($0.0003)
âš¡ Performance: 431.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1774
   â€¢ Completion Tokens: 294
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 3 Single Batch Time: 4796ms (4.80s)

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 4796ms (4.80s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2068 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.8 sessions/sec
âš¡ Avg Time Per Session: 1199.00ms
[ParallelProcessingOrchestrator] Parallel processing complete: 6/6 streams succeeded
â±ï¸  Parallel Processing Time: 4798ms (4.80s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 6 streams
[ParallelProcessingOrchestrator] Synchronization complete: 1 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 1
ğŸ“Š Total Classifications: 11

âœ… ============ ROUND 3 COMPLETED ============
â±ï¸  Round 3 Total Time: 4798ms (4.80s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 0
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 4798ms (100.0%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ‰ ============ PARALLEL PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 12419ms (12.42s)
ğŸ“Š Sessions Processed: 85/85
ğŸ”„ Total Rounds: 3
ğŸŒŠ Stream Results: 22
ğŸ’° Token Usage: 45393 tokens ($0.0062)
ğŸ“ˆ Stream Utilization: 100.0%
ğŸ¯ Performance: 6.8 sessions/second
âš¡ Avg Time Per Session: 146.11ms

ğŸ“Š Stream Performance Breakdown:
   Stream 1: 4 sessions in 3862ms (538.8 tokens/sec)
   Stream 2: 4 sessions in 3762ms (513.6 tokens/sec)
   Stream 3: 4 sessions in 3578ms (547.5 tokens/sec)
   Stream 4: 4 sessions in 3237ms (683.0 tokens/sec)
   Stream 5: 4 sessions in 2728ms (698.7 tokens/sec)
   Stream 6: 4 sessions in 3877ms (555.8 tokens/sec)
   Stream 7: 4 sessions in 4246ms (453.4 tokens/sec)
   Stream 8: 4 sessions in 3722ms (638.6 tokens/sec)
   Stream 1: 4 sessions in 2327ms (960.0 tokens/sec)
   Stream 2: 4 sessions in 2608ms (1000.8 tokens/sec)
   Stream 3: 4 sessions in 2644ms (792.4 tokens/sec)
   Stream 4: 4 sessions in 3034ms (723.5 tokens/sec)
   Stream 5: 4 sessions in 3365ms (584.8 tokens/sec)
   Stream 6: 4 sessions in 2656ms (730.0 tokens/sec)
   Stream 7: 4 sessions in 2912ms (674.1 tokens/sec)
   Stream 8: 4 sessions in 2196ms (959.9 tokens/sec)
   Stream 1: 4 sessions in 3747ms (546.8 tokens/sec)
   Stream 2: 4 sessions in 3895ms (554.6 tokens/sec)
   Stream 3: 4 sessions in 4796ms (431.2 tokens/sec)
   Stream 4: 4 sessions in 2541ms (850.5 tokens/sec)
   Stream 5: 4 sessions in 3481ms (569.7 tokens/sec)
   Stream 6: 1 sessions in 1027ms (1279.5 tokens/sec)
[ConflictResolutionService] Starting conflict resolution for 99 sessions
[ConflictResolutionService] Found classifications: { intents: 9, reasons: 1, locations: 1 }
[ConflictResolutionService] Calling LLM for conflict resolution with model gpt-4.1-nano
ğŸ”§ Conflict Resolution Prompt Preview: You are reviewing classifications from parallel analysis streams. Identify any semantic duplicates and choose the canonical version for each group.

**Instructions:**
1. Look for classifications that refer to the same concept but use different wording
2. For each group of duplicates, choose the most...
::1 - - [12/Aug/2025:17:02:39 +0000] "GET /api/analysis/auto-analyze/parallel/progress/9bca8d52-50ef-4527-b3fd-115db8c75919 HTTP/1.1" 200 1550 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[ConflictResolutionService] LLM conflict resolution complete: { intents: 7, reasons: 1, locations: 1, tokens: 783, cost: 0.0001197 }
ğŸ”§ Conflict Resolution Response: {
  "generalIntents": [
    {
      "canonical": "Claim Status Inquiry",
      "aliases": [
        "Claim Status",
        "Claim status"
      ]
    },
    {
      "canonical": "Customer Service Interaction",
      "aliases": [
        "Customer Service"
      ]
    },
    {
      "canonical": "FMLA Leave Inquiry",
      "aliases": [
        "FMLA leave"
      ]
    },
    {
      "canonical": "Leave of Absence Inquiry",
      "aliases": [
        "Leave of Absence"
      ]
    },
    {
      "canonical": "Live Agent Transfer",
      "aliases": [
        "Live Agent"
      ]
    },
    {
      "canonical": "Time Reporting",
      "aliases": [
        "Report Time",
        "Time Entry"
      ]
    },
    {
      "canonical": "Unknown",
      "aliases": [
        "Unknown"
      ]
    }
  ],
  "transferReasons": [
    {
      "canonical": "Live Agent Request",
      "aliases": [
        "Live Agent Request"
      ]
    }
  ],
  "dropOffLocations": [
    {
      "canonical": "Help Offer Prompt",
      "aliases": [
        "Help Offer Prompt"
      ]
    }
  ]
}
[ConflictResolutionService] Applying resolutions to 99 sessions
[ConflictResolutionService] Applied 54 classification mappings across 99 sessions
[ConflictResolutionService] Identified 3 potential conflict groups
[ConflictResolutionService] Conflict resolution complete in 1836ms: { conflictsFound: 3, conflictsResolved: 9, canonicalMappings: 11 }
[ParallelAutoAnalyzeService] Using real analysis summary service
::1 - - [12/Aug/2025:17:02:41 +0000] "GET /api/analysis/auto-analyze/parallel/progress/9bca8d52-50ef-4527-b3fd-115db8c75919 HTTP/1.1" 200 1627 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:02:43 +0000] "GET /api/analysis/auto-analyze/parallel/progress/9bca8d52-50ef-4527-b3fd-115db8c75919 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:02:45 +0000] "GET /api/analysis/auto-analyze/parallel/progress/9bca8d52-50ef-4527-b3fd-115db8c75919 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:02:47 +0000] "GET /api/analysis/auto-analyze/parallel/progress/9bca8d52-50ef-4527-b3fd-115db8c75919 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:02:49 +0000] "GET /api/analysis/auto-analyze/parallel/progress/9bca8d52-50ef-4527-b3fd-115db8c75919 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:02:51 +0000] "GET /api/analysis/auto-analyze/parallel/progress/9bca8d52-50ef-4527-b3fd-115db8c75919 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:02:53 +0000] "GET /api/analysis/auto-analyze/parallel/progress/9bca8d52-50ef-4527-b3fd-115db8c75919 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:02:55 +0000] "GET /api/analysis/auto-analyze/parallel/progress/9bca8d52-50ef-4527-b3fd-115db8c75919 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:02:57 +0000] "GET /api/analysis/auto-analyze/parallel/progress/9bca8d52-50ef-4527-b3fd-115db8c75919 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[ParallelAutoAnalyzeService] Parallel analysis 9bca8d52-50ef-4527-b3fd-115db8c75919 completed successfully
[BackgroundJobQueue] Updated job progress to final state: complete
[BackgroundJobQueue] Parallel analysis job 9bca8d52-50ef-4527-b3fd-115db8c75919-parallel completed successfully
::1 - - [12/Aug/2025:17:02:59 +0000] "GET /api/analysis/auto-analyze/parallel/progress/9bca8d52-50ef-4527-b3fd-115db8c75919 HTTP/1.1" 200 1651 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:03:00 +0000] "GET /api/analysis/auto-analyze/parallel/results/9bca8d52-50ef-4527-b3fd-115db8c75919 HTTP/1.1" 200 688134 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T17:18:21.960Z",
  "dateTo": "2025-08-12T17:19:21.960Z",
  "skip": 0,
  "limit": 1
}
[fetchContainmentTypeMetadata] API Response: 1 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [ '689b775e0cef90d20303938d' ]
[getSessionsMetadataForConnectionTest] Single API call succeeded with 1 sessions
::1 - - [12/Aug/2025:17:19:24 +0000] "GET /api/kore/test HTTP/1.1" 200 851 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[Direct API] Fetching real Kore.ai sessions from 2025-08-05T17:19:25.386Z to 2025-08-12T17:19:25.386Z for User Bot st-90549... (limit=50)
Retrieving sessions from 2025-08-05T17:19:25.386Z to 2025-08-12T17:19:25.386Z (limit=50), populateMessages=true...
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T17:19:25.386Z",
  "dateTo": "2025-08-12T17:19:25.386Z",
  "limit": 50
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T17:19:25.386Z",
  "dateTo": "2025-08-12T17:19:25.386Z",
  "skip": 0,
  "limit": 50
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T17:19:25.386Z",
  "dateTo": "2025-08-12T17:19:25.386Z",
  "skip": 0,
  "limit": 50
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T17:19:25.386Z",
  "dateTo": "2025-08-12T17:19:25.386Z",
  "skip": 0,
  "limit": 50
}
::1 - - [12/Aug/2025:17:19:26 +0000] "GET /api/analysis/sessions?limit=50 HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 50 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b7794144f8feea180f65a',
  '689b77931cf7bdce60f96a04',
  '689b773505a45fff8906e3a7'
]
[fetchContainmentTypeMetadata] API Response: 50 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b775e0cef90d20303938d',
  '689b774c144f8feea180ecff',
  '689b7749e11e897de6065bb5'
]
[fetchContainmentTypeMetadata] API Response: 50 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b73340989a8bc72a44903',
  '689b7295995362de8df067cc',
  '689b727f3f99afdf156f35f7'
]
[getSessionsMetadata] agent API call succeeded with 50 sessions
[getSessionsMetadata] selfService API call succeeded with 50 sessions
[getSessionsMetadata] dropOff API call succeeded with 50 sessions
Total session metadata retrieved: 150 (parallel execution)
Retrieved 150 session metadata objects
Creating 150 SWTs from metadata (no messages)
Created 150 SWT objects from metadata
Populating messages for all sessions (legacy behavior)
Populating messages for 150 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 150 sessions from 2025-08-12T16:08:09.537Z to 2025-08-12T17:19:21.290Z at 2025-08-12T17:19:31.794Z
ğŸš€ [ConcurrentBatch] Split 150 sessions into 8 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/8] Starting: 20 sessions
[Batch 2/8] Starting: 20 sessions
[Batch 3/8] Starting: 20 sessions
[Batch 4/8] Starting: 20 sessions
[Batch 5/8] Starting: 20 sessions
[Batch 6/8] Starting: 20 sessions
[Batch 7/8] Starting: 20 sessions
[Batch 8/8] Starting: 10 sessions
[Batch 1/8] Completed in 237ms: 207 messages retrieved (1/8 done)
[Batch 3/8] Completed in 276ms: 225 messages retrieved (2/8 done)
[Batch 2/8] Completed in 287ms: 232 messages retrieved (3/8 done)
[Batch 8/8] Completed in 500ms: 132 messages retrieved (4/8 done)
[Batch 6/8] Completed in 552ms: 227 messages retrieved (5/8 done)
[Batch 4/8] Completed in 606ms: 406 messages retrieved (6/8 done)
[Batch 7/8] Completed in 630ms: 234 messages retrieved (7/8 done)
[Batch 5/8] Completed in 856ms: 503 messages retrieved (8/8 done)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 856ms (0.86s)
â±ï¸  Batch Processing: 856ms (0.86s)
ğŸ“¦ Total batches: 8 (max 10 concurrent)
âœ… Successful batches: 8/8
ğŸ’¬ Total messages: 2166
ğŸ“ˆ Avg time per batch: 107ms
ğŸš€ Time per session: 6ms
ğŸ’ª Performance: 175.2 sessions/second
=======================================================

Retrieved 2166 messages for 150 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
Populated messages for 150 SWT objects
Generated 150 SWT objects in 7273ms using layered architecture
ğŸš€ [ParallelAutoAnalyzeRoute] Starting parallel analysis for bot ***REMOVED*** with real credentials
ğŸš€ [ParallelAutoAnalyzeService] Starting parallel analysis 1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc with bot ***REMOVED***
ğŸš€ [ParallelAutoAnalyzeService] Using credentials: real
ğŸš€ [ParallelAutoAnalyzeRoute] Parallel analysis started: 1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc
::1 - - [12/Aug/2025:17:19:44 +0000] "POST /api/analysis/auto-analyze/parallel/start HTTP/1.1" 200 214 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:19:44 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 200 542 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:19:44 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[BackgroundJobQueue] Starting job processing after delay for job 1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc-parallel
[BackgroundJobQueue] Starting processing for job 1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc-parallel, phase: sampling
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing parallel analysis job 1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc-parallel
[BackgroundJobQueue] Processing parallel analysis for bot ***REMOVED***
[BackgroundJobQueue] Using existing ParallelAutoAnalyzeService instance for bot ***REMOVED***
[BackgroundJobQueue] Session recreated for 1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc
[ParallelAutoAnalyzeService] Running parallel analysis for 1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc
[ParallelAutoAnalyzeService] Phase 0: Starting session sampling for 1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc

ğŸ• ============ SESSION SAMPLING STARTED ============
ğŸ• [SessionSampling] Starting session sampling at 2025-08-12T17:19:45.356Z
ğŸ” [SessionDiscovery] Starting window 1/4: Initial 3-hour window
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
::1 - - [12/Aug/2025:17:19:46 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 200 719 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 80 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a1287849680ad9fe59e',
  '689229f9583056c6108e38fb',
  '68922914f8bee7ba6c3e67b8'
]
[fetchContainmentTypeMetadata] API Response: 139 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6a14dd27c3112087cd',
  '68922a22ef03d8ad2ec7b4ba',
  '68922a1278c1fe09a079719c'
]
::1 - - [12/Aug/2025:17:19:48 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 1338 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6d14dd27c31120888b',
  '68922a62e3804084741191d5',
  '68922a523a3160d25de144c8'
]
[getSessionsMetadata] agent API call succeeded with 1338 sessions
[getSessionsMetadata] selfService API call succeeded with 80 sessions
[getSessionsMetadata] dropOff API call succeeded with 139 sessions
Total session metadata retrieved: 1557 (parallel execution)
Creating 1557 SWTs from metadata (no messages)
Created 1557 SWT objects from metadata
âœ… [SessionDiscovery] Window 1 completed in 4964ms: found 1557 new sessions (total: 1557)
â±ï¸  TIMING: Window 1 took 4964ms (4.96s)
ğŸ¯ [SessionDiscovery] Target reached! Found 1557 sessions in 4964ms
ğŸ² [SessionSampling] Random sampling from 1557 sessions to 100 sessions

ğŸ“¬ ============ MESSAGE RETRIEVAL STARTED ============
ğŸ“¬ [MessageRetrieval] Starting message retrieval for 100 sampled sessions at 2025-08-12T17:19:50.320Z
Using new lazy loading approach to populate messages for 100 sampled sessions
Populating messages for 100 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 100 sessions from 2025-08-05T13:02:05.697Z to 2025-08-05T16:00:17.242Z at 2025-08-12T17:19:50.320Z
ğŸš€ [ConcurrentBatch] Split 100 sessions into 5 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/5] Starting: 20 sessions
[Batch 2/5] Starting: 20 sessions
[Batch 3/5] Starting: 20 sessions
[Batch 4/5] Starting: 20 sessions
[Batch 5/5] Starting: 20 sessions
::1 - - [12/Aug/2025:17:19:50 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 200 739 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[Batch 1/5] Completed in 376ms: 242 messages retrieved (1/5 done)
ğŸ“Š [BatchProgress] Reporting batch 1/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 40/100 sessions (Batch 2/5)
[Batch 3/5] Completed in 435ms: 268 messages retrieved (2/5 done)
ğŸ“Š [BatchProgress] Reporting batch 2/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 60/100 sessions (Batch 3/5)
[Batch 2/5] Completed in 439ms: 295 messages retrieved (3/5 done)
ğŸ“Š [BatchProgress] Reporting batch 3/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 80/100 sessions (Batch 4/5)
[Batch 4/5] Completed in 500ms: 246 messages retrieved (4/5 done)
ğŸ“Š [BatchProgress] Reporting batch 4/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 100/100 sessions (Batch 5/5)
[Batch 5/5] Completed in 516ms: 217 messages retrieved (5/5 done)
ğŸ“Š [BatchProgress] Reporting batch 5/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 100/100 sessions (Batch 6/5)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 516ms (0.52s)
â±ï¸  Batch Processing: 516ms (0.52s)
ğŸ“¦ Total batches: 5 (max 10 concurrent)
âœ… Successful batches: 5/5
ğŸ’¬ Total messages: 1268
ğŸ“ˆ Avg time per batch: 103ms
ğŸš€ Time per session: 5ms
ğŸ’ª Performance: 193.8 sessions/second
=======================================================

Retrieved 1268 messages for 100 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
Populated messages for 100 SWT objects
Successfully populated messages for 100 sessions using lazy loading
Applying final filtering to 100 sessions with populated messages
Final result: 99 sessions passed filtering with populated messages

ğŸ‰ ============ SESSION SAMPLING COMPLETED ============
â±ï¸  TOTAL TIME: 5489ms (5.49s)
â±ï¸  Session Discovery: 4964ms (4.96s) - 90.4% of total
â±ï¸  Message Retrieval: 525ms (0.53s) - 9.6% of total
â±ï¸  Performance: 18.0 sessions/second
ğŸ¯ Final result: 99 sessions with messages retrieved
====================================================

[StrategicDiscoveryService] Starting discovery phase with 99 total sessions
[StrategicDiscoveryService] Discovery config: {
  targetPercentage: 15,
  minSessions: 9,
  maxSessions: 14,
  diversityStrategy: {
    sessionLengths: [ 'short', 'medium', 'long' ],
    containmentTypes: [ 'agent', 'selfService', 'dropOff' ],
    timeDistribution: 'spread'
  }
}
[StrategicDiscoveryService] Selecting 14 diverse sessions from 99 total
[StrategicDiscoveryService] Session diversity groups: { short: 26, medium: 72, long: 1, early: 33, middle: 33, late: 33 }
[StrategicDiscoveryService] Selected sessions by length distribution: { short: 5, medium: 8, long: 1 }
[StrategicDiscoveryService] Selected 14 sessions for discovery

ğŸ“¦ ===== BATCH 6 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T17:19:50.846Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 0
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T17:19:50.846Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:19:50.846Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6449,
  existingClassifications: { intents: 0, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.



For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and another intent, classify the intent as the other i...
::1 - - [12/Aug/2025:17:19:52 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 200 932 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:19:54 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:19:55.940Z',
  duration: '5090ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1867,
    completion_tokens: 301,
    total_tokens: 2168,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Report Absence', 'Claim Initiation', 'Live Agent' ],
  transferCount: 4,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-dfae4a1c-64bc-55e9-9561-567b107752d0",
      "general_intent": "Report Absence",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "The user reported an absence and confirmed the details before the session ended."
    },
    {
      "user_id": "u-afe49426-bc8f-59cb-8f7d-41caafb7e4dc",
      "general_intent": "Claim Initiation",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-df1f1f06-e426-5f38-8e5d-35f03f3ec40e",
      "general_intent": "Claim Initiation",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-e197d3a9-ad4a-5bdb-9056-d4dfdc84e4af",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-8b2886db-9886-5648-aaca-a9740beb6607",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1867,
  completionTokens: 301,
  totalTokens: 2168,
  cost: '$0.000307',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 5094ms (5.09s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2168 ($0.0003)
âš¡ Performance: 425.6 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 1ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 5095ms (5.09s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2168

âœ… ===== BATCH 6 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 5095ms (5.09s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2168 ($0.0003)
âš¡ Performance: 1.0 sessions/sec
âš¡ Avg Time Per Session: 1019.00ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 1 complete: 5 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 3, reasons: 1, locations: 1, total: 5 }

ğŸ“¦ ===== BATCH 7 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T17:19:55.941Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T17:19:55.941Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:19:55.942Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 11040,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Initiation, Live Agent, Report Absence
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing",...
::1 - - [12/Aug/2025:17:19:56 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 200 950 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:19:58 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:20:00 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:20:01.118Z',
  duration: '5176ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 3082,
    completion_tokens: 385,
    total_tokens: 3467,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Claim Status', 'Unknown' ],
  transferCount: 3,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-28e16169-8a69-5c7c-b536-1fd7ed509d44",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User was trying to follow up on FMLA renewal status but was unable to provide specific request details, and the session was handled by the bot without transfer."
    },
    {
      "user_id": "u-8a7ffe93-f90d-5b31-af01-c20ca8bb316a",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User did not engage with the bot, which closed the session due to no input."
    },
    {
      "user_id": "u-0f1a86ea-f601-5d0a-848c-14c4aa8856ec",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Claim Details",
      "notes": "User attempted to access time entry but was unable to provide correct information, leading to transfer to a live agent."
    },
    {
      "user_id": "u-4b4676c6-5a89-5fb7-9c7b-769afe76c3e9",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User inquired about return to work with accommodation forms but was transferred to a live agent."
    },
    {
      "user_id": "u-4b4676c6-5a89-5fb7-9c7b-769afe76c3e9",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User again inquired about return to work with accommodation forms and was transferred to a live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 3082,
  completionTokens: 385,
  totalTokens: 3467,
  cost: '$0.000462',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 5178ms (5.18s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 3467 ($0.0005)
âš¡ Performance: 669.6 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 4
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 5178ms (5.18s)
ğŸ“Š Regular Sessions Processed: 4
ğŸ’° Regular Tokens Used: 3467

âœ… ===== BATCH 7 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 5178ms (5.18s)
ğŸ“Š Sessions Processed: 4/5
ğŸ’° Total Tokens: 3467 ($0.0005)
âš¡ Performance: 0.8 sessions/sec
âš¡ Avg Time Per Session: 1294.50ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 2 complete: 3 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 5, reasons: 1, locations: 2, total: 8 }

ğŸ“¦ ===== BATCH 8 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T17:20:01.119Z
ğŸ“Š Sessions in Batch: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 2

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 4
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T17:20:01.119Z
ğŸ“Š Sessions to Analyze: 4

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:20:01.119Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6049,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Initiation, Claim Status, Live Agent, Report Absence, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Claim Details, Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Commo...
::1 - - [12/Aug/2025:17:20:02 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 200 949 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:20:04 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:20:04.960Z',
  duration: '3840ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1734,
    completion_tokens: 258,
    total_tokens: 1992,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Claim Status' ],
  transferCount: 2,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-81d20619-f7ea-5471-8497-b517cfe87002",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-87800593-10b4-51e6-afdf-4738c9e1b93d",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User attempted to request leave but did not complete the session."
    },
    {
      "user_id": "u-096ea020-27b8-5ecd-9d66-2884c67be145",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User attempted to apply for FMLA but did not complete the session."
    },
    {
      "user_id": "u-014636f8-2374-5f0e-803c-d53dd3acc3b5",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested customer service and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1734,
  completionTokens: 258,
  totalTokens: 1992,
  cost: '$0.000277',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 3842ms (3.84s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1992 ($0.0003)
âš¡ Performance: 518.5 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 4
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 3842ms (3.84s)
ğŸ“Š Regular Sessions Processed: 4
ğŸ’° Regular Tokens Used: 1992

âœ… ===== BATCH 8 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 3842ms (3.84s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Total Tokens: 1992 ($0.0003)
âš¡ Performance: 1.0 sessions/sec
âš¡ Avg Time Per Session: 960.50ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 3 complete: 0 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 5, reasons: 1, locations: 2, total: 8 }
[StrategicDiscoveryService] Discovery phase complete: {
  totalProcessed: 13,
  uniqueIntents: 5,
  uniqueReasons: 1,
  uniqueLocations: 2,
  discoveryRate: 0.5333333333333333
}

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T17:20:04.961Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms
[ParallelProcessingOrchestrator] Configuration for 86 sessions:
  Design: 8 streams Ã— 4 sessions = 32 per round
  Optimal: 8 streams Ã— 4 sessions = 32 per round
  Estimated Rounds: 3
[ParallelAutoAnalyzeService] Using parallel config: {
  streamCount: 8,
  sessionsPerStream: 4,
  maxSessionsPerLLMCall: 50,
  syncFrequency: 'after_each_round',
  retryAttempts: 3,
  debugLogging: false
}

ğŸš€ ============ PARALLEL PROCESSING STARTED ============
â±ï¸  Start Time: 2025-08-12T17:20:04.963Z
ğŸ“Š Total Sessions: 86

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T17:20:04.963Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms

âš™ï¸  ============ PARALLEL CONFIGURATION ============
â±ï¸  Config Time: 0ms
ğŸ”§ Stream Count: 8
ğŸ“¦ Sessions Per Stream: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per API Call: 50
ğŸ¯ Debug Logging: false

ğŸ”„ ============ ROUND 1/3 STARTED ============
â±ï¸  Round 1 Start: 2025-08-12T17:20:04.963Z
ğŸ“Š Sessions Remaining: 86
[ParallelProcessingOrchestrator] Distributed 32 sessions across 8 streams: [
  'Stream 1: 4 sessions',
  'Stream 2: 4 sessions',
  'Stream 3: 4 sessions',
  'Stream 4: 4 sessions',
  'Stream 5: 4 sessions',
  'Stream 6: 4 sessions',
  'Stream 7: 4 sessions',
  'Stream 8: 4 sessions'
]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 8

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 8 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T17:20:04.963Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:20:04.963Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 655
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6155
   â€¢ Avg Per Session: 164 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6155
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6155
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:20:04.963Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 2

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:20:04.964Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5814,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Initiation, Claim Status, Live Agent, Report Absence, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Claim Details, Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Commo...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T17:20:04.964Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:20:04.964Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 766
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6266
   â€¢ Avg Per Session: 192 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6266
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6266
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:20:04.964Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 2

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:20:04.965Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6308,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Initiation, Claim Status, Live Agent, Report Absence, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Claim Details, Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Commo...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T17:20:04.965Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:20:04.965Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 752
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6252
   â€¢ Avg Per Session: 188 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6252
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6252
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:20:04.965Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 2

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:20:04.965Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6225,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Initiation, Claim Status, Live Agent, Report Absence, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Claim Details, Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Commo...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T17:20:04.965Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:20:04.965Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 750
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6250
   â€¢ Avg Per Session: 188 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6250
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6250
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:20:04.966Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 2

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:20:04.966Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6235,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Initiation, Claim Status, Live Agent, Report Absence, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Claim Details, Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Commo...

ğŸŒŠ ===== STREAM 5 PROCESSING START =====
â±ï¸  Stream 5 Start: 2025-08-12T17:20:04.966Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:20:04.966Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 812
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6312
   â€¢ Avg Per Session: 203 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6312
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 5) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6312
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 5: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:20:04.967Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 2

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:20:04.967Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6581,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Initiation, Claim Status, Live Agent, Report Absence, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Claim Details, Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Commo...

ğŸŒŠ ===== STREAM 6 PROCESSING START =====
â±ï¸  Stream 6 Start: 2025-08-12T17:20:04.967Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:20:04.967Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 1006
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6506
   â€¢ Avg Per Session: 252 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6506
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 6) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6506
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 6: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:20:04.967Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 2

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:20:04.967Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7411,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Initiation, Claim Status, Live Agent, Report Absence, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Claim Details, Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Commo...

ğŸŒŠ ===== STREAM 7 PROCESSING START =====
â±ï¸  Stream 7 Start: 2025-08-12T17:20:04.967Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:20:04.967Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 1098
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6598
   â€¢ Avg Per Session: 275 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6598
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0011
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 7) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6598
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0011

âš¡ Stream 7: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:20:04.967Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 2

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:20:04.967Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7863,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Initiation, Claim Status, Live Agent, Report Absence, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Claim Details, Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Commo...

ğŸŒŠ ===== STREAM 8 PROCESSING START =====
â±ï¸  Stream 8 Start: 2025-08-12T17:20:04.967Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:20:04.967Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 758
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6258
   â€¢ Avg Per Session: 190 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6258
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 8) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6258
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 8: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:20:04.968Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 2

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:20:04.968Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6227,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Initiation, Claim Status, Live Agent, Report Absence, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Claim Details, Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Commo...
::1 - - [12/Aug/2025:17:20:06 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 200 1725 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:20:08 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:20:08.943Z',
  duration: '3976ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2074,
    completion_tokens: 199,
    total_tokens: 2273,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-5f275d3d-03dd-5f57-8145-92286c70a3df",
      "notes": "User wanted to speak with an operator, and the session was transferred to an agent."
    },
    {
      "user_id": "u-de4e79e5-3735-595e-bc80-e86e2284237c",
      "notes": "User attempted to file a new leave request but did not provide sufficient information, and the session was closed without transfer."
    },
    {
      "user_id": "u-82b0d908-7add-5f9b-b707-8bf4250d815b",
      "notes": "User wanted to speak to somebody, and the session was transferred to an agent."
    },
    {
      "user_id": "u-782053ba-f998-534c-ac07-5137fdf931a9",
      "notes": "User reported time for a leave request, and the session was handled without transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2074,
  completionTokens: 199,
  totalTokens: 2273,
  cost: '$0.000287',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 3977ms (3.98s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2273 ($0.0003)
âš¡ Performance: 571.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2074
   â€¢ Completion Tokens: 199
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-5f275d3d-03dd-5f57-8145-92286c70a3df: Invalid general_intent, u-5f275d3d-03dd-5f57-8145-92286c70a3df: Invalid session_outcome, u-de4e79e5-3735-595e-bc80-e86e2284237c: Invalid general_intent, u-de4e79e5-3735-595e-bc80-e86e2284237c: Invalid session_outcome, u-82b0d908-7add-5f9b-b707-8bf4250d815b: Invalid general_intent, u-82b0d908-7add-5f9b-b707-8bf4250d815b: Invalid session_outcome, u-782053ba-f998-534c-ac07-5137fdf931a9: Invalid general_intent, u-782053ba-f998-534c-ac07-5137fdf931a9: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 6 Single Batch Time: 3977ms (3.98s)

âœ… ===== STREAM 6 PROCESSING COMPLETE =====
â±ï¸  Stream 6 Total Time: 3977ms (3.98s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2273 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.0 sessions/sec
âš¡ Avg Time Per Session: 994.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:20:10.283Z',
  duration: '5319ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1684,
    completion_tokens: 302,
    total_tokens: 1986,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Initiation', 'Unknown', 'Live Agent' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-48e8df79-b118-5ba6-af2a-e1320fbe7695",
      "general_intent": "Claim Initiation",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to file a claim but was transferred to an agent."
    },
    {
      "user_id": "u-096c5b8a-751b-5690-8a72-c9f5775dc9c0",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a password reset and was transferred to an agent."
    },
    {
      "user_id": "u-37e8c57b-0410-5d7f-8da4-84a9231ac9ff",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an operator and was transferred."
    },
    {
      "user_id": "u-1fd6c317-0f93-5882-8c1f-9f6de2b11577",
      "general_intent": "Claim Initiation",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to extend and reopen a claim, transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1684,
  completionTokens: 302,
  totalTokens: 1986,
  cost: '$0.000289',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 5320ms (5.32s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1986 ($0.0003)
âš¡ Performance: 373.3 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1684
   â€¢ Completion Tokens: 302
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 1 Single Batch Time: 5321ms (5.32s)

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 5321ms (5.32s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1986 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.8 sessions/sec
âš¡ Avg Time Per Session: 1330.25ms
::1 - - [12/Aug/2025:17:20:10 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 200 1729 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:20:10.523Z',
  duration: '5556ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1882,
    completion_tokens: 271,
    total_tokens: 2153,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Claim Status', 'Unknown', 'Time Entry' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-09af71ad-c11a-5230-97fa-5e9028f3c867",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent and was transferred."
    },
    {
      "user_id": "u-d112df13-7068-5eec-9a13-52b980bd67c9",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User inquired about claim status and was transferred after verification."
    },
    {
      "user_id": "u-1e59eba7-77d5-566f-a889-01c9b32fc3a9",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted password help and was transferred to an agent."
    },
    {
      "user_id": "u-bc728a28-1362-5cc7-9575-dfe481ce1b73",
      "general_intent": "Time Entry",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1882,
  completionTokens: 271,
  totalTokens: 2153,
  cost: '$0.000297',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 5556ms (5.56s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2153 ($0.0003)
âš¡ Performance: 387.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1882
   â€¢ Completion Tokens: 271
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 5 Single Batch Time: 5557ms (5.56s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 5 PROCESSING COMPLETE =====
â±ï¸  Stream 5 Total Time: 5558ms (5.56s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2153 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.7 sessions/sec
âš¡ Avg Time Per Session: 1389.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:20:10.620Z',
  duration: '5655ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1775,
    completion_tokens: 275,
    total_tokens: 2050,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status', 'Live Agent' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-4581830b-f150-56f9-abbb-9765a379f7be",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User provided claim details and verified account, session ended without transfer."
    },
    {
      "user_id": "u-f95e3438-8716-5204-852a-371b2ff8fa67",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent, session transferred to live agent."
    },
    {
      "user_id": "u-26ccd4e1-65b1-5022-a9f9-164fb96f598a",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent, session transferred to live agent."
    },
    {
      "user_id": "u-52338ad0-a737-5acf-a51f-a40963f02441",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent, session transferred to live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1775,
  completionTokens: 275,
  totalTokens: 2050,
  cost: '$0.000288',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 5656ms (5.66s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2050 ($0.0003)
âš¡ Performance: 362.4 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1775
   â€¢ Completion Tokens: 275
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 3 Single Batch Time: 5656ms (5.66s)

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 5656ms (5.66s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2050 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.7 sessions/sec
âš¡ Avg Time Per Session: 1414.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:20:10.713Z',
  duration: '5745ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1796,
    completion_tokens: 287,
    total_tokens: 2083,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Unknown' ],
  transferCount: 2,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-6941eacb-13b7-5840-9ffb-ef337830c957",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred to an agent."
    },
    {
      "user_id": "u-aec0380a-aad1-5393-9adf-03e177fad604",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User indicated desire to speak with an agent and was transferred, but session was closed due to no input."
    },
    {
      "user_id": "u-abc89e36-f67e-5725-933b-1a87a3f98e2e",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User attempted to get FMLA information and requested to speak to someone, but no transfer occurred."
    },
    {
      "user_id": "u-1881b5aa-8a67-57f2-b801-c7421085d00f",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User asked to be transferred to a human, but no transfer was made; session was closed due to no input."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1796,
  completionTokens: 287,
  totalTokens: 2083,
  cost: '$0.000294',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 5746ms (5.75s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2083 ($0.0003)
âš¡ Performance: 362.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1796
   â€¢ Completion Tokens: 287
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 8 Single Batch Time: 5746ms (5.75s)

âœ… ===== STREAM 8 PROCESSING COMPLETE =====
â±ï¸  Stream 8 Total Time: 5747ms (5.75s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2083 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.7 sessions/sec
âš¡ Avg Time Per Session: 1436.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:20:10.768Z',
  duration: '5803ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1811,
    completion_tokens: 281,
    total_tokens: 2092,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-9ec4bf15-44b1-5eb2-8075-303b8065f4c0",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User requested a new leave, but the session was not transferred to an agent."
    },
    {
      "user_id": "u-5793f8f6-ae7e-5f7d-9aa4-b7ca64311b80",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested leave management assistance and was transferred to an agent."
    },
    {
      "user_id": "u-06b4122f-84f4-57f0-989f-330c02feecd7",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested an extension on leave and was transferred to an agent."
    },
    {
      "user_id": "u-959c6d85-5329-557e-a44c-5ca4ce243240",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1811,
  completionTokens: 281,
  totalTokens: 2092,
  cost: '$0.000294',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 5804ms (5.80s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2092 ($0.0003)
âš¡ Performance: 360.4 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1811
   â€¢ Completion Tokens: 281
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 2 Single Batch Time: 5805ms (5.80s)

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 5805ms (5.80s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2092 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.7 sessions/sec
âš¡ Avg Time Per Session: 1451.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:20:10.943Z',
  duration: '5977ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1789,
    completion_tokens: 301,
    total_tokens: 2090,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-fbbe12b4-aff4-50b5-8484-f7d91b7539da",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and did not respond, leading to transfer to a live agent."
    },
    {
      "user_id": "u-4d9a999c-e567-596f-a683-38083a02473c",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative, resulting in transfer to a live agent."
    },
    {
      "user_id": "u-6ee21991-54cc-51ea-88e6-e72016cdd828",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an operator, leading to transfer to a live agent."
    },
    {
      "user_id": "u-36240b91-97cc-5689-9c43-1adb5fc44b22",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User expressed intent to put in for days off and was transferred to a live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1789,
  completionTokens: 301,
  totalTokens: 2090,
  cost: '$0.000299',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 5978ms (5.98s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2090 ($0.0003)
âš¡ Performance: 349.6 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1789
   â€¢ Completion Tokens: 301
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 4 Single Batch Time: 5978ms (5.98s)

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 5979ms (5.98s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2090 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.7 sessions/sec
âš¡ Avg Time Per Session: 1494.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:20:11.153Z',
  duration: '6186ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2220,
    completion_tokens: 310,
    total_tokens: 2530,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Time Entry', 'Claim Status', 'Live Agent' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-750a888c-e36b-5b23-a506-5be6e1e0f3ea",
      "general_intent": "Time Entry",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to provide time entry details but was transferred to an agent after multiple input issues."
    },
    {
      "user_id": "u-5963eb00-fc3e-5583-9f1c-578b7f1dc3b6",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User sought claim expiration info but was transferred to an agent after difficulty with account details."
    },
    {
      "user_id": "u-4e5aa05c-2163-5359-912b-ad826a074166",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and then transferred to an agent for new leave request assistance."
    },
    {
      "user_id": "u-9dce3e7c-195d-5e95-ab98-34558cf94f67",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative about leave status and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2220,
  completionTokens: 310,
  totalTokens: 2530,
  cost: '$0.000346',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 6186ms (6.19s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2530 ($0.0003)
âš¡ Performance: 409.0 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2220
   â€¢ Completion Tokens: 310
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 7 Single Batch Time: 6186ms (6.19s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 7 PROCESSING COMPLETE =====
â±ï¸  Stream 7 Total Time: 6186ms (6.19s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2530 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1546.50ms
[ParallelProcessingOrchestrator] Parallel processing complete: 8/8 streams succeeded
â±ï¸  Parallel Processing Time: 6190ms (6.19s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 8 streams
[ParallelProcessingOrchestrator] Synchronization complete: 1 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 1
ğŸ“Š Total Classifications: 9

âœ… ============ ROUND 1 COMPLETED ============
â±ï¸  Round 1 Total Time: 6190ms (6.19s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 54
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 6190ms (100.0%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ”„ ============ ROUND 2/3 STARTED ============
â±ï¸  Round 2 Start: 2025-08-12T17:20:11.154Z
ğŸ“Š Sessions Remaining: 54
[ParallelProcessingOrchestrator] Distributed 32 sessions across 8 streams: [
  'Stream 1: 4 sessions',
  'Stream 2: 4 sessions',
  'Stream 3: 4 sessions',
  'Stream 4: 4 sessions',
  'Stream 5: 4 sessions',
  'Stream 6: 4 sessions',
  'Stream 7: 4 sessions',
  'Stream 8: 4 sessions'
]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 8

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 8 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T17:20:11.154Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:20:11.154Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 730
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6230
   â€¢ Avg Per Session: 183 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6230
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6230
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:20:11.154Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 6
   â€¢ Reasons: 1
   â€¢ Locations: 2

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:20:11.155Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6138,
  existingClassifications: { intents: 6, transferReasons: 1, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Initiation, Claim Status, Live Agent, Report Absence, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Claim Details, Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 w...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T17:20:11.155Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:20:11.155Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 816
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6316
   â€¢ Avg Per Session: 204 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6316
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6316
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:20:11.155Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 6
   â€¢ Reasons: 1
   â€¢ Locations: 2

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:20:11.155Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6585,
  existingClassifications: { intents: 6, transferReasons: 1, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Initiation, Claim Status, Live Agent, Report Absence, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Claim Details, Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 w...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T17:20:11.155Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:20:11.155Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 743
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6243
   â€¢ Avg Per Session: 186 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6243
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 1ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6243
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:20:11.156Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 6
   â€¢ Reasons: 1
   â€¢ Locations: 2

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:20:11.156Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6196,
  existingClassifications: { intents: 6, transferReasons: 1, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Initiation, Claim Status, Live Agent, Report Absence, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Claim Details, Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 w...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T17:20:11.156Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:20:11.156Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 934
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6434
   â€¢ Avg Per Session: 234 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6434
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6434
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:20:11.156Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 6
   â€¢ Reasons: 1
   â€¢ Locations: 2

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:20:11.156Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7116,
  existingClassifications: { intents: 6, transferReasons: 1, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Initiation, Claim Status, Live Agent, Report Absence, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Claim Details, Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 w...

ğŸŒŠ ===== STREAM 5 PROCESSING START =====
â±ï¸  Stream 5 Start: 2025-08-12T17:20:11.156Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:20:11.156Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 971
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6471
   â€¢ Avg Per Session: 243 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6471
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 5) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6471
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 5: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:20:11.157Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 6
   â€¢ Reasons: 1
   â€¢ Locations: 2

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:20:11.157Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7238,
  existingClassifications: { intents: 6, transferReasons: 1, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Initiation, Claim Status, Live Agent, Report Absence, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Claim Details, Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 w...

ğŸŒŠ ===== STREAM 6 PROCESSING START =====
â±ï¸  Stream 6 Start: 2025-08-12T17:20:11.157Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:20:11.157Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 884
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6384
   â€¢ Avg Per Session: 221 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6384
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 6) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6384
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 6: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:20:11.157Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 6
   â€¢ Reasons: 1
   â€¢ Locations: 2

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:20:11.157Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6914,
  existingClassifications: { intents: 6, transferReasons: 1, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Initiation, Claim Status, Live Agent, Report Absence, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Claim Details, Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 w...

ğŸŒŠ ===== STREAM 7 PROCESSING START =====
â±ï¸  Stream 7 Start: 2025-08-12T17:20:11.157Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:20:11.157Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 835
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6335
   â€¢ Avg Per Session: 209 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6335
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 1ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 7) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6335
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 7: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:20:11.158Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 6
   â€¢ Reasons: 1
   â€¢ Locations: 2

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:20:11.158Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6620,
  existingClassifications: { intents: 6, transferReasons: 1, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Initiation, Claim Status, Live Agent, Report Absence, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Claim Details, Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 w...

ğŸŒŠ ===== STREAM 8 PROCESSING START =====
â±ï¸  Stream 8 Start: 2025-08-12T17:20:11.158Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:20:11.158Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 841
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6341
   â€¢ Avg Per Session: 210 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6341
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 8) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6341
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 8: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:20:11.158Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 6
   â€¢ Reasons: 1
   â€¢ Locations: 2

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:20:11.158Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6628,
  existingClassifications: { intents: 6, transferReasons: 1, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Initiation, Claim Status, Live Agent, Report Absence, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Claim Details, Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 w...
::1 - - [12/Aug/2025:17:20:12 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 200 1725 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:20:14 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:20:14.541Z',
  duration: '3383ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1873,
    completion_tokens: 277,
    total_tokens: 2150,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Claim status' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-a56d9452-9d50-59e8-a174-14885c44a01a",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-4555a175-abb4-5fff-aa89-7a8dea2b45ee",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-5d1d7171-e0c4-5466-9da1-2292bf04aa23",
      "general_intent": "Claim status",
      "session_outcome": "Contained",
      "notes": "User inquired about claim status, provided details, and session was handled by bot."
    },
    {
      "user_id": "u-3cf89b7b-28da-5cbc-8d86-f1205521705e",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1873,
  completionTokens: 277,
  totalTokens: 2150,
  cost: '$0.000298',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 3384ms (3.38s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2150 ($0.0003)
âš¡ Performance: 635.3 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1873
   â€¢ Completion Tokens: 277
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 7 Single Batch Time: 3384ms (3.38s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 7 PROCESSING COMPLETE =====
â±ï¸  Stream 7 Total Time: 3385ms (3.38s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2150 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.2 sessions/sec
âš¡ Avg Time Per Session: 846.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:20:14.683Z',
  duration: '3526ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2032,
    completion_tokens: 188,
    total_tokens: 2220,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-e5b99f58-033f-599e-902a-9f42f5350365",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-d6c25e65-0980-5ecf-9f22-9e7faf5dda31",
      "notes": "User was seeking assistance with updating FMLA claim, but session was transferred to an agent after initial interaction."
    },
    {
      "user_id": "u-12ddc522-bd83-515d-ab38-faa7376b4cec",
      "notes": "User reported time for absence, confirmed details, but was transferred after incorrect date input."
    },
    {
      "user_id": "u-7faada7a-4cee-5f40-b53b-be0790cc7364",
      "notes": "User requested to speak with an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2032,
  completionTokens: 188,
  totalTokens: 2220,
  cost: '$0.000278',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 3527ms (3.53s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2220 ($0.0003)
âš¡ Performance: 629.4 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2032
   â€¢ Completion Tokens: 188
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-e5b99f58-033f-599e-902a-9f42f5350365: Invalid general_intent, u-e5b99f58-033f-599e-902a-9f42f5350365: Invalid session_outcome, u-d6c25e65-0980-5ecf-9f22-9e7faf5dda31: Invalid general_intent, u-d6c25e65-0980-5ecf-9f22-9e7faf5dda31: Invalid session_outcome, u-12ddc522-bd83-515d-ab38-faa7376b4cec: Invalid general_intent, u-12ddc522-bd83-515d-ab38-faa7376b4cec: Invalid session_outcome, u-7faada7a-4cee-5f40-b53b-be0790cc7364: Invalid general_intent, u-7faada7a-4cee-5f40-b53b-be0790cc7364: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 5 Single Batch Time: 3527ms (3.53s)

âœ… ===== STREAM 5 PROCESSING COMPLETE =====
â±ï¸  Stream 5 Total Time: 3528ms (3.53s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2220 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.1 sessions/sec
âš¡ Avg Time Per Session: 882.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:20:14.998Z',
  duration: '3842ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2010,
    completion_tokens: 191,
    total_tokens: 2201,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-4bb4acd3-2bf1-5578-98fd-a26d21db8529",
      "notes": "User successfully submitted a time entry for an absence."
    },
    {
      "user_id": "u-338e8b0f-8d24-57e2-9d02-852d3fd5b262",
      "notes": "User requested information about a leave request and was transferred to an agent."
    },
    {
      "user_id": "u-486516ab-3c5c-5694-a9fe-6e098e64b961",
      "notes": "User wanted to speak with an agent; session was transferred to an agent."
    },
    {
      "user_id": "u-479d5b7b-6904-5dd5-8a3c-8a4c7470a3d4",
      "notes": "User checked claim status; session was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2010,
  completionTokens: 191,
  totalTokens: 2201,
  cost: '$0.000277',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 3843ms (3.84s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2201 ($0.0003)
âš¡ Performance: 572.7 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2010
   â€¢ Completion Tokens: 191
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-4bb4acd3-2bf1-5578-98fd-a26d21db8529: Invalid general_intent, u-4bb4acd3-2bf1-5578-98fd-a26d21db8529: Invalid session_outcome, u-338e8b0f-8d24-57e2-9d02-852d3fd5b262: Invalid general_intent, u-338e8b0f-8d24-57e2-9d02-852d3fd5b262: Invalid session_outcome, u-486516ab-3c5c-5694-a9fe-6e098e64b961: Invalid general_intent, u-486516ab-3c5c-5694-a9fe-6e098e64b961: Invalid session_outcome, u-479d5b7b-6904-5dd5-8a3c-8a4c7470a3d4: Invalid general_intent, u-479d5b7b-6904-5dd5-8a3c-8a4c7470a3d4: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 4 Single Batch Time: 3843ms (3.84s)

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 3843ms (3.84s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2201 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.0 sessions/sec
âš¡ Avg Time Per Session: 960.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:20:15.862Z',
  duration: '4707ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1885,
    completion_tokens: 279,
    total_tokens: 2164,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Time Entry', 'Unknown', 'Claim Status' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-94469f68-68d3-555b-b658-fe528991cb85",
      "general_intent": "Time Entry",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User inquired about checking the status of a personal leave of absence and was transferred to an agent."
    },
    {
      "user_id": "u-51260be0-0ce7-5ce9-ae63-af25a29cf9ff",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User was silent and did not provide enough input, leading to session closure."
    },
    {
      "user_id": "u-cc7c7052-942c-5b21-8d4b-3cdaceec095f",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent, resulting in transfer."
    },
    {
      "user_id": "u-c59ead95-a098-5221-908b-4b9aceb43bff",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent, resulting in transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1885,
  completionTokens: 279,
  totalTokens: 2164,
  cost: '$0.000300',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 4708ms (4.71s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2164 ($0.0003)
âš¡ Performance: 459.6 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1885
   â€¢ Completion Tokens: 279
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 2 Single Batch Time: 4708ms (4.71s)

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 4708ms (4.71s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2164 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.8 sessions/sec
âš¡ Avg Time Per Session: 1177.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:20:16.074Z',
  duration: '4916ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1880,
    completion_tokens: 292,
    total_tokens: 2172,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Unknown' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-9fbd2c0f-e039-51c2-9484-6fa6b4893013",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative and was transferred to an agent."
    },
    {
      "user_id": "u-0c1f7ce5-4a93-566a-853a-2fe2fa90e691",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative and was transferred to an agent."
    },
    {
      "user_id": "u-acf577e5-8843-5f83-b158-cb53417d0bb1",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative and was transferred to an agent."
    },
    {
      "user_id": "u-a75474c5-15de-56cf-af77-105210f60c55",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User expressed interest in short term disability and was transferred to an agent after multiple prompts."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1880,
  completionTokens: 292,
  totalTokens: 2172,
  cost: '$0.000305',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 4917ms (4.92s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2172 ($0.0003)
âš¡ Performance: 441.7 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1880
   â€¢ Completion Tokens: 292
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 8 Single Batch Time: 4917ms (4.92s)

âœ… ===== STREAM 8 PROCESSING COMPLETE =====
â±ï¸  Stream 8 Total Time: 4917ms (4.92s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2172 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.8 sessions/sec
âš¡ Avg Time Per Session: 1229.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:20:16.200Z',
  duration: '5045ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1748,
    completion_tokens: 261,
    total_tokens: 2009,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status', 'Report Absence' ],
  transferCount: 2,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-8a018f11-820a-55e1-a70a-5555eb0bf95d",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested claim status and was transferred to an agent."
    },
    {
      "user_id": "u-bad71d3a-3b6c-52bd-ad87-9b089ecb5f84",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User was silent and did not respond, session was closed by the bot."
    },
    {
      "user_id": "u-01e6783a-3d62-5fb0-a980-64d59fe1546b",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User was silent and session was closed by the bot."
    },
    {
      "user_id": "u-997f7973-0eee-5951-b92c-ddfd9acf73be",
      "general_intent": "Report Absence",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1748,
  completionTokens: 261,
  totalTokens: 2009,
  cost: '$0.000279',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 5047ms (5.05s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2009 ($0.0003)
âš¡ Performance: 398.1 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1748
   â€¢ Completion Tokens: 261
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 1 Single Batch Time: 5047ms (5.05s)

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 5047ms (5.05s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2009 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.8 sessions/sec
âš¡ Avg Time Per Session: 1261.75ms
::1 - - [12/Aug/2025:17:20:16 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 200 1737 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:20:16.408Z',
  duration: '5252ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1775,
    completion_tokens: 290,
    total_tokens: 2065,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-473e7551-c697-5dd2-b014-7b10edf695c6",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent but was silent and then pressed star to transfer."
    },
    {
      "user_id": "u-e1d9a63c-9298-58d7-a2c0-707dac00e634",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested customer service and was transferred to an agent."
    },
    {
      "user_id": "u-f37a591f-e2cc-5cf2-91ee-f45cb6e30aa6",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User said 'Representative' and was transferred to an agent."
    },
    {
      "user_id": "u-e9b42c89-dcc8-56f3-9871-7b2abfda717e",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User said 'Agent' and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1775,
  completionTokens: 290,
  totalTokens: 2065,
  cost: '$0.000294',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 5252ms (5.25s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2065 ($0.0003)
âš¡ Performance: 393.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1775
   â€¢ Completion Tokens: 290
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 3 Single Batch Time: 5252ms (5.25s)

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 5253ms (5.25s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2065 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.8 sessions/sec
âš¡ Avg Time Per Session: 1313.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:20:16.653Z',
  duration: '5496ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1980,
    completion_tokens: 286,
    total_tokens: 2266,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Claim Status', 'Unknown' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-206b528e-c6be-5b7a-a4d4-d36634db21ea",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-336964cc-89d8-5f7d-8752-594032bb16c8",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User attempted to inform about returning to work and inquired about leave request, but did not get transferred to an agent."
    },
    {
      "user_id": "u-2337f5fb-8df7-5bc2-846f-d04fb002ffa3",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User provided leave request and employee number, but records did not match, leading to transfer."
    },
    {
      "user_id": "u-ed3e45c9-7f49-5dbd-925d-836547cac3bd",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a representative and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1980,
  completionTokens: 286,
  totalTokens: 2266,
  cost: '$0.000312',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 5497ms (5.50s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2266 ($0.0003)
âš¡ Performance: 412.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1980
   â€¢ Completion Tokens: 286
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 6 Single Batch Time: 5497ms (5.50s)

âœ… ===== STREAM 6 PROCESSING COMPLETE =====
â±ï¸  Stream 6 Total Time: 5497ms (5.50s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2266 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.7 sessions/sec
âš¡ Avg Time Per Session: 1374.25ms
[ParallelProcessingOrchestrator] Parallel processing complete: 8/8 streams succeeded
â±ï¸  Parallel Processing Time: 5500ms (5.50s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 8 streams
[ParallelProcessingOrchestrator] Synchronization complete: 1 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 1
ğŸ“Š Total Classifications: 10

âœ… ============ ROUND 2 COMPLETED ============
â±ï¸  Round 2 Total Time: 5501ms (5.50s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 22
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 5500ms (100.0%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ”„ ============ ROUND 3/3 STARTED ============
â±ï¸  Round 3 Start: 2025-08-12T17:20:16.655Z
ğŸ“Š Sessions Remaining: 22
[ParallelProcessingOrchestrator] Distributed 22 sessions across 6 streams: [
  'Stream 1: 4 sessions',
  'Stream 2: 4 sessions',
  'Stream 3: 4 sessions',
  'Stream 4: 4 sessions',
  'Stream 5: 4 sessions',
  'Stream 6: 2 sessions'
]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 6

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 6 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T17:20:16.655Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:20:16.655Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 653
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6153
   â€¢ Avg Per Session: 163 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6153
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6153
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:20:16.655Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 2

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:20:16.655Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5797,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Initiation, Claim Status, Claim status, Live Agent, Report Absence, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Claim Details, Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish ...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T17:20:16.656Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:20:16.656Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 827
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6327
   â€¢ Avg Per Session: 207 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6327
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6327
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:20:16.656Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 2

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:20:16.656Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6635,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Initiation, Claim Status, Claim status, Live Agent, Report Absence, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Claim Details, Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish ...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T17:20:16.656Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:20:16.657Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 661
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6161
   â€¢ Avg Per Session: 165 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6161
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6161
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:20:16.657Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 2

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:20:16.657Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5843,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Initiation, Claim Status, Claim status, Live Agent, Report Absence, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Claim Details, Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish ...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T17:20:16.657Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:20:16.657Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 768
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6268
   â€¢ Avg Per Session: 192 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6268
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6268
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:20:16.657Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 2

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:20:16.657Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6299,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Initiation, Claim Status, Claim status, Live Agent, Report Absence, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Claim Details, Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish ...

ğŸŒŠ ===== STREAM 5 PROCESSING START =====
â±ï¸  Stream 5 Start: 2025-08-12T17:20:16.657Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:20:16.657Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 805
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6305
   â€¢ Avg Per Session: 201 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6305
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 5) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6305
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 5: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:20:16.657Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 2

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:20:16.657Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6489,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Initiation, Claim Status, Claim status, Live Agent, Report Absence, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Claim Details, Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish ...

ğŸŒŠ ===== STREAM 6 PROCESSING START =====
â±ï¸  Stream 6 Start: 2025-08-12T17:20:16.657Z
ğŸ“Š Sessions Assigned: 2
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T17:20:16.657Z
ğŸ“Š Sessions to Estimate: 2
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 2
   â€¢ Session Tokens: 359
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 5859
   â€¢ Avg Per Session: 180 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 5859
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0009
ğŸ“Š Recommended Batch Size: 2

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 6) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 5859
ğŸ“¦ Recommended Batch Size: 2
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0009

âš¡ Stream 6: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T17:20:16.657Z
ğŸ“Š Sessions to Analyze: 2
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 2

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T17:20:16.658Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 2,
  apiKey: 'sk-proj-...',
  promptLength: 4797,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 2 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Initiation, Claim Status, Claim status, Live Agent, Report Absence, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Claim Details, Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish ...
::1 - - [12/Aug/2025:17:20:18 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 200 1535 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:20:19.659Z',
  duration: '3001ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1397,
    completion_tokens: 147,
    total_tokens: 1544,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 2,
  intentsFound: [ 'Live Agent' ],
  transferCount: 2,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-523a05a6-26af-5150-8a7d-d66f97ab3cac",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-2eb5c812-7237-5c28-8b56-c8849f28b249",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1397,
  completionTokens: 147,
  totalTokens: 1544,
  cost: '$0.000199',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 3003ms (3.00s)
ğŸ“Š Sessions Returned: 2
ğŸ’° Tokens Used: 1544 ($0.0002)
âš¡ Performance: 514.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1397
   â€¢ Completion Tokens: 147
[SessionValidationService] Validating batch response: 2 input sessions, 2 response sessions
[SessionValidationService] Validation successful: all 2 sessions processed
[SessionValidationService] Validating batch response: 2 input sessions, 2 response sessions
[SessionValidationService] Validation successful: all 2 sessions processed
â±ï¸  Stream 6 Single Batch Time: 3003ms (3.00s)

âœ… ===== STREAM 6 PROCESSING COMPLETE =====
â±ï¸  Stream 6 Total Time: 3003ms (3.00s)
ğŸ“Š Sessions Processed: 2/2
ğŸ’° Tokens Used: 1544 ($0.0002)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.7 sessions/sec
âš¡ Avg Time Per Session: 1501.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:20:19.773Z',
  duration: '3116ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1856,
    completion_tokens: 175,
    total_tokens: 2031,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-f0baa8b8-3aad-5a4b-9ce7-102c9be791e2",
      "notes": "User attempted to report time off but did not complete the process."
    },
    {
      "user_id": "u-b0b399fe-f6e0-58ff-98ed-7b75500d360c",
      "notes": "User requested to speak with an agent; session was transferred."
    },
    {
      "user_id": "u-94237b4f-646a-53e0-ac7b-cfa024a304e6",
      "notes": "User requested customer service; session was transferred."
    },
    {
      "user_id": "u-b36cc8dc-5a3e-5548-8a1c-917130856581",
      "notes": "User requested customer service; session was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1856,
  completionTokens: 175,
  totalTokens: 2031,
  cost: '$0.000256',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 3116ms (3.12s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2031 ($0.0003)
âš¡ Performance: 651.8 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1856
   â€¢ Completion Tokens: 175
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-f0baa8b8-3aad-5a4b-9ce7-102c9be791e2: Invalid general_intent, u-f0baa8b8-3aad-5a4b-9ce7-102c9be791e2: Invalid session_outcome, u-b0b399fe-f6e0-58ff-98ed-7b75500d360c: Invalid general_intent, u-b0b399fe-f6e0-58ff-98ed-7b75500d360c: Invalid session_outcome, u-94237b4f-646a-53e0-ac7b-cfa024a304e6: Invalid general_intent, u-94237b4f-646a-53e0-ac7b-cfa024a304e6: Invalid session_outcome, u-b36cc8dc-5a3e-5548-8a1c-917130856581: Invalid general_intent, u-b36cc8dc-5a3e-5548-8a1c-917130856581: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 5 Single Batch Time: 3117ms (3.12s)

âœ… ===== STREAM 5 PROCESSING COMPLETE =====
â±ï¸  Stream 5 Total Time: 3117ms (3.12s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2031 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.3 sessions/sec
âš¡ Avg Time Per Session: 779.25ms
::1 - - [12/Aug/2025:17:20:20 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 200 1539 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:20:21.174Z',
  duration: '4518ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1667,
    completion_tokens: 285,
    total_tokens: 1952,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Claim Initiation' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-2aba4862-9b7b-57aa-9d06-6d9a8a912289",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent and was transferred."
    },
    {
      "user_id": "u-ad8a401d-f819-50e4-b0de-933caf504220",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent and was transferred."
    },
    {
      "user_id": "u-32ee0a12-ac74-5191-a0a3-873f84018dfd",
      "general_intent": "Claim Initiation",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to file a claim and was transferred to an agent."
    },
    {
      "user_id": "u-c43a5c69-fb18-5cb3-968b-b7f3f1135ad8",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a representative and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1667,
  completionTokens: 285,
  totalTokens: 1952,
  cost: '$0.000281',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 4519ms (4.52s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1952 ($0.0003)
âš¡ Performance: 432.0 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1667
   â€¢ Completion Tokens: 285
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 1 Single Batch Time: 4519ms (4.52s)

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 4519ms (4.52s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1952 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.9 sessions/sec
âš¡ Avg Time Per Session: 1129.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:20:21.305Z',
  duration: '4648ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1794,
    completion_tokens: 291,
    total_tokens: 2085,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-c01ac970-eda7-5053-8d9e-973e7818c4c2",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an operator and was transferred to an agent."
    },
    {
      "user_id": "u-4f6a4409-36e3-598e-b569-f678335d8ebf",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User indicated a desire to speak with an agent and was transferred."
    },
    {
      "user_id": "u-9f68b0f5-4be4-5b8c-98b8-ed452f0be598",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a representative and was transferred to an agent."
    },
    {
      "user_id": "u-9718ce7a-efcd-5bc7-9bf7-66a2d2c21bdd",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1794,
  completionTokens: 291,
  totalTokens: 2085,
  cost: '$0.000296',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 4648ms (4.65s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2085 ($0.0003)
âš¡ Performance: 448.6 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1794
   â€¢ Completion Tokens: 291
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 4 Single Batch Time: 4648ms (4.65s)

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 4648ms (4.65s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2085 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.9 sessions/sec
âš¡ Avg Time Per Session: 1162.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:20:21.470Z',
  duration: '4814ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1910,
    completion_tokens: 312,
    total_tokens: 2222,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status', 'Time Entry' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-6c6e70f3-ca86-55e7-a92d-0f2f9f89e0b1",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to inquire about FMLA and was transferred to a live agent after difficulty providing information."
    },
    {
      "user_id": "u-20f2f80a-a362-598d-aa52-b88c12f6bd5f",
      "general_intent": "Time Entry",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to notify time but was transferred to an agent after unclear communication."
    },
    {
      "user_id": "u-53ac09d6-06f7-5a8b-a1a9-e7d6b8623e78",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to someone and was transferred to a live agent."
    },
    {
      "user_id": "u-cb8b567c-90f7-535c-9063-1e3615295140",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested agent assistance and was transferred after minimal input."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1910,
  completionTokens: 312,
  totalTokens: 2222,
  cost: '$0.000316',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 4815ms (4.82s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2222 ($0.0003)
âš¡ Performance: 461.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1910
   â€¢ Completion Tokens: 312
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 2 Single Batch Time: 4815ms (4.82s)

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 4815ms (4.82s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2222 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.8 sessions/sec
âš¡ Avg Time Per Session: 1203.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T17:20:22.080Z',
  duration: '5423ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1685,
    completion_tokens: 309,
    total_tokens: 1994,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Claim Status', 'Unknown' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-3e6f1bc5-2b7a-5854-81eb-fdc23a96320b",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent but was silent, leading to transfer."
    },
    {
      "user_id": "u-7481b906-77e6-5567-87e4-a41ea5483043",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked about FMLA and then requested customer service, resulting in transfer."
    },
    {
      "user_id": "u-d314c8e3-23f4-554e-bd17-f310596a3d8f",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and then asked about opening a leave request, leading to transfer."
    },
    {
      "user_id": "u-c1676cdb-3c2c-5ac8-84f8-1ecd8ff4c7ae",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent and pressed star, leading to transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1685,
  completionTokens: 309,
  totalTokens: 1994,
  cost: '$0.000292',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 5424ms (5.42s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1994 ($0.0003)
âš¡ Performance: 367.6 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1685
   â€¢ Completion Tokens: 309
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 3 Single Batch Time: 5424ms (5.42s)

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 5425ms (5.42s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1994 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.7 sessions/sec
âš¡ Avg Time Per Session: 1356.25ms
[ParallelProcessingOrchestrator] Parallel processing complete: 6/6 streams succeeded
â±ï¸  Parallel Processing Time: 5426ms (5.43s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 6 streams
[ParallelProcessingOrchestrator] Synchronization complete: 0 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 0
ğŸ“Š Total Classifications: 10

âœ… ============ ROUND 3 COMPLETED ============
â±ï¸  Round 3 Total Time: 5427ms (5.43s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 0
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 5426ms (100.0%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ‰ ============ PARALLEL PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 17119ms (17.12s)
ğŸ“Š Sessions Processed: 86/86
ğŸ”„ Total Rounds: 3
ğŸŒŠ Stream Results: 22
ğŸ’° Token Usage: 46332 tokens ($0.0064)
ğŸ“ˆ Stream Utilization: 100.0%
ğŸ¯ Performance: 5.0 sessions/second
âš¡ Avg Time Per Session: 199.06ms

ğŸ“Š Stream Performance Breakdown:
   Stream 1: 4 sessions in 5321ms (373.2 tokens/sec)
   Stream 2: 4 sessions in 5805ms (360.4 tokens/sec)
   Stream 3: 4 sessions in 5656ms (362.4 tokens/sec)
   Stream 4: 4 sessions in 5979ms (349.6 tokens/sec)
   Stream 5: 4 sessions in 5558ms (387.4 tokens/sec)
   Stream 6: 4 sessions in 3977ms (571.5 tokens/sec)
   Stream 7: 4 sessions in 6186ms (409.0 tokens/sec)
   Stream 8: 4 sessions in 5747ms (362.4 tokens/sec)
   Stream 1: 4 sessions in 5047ms (398.1 tokens/sec)
   Stream 2: 4 sessions in 4708ms (459.6 tokens/sec)
   Stream 3: 4 sessions in 5253ms (393.1 tokens/sec)
   Stream 4: 4 sessions in 3843ms (572.7 tokens/sec)
   Stream 5: 4 sessions in 3528ms (629.3 tokens/sec)
   Stream 6: 4 sessions in 5497ms (412.2 tokens/sec)
   Stream 7: 4 sessions in 3385ms (635.2 tokens/sec)
   Stream 8: 4 sessions in 4917ms (441.7 tokens/sec)
   Stream 1: 4 sessions in 4519ms (432.0 tokens/sec)
   Stream 2: 4 sessions in 4815ms (461.5 tokens/sec)
   Stream 3: 4 sessions in 5425ms (367.6 tokens/sec)
   Stream 4: 4 sessions in 4648ms (448.6 tokens/sec)
   Stream 5: 4 sessions in 3117ms (651.6 tokens/sec)
   Stream 6: 2 sessions in 3003ms (514.2 tokens/sec)
[ConflictResolutionService] Starting conflict resolution for 99 sessions
[ConflictResolutionService] Found classifications: { intents: 7, reasons: 1, locations: 2 }
[ConflictResolutionService] Calling LLM for conflict resolution with model gpt-4.1-nano
ğŸ”§ Conflict Resolution Prompt Preview: You are reviewing classifications from parallel analysis streams. Identify any semantic duplicates and choose the canonical version for each group.

**Instructions:**
1. Look for classifications that refer to the same concept but use different wording
2. For each group of duplicates, choose the most...
::1 - - [12/Aug/2025:17:20:22 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 200 1578 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[ConflictResolutionService] LLM conflict resolution complete: { intents: 6, reasons: 1, locations: 2, tokens: 765, cost: 0.0001149 }
ğŸ”§ Conflict Resolution Response: {
  "generalIntents": [
    {
      "canonical": "Claim Initiation",
      "aliases": [
        "Claim Initiation"
      ]
    },
    {
      "canonical": "Claim Status Inquiry",
      "aliases": [
        "Claim Status",
        "Claim status"
      ]
    },
    {
      "canonical": "Live Agent Support",
      "aliases": [
        "Live Agent"
      ]
    },
    {
      "canonical": "Report Absence",
      "aliases": [
        "Report Absence"
      ]
    },
    {
      "canonical": "Time Entry",
      "aliases": [
        "Time Entry"
      ]
    },
    {
      "canonical": "Unknown",
      "aliases": [
        "Unknown"
      ]
    }
  ],
  "transferReasons": [
    {
      "canonical": "Live Agent Request",
      "aliases": [
        "Live Agent Request"
      ]
    }
  ],
  "dropOffLocations": [
    {
      "canonical": "Claim Details",
      "aliases": [
        "Claim Details"
      ]
    },
    {
      "canonical": "Help Offer Prompt",
      "aliases": [
        "Help Offer Prompt"
      ]
    }
  ]
}
[ConflictResolutionService] Applying resolutions to 99 sessions
[ConflictResolutionService] Applied 48 classification mappings across 99 sessions
[ConflictResolutionService] Identified 1 potential conflict groups
[ConflictResolutionService] Conflict resolution complete in 1803ms: { conflictsFound: 1, conflictsResolved: 9, canonicalMappings: 10 }
[ParallelAutoAnalyzeService] Using real analysis summary service
::1 - - [12/Aug/2025:17:20:24 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 200 1654 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:20:26 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:20:28 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:20:30 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:20:32 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:20:34 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:20:36 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:20:38 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:20:40 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:20:42 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:20:44 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:20:46 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:20:48 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[ParallelAutoAnalyzeService] Parallel analysis 1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc completed successfully
[BackgroundJobQueue] Updated job progress to final state: complete
[BackgroundJobQueue] Parallel analysis job 1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc-parallel completed successfully
::1 - - [12/Aug/2025:17:20:50 +0000] "GET /api/analysis/auto-analyze/parallel/progress/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 200 1677 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:17:20:50 +0000] "GET /api/analysis/auto-analyze/parallel/results/1da1d39c-e9c3-42d3-b5fd-42aa54dd8acc HTTP/1.1" 200 690040 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[BackgroundJobQueue] Cleaned up 4 expired jobs
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T19:00:49.405Z",
  "dateTo": "2025-08-12T19:01:49.405Z",
  "skip": 0,
  "limit": 1
}
[getSessionsMetadataForConnectionTest] Connection test failed: Error: Connection test timeout after 10000ms
    at Timeout._onTimeout (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:491:33)
    at listOnTimeout (node:internal/timers:608:17)
    at process.processTimers (node:internal/timers:543:7)
Kore.ai API connection test failed: Error: Connection test timeout after 10000ms
    at Timeout._onTimeout (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:491:33)
    at listOnTimeout (node:internal/timers:608:17)
    at process.processTimers (node:internal/timers:543:7)
::1 - - [12/Aug/2025:19:01:59 +0000] "GET /api/kore/test HTTP/1.1" 500 248 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T19:07:06.770Z",
  "dateTo": "2025-08-12T19:08:06.771Z",
  "skip": 0,
  "limit": 1
}
::1 - - [12/Aug/2025:19:08:11 +0000] "GET /api/kore/test HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[getSessionsMetadataForConnectionTest] Connection test failed: Error: Connection test timeout after 10000ms
    at Timeout._onTimeout (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:491:33)
    at listOnTimeout (node:internal/timers:608:17)
    at process.processTimers (node:internal/timers:543:7)
Kore.ai API connection test failed: Error: Connection test timeout after 10000ms
    at Timeout._onTimeout (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:491:33)
    at listOnTimeout (node:internal/timers:608:17)
    at process.processTimers (node:internal/timers:543:7)
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T19:07:33.634Z",
  "dateTo": "2025-08-12T19:08:33.634Z",
  "skip": 0,
  "limit": 1
}
::1 - - [12/Aug/2025:19:08:38 +0000] "GET /api/kore/test HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[getSessionsMetadataForConnectionTest] Connection test failed: AxiosError: Request failed with status code 400
    at settle (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/settle.js:19:12)
    at IncomingMessage.handleStreamEnd (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:599:11)
    at IncomingMessage.emit (node:events:519:35)
    at endReadableNT (node:internal/streams/readable:1701:12)
    at process.processTicksAndRejections (node:internal/process/task_queues:90:21)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async KoreApiService.getSessionsMetadataForConnectionTest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:503:22)
    at async <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/kore.ts:28:29) {
  code: 'ERR_BAD_REQUEST',
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjU3MTMsImV4cCI6MTc1NTAyOTMxMywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.b8_AY1bFJj-xIjVOKqCNLmynLCdGE-J62GZyZu7UaT4',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '94',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
    data: '{"dateFrom":"2025-08-12T19:07:33.634Z","dateTo":"2025-08-12T19:08:33.634Z","skip":0,"limit":1}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> ClientRequest {
    _events: [Object: null prototype] {
      abort: [Function (anonymous)],
      aborted: [Function (anonymous)],
      connect: [Function (anonymous)],
      error: [Function (anonymous)],
      socket: [Function (anonymous)],
      timeout: [Function (anonymous)],
      finish: [Function: requestOnFinish]
    },
    _eventsCount: 7,
    _maxListeners: undefined,
    outputData: [],
    outputSize: 0,
    writable: true,
    destroyed: true,
    _last: false,
    chunkedEncoding: false,
    shouldKeepAlive: true,
    maxRequestsOnConnectionReached: false,
    _defaultKeepAlive: true,
    useChunkedEncodingByDefault: true,
    sendDate: false,
    _removedConnection: false,
    _removedContLen: false,
    _removedTE: false,
    strictContentLength: false,
    _contentLength: 94,
    _hasBody: true,
    _trailer: '',
    finished: true,
    _headerSent: true,
    _closed: true,
    _header: 'POST /api/public/bot/***REMOVED***/getSessions?containmentType=agent HTTP/1.1\r\n' +
      'Accept: application/json, text/plain, */*\r\n' +
      'Content-Type: application/json\r\n' +
      'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjU3MTMsImV4cCI6MTc1NTAyOTMxMywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.b8_AY1bFJj-xIjVOKqCNLmynLCdGE-J62GZyZu7UaT4\r\n' +
      'User-Agent: axios/1.11.0\r\n' +
      'Content-Length: 94\r\n' +
      'Accept-Encoding: gzip, compress, deflate, br\r\n' +
      'Host: bots.kore.ai\r\n' +
      'Connection: keep-alive\r\n' +
      '\r\n',
    _keepAliveTimeout: 0,
    _onPendingData: [Function: nop],
    agent: Agent {
      _events: [Object: null prototype],
      _eventsCount: 2,
      _maxListeners: undefined,
      defaultPort: 443,
      protocol: 'https:',
      options: [Object: null prototype],
      requests: [Object: null prototype] {},
      sockets: [Object: null prototype] {},
      freeSockets: [Object: null prototype],
      keepAliveMsecs: 1000,
      keepAlive: true,
      maxSockets: Infinity,
      maxFreeSockets: 256,
      scheduling: 'lifo',
      maxTotalSockets: Infinity,
      totalSocketCount: 1,
      maxCachedSessions: 100,
      _sessionCache: [Object],
      Symbol(shapeMode): false,
      Symbol(kCapture): false
    },
    socketPath: undefined,
    method: 'POST',
    maxHeaderSize: undefined,
    insecureHTTPParser: undefined,
    joinDuplicateHeaders: undefined,
    path: '/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
    _ended: true,
    res: IncomingMessage {
      _events: [Object],
      _readableState: [ReadableState],
      _maxListeners: undefined,
      socket: null,
      httpVersionMajor: 1,
      httpVersionMinor: 1,
      httpVersion: '1.1',
      complete: true,
      rawHeaders: [Array],
      rawTrailers: [],
      joinDuplicateHeaders: undefined,
      aborted: false,
      upgrade: false,
      url: '',
      method: null,
      statusCode: 400,
      statusMessage: 'Bad Request',
      client: [TLSSocket],
      _consuming: false,
      _dumped: false,
      req: [Circular *1],
      _eventsCount: 4,
      responseUrl: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
      redirects: [],
      Symbol(shapeMode): true,
      Symbol(kCapture): false,
      Symbol(kHeaders): [Object],
      Symbol(kHeadersCount): 34,
      Symbol(kTrailers): null,
      Symbol(kTrailersCount): 0
    },
    aborted: false,
    timeoutCb: null,
    upgradeOrConnect: false,
    parser: null,
    maxHeadersCount: null,
    reusedSocket: false,
    host: 'bots.kore.ai',
    protocol: 'https:',
    _redirectable: Writable {
      _events: [Object],
      _writableState: [WritableState],
      _maxListeners: undefined,
      _options: [Object],
      _ended: true,
      _ending: true,
      _redirectCount: 0,
      _redirects: [],
      _requestBodyLength: 94,
      _requestBodyBuffers: [],
      _eventsCount: 3,
      _onNativeResponse: [Function (anonymous)],
      _currentRequest: [Circular *1],
      _currentUrl: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
      _timeout: null,
      Symbol(shapeMode): true,
      Symbol(kCapture): false
    },
    Symbol(shapeMode): false,
    Symbol(kCapture): false,
    Symbol(kBytesWritten): 0,
    Symbol(kNeedDrain): false,
    Symbol(corked): 0,
    Symbol(kChunkedBuffer): [],
    Symbol(kChunkedLength): 0,
    Symbol(kSocket): TLSSocket {
      _tlsOptions: [Object],
      _secureEstablished: true,
      _securePending: false,
      _newSessionPending: false,
      _controlReleased: true,
      secureConnecting: false,
      _SNICallback: null,
      servername: 'bots.kore.ai',
      alpnProtocol: false,
      authorized: true,
      authorizationError: null,
      encrypted: true,
      _events: [Object: null prototype],
      _eventsCount: 9,
      connecting: false,
      _hadError: false,
      _parent: null,
      _host: 'bots.kore.ai',
      _closeAfterHandlingError: false,
      _readableState: [ReadableState],
      _writableState: [WritableState],
      allowHalfOpen: false,
      _maxListeners: undefined,
      _sockname: null,
      _pendingData: null,
      _pendingEncoding: '',
      server: undefined,
      _server: null,
      ssl: [TLSWrap],
      _requestCert: true,
      _rejectUnauthorized: true,
      timeout: 5000,
      parser: null,
      _httpMessage: null,
      autoSelectFamilyAttemptedAddresses: [Array],
      Symbol(alpncallback): null,
      Symbol(res): [TLSWrap],
      Symbol(verified): true,
      Symbol(pendingSession): null,
      Symbol(async_id_symbol): -1,
      Symbol(kHandle): [TLSWrap],
      Symbol(lastWriteQueueSize): 0,
      Symbol(timeout): Timeout {
        _idleTimeout: 5000,
        _idlePrev: [TimersList],
        _idleNext: [TimersList],
        _idleStart: 8209266,
        _onTimeout: [Function: bound ],
        _timerArgs: undefined,
        _repeat: null,
        _destroyed: false,
        Symbol(refed): false,
        Symbol(kHasPrimitive): false,
        Symbol(asyncId): 8652,
        Symbol(triggerId): 8650,
        Symbol(kAsyncContextFrame): undefined
      },
      Symbol(kBuffer): null,
      Symbol(kBufferCb): null,
      Symbol(kBufferGen): null,
      Symbol(shapeMode): true,
      Symbol(kCapture): false,
      Symbol(kSetNoDelay): false,
      Symbol(kSetKeepAlive): true,
      Symbol(kSetKeepAliveInitialDelay): 1,
      Symbol(kBytesRead): 0,
      Symbol(kBytesWritten): 0,
      Symbol(connect-options): [Object]
    },
    Symbol(kOutHeaders): [Object: null prototype] {
      accept: [Array],
      'content-type': [Array],
      auth: [Array],
      'user-agent': [Array],
      'content-length': [Array],
      'accept-encoding': [Array],
      host: [Array]
    },
    Symbol(errored): null,
    Symbol(kHighWaterMark): 65536,
    Symbol(kRejectNonStandardBodyWrites): false,
    Symbol(kUniqueHeaders): null
  },
  response: {
    status: 400,
    statusText: 'Bad Request',
    headers: Object [AxiosHeaders] {
      date: 'Tue, 12 Aug 2025 19:08:41 GMT',
      'content-type': 'application/json; charset=utf-8',
      'content-length': '66',
      connection: 'keep-alive',
      server: 'KoreServer/COMMITH',
      'access-control-allow-methods': 'GET,POST,PUT',
      'access-control-allow-headers': 'Authorization,Content-Type,X-Requested-With,X-HTTP-Method-Override,X-UserToken,X-Timezone-Offset,smartassist,state,X-Request-Id,bot-language,app-language,accountid,iId,x-timezone',
      'access-control-allow-credentials': 'true',
      'access-control-allow-origin': '*',
      'x-requesttime': '1755025713909',
      pid: '127315',
      'x-traceid': '4598140d-116b-4271-8cc3-edb2a8a39264',
      'content-security-policy': "frame-ancestors https://*.smartassist.ai https://*.kore.ai https://*.korebots.com https://kore.ai https://*.force.com https://*.zendesk.com https://*.mypurecloud.com https://*.mypurecloud.jp https://*.usw2.pure.cloud https://*.onbmc.com https://*.workspace.ai https://*.niceincontact.com https://*.kore.ai https://*.kore.com; script-src 'self' 'unsafe-inline' 'unsafe-eval' https://*.kore.ai https://*.force.com https://*.zendesk.com https://*.mypurecloud.com https://*.mypurecloud.jp https://*.usw2.pure.cloud https://*.onbmc.com https://*.pendo.io https://*.appcues.com https://*.inlinemanual.com https://inlinemanual.com  https://cdn.mxpnl.com https://www.google-analytics.com  https://maps.googleapis.com https://canny.io https://js.hs-scripts.com https://www.googletagmanager.com https://*.grammarly.com https://*.grammarly.io https://unpkg.com/ https://*.niceincontact.com",
      'x-content-type-options': 'nosniff',
      'x-xss-protection': '1; mode=block',
      'strict-transport-security': 'max-age=31536000; includeSubdomains;',
      'referrer-policy': 'strict-origin-when-cross-origin'
    },
    config: {
      transitional: [Object],
      adapter: [Array],
      transformRequest: [Array],
      transformResponse: [Array],
      timeout: 30000,
      xsrfCookieName: 'XSRF-TOKEN',
      xsrfHeaderName: 'X-XSRF-TOKEN',
      maxContentLength: -1,
      maxBodyLength: -1,
      env: [Object],
      validateStatus: [Function: validateStatus],
      headers: [Object [AxiosHeaders]],
      method: 'post',
      url: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
      data: '{"dateFrom":"2025-08-12T19:07:33.634Z","dateTo":"2025-08-12T19:08:33.634Z","skip":0,"limit":1}',
      allowAbsoluteUrls: true
    },
    request: <ref *1> ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: true,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 94,
      _hasBody: true,
      _trailer: '',
      finished: true,
      _headerSent: true,
      _closed: true,
      _header: 'POST /api/public/bot/***REMOVED***/getSessions?containmentType=agent HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjU3MTMsImV4cCI6MTc1NTAyOTMxMywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.b8_AY1bFJj-xIjVOKqCNLmynLCdGE-J62GZyZu7UaT4\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 94\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: bots.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
      _ended: true,
      res: [IncomingMessage],
      aborted: false,
      timeoutCb: null,
      upgradeOrConnect: false,
      parser: null,
      maxHeadersCount: null,
      reusedSocket: false,
      host: 'bots.kore.ai',
      protocol: 'https:',
      _redirectable: [Writable],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    data: { errors: [Array] }
  },
  status: 400
}
Kore.ai API connection test failed: AxiosError: Request failed with status code 400
    at settle (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/settle.js:19:12)
    at IncomingMessage.handleStreamEnd (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:599:11)
    at IncomingMessage.emit (node:events:519:35)
    at endReadableNT (node:internal/streams/readable:1701:12)
    at process.processTicksAndRejections (node:internal/process/task_queues:90:21)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async KoreApiService.getSessionsMetadataForConnectionTest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:503:22)
    at async <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/kore.ts:28:29) {
  code: 'ERR_BAD_REQUEST',
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjU3MTMsImV4cCI6MTc1NTAyOTMxMywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.b8_AY1bFJj-xIjVOKqCNLmynLCdGE-J62GZyZu7UaT4',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '94',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
    data: '{"dateFrom":"2025-08-12T19:07:33.634Z","dateTo":"2025-08-12T19:08:33.634Z","skip":0,"limit":1}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> ClientRequest {
    _events: [Object: null prototype] {
      abort: [Function (anonymous)],
      aborted: [Function (anonymous)],
      connect: [Function (anonymous)],
      error: [Function (anonymous)],
      socket: [Function (anonymous)],
      timeout: [Function (anonymous)],
      finish: [Function: requestOnFinish]
    },
    _eventsCount: 7,
    _maxListeners: undefined,
    outputData: [],
    outputSize: 0,
    writable: true,
    destroyed: true,
    _last: false,
    chunkedEncoding: false,
    shouldKeepAlive: true,
    maxRequestsOnConnectionReached: false,
    _defaultKeepAlive: true,
    useChunkedEncodingByDefault: true,
    sendDate: false,
    _removedConnection: false,
    _removedContLen: false,
    _removedTE: false,
    strictContentLength: false,
    _contentLength: 94,
    _hasBody: true,
    _trailer: '',
    finished: true,
    _headerSent: true,
    _closed: true,
    _header: 'POST /api/public/bot/***REMOVED***/getSessions?containmentType=agent HTTP/1.1\r\n' +
      'Accept: application/json, text/plain, */*\r\n' +
      'Content-Type: application/json\r\n' +
      'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjU3MTMsImV4cCI6MTc1NTAyOTMxMywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.b8_AY1bFJj-xIjVOKqCNLmynLCdGE-J62GZyZu7UaT4\r\n' +
      'User-Agent: axios/1.11.0\r\n' +
      'Content-Length: 94\r\n' +
      'Accept-Encoding: gzip, compress, deflate, br\r\n' +
      'Host: bots.kore.ai\r\n' +
      'Connection: keep-alive\r\n' +
      '\r\n',
    _keepAliveTimeout: 0,
    _onPendingData: [Function: nop],
    agent: Agent {
      _events: [Object: null prototype],
      _eventsCount: 2,
      _maxListeners: undefined,
      defaultPort: 443,
      protocol: 'https:',
      options: [Object: null prototype],
      requests: [Object: null prototype] {},
      sockets: [Object: null prototype] {},
      freeSockets: [Object: null prototype],
      keepAliveMsecs: 1000,
      keepAlive: true,
      maxSockets: Infinity,
      maxFreeSockets: 256,
      scheduling: 'lifo',
      maxTotalSockets: Infinity,
      totalSocketCount: 1,
      maxCachedSessions: 100,
      _sessionCache: [Object],
      Symbol(shapeMode): false,
      Symbol(kCapture): false
    },
    socketPath: undefined,
    method: 'POST',
    maxHeaderSize: undefined,
    insecureHTTPParser: undefined,
    joinDuplicateHeaders: undefined,
    path: '/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
    _ended: true,
    res: IncomingMessage {
      _events: [Object],
      _readableState: [ReadableState],
      _maxListeners: undefined,
      socket: null,
      httpVersionMajor: 1,
      httpVersionMinor: 1,
      httpVersion: '1.1',
      complete: true,
      rawHeaders: [Array],
      rawTrailers: [],
      joinDuplicateHeaders: undefined,
      aborted: false,
      upgrade: false,
      url: '',
      method: null,
      statusCode: 400,
      statusMessage: 'Bad Request',
      client: [TLSSocket],
      _consuming: false,
      _dumped: false,
      req: [Circular *1],
      _eventsCount: 4,
      responseUrl: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
      redirects: [],
      Symbol(shapeMode): true,
      Symbol(kCapture): false,
      Symbol(kHeaders): [Object],
      Symbol(kHeadersCount): 34,
      Symbol(kTrailers): null,
      Symbol(kTrailersCount): 0
    },
    aborted: false,
    timeoutCb: null,
    upgradeOrConnect: false,
    parser: null,
    maxHeadersCount: null,
    reusedSocket: false,
    host: 'bots.kore.ai',
    protocol: 'https:',
    _redirectable: Writable {
      _events: [Object],
      _writableState: [WritableState],
      _maxListeners: undefined,
      _options: [Object],
      _ended: true,
      _ending: true,
      _redirectCount: 0,
      _redirects: [],
      _requestBodyLength: 94,
      _requestBodyBuffers: [],
      _eventsCount: 3,
      _onNativeResponse: [Function (anonymous)],
      _currentRequest: [Circular *1],
      _currentUrl: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
      _timeout: null,
      Symbol(shapeMode): true,
      Symbol(kCapture): false
    },
    Symbol(shapeMode): false,
    Symbol(kCapture): false,
    Symbol(kBytesWritten): 0,
    Symbol(kNeedDrain): false,
    Symbol(corked): 0,
    Symbol(kChunkedBuffer): [],
    Symbol(kChunkedLength): 0,
    Symbol(kSocket): TLSSocket {
      _tlsOptions: [Object],
      _secureEstablished: true,
      _securePending: false,
      _newSessionPending: false,
      _controlReleased: true,
      secureConnecting: false,
      _SNICallback: null,
      servername: 'bots.kore.ai',
      alpnProtocol: false,
      authorized: true,
      authorizationError: null,
      encrypted: true,
      _events: [Object: null prototype],
      _eventsCount: 9,
      connecting: false,
      _hadError: false,
      _parent: null,
      _host: 'bots.kore.ai',
      _closeAfterHandlingError: false,
      _readableState: [ReadableState],
      _writableState: [WritableState],
      allowHalfOpen: false,
      _maxListeners: undefined,
      _sockname: null,
      _pendingData: null,
      _pendingEncoding: '',
      server: undefined,
      _server: null,
      ssl: [TLSWrap],
      _requestCert: true,
      _rejectUnauthorized: true,
      timeout: 5000,
      parser: null,
      _httpMessage: null,
      autoSelectFamilyAttemptedAddresses: [Array],
      Symbol(alpncallback): null,
      Symbol(res): [TLSWrap],
      Symbol(verified): true,
      Symbol(pendingSession): null,
      Symbol(async_id_symbol): -1,
      Symbol(kHandle): [TLSWrap],
      Symbol(lastWriteQueueSize): 0,
      Symbol(timeout): Timeout {
        _idleTimeout: 5000,
        _idlePrev: [TimersList],
        _idleNext: [TimersList],
        _idleStart: 8209266,
        _onTimeout: [Function: bound ],
        _timerArgs: undefined,
        _repeat: null,
        _destroyed: false,
        Symbol(refed): false,
        Symbol(kHasPrimitive): false,
        Symbol(asyncId): 8652,
        Symbol(triggerId): 8650,
        Symbol(kAsyncContextFrame): undefined
      },
      Symbol(kBuffer): null,
      Symbol(kBufferCb): null,
      Symbol(kBufferGen): null,
      Symbol(shapeMode): true,
      Symbol(kCapture): false,
      Symbol(kSetNoDelay): false,
      Symbol(kSetKeepAlive): true,
      Symbol(kSetKeepAliveInitialDelay): 1,
      Symbol(kBytesRead): 0,
      Symbol(kBytesWritten): 0,
      Symbol(connect-options): [Object]
    },
    Symbol(kOutHeaders): [Object: null prototype] {
      accept: [Array],
      'content-type': [Array],
      auth: [Array],
      'user-agent': [Array],
      'content-length': [Array],
      'accept-encoding': [Array],
      host: [Array]
    },
    Symbol(errored): null,
    Symbol(kHighWaterMark): 65536,
    Symbol(kRejectNonStandardBodyWrites): false,
    Symbol(kUniqueHeaders): null
  },
  response: {
    status: 400,
    statusText: 'Bad Request',
    headers: Object [AxiosHeaders] {
      date: 'Tue, 12 Aug 2025 19:08:41 GMT',
      'content-type': 'application/json; charset=utf-8',
      'content-length': '66',
      connection: 'keep-alive',
      server: 'KoreServer/COMMITH',
      'access-control-allow-methods': 'GET,POST,PUT',
      'access-control-allow-headers': 'Authorization,Content-Type,X-Requested-With,X-HTTP-Method-Override,X-UserToken,X-Timezone-Offset,smartassist,state,X-Request-Id,bot-language,app-language,accountid,iId,x-timezone',
      'access-control-allow-credentials': 'true',
      'access-control-allow-origin': '*',
      'x-requesttime': '1755025713909',
      pid: '127315',
      'x-traceid': '4598140d-116b-4271-8cc3-edb2a8a39264',
      'content-security-policy': "frame-ancestors https://*.smartassist.ai https://*.kore.ai https://*.korebots.com https://kore.ai https://*.force.com https://*.zendesk.com https://*.mypurecloud.com https://*.mypurecloud.jp https://*.usw2.pure.cloud https://*.onbmc.com https://*.workspace.ai https://*.niceincontact.com https://*.kore.ai https://*.kore.com; script-src 'self' 'unsafe-inline' 'unsafe-eval' https://*.kore.ai https://*.force.com https://*.zendesk.com https://*.mypurecloud.com https://*.mypurecloud.jp https://*.usw2.pure.cloud https://*.onbmc.com https://*.pendo.io https://*.appcues.com https://*.inlinemanual.com https://inlinemanual.com  https://cdn.mxpnl.com https://www.google-analytics.com  https://maps.googleapis.com https://canny.io https://js.hs-scripts.com https://www.googletagmanager.com https://*.grammarly.com https://*.grammarly.io https://unpkg.com/ https://*.niceincontact.com",
      'x-content-type-options': 'nosniff',
      'x-xss-protection': '1; mode=block',
      'strict-transport-security': 'max-age=31536000; includeSubdomains;',
      'referrer-policy': 'strict-origin-when-cross-origin'
    },
    config: {
      transitional: [Object],
      adapter: [Array],
      transformRequest: [Array],
      transformResponse: [Array],
      timeout: 30000,
      xsrfCookieName: 'XSRF-TOKEN',
      xsrfHeaderName: 'X-XSRF-TOKEN',
      maxContentLength: -1,
      maxBodyLength: -1,
      env: [Object],
      validateStatus: [Function: validateStatus],
      headers: [Object [AxiosHeaders]],
      method: 'post',
      url: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
      data: '{"dateFrom":"2025-08-12T19:07:33.634Z","dateTo":"2025-08-12T19:08:33.634Z","skip":0,"limit":1}',
      allowAbsoluteUrls: true
    },
    request: <ref *1> ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: true,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 94,
      _hasBody: true,
      _trailer: '',
      finished: true,
      _headerSent: true,
      _closed: true,
      _header: 'POST /api/public/bot/***REMOVED***/getSessions?containmentType=agent HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjU3MTMsImV4cCI6MTc1NTAyOTMxMywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.b8_AY1bFJj-xIjVOKqCNLmynLCdGE-J62GZyZu7UaT4\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 94\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: bots.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
      _ended: true,
      res: [IncomingMessage],
      aborted: false,
      timeoutCb: null,
      upgradeOrConnect: false,
      parser: null,
      maxHeadersCount: null,
      reusedSocket: false,
      host: 'bots.kore.ai',
      protocol: 'https:',
      _redirectable: [Writable],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    data: { errors: [Array] }
  },
  status: 400
}
ğŸ­ Detected mock credentials - using mock service configuration
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://mock.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://mock.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T19:09:15.153Z",
  "dateTo": "2025-08-12T19:10:15.153Z",
  "skip": 0,
  "limit": 1
}
[getSessionsMetadataForConnectionTest] Connection test failed: AxiosError: getaddrinfo ENOTFOUND mock.kore.ai
    at AxiosError.AxiosError.from (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/AxiosError.js:92:14)
    at RedirectableRequest.handleRequestError (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:620:25)
    at RedirectableRequest.emit (node:events:519:35)
    at eventHandlers.<computed> (/Users/kengrafals/workspace/xobcat/node_modules/follow-redirects/index.js:49:24)
    at ClientRequest.emit (node:events:507:28)
    at emitErrorEvent (node:_http_client:104:11)
    at TLSSocket.socketErrorListener (node:_http_client:518:5)
    at TLSSocket.emit (node:events:507:28)
    at emitErrorNT (node:internal/streams/destroy:170:8)
    at emitErrorCloseNT (node:internal/streams/destroy:129:3)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async KoreApiService.getSessionsMetadataForConnectionTest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:503:22)
    at async <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/kore.ts:28:29) {
  hostname: 'mock.kore.ai',
  syscall: 'getaddrinfo',
  code: 'ENOTFOUND',
  errno: -3008,
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU1MDI1ODE1LCJleHAiOjE3NTUwMjk0MTUsImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.HYDDxAiojQfbKBU2L8610kjCA35egx0AxCWhEZfoCO0',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '94',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://mock.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
    data: '{"dateFrom":"2025-08-12T19:09:15.153Z","dateTo":"2025-08-12T19:10:15.153Z","skip":0,"limit":1}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> Writable {
    _events: {
      close: undefined,
      error: [Function: handleRequestError],
      prefinish: undefined,
      finish: undefined,
      drain: undefined,
      response: [Function: handleResponse],
      socket: [Array],
      timeout: undefined,
      abort: undefined
    },
    _writableState: WritableState {
      highWaterMark: 65536,
      length: 0,
      corked: 0,
      onwrite: [Function: bound onwrite],
      writelen: 0,
      bufferedIndex: 0,
      pendingcb: 0,
      Symbol(kState): 17580812,
      Symbol(kBufferedValue): null
    },
    _maxListeners: undefined,
    _options: {
      maxRedirects: 21,
      maxBodyLength: Infinity,
      protocol: 'https:',
      path: '/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      method: 'POST',
      headers: [Object: null prototype],
      agents: [Object],
      auth: undefined,
      family: undefined,
      beforeRedirect: [Function: dispatchBeforeRedirect],
      beforeRedirects: [Object],
      hostname: 'mock.kore.ai',
      port: '',
      agent: undefined,
      nativeProtocols: [Object],
      pathname: '/api/public/bot/mock-bot-id/getSessions',
      search: '?containmentType=agent'
    },
    _ended: false,
    _ending: true,
    _redirectCount: 0,
    _redirects: [],
    _requestBodyLength: 94,
    _requestBodyBuffers: [ [Object] ],
    _eventsCount: 3,
    _onNativeResponse: [Function (anonymous)],
    _currentRequest: ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: false,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 94,
      _hasBody: true,
      _trailer: '',
      finished: false,
      _headerSent: true,
      _closed: false,
      _header: 'POST /api/public/bot/mock-bot-id/getSessions?containmentType=agent HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU1MDI1ODE1LCJleHAiOjE3NTUwMjk0MTUsImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.HYDDxAiojQfbKBU2L8610kjCA35egx0AxCWhEZfoCO0\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 94\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: mock.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      _ended: false,
      res: null,
      aborted: false,
      timeoutCb: [Function: emitRequestTimeout],
      upgradeOrConnect: false,
      parser: null,
      maxHeadersCount: null,
      reusedSocket: false,
      host: 'mock.kore.ai',
      protocol: 'https:',
      _redirectable: [Circular *1],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    _currentUrl: 'https://mock.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
    _timeout: null,
    Symbol(shapeMode): true,
    Symbol(kCapture): false
  },
  cause: Error: getaddrinfo ENOTFOUND mock.kore.ai
      at GetAddrInfoReqWrap.onlookupall [as oncomplete] (node:dns:122:26) {
    errno: -3008,
    code: 'ENOTFOUND',
    syscall: 'getaddrinfo',
    hostname: 'mock.kore.ai'
  }
}
Kore.ai API connection test failed: AxiosError: getaddrinfo ENOTFOUND mock.kore.ai
    at AxiosError.AxiosError.from (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/AxiosError.js:92:14)
    at RedirectableRequest.handleRequestError (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:620:25)
    at RedirectableRequest.emit (node:events:519:35)
    at eventHandlers.<computed> (/Users/kengrafals/workspace/xobcat/node_modules/follow-redirects/index.js:49:24)
    at ClientRequest.emit (node:events:507:28)
    at emitErrorEvent (node:_http_client:104:11)
    at TLSSocket.socketErrorListener (node:_http_client:518:5)
    at TLSSocket.emit (node:events:507:28)
    at emitErrorNT (node:internal/streams/destroy:170:8)
    at emitErrorCloseNT (node:internal/streams/destroy:129:3)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async KoreApiService.getSessionsMetadataForConnectionTest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:503:22)
    at async <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/kore.ts:28:29) {
  hostname: 'mock.kore.ai',
  syscall: 'getaddrinfo',
  code: 'ENOTFOUND',
  errno: -3008,
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU1MDI1ODE1LCJleHAiOjE3NTUwMjk0MTUsImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.HYDDxAiojQfbKBU2L8610kjCA35egx0AxCWhEZfoCO0',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '94',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://mock.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
    data: '{"dateFrom":"2025-08-12T19:09:15.153Z","dateTo":"2025-08-12T19:10:15.153Z","skip":0,"limit":1}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> Writable {
    _events: {
      close: undefined,
      error: [Function: handleRequestError],
      prefinish: undefined,
      finish: undefined,
      drain: undefined,
      response: [Function: handleResponse],
      socket: [Array],
      timeout: undefined,
      abort: undefined
    },
    _writableState: WritableState {
      highWaterMark: 65536,
      length: 0,
      corked: 0,
      onwrite: [Function: bound onwrite],
      writelen: 0,
      bufferedIndex: 0,
      pendingcb: 0,
      Symbol(kState): 17580812,
      Symbol(kBufferedValue): null
    },
    _maxListeners: undefined,
    _options: {
      maxRedirects: 21,
      maxBodyLength: Infinity,
      protocol: 'https:',
      path: '/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      method: 'POST',
      headers: [Object: null prototype],
      agents: [Object],
      auth: undefined,
      family: undefined,
      beforeRedirect: [Function: dispatchBeforeRedirect],
      beforeRedirects: [Object],
      hostname: 'mock.kore.ai',
      port: '',
      agent: undefined,
      nativeProtocols: [Object],
      pathname: '/api/public/bot/mock-bot-id/getSessions',
      search: '?containmentType=agent'
    },
    _ended: false,
    _ending: true,
    _redirectCount: 0,
    _redirects: [],
    _requestBodyLength: 94,
    _requestBodyBuffers: [ [Object] ],
    _eventsCount: 3,
    _onNativeResponse: [Function (anonymous)],
    _currentRequest: ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: false,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 94,
      _hasBody: true,
      _trailer: '',
      finished: false,
      _headerSent: true,
      _closed: false,
      _header: 'POST /api/public/bot/mock-bot-id/getSessions?containmentType=agent HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU1MDI1ODE1LCJleHAiOjE3NTUwMjk0MTUsImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.HYDDxAiojQfbKBU2L8610kjCA35egx0AxCWhEZfoCO0\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 94\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: mock.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      _ended: false,
      res: null,
      aborted: false,
      timeoutCb: [Function: emitRequestTimeout],
      upgradeOrConnect: false,
      parser: null,
      maxHeadersCount: null,
      reusedSocket: false,
      host: 'mock.kore.ai',
      protocol: 'https:',
      _redirectable: [Circular *1],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    _currentUrl: 'https://mock.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
    _timeout: null,
    Symbol(shapeMode): true,
    Symbol(kCapture): false
  },
  cause: Error: getaddrinfo ENOTFOUND mock.kore.ai
      at GetAddrInfoReqWrap.onlookupall [as oncomplete] (node:dns:122:26) {
    errno: -3008,
    code: 'ENOTFOUND',
    syscall: 'getaddrinfo',
    hostname: 'mock.kore.ai'
  }
}
::1 - - [12/Aug/2025:19:10:15 +0000] "GET /api/kore/test HTTP/1.1" 500 245 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:11:16 +0000] "GET /health HTTP/1.1" 200 193 "-" "curl/8.7.1"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T19:10:54.863Z",
  "dateTo": "2025-08-12T19:11:54.863Z",
  "skip": 0,
  "limit": 1
}
::1 - - [12/Aug/2025:19:11:59 +0000] "GET /api/kore/test HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 1 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [ '689b91d49516e359d081492d' ]
[getSessionsMetadataForConnectionTest] Single API call succeeded with 1 sessions
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T19:12:20.037Z",
  "dateTo": "2025-08-12T19:13:20.037Z",
  "skip": 0,
  "limit": 1
}
[fetchContainmentTypeMetadata] API Response: 0 agent sessions received
[getSessionsMetadataForConnectionTest] Single API call succeeded with 0 sessions
::1 - - [12/Aug/2025:19:13:23 +0000] "GET /api/kore/test HTTP/1.1" 200 299 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[Direct API] Fetching real Kore.ai sessions from 2025-08-05T19:13:23.870Z to 2025-08-12T19:13:23.870Z for User Bot st-90549... (limit=50)
Retrieving sessions from 2025-08-05T19:13:23.870Z to 2025-08-12T19:13:23.870Z (limit=50), populateMessages=true...
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T19:13:23.870Z",
  "dateTo": "2025-08-12T19:13:23.870Z",
  "limit": 50
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:13:23.870Z",
  "dateTo": "2025-08-12T19:13:23.870Z",
  "skip": 0,
  "limit": 50
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:13:23.870Z",
  "dateTo": "2025-08-12T19:13:23.870Z",
  "skip": 0,
  "limit": 50
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:13:23.870Z",
  "dateTo": "2025-08-12T19:13:23.870Z",
  "skip": 0,
  "limit": 50
}
::1 - - [12/Aug/2025:19:13:24 +0000] "GET /api/analysis/sessions?limit=50 HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸš€ [ParallelAutoAnalyzeRoute] Starting parallel analysis for bot ***REMOVED*** with real credentials
ğŸš€ [ParallelAutoAnalyzeService] Starting parallel analysis 60dd66b0-501f-4d49-9ed7-89bc0467896d with bot ***REMOVED***
ğŸš€ [ParallelAutoAnalyzeService] Using credentials: real
ğŸš€ [ParallelAutoAnalyzeRoute] Parallel analysis started: 60dd66b0-501f-4d49-9ed7-89bc0467896d
::1 - - [12/Aug/2025:19:13:42 +0000] "POST /api/analysis/auto-analyze/parallel/start HTTP/1.1" 200 214 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:13:42 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 200 541 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:13:42 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[BackgroundJobQueue] Starting job processing after delay for job 60dd66b0-501f-4d49-9ed7-89bc0467896d-parallel
[BackgroundJobQueue] Starting processing for job 60dd66b0-501f-4d49-9ed7-89bc0467896d-parallel, phase: sampling
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing parallel analysis job 60dd66b0-501f-4d49-9ed7-89bc0467896d-parallel
[BackgroundJobQueue] Processing parallel analysis for bot ***REMOVED***
[BackgroundJobQueue] Using existing ParallelAutoAnalyzeService instance for bot ***REMOVED***
[BackgroundJobQueue] Session recreated for 60dd66b0-501f-4d49-9ed7-89bc0467896d
[ParallelAutoAnalyzeService] Running parallel analysis for 60dd66b0-501f-4d49-9ed7-89bc0467896d
[ParallelAutoAnalyzeService] Phase 0: Starting session sampling for 60dd66b0-501f-4d49-9ed7-89bc0467896d

ğŸ• ============ SESSION SAMPLING STARTED ============
ğŸ• [SessionSampling] Starting session sampling at 2025-08-12T19:13:43.460Z
ğŸ” [SessionDiscovery] Starting window 1/4: Initial 3-hour window
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
::1 - - [12/Aug/2025:19:13:44 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 200 717 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:13:46 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:13:48 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:13:50 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:13:52 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[getSessionsMetadata] agent API call failed: AxiosError: timeout of 30000ms exceeded
    at RedirectableRequest.handleRequestTimeout (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:657:16)
    at RedirectableRequest.emit (node:events:507:28)
    at Timeout.<anonymous> (/Users/kengrafals/workspace/xobcat/node_modules/follow-redirects/index.js:221:12)
    at listOnTimeout (node:internal/timers:608:17)
    at process.processTimers (node:internal/timers:543:7)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at runNextTicks (node:internal/process/task_queues:65:5)
    at listOnTimeout (node:internal/timers:569:9)
    at process.processTimers (node:internal/timers:543:7)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async Promise.allSettled (index 0)
    at async KoreApiService.getSessionsMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:342:23)
    at async SWTService.generateSWTs (/Users/kengrafals/workspace/xobcat/backend/src/services/swtService.ts:214:29)
    at async <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/analysis.ts:92:18) {
  code: 'ECONNABORTED',
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjYwMDMsImV4cCI6MTc1NTAyOTYwMywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ._Yl7S5m5apkkao1r7Gj0GmKiYVEHBZmU0c6ByNbXhts',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '95',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
    data: '{"dateFrom":"2025-08-05T19:13:23.870Z","dateTo":"2025-08-12T19:13:23.870Z","skip":0,"limit":50}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> Writable {
    _events: {
      close: undefined,
      error: [Function: handleRequestError],
      prefinish: undefined,
      finish: undefined,
      drain: undefined,
      response: [Function: handleResponse],
      socket: [Array],
      timeout: undefined,
      abort: undefined
    },
    _writableState: WritableState {
      highWaterMark: 65536,
      length: 0,
      corked: 0,
      onwrite: [Function: bound onwrite],
      writelen: 0,
      bufferedIndex: 0,
      pendingcb: 0,
      Symbol(kState): 17580812,
      Symbol(kBufferedValue): null
    },
    _maxListeners: undefined,
    _options: {
      maxRedirects: 21,
      maxBodyLength: Infinity,
      protocol: 'https:',
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
      method: 'POST',
      headers: [Object: null prototype],
      agents: [Object],
      auth: undefined,
      family: undefined,
      beforeRedirect: [Function: dispatchBeforeRedirect],
      beforeRedirects: [Object],
      hostname: 'bots.kore.ai',
      port: '',
      agent: undefined,
      nativeProtocols: [Object],
      pathname: '/api/public/bot/***REMOVED***/getSessions',
      search: '?containmentType=agent'
    },
    _ended: true,
    _ending: true,
    _redirectCount: 0,
    _redirects: [],
    _requestBodyLength: 95,
    _requestBodyBuffers: [ [Object] ],
    _eventsCount: 3,
    _onNativeResponse: [Function (anonymous)],
    _currentRequest: ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: false,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 95,
      _hasBody: true,
      _trailer: '',
      finished: true,
      _headerSent: true,
      _closed: false,
      _header: 'POST /api/public/bot/***REMOVED***/getSessions?containmentType=agent HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjYwMDMsImV4cCI6MTc1NTAyOTYwMywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ._Yl7S5m5apkkao1r7Gj0GmKiYVEHBZmU0c6ByNbXhts\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 95\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: bots.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
      _ended: false,
      res: null,
      aborted: false,
      timeoutCb: [Function: emitRequestTimeout],
      upgradeOrConnect: false,
      parser: [HTTPParser],
      maxHeadersCount: null,
      reusedSocket: true,
      host: 'bots.kore.ai',
      protocol: 'https:',
      _redirectable: [Circular *1],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    _currentUrl: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
    _timeout: null,
    Symbol(shapeMode): true,
    Symbol(kCapture): false
  }
}
[getSessionsMetadata] selfService API call failed: AxiosError: timeout of 30000ms exceeded
    at RedirectableRequest.handleRequestTimeout (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:657:16)
    at RedirectableRequest.emit (node:events:507:28)
    at Timeout.<anonymous> (/Users/kengrafals/workspace/xobcat/node_modules/follow-redirects/index.js:221:12)
    at listOnTimeout (node:internal/timers:608:17)
    at process.processTimers (node:internal/timers:543:7)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at runNextTicks (node:internal/process/task_queues:65:5)
    at listOnTimeout (node:internal/timers:569:9)
    at process.processTimers (node:internal/timers:543:7)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async Promise.allSettled (index 1)
    at async KoreApiService.getSessionsMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:342:23)
    at async SWTService.generateSWTs (/Users/kengrafals/workspace/xobcat/backend/src/services/swtService.ts:214:29)
    at async <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/analysis.ts:92:18) {
  code: 'ECONNABORTED',
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjYwMDMsImV4cCI6MTc1NTAyOTYwMywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ._Yl7S5m5apkkao1r7Gj0GmKiYVEHBZmU0c6ByNbXhts',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '95',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService',
    data: '{"dateFrom":"2025-08-05T19:13:23.870Z","dateTo":"2025-08-12T19:13:23.870Z","skip":0,"limit":50}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> Writable {
    _events: {
      close: undefined,
      error: [Function: handleRequestError],
      prefinish: undefined,
      finish: undefined,
      drain: undefined,
      response: [Function: handleResponse],
      socket: [Array],
      timeout: undefined,
      abort: undefined
    },
    _writableState: WritableState {
      highWaterMark: 65536,
      length: 0,
      corked: 0,
      onwrite: [Function: bound onwrite],
      writelen: 0,
      bufferedIndex: 0,
      pendingcb: 0,
      Symbol(kState): 17580812,
      Symbol(kBufferedValue): null
    },
    _maxListeners: undefined,
    _options: {
      maxRedirects: 21,
      maxBodyLength: Infinity,
      protocol: 'https:',
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=selfService',
      method: 'POST',
      headers: [Object: null prototype],
      agents: [Object],
      auth: undefined,
      family: undefined,
      beforeRedirect: [Function: dispatchBeforeRedirect],
      beforeRedirects: [Object],
      hostname: 'bots.kore.ai',
      port: '',
      agent: undefined,
      nativeProtocols: [Object],
      pathname: '/api/public/bot/***REMOVED***/getSessions',
      search: '?containmentType=selfService'
    },
    _ended: true,
    _ending: true,
    _redirectCount: 0,
    _redirects: [],
    _requestBodyLength: 95,
    _requestBodyBuffers: [ [Object] ],
    _eventsCount: 3,
    _onNativeResponse: [Function (anonymous)],
    _currentRequest: ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: false,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 95,
      _hasBody: true,
      _trailer: '',
      finished: true,
      _headerSent: true,
      _closed: false,
      _header: 'POST /api/public/bot/***REMOVED***/getSessions?containmentType=selfService HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjYwMDMsImV4cCI6MTc1NTAyOTYwMywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ._Yl7S5m5apkkao1r7Gj0GmKiYVEHBZmU0c6ByNbXhts\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 95\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: bots.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=selfService',
      _ended: false,
      res: null,
      aborted: false,
      timeoutCb: [Function: emitRequestTimeout],
      upgradeOrConnect: false,
      parser: [HTTPParser],
      maxHeadersCount: null,
      reusedSocket: false,
      host: 'bots.kore.ai',
      protocol: 'https:',
      _redirectable: [Circular *1],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    _currentUrl: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService',
    _timeout: null,
    Symbol(shapeMode): true,
    Symbol(kCapture): false
  }
}
[getSessionsMetadata] dropOff API call failed: AxiosError: timeout of 30000ms exceeded
    at RedirectableRequest.handleRequestTimeout (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:657:16)
    at RedirectableRequest.emit (node:events:507:28)
    at Timeout.<anonymous> (/Users/kengrafals/workspace/xobcat/node_modules/follow-redirects/index.js:221:12)
    at listOnTimeout (node:internal/timers:608:17)
    at process.processTimers (node:internal/timers:543:7)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at runNextTicks (node:internal/process/task_queues:65:5)
    at listOnTimeout (node:internal/timers:569:9)
    at process.processTimers (node:internal/timers:543:7)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async Promise.allSettled (index 2)
    at async KoreApiService.getSessionsMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:342:23)
    at async SWTService.generateSWTs (/Users/kengrafals/workspace/xobcat/backend/src/services/swtService.ts:214:29)
    at async <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/analysis.ts:92:18) {
  code: 'ECONNABORTED',
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjYwMDMsImV4cCI6MTc1NTAyOTYwMywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ._Yl7S5m5apkkao1r7Gj0GmKiYVEHBZmU0c6ByNbXhts',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '95',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff',
    data: '{"dateFrom":"2025-08-05T19:13:23.870Z","dateTo":"2025-08-12T19:13:23.870Z","skip":0,"limit":50}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> Writable {
    _events: {
      close: undefined,
      error: [Function: handleRequestError],
      prefinish: undefined,
      finish: undefined,
      drain: undefined,
      response: [Function: handleResponse],
      socket: [Array],
      timeout: undefined,
      abort: undefined
    },
    _writableState: WritableState {
      highWaterMark: 65536,
      length: 0,
      corked: 0,
      onwrite: [Function: bound onwrite],
      writelen: 0,
      bufferedIndex: 0,
      pendingcb: 0,
      Symbol(kState): 17580812,
      Symbol(kBufferedValue): null
    },
    _maxListeners: undefined,
    _options: {
      maxRedirects: 21,
      maxBodyLength: Infinity,
      protocol: 'https:',
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff',
      method: 'POST',
      headers: [Object: null prototype],
      agents: [Object],
      auth: undefined,
      family: undefined,
      beforeRedirect: [Function: dispatchBeforeRedirect],
      beforeRedirects: [Object],
      hostname: 'bots.kore.ai',
      port: '',
      agent: undefined,
      nativeProtocols: [Object],
      pathname: '/api/public/bot/***REMOVED***/getSessions',
      search: '?containmentType=dropOff'
    },
    _ended: true,
    _ending: true,
    _redirectCount: 0,
    _redirects: [],
    _requestBodyLength: 95,
    _requestBodyBuffers: [ [Object] ],
    _eventsCount: 3,
    _onNativeResponse: [Function (anonymous)],
    _currentRequest: ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: false,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 95,
      _hasBody: true,
      _trailer: '',
      finished: true,
      _headerSent: true,
      _closed: false,
      _header: 'POST /api/public/bot/***REMOVED***/getSessions?containmentType=dropOff HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjYwMDMsImV4cCI6MTc1NTAyOTYwMywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ._Yl7S5m5apkkao1r7Gj0GmKiYVEHBZmU0c6ByNbXhts\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 95\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: bots.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff',
      _ended: false,
      res: null,
      aborted: false,
      timeoutCb: [Function: emitRequestTimeout],
      upgradeOrConnect: false,
      parser: [HTTPParser],
      maxHeadersCount: null,
      reusedSocket: false,
      host: 'bots.kore.ai',
      protocol: 'https:',
      _redirectable: [Circular *1],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    _currentUrl: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff',
    _timeout: null,
    Symbol(shapeMode): true,
    Symbol(kCapture): false
  }
}
Total session metadata retrieved: 0 (parallel execution)
Retrieved 0 session metadata objects
No sessions found in the specified date range
::1 - - [12/Aug/2025:19:13:54 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:13:56 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:13:58 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:14:00 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:14:02 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:14:04 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:14:06 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:14:08 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:14:10 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:14:12 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[getSessionsMetadata] agent API call failed: AxiosError: timeout of 30000ms exceeded
    at RedirectableRequest.handleRequestTimeout (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:657:16)
    at RedirectableRequest.emit (node:events:507:28)
    at Timeout.<anonymous> (/Users/kengrafals/workspace/xobcat/node_modules/follow-redirects/index.js:221:12)
    at listOnTimeout (node:internal/timers:608:17)
    at process.processTimers (node:internal/timers:543:7)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at runNextTicks (node:internal/process/task_queues:65:5)
    at listOnTimeout (node:internal/timers:569:9)
    at process.processTimers (node:internal/timers:543:7)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async Promise.allSettled (index 0)
    at async KoreApiService.getSessionsMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:342:23)
    at async SessionSamplingService.getSessionsInTimeWindow (/Users/kengrafals/workspace/xobcat/backend/src/services/sessionSamplingService.ts:233:31)
    at async SessionSamplingService.sampleSessions (/Users/kengrafals/workspace/xobcat/backend/src/services/sessionSamplingService.ts:64:34) {
  code: 'ECONNABORTED',
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjYwMjMsImV4cCI6MTc1NTAyOTYyMywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.y-oMROe2YA6S4g6L-JvpHkAE0OnoS4_ZDLZouYkj0iQ',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '98',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
    data: '{"dateFrom":"2025-08-05T13:00:00.000Z","dateTo":"2025-08-05T16:00:00.000Z","skip":0,"limit":10000}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> Writable {
    _events: {
      close: undefined,
      error: [Function: handleRequestError],
      prefinish: undefined,
      finish: undefined,
      drain: undefined,
      response: [Function: handleResponse],
      socket: [Array],
      timeout: undefined,
      abort: undefined
    },
    _writableState: WritableState {
      highWaterMark: 65536,
      length: 0,
      corked: 0,
      onwrite: [Function: bound onwrite],
      writelen: 0,
      bufferedIndex: 0,
      pendingcb: 0,
      Symbol(kState): 17580812,
      Symbol(kBufferedValue): null
    },
    _maxListeners: undefined,
    _options: {
      maxRedirects: 21,
      maxBodyLength: Infinity,
      protocol: 'https:',
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
      method: 'POST',
      headers: [Object: null prototype],
      agents: [Object],
      auth: undefined,
      family: undefined,
      beforeRedirect: [Function: dispatchBeforeRedirect],
      beforeRedirects: [Object],
      hostname: 'bots.kore.ai',
      port: '',
      agent: undefined,
      nativeProtocols: [Object],
      pathname: '/api/public/bot/***REMOVED***/getSessions',
      search: '?containmentType=agent'
    },
    _ended: true,
    _ending: true,
    _redirectCount: 0,
    _redirects: [],
    _requestBodyLength: 98,
    _requestBodyBuffers: [ [Object] ],
    _eventsCount: 3,
    _onNativeResponse: [Function (anonymous)],
    _currentRequest: ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: false,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 98,
      _hasBody: true,
      _trailer: '',
      finished: true,
      _headerSent: true,
      _closed: false,
      _header: 'POST /api/public/bot/***REMOVED***/getSessions?containmentType=agent HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjYwMjMsImV4cCI6MTc1NTAyOTYyMywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.y-oMROe2YA6S4g6L-JvpHkAE0OnoS4_ZDLZouYkj0iQ\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 98\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: bots.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
      _ended: false,
      res: null,
      aborted: false,
      timeoutCb: [Function: emitRequestTimeout],
      upgradeOrConnect: false,
      parser: [HTTPParser],
      maxHeadersCount: null,
      reusedSocket: false,
      host: 'bots.kore.ai',
      protocol: 'https:',
      _redirectable: [Circular *1],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    _currentUrl: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
    _timeout: null,
    Symbol(shapeMode): true,
    Symbol(kCapture): false
  }
}
[getSessionsMetadata] selfService API call failed: AxiosError: timeout of 30000ms exceeded
    at RedirectableRequest.handleRequestTimeout (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:657:16)
    at RedirectableRequest.emit (node:events:507:28)
    at Timeout.<anonymous> (/Users/kengrafals/workspace/xobcat/node_modules/follow-redirects/index.js:221:12)
    at listOnTimeout (node:internal/timers:608:17)
    at process.processTimers (node:internal/timers:543:7)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at runNextTicks (node:internal/process/task_queues:65:5)
    at listOnTimeout (node:internal/timers:569:9)
    at process.processTimers (node:internal/timers:543:7)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async Promise.allSettled (index 1)
    at async KoreApiService.getSessionsMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:342:23)
    at async SessionSamplingService.getSessionsInTimeWindow (/Users/kengrafals/workspace/xobcat/backend/src/services/sessionSamplingService.ts:233:31)
    at async SessionSamplingService.sampleSessions (/Users/kengrafals/workspace/xobcat/backend/src/services/sessionSamplingService.ts:64:34) {
  code: 'ECONNABORTED',
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjYwMjMsImV4cCI6MTc1NTAyOTYyMywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.y-oMROe2YA6S4g6L-JvpHkAE0OnoS4_ZDLZouYkj0iQ',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '98',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService',
    data: '{"dateFrom":"2025-08-05T13:00:00.000Z","dateTo":"2025-08-05T16:00:00.000Z","skip":0,"limit":10000}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> Writable {
    _events: {
      close: undefined,
      error: [Function: handleRequestError],
      prefinish: undefined,
      finish: undefined,
      drain: undefined,
      response: [Function: handleResponse],
      socket: [Array],
      timeout: undefined,
      abort: undefined
    },
    _writableState: WritableState {
      highWaterMark: 65536,
      length: 0,
      corked: 0,
      onwrite: [Function: bound onwrite],
      writelen: 0,
      bufferedIndex: 0,
      pendingcb: 0,
      Symbol(kState): 17580812,
      Symbol(kBufferedValue): null
    },
    _maxListeners: undefined,
    _options: {
      maxRedirects: 21,
      maxBodyLength: Infinity,
      protocol: 'https:',
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=selfService',
      method: 'POST',
      headers: [Object: null prototype],
      agents: [Object],
      auth: undefined,
      family: undefined,
      beforeRedirect: [Function: dispatchBeforeRedirect],
      beforeRedirects: [Object],
      hostname: 'bots.kore.ai',
      port: '',
      agent: undefined,
      nativeProtocols: [Object],
      pathname: '/api/public/bot/***REMOVED***/getSessions',
      search: '?containmentType=selfService'
    },
    _ended: true,
    _ending: true,
    _redirectCount: 0,
    _redirects: [],
    _requestBodyLength: 98,
    _requestBodyBuffers: [ [Object] ],
    _eventsCount: 3,
    _onNativeResponse: [Function (anonymous)],
    _currentRequest: ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: false,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 98,
      _hasBody: true,
      _trailer: '',
      finished: true,
      _headerSent: true,
      _closed: false,
      _header: 'POST /api/public/bot/***REMOVED***/getSessions?containmentType=selfService HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjYwMjMsImV4cCI6MTc1NTAyOTYyMywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.y-oMROe2YA6S4g6L-JvpHkAE0OnoS4_ZDLZouYkj0iQ\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 98\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: bots.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=selfService',
      _ended: false,
      res: null,
      aborted: false,
      timeoutCb: [Function: emitRequestTimeout],
      upgradeOrConnect: false,
      parser: [HTTPParser],
      maxHeadersCount: null,
      reusedSocket: false,
      host: 'bots.kore.ai',
      protocol: 'https:',
      _redirectable: [Circular *1],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    _currentUrl: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService',
    _timeout: null,
    Symbol(shapeMode): true,
    Symbol(kCapture): false
  }
}
[getSessionsMetadata] dropOff API call failed: AxiosError: timeout of 30000ms exceeded
    at RedirectableRequest.handleRequestTimeout (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:657:16)
    at RedirectableRequest.emit (node:events:507:28)
    at Timeout.<anonymous> (/Users/kengrafals/workspace/xobcat/node_modules/follow-redirects/index.js:221:12)
    at listOnTimeout (node:internal/timers:608:17)
    at process.processTimers (node:internal/timers:543:7)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async Promise.allSettled (index 2)
    at async KoreApiService.getSessionsMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:342:23)
    at async SessionSamplingService.getSessionsInTimeWindow (/Users/kengrafals/workspace/xobcat/backend/src/services/sessionSamplingService.ts:233:31)
    at async SessionSamplingService.sampleSessions (/Users/kengrafals/workspace/xobcat/backend/src/services/sessionSamplingService.ts:64:34)
    at async ParallelAutoAnalyzeService.runSamplingPhase (/Users/kengrafals/workspace/xobcat/backend/src/services/parallelAutoAnalyzeService.ts:314:30)
    at async ParallelAutoAnalyzeService.runParallelAnalysis (/Users/kengrafals/workspace/xobcat/backend/src/services/parallelAutoAnalyzeService.ts:261:30)
    at async BackgroundJobQueue.processParallelAnalysis (/Users/kengrafals/workspace/xobcat/backend/src/services/backgroundJobQueue.ts:469:7) {
  code: 'ECONNABORTED',
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjYwMjMsImV4cCI6MTc1NTAyOTYyMywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.y-oMROe2YA6S4g6L-JvpHkAE0OnoS4_ZDLZouYkj0iQ',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '98',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff',
    data: '{"dateFrom":"2025-08-05T13:00:00.000Z","dateTo":"2025-08-05T16:00:00.000Z","skip":0,"limit":10000}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> Writable {
    _events: {
      close: undefined,
      error: [Function: handleRequestError],
      prefinish: undefined,
      finish: undefined,
      drain: undefined,
      response: [Function: handleResponse],
      socket: [Array],
      timeout: undefined,
      abort: undefined
    },
    _writableState: WritableState {
      highWaterMark: 65536,
      length: 0,
      corked: 0,
      onwrite: [Function: bound onwrite],
      writelen: 0,
      bufferedIndex: 0,
      pendingcb: 0,
      Symbol(kState): 17580812,
      Symbol(kBufferedValue): null
    },
    _maxListeners: undefined,
    _options: {
      maxRedirects: 21,
      maxBodyLength: Infinity,
      protocol: 'https:',
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff',
      method: 'POST',
      headers: [Object: null prototype],
      agents: [Object],
      auth: undefined,
      family: undefined,
      beforeRedirect: [Function: dispatchBeforeRedirect],
      beforeRedirects: [Object],
      hostname: 'bots.kore.ai',
      port: '',
      agent: undefined,
      nativeProtocols: [Object],
      pathname: '/api/public/bot/***REMOVED***/getSessions',
      search: '?containmentType=dropOff'
    },
    _ended: true,
    _ending: true,
    _redirectCount: 0,
    _redirects: [],
    _requestBodyLength: 98,
    _requestBodyBuffers: [ [Object] ],
    _eventsCount: 3,
    _onNativeResponse: [Function (anonymous)],
    _currentRequest: ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: false,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 98,
      _hasBody: true,
      _trailer: '',
      finished: true,
      _headerSent: true,
      _closed: false,
      _header: 'POST /api/public/bot/***REMOVED***/getSessions?containmentType=dropOff HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjYwMjMsImV4cCI6MTc1NTAyOTYyMywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.y-oMROe2YA6S4g6L-JvpHkAE0OnoS4_ZDLZouYkj0iQ\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 98\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: bots.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff',
      _ended: false,
      res: null,
      aborted: false,
      timeoutCb: [Function: emitRequestTimeout],
      upgradeOrConnect: false,
      parser: [HTTPParser],
      maxHeadersCount: null,
      reusedSocket: false,
      host: 'bots.kore.ai',
      protocol: 'https:',
      _redirectable: [Circular *1],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    _currentUrl: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff',
    _timeout: null,
    Symbol(shapeMode): true,
    Symbol(kCapture): false
  }
}
Total session metadata retrieved: 0 (parallel execution)
Creating 0 SWTs from metadata (no messages)
Created 0 SWT objects from metadata
âœ… [SessionDiscovery] Window 1 completed in 30014ms: found 0 new sessions (total: 0)
â±ï¸  TIMING: Window 1 took 30014ms (30.01s)
ğŸ” [SessionDiscovery] Starting window 2/4: Extended to 6 hours
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T19:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T19:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T19:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T19:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
::1 - - [12/Aug/2025:19:14:14 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 200 713 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:14:16 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:14:18 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:14:20 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:14:22 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:14:24 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:14:26 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:14:28 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:14:30 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:14:32 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:14:34 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:14:36 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:14:38 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:14:40 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:14:42 +0000] "GET /api/analysis/auto-analyze/parallel/progress/60dd66b0-501f-4d49-9ed7-89bc0467896d HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[getSessionsMetadata] agent API call failed: AxiosError: timeout of 30000ms exceeded
    at RedirectableRequest.handleRequestTimeout (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:657:16)
    at RedirectableRequest.emit (node:events:507:28)
    at Timeout.<anonymous> (/Users/kengrafals/workspace/xobcat/node_modules/follow-redirects/index.js:221:12)
    at listOnTimeout (node:internal/timers:608:17)
    at process.processTimers (node:internal/timers:543:7)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at runNextTicks (node:internal/process/task_queues:65:5)
    at listOnTimeout (node:internal/timers:569:9)
    at process.processTimers (node:internal/timers:543:7)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async Promise.allSettled (index 0)
    at async KoreApiService.getSessionsMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:342:23)
    at async SessionSamplingService.getSessionsInTimeWindow (/Users/kengrafals/workspace/xobcat/backend/src/services/sessionSamplingService.ts:233:31)
    at async SessionSamplingService.sampleSessions (/Users/kengrafals/workspace/xobcat/backend/src/services/sessionSamplingService.ts:64:34) {
  code: 'ECONNABORTED',
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjYwNTMsImV4cCI6MTc1NTAyOTY1MywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.Dbw1W9COeklSSgZa-_XVYqJgG7cwSalyMO35qOtKUZQ',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '98',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
    data: '{"dateFrom":"2025-08-05T13:00:00.000Z","dateTo":"2025-08-05T19:00:00.000Z","skip":0,"limit":10000}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> Writable {
    _events: {
      close: undefined,
      error: [Function: handleRequestError],
      prefinish: undefined,
      finish: undefined,
      drain: undefined,
      response: [Function: handleResponse],
      socket: [Array],
      timeout: undefined,
      abort: undefined
    },
    _writableState: WritableState {
      highWaterMark: 65536,
      length: 0,
      corked: 0,
      onwrite: [Function: bound onwrite],
      writelen: 0,
      bufferedIndex: 0,
      pendingcb: 0,
      Symbol(kState): 17580812,
      Symbol(kBufferedValue): null
    },
    _maxListeners: undefined,
    _options: {
      maxRedirects: 21,
      maxBodyLength: Infinity,
      protocol: 'https:',
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
      method: 'POST',
      headers: [Object: null prototype],
      agents: [Object],
      auth: undefined,
      family: undefined,
      beforeRedirect: [Function: dispatchBeforeRedirect],
      beforeRedirects: [Object],
      hostname: 'bots.kore.ai',
      port: '',
      agent: undefined,
      nativeProtocols: [Object],
      pathname: '/api/public/bot/***REMOVED***/getSessions',
      search: '?containmentType=agent'
    },
    _ended: true,
    _ending: true,
    _redirectCount: 0,
    _redirects: [],
    _requestBodyLength: 98,
    _requestBodyBuffers: [ [Object] ],
    _eventsCount: 3,
    _onNativeResponse: [Function (anonymous)],
    _currentRequest: ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: false,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 98,
      _hasBody: true,
      _trailer: '',
      finished: true,
      _headerSent: true,
      _closed: false,
      _header: 'POST /api/public/bot/***REMOVED***/getSessions?containmentType=agent HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjYwNTMsImV4cCI6MTc1NTAyOTY1MywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.Dbw1W9COeklSSgZa-_XVYqJgG7cwSalyMO35qOtKUZQ\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 98\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: bots.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
      _ended: false,
      res: null,
      aborted: false,
      timeoutCb: [Function: emitRequestTimeout],
      upgradeOrConnect: false,
      parser: [HTTPParser],
      maxHeadersCount: null,
      reusedSocket: false,
      host: 'bots.kore.ai',
      protocol: 'https:',
      _redirectable: [Circular *1],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    _currentUrl: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
    _timeout: null,
    Symbol(shapeMode): true,
    Symbol(kCapture): false
  }
}
[getSessionsMetadata] selfService API call failed: AxiosError: timeout of 30000ms exceeded
    at RedirectableRequest.handleRequestTimeout (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:657:16)
    at RedirectableRequest.emit (node:events:507:28)
    at Timeout.<anonymous> (/Users/kengrafals/workspace/xobcat/node_modules/follow-redirects/index.js:221:12)
    at listOnTimeout (node:internal/timers:608:17)
    at process.processTimers (node:internal/timers:543:7)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at runNextTicks (node:internal/process/task_queues:65:5)
    at listOnTimeout (node:internal/timers:569:9)
    at process.processTimers (node:internal/timers:543:7)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async Promise.allSettled (index 1)
    at async KoreApiService.getSessionsMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:342:23)
    at async SessionSamplingService.getSessionsInTimeWindow (/Users/kengrafals/workspace/xobcat/backend/src/services/sessionSamplingService.ts:233:31)
    at async SessionSamplingService.sampleSessions (/Users/kengrafals/workspace/xobcat/backend/src/services/sessionSamplingService.ts:64:34) {
  code: 'ECONNABORTED',
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjYwNTMsImV4cCI6MTc1NTAyOTY1MywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.Dbw1W9COeklSSgZa-_XVYqJgG7cwSalyMO35qOtKUZQ',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '98',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService',
    data: '{"dateFrom":"2025-08-05T13:00:00.000Z","dateTo":"2025-08-05T19:00:00.000Z","skip":0,"limit":10000}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> Writable {
    _events: {
      close: undefined,
      error: [Function: handleRequestError],
      prefinish: undefined,
      finish: undefined,
      drain: undefined,
      response: [Function: handleResponse],
      socket: [Array],
      timeout: undefined,
      abort: undefined
    },
    _writableState: WritableState {
      highWaterMark: 65536,
      length: 0,
      corked: 0,
      onwrite: [Function: bound onwrite],
      writelen: 0,
      bufferedIndex: 0,
      pendingcb: 0,
      Symbol(kState): 17580812,
      Symbol(kBufferedValue): null
    },
    _maxListeners: undefined,
    _options: {
      maxRedirects: 21,
      maxBodyLength: Infinity,
      protocol: 'https:',
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=selfService',
      method: 'POST',
      headers: [Object: null prototype],
      agents: [Object],
      auth: undefined,
      family: undefined,
      beforeRedirect: [Function: dispatchBeforeRedirect],
      beforeRedirects: [Object],
      hostname: 'bots.kore.ai',
      port: '',
      agent: undefined,
      nativeProtocols: [Object],
      pathname: '/api/public/bot/***REMOVED***/getSessions',
      search: '?containmentType=selfService'
    },
    _ended: true,
    _ending: true,
    _redirectCount: 0,
    _redirects: [],
    _requestBodyLength: 98,
    _requestBodyBuffers: [ [Object] ],
    _eventsCount: 3,
    _onNativeResponse: [Function (anonymous)],
    _currentRequest: ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: false,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 98,
      _hasBody: true,
      _trailer: '',
      finished: true,
      _headerSent: true,
      _closed: false,
      _header: 'POST /api/public/bot/***REMOVED***/getSessions?containmentType=selfService HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjYwNTMsImV4cCI6MTc1NTAyOTY1MywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.Dbw1W9COeklSSgZa-_XVYqJgG7cwSalyMO35qOtKUZQ\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 98\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: bots.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=selfService',
      _ended: false,
      res: null,
      aborted: false,
      timeoutCb: [Function: emitRequestTimeout],
      upgradeOrConnect: false,
      parser: [HTTPParser],
      maxHeadersCount: null,
      reusedSocket: false,
      host: 'bots.kore.ai',
      protocol: 'https:',
      _redirectable: [Circular *1],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    _currentUrl: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService',
    _timeout: null,
    Symbol(shapeMode): true,
    Symbol(kCapture): false
  }
}
[getSessionsMetadata] dropOff API call failed: AxiosError: timeout of 30000ms exceeded
    at RedirectableRequest.handleRequestTimeout (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:657:16)
    at RedirectableRequest.emit (node:events:507:28)
    at Timeout.<anonymous> (/Users/kengrafals/workspace/xobcat/node_modules/follow-redirects/index.js:221:12)
    at listOnTimeout (node:internal/timers:608:17)
    at process.processTimers (node:internal/timers:543:7)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async Promise.allSettled (index 2)
    at async KoreApiService.getSessionsMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:342:23)
    at async SessionSamplingService.getSessionsInTimeWindow (/Users/kengrafals/workspace/xobcat/backend/src/services/sessionSamplingService.ts:233:31)
    at async SessionSamplingService.sampleSessions (/Users/kengrafals/workspace/xobcat/backend/src/services/sessionSamplingService.ts:64:34)
    at async ParallelAutoAnalyzeService.runSamplingPhase (/Users/kengrafals/workspace/xobcat/backend/src/services/parallelAutoAnalyzeService.ts:314:30)
    at async ParallelAutoAnalyzeService.runParallelAnalysis (/Users/kengrafals/workspace/xobcat/backend/src/services/parallelAutoAnalyzeService.ts:261:30)
    at async BackgroundJobQueue.processParallelAnalysis (/Users/kengrafals/workspace/xobcat/backend/src/services/backgroundJobQueue.ts:469:7) {
  code: 'ECONNABORTED',
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjYwNTMsImV4cCI6MTc1NTAyOTY1MywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.Dbw1W9COeklSSgZa-_XVYqJgG7cwSalyMO35qOtKUZQ',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '98',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff',
    data: '{"dateFrom":"2025-08-05T13:00:00.000Z","dateTo":"2025-08-05T19:00:00.000Z","skip":0,"limit":10000}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> Writable {
    _events: {
      close: undefined,
      error: [Function: handleRequestError],
      prefinish: undefined,
      finish: undefined,
      drain: undefined,
      response: [Function: handleResponse],
      socket: [Array],
      timeout: undefined,
      abort: undefined
    },
    _writableState: WritableState {
      highWaterMark: 65536,
      length: 0,
      corked: 0,
      onwrite: [Function: bound onwrite],
      writelen: 0,
      bufferedIndex: 0,
      pendingcb: 0,
      Symbol(kState): 17580812,
      Symbol(kBufferedValue): null
    },
    _maxListeners: undefined,
    _options: {
      maxRedirects: 21,
      maxBodyLength: Infinity,
      protocol: 'https:',
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff',
      method: 'POST',
      headers: [Object: null prototype],
      agents: [Object],
      auth: undefined,
      family: undefined,
      beforeRedirect: [Function: dispatchBeforeRedirect],
      beforeRedirects: [Object],
      hostname: 'bots.kore.ai',
      port: '',
      agent: undefined,
      nativeProtocols: [Object],
      pathname: '/api/public/bot/***REMOVED***/getSessions',
      search: '?containmentType=dropOff'
    },
    _ended: true,
    _ending: true,
    _redirectCount: 0,
    _redirects: [],
    _requestBodyLength: 98,
    _requestBodyBuffers: [ [Object] ],
    _eventsCount: 3,
    _onNativeResponse: [Function (anonymous)],
    _currentRequest: ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: false,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 98,
      _hasBody: true,
      _trailer: '',
      finished: true,
      _headerSent: true,
      _closed: false,
      _header: 'POST /api/public/bot/***REMOVED***/getSessions?containmentType=dropOff HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjYwNTMsImV4cCI6MTc1NTAyOTY1MywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.Dbw1W9COeklSSgZa-_XVYqJgG7cwSalyMO35qOtKUZQ\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 98\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: bots.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff',
      _ended: false,
      res: null,
      aborted: false,
      timeoutCb: [Function: emitRequestTimeout],
      upgradeOrConnect: false,
      parser: [HTTPParser],
      maxHeadersCount: null,
      reusedSocket: false,
      host: 'bots.kore.ai',
      protocol: 'https:',
      _redirectable: [Circular *1],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    _currentUrl: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff',
    _timeout: null,
    Symbol(shapeMode): true,
    Symbol(kCapture): false
  }
}
Total session metadata retrieved: 0 (parallel execution)
Creating 0 SWTs from metadata (no messages)
Created 0 SWT objects from metadata
âœ… [SessionDiscovery] Window 2 completed in 30010ms: found 0 new sessions (total: 0)
â±ï¸  TIMING: Window 2 took 30010ms (30.01s)
ğŸ” [SessionDiscovery] Starting window 3/4: Extended to 12 hours
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-06T01:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-06T01:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-06T01:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-06T01:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
[fetchContainmentTypeMetadata] API Response: 282 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '6892a6f4971bb5cf71d00cb1',
  '6892a6ae4f90896c1f949898',
  '6892a5a40d700d1adb6e6992'
]
[fetchContainmentTypeMetadata] API Response: 493 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '6892a8fee196ca76097afca1',
  '6892a7ae1fd8cbc95a105438',
  '6892a744f429031e544d2026'
]
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T19:13:56.920Z",
  "dateTo": "2025-08-12T19:14:56.920Z",
  "skip": 0,
  "limit": 1
}
[fetchContainmentTypeMetadata] API Response: 1 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [ '689b9293b8ac2322b82b371c' ]
[getSessionsMetadataForConnectionTest] Single API call succeeded with 1 sessions
::1 - - [12/Aug/2025:19:15:02 +0000] "GET /api/kore/test HTTP/1.1" 200 851 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[Direct API] Fetching real Kore.ai sessions from 2025-08-05T19:15:03.104Z to 2025-08-12T19:15:03.104Z for User Bot st-90549... (limit=50)
Retrieving sessions from 2025-08-05T19:15:03.104Z to 2025-08-12T19:15:03.104Z (limit=50), populateMessages=true...
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T19:15:03.104Z",
  "dateTo": "2025-08-12T19:15:03.104Z",
  "limit": 50
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:15:03.104Z",
  "dateTo": "2025-08-12T19:15:03.104Z",
  "skip": 0,
  "limit": 50
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:15:03.104Z",
  "dateTo": "2025-08-12T19:15:03.104Z",
  "skip": 0,
  "limit": 50
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:15:03.104Z",
  "dateTo": "2025-08-12T19:15:03.104Z",
  "skip": 0,
  "limit": 50
}
[fetchContainmentTypeMetadata] API Response: 4176 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '6892a8e586de973c12f18280',
  '6892a87c82adb3e298407434',
  '6892a875aaf5c5204e698f89'
]
[getSessionsMetadata] agent API call succeeded with 4176 sessions
[getSessionsMetadata] selfService API call succeeded with 282 sessions
[getSessionsMetadata] dropOff API call succeeded with 493 sessions
Total session metadata retrieved: 4951 (parallel execution)
Creating 4951 SWTs from metadata (no messages)
Created 4951 SWT objects from metadata
âœ… [SessionDiscovery] Window 3 completed in 19752ms: found 4951 new sessions (total: 4951)
â±ï¸  TIMING: Window 3 took 19752ms (19.75s)
ğŸ¯ [SessionDiscovery] Target reached! Found 4951 sessions in 79777ms
ğŸ² [SessionSampling] Random sampling from 4951 sessions to 10 sessions

ğŸ“¬ ============ MESSAGE RETRIEVAL STARTED ============
ğŸ“¬ [MessageRetrieval] Starting message retrieval for 10 sampled sessions at 2025-08-12T19:15:03.240Z
Using new lazy loading approach to populate messages for 10 sampled sessions
Populating messages for 10 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 10 sessions from 2025-08-05T13:46:56.755Z to 2025-08-05T19:36:16.067Z at 2025-08-12T19:15:03.240Z
ğŸ”„ [KoreAPI] Using single API call for 10 sessions (â‰¤20)
âœ… [KoreAPI] Single call completed in 271ms: 150 messages
Retrieved 150 messages for 10 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
Populated messages for 10 SWT objects
Successfully populated messages for 10 sessions using lazy loading
Applying final filtering to 10 sessions with populated messages
Final result: 10 sessions passed filtering with populated messages

ğŸ‰ ============ SESSION SAMPLING COMPLETED ============
â±ï¸  TOTAL TIME: 80052ms (80.05s)
â±ï¸  Session Discovery: 79777ms (79.78s) - 99.7% of total
â±ï¸  Message Retrieval: 272ms (0.27s) - 0.3% of total
â±ï¸  Performance: 0.1 sessions/second
ğŸ¯ Final result: 10 sessions with messages retrieved
====================================================

[StrategicDiscoveryService] Starting discovery phase with 10 total sessions
[StrategicDiscoveryService] Discovery config: {
  targetPercentage: 15,
  minSessions: 5,
  maxSessions: 5,
  diversityStrategy: {
    sessionLengths: [ 'short', 'medium', 'long' ],
    containmentTypes: [ 'agent', 'selfService', 'dropOff' ],
    timeDistribution: 'spread'
  }
}
[StrategicDiscoveryService] Selecting 5 diverse sessions from 10 total
[StrategicDiscoveryService] Session diversity groups: { short: 4, medium: 6, early: 3, middle: 3, late: 4 }
[StrategicDiscoveryService] Selected sessions by length distribution: { short: 2, medium: 3, long: 0 }
[StrategicDiscoveryService] Selected 5 sessions for discovery

ğŸ“¦ ===== BATCH 9 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T19:15:03.513Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 0
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T19:15:03.513Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:15:03.513Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7006,
  existingClassifications: { intents: 0, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.



For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and another intent, classify the intent as the other i...
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:15:06.753Z',
  duration: '3240ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2014,
    completion_tokens: 310,
    total_tokens: 2324,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Claim Status', 'Unknown', 'FMLA' ],
  transferCount: 3,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-bbe5e080-66b9-528b-afab-0f75bdbe8119",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-d95e05dc-a07b-540a-a983-223b43833c85",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-f2fc7c7c-781f-5775-8f5d-2bca7af049cc",
      "general_intent": "FMLA",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User inquired about renewing and expiring FMLA, and the session was handled by the bot."
    },
    {
      "user_id": "u-bbe5e080-66b9-528b-afab-0f75bdbe8119",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-8e28888e-fed9-557f-b326-a486f5a56e35",
      "general_intent": "FMLA",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User extended FMLA and changed return to work date, handled by the bot."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2014,
  completionTokens: 310,
  totalTokens: 2324,
  cost: '$0.000325',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 3241ms (3.24s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2324 ($0.0003)
âš¡ Performance: 717.1 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 4
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 3241ms (3.24s)
ğŸ“Š Regular Sessions Processed: 4
ğŸ’° Regular Tokens Used: 2324

âœ… ===== BATCH 9 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 3241ms (3.24s)
ğŸ“Š Sessions Processed: 4/5
ğŸ’° Total Tokens: 2324 ($0.0003)
âš¡ Performance: 1.2 sessions/sec
âš¡ Avg Time Per Session: 810.25ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 1 complete: 5 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 3, reasons: 1, locations: 1, total: 5 }
[StrategicDiscoveryService] Discovery phase complete: {
  totalProcessed: 4,
  uniqueIntents: 3,
  uniqueReasons: 1,
  uniqueLocations: 1,
  discoveryRate: 0.3333333333333333
}

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T19:15:06.755Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms
[ParallelProcessingOrchestrator] Configuration for 6 sessions:
  Design: 8 streams Ã— 4 sessions = 32 per round
  Optimal: 2 streams Ã— 3 sessions = 6 per round
  Estimated Rounds: 1
[ParallelAutoAnalyzeService] Using parallel config: {
  streamCount: 2,
  sessionsPerStream: 3,
  maxSessionsPerLLMCall: 50,
  syncFrequency: 'after_each_round',
  retryAttempts: 3,
  debugLogging: false
}

ğŸš€ ============ PARALLEL PROCESSING STARTED ============
â±ï¸  Start Time: 2025-08-12T19:15:06.758Z
ğŸ“Š Total Sessions: 6

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T19:15:06.758Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms

âš™ï¸  ============ PARALLEL CONFIGURATION ============
â±ï¸  Config Time: 0ms
ğŸ”§ Stream Count: 2
ğŸ“¦ Sessions Per Stream: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per API Call: 50
ğŸ¯ Debug Logging: false

ğŸ”„ ============ ROUND 1/1 STARTED ============
â±ï¸  Round 1 Start: 2025-08-12T19:15:06.758Z
ğŸ“Š Sessions Remaining: 6
[ParallelProcessingOrchestrator] Distributed 6 sessions across 2 streams: [ 'Stream 1: 3 sessions', 'Stream 2: 3 sessions' ]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 2

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 2 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T19:15:06.758Z
ğŸ“Š Sessions Assigned: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:15:06.758Z
ğŸ“Š Sessions to Estimate: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 3
   â€¢ Session Tokens: 815
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6315
   â€¢ Avg Per Session: 272 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6315
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 3

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6315
ğŸ“¦ Recommended Batch Size: 3
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:15:06.758Z
ğŸ“Š Sessions to Analyze: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:15:06.758Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 3,
  apiKey: 'sk-proj-...',
  promptLength: 6711,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, FMLA, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T19:15:06.758Z
ğŸ“Š Sessions Assigned: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:15:06.758Z
ğŸ“Š Sessions to Estimate: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 3
   â€¢ Session Tokens: 392
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 5892
   â€¢ Avg Per Session: 131 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 5892
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0009
ğŸ“Š Recommended Batch Size: 3

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 5892
ğŸ“¦ Recommended Batch Size: 3
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0009

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:15:06.758Z
ğŸ“Š Sessions to Analyze: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:15:06.758Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 3,
  apiKey: 'sk-proj-...',
  promptLength: 4730,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, FMLA, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "...
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:15:08.643Z',
  duration: '1885ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1413,
    completion_tokens: 217,
    total_tokens: 1630,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 3,
  intentsFound: [ 'Unknown', 'Claim Status' ],
  transferCount: 2,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-ec9d1fcf-2ffb-5712-add4-1492a1a67f6f",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User inquired about leave, bot prompted for leave request number but did not transfer."
    },
    {
      "user_id": "u-b6c8cf4b-0c23-5849-964d-5b5a8337f1e3",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to file a claim, session transferred to an agent."
    },
    {
      "user_id": "u-c1676cdb-3c2c-5ac8-84f8-1ecd8ff4c7ae",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested representative, session transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1413,
  completionTokens: 217,
  totalTokens: 1630,
  cost: '$0.000228',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1885ms (1.89s)
ğŸ“Š Sessions Returned: 3
ğŸ’° Tokens Used: 1630 ($0.0002)
âš¡ Performance: 864.7 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1413
   â€¢ Completion Tokens: 217
[SessionValidationService] Validating batch response: 3 input sessions, 3 response sessions
[SessionValidationService] Validation successful: all 3 sessions processed
[SessionValidationService] Validating batch response: 3 input sessions, 3 response sessions
[SessionValidationService] Validation successful: all 3 sessions processed
â±ï¸  Stream 2 Single Batch Time: 1886ms (1.89s)

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 1886ms (1.89s)
ğŸ“Š Sessions Processed: 3/3
ğŸ’° Tokens Used: 1630 ($0.0002)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.6 sessions/sec
âš¡ Avg Time Per Session: 628.67ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:15:08.676Z',
  duration: '1918ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1904,
    completion_tokens: 222,
    total_tokens: 2126,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 3,
  intentsFound: [ 'Claim Status' ],
  transferCount: 3,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-aeb8d386-64f2-56d8-ab42-c6a78d5be396",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to report time entry but was transferred to an agent when requesting help."
    },
    {
      "user_id": "u-269aa48d-26eb-5322-bb9f-d686239258df",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User inquired about claim denial and was transferred to an agent."
    },
    {
      "user_id": "u-b6ca12a4-bd1b-5be0-b823-3c132427cfcc",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked to report return to work and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1904,
  completionTokens: 222,
  totalTokens: 2126,
  cost: '$0.000279',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1919ms (1.92s)
ğŸ“Š Sessions Returned: 3
ğŸ’° Tokens Used: 2126 ($0.0003)
âš¡ Performance: 1107.9 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1904
   â€¢ Completion Tokens: 222
[SessionValidationService] Validating batch response: 3 input sessions, 3 response sessions
[SessionValidationService] Validation successful: all 3 sessions processed
[SessionValidationService] Validating batch response: 3 input sessions, 3 response sessions
[SessionValidationService] Validation successful: all 3 sessions processed
â±ï¸  Stream 1 Single Batch Time: 1919ms (1.92s)

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 1919ms (1.92s)
ğŸ“Š Sessions Processed: 3/3
ğŸ’° Tokens Used: 2126 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.6 sessions/sec
âš¡ Avg Time Per Session: 639.67ms
[ParallelProcessingOrchestrator] Parallel processing complete: 2/2 streams succeeded
â±ï¸  Parallel Processing Time: 1919ms (1.92s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 2 streams
[ParallelProcessingOrchestrator] Synchronization complete: 0 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 0
ğŸ“Š Total Classifications: 5

âœ… ============ ROUND 1 COMPLETED ============
â±ï¸  Round 1 Total Time: 1919ms (1.92s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 0
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 1919ms (100.0%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ‰ ============ PARALLEL PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 1919ms (1.92s)
ğŸ“Š Sessions Processed: 6/6
ğŸ”„ Total Rounds: 1
ğŸŒŠ Stream Results: 2
ğŸ’° Token Usage: 3756 tokens ($0.0005)
ğŸ“ˆ Stream Utilization: 100.0%
ğŸ¯ Performance: 3.1 sessions/second
âš¡ Avg Time Per Session: 319.83ms

ğŸ“Š Stream Performance Breakdown:
   Stream 1: 3 sessions in 1919ms (1107.9 tokens/sec)
   Stream 2: 3 sessions in 1886ms (864.3 tokens/sec)
[ConflictResolutionService] Starting conflict resolution for 10 sessions
[ConflictResolutionService] Found classifications: { intents: 3, reasons: 1, locations: 1 }
[ConflictResolutionService] No conflicts detected, skipping resolution
[ParallelAutoAnalyzeService] Using real analysis summary service
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[Direct API] Fetching real Kore.ai sessions from 2025-08-05T19:15:23.118Z to 2025-08-12T19:15:23.118Z for User Bot st-90549... (limit=50)
Retrieving sessions from 2025-08-05T19:15:23.118Z to 2025-08-12T19:15:23.118Z (limit=50), populateMessages=true...
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T19:15:23.118Z",
  "dateTo": "2025-08-12T19:15:23.118Z",
  "limit": 50
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:15:23.118Z",
  "dateTo": "2025-08-12T19:15:23.118Z",
  "skip": 0,
  "limit": 50
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:15:23.118Z",
  "dateTo": "2025-08-12T19:15:23.118Z",
  "skip": 0,
  "limit": 50
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:15:23.118Z",
  "dateTo": "2025-08-12T19:15:23.118Z",
  "skip": 0,
  "limit": 50
}
[getSessionsMetadata] agent API call failed: AxiosError: timeout of 30000ms exceeded
    at RedirectableRequest.handleRequestTimeout (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:657:16)
    at RedirectableRequest.emit (node:events:507:28)
    at Timeout.<anonymous> (/Users/kengrafals/workspace/xobcat/node_modules/follow-redirects/index.js:221:12)
    at listOnTimeout (node:internal/timers:608:17)
    at process.processTimers (node:internal/timers:543:7)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at runNextTicks (node:internal/process/task_queues:65:5)
    at listOnTimeout (node:internal/timers:569:9)
    at process.processTimers (node:internal/timers:543:7)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async Promise.allSettled (index 0)
    at async KoreApiService.getSessionsMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:342:23)
    at async SWTService.generateSWTs (/Users/kengrafals/workspace/xobcat/backend/src/services/swtService.ts:214:29)
    at async <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/analysis.ts:92:18) {
  code: 'ECONNABORTED',
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjYxMDMsImV4cCI6MTc1NTAyOTcwMywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.z_qzGDDBJSYGrGuH7JbveM7xTmFw4g_I7d4PVeLkJK4',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '95',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
    data: '{"dateFrom":"2025-08-05T19:15:03.104Z","dateTo":"2025-08-12T19:15:03.104Z","skip":0,"limit":50}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> Writable {
    _events: {
      close: undefined,
      error: [Function: handleRequestError],
      prefinish: undefined,
      finish: undefined,
      drain: undefined,
      response: [Function: handleResponse],
      socket: [Array],
      timeout: undefined,
      abort: undefined
    },
    _writableState: WritableState {
      highWaterMark: 65536,
      length: 0,
      corked: 0,
      onwrite: [Function: bound onwrite],
      writelen: 0,
      bufferedIndex: 0,
      pendingcb: 0,
      Symbol(kState): 17580812,
      Symbol(kBufferedValue): null
    },
    _maxListeners: undefined,
    _options: {
      maxRedirects: 21,
      maxBodyLength: Infinity,
      protocol: 'https:',
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
      method: 'POST',
      headers: [Object: null prototype],
      agents: [Object],
      auth: undefined,
      family: undefined,
      beforeRedirect: [Function: dispatchBeforeRedirect],
      beforeRedirects: [Object],
      hostname: 'bots.kore.ai',
      port: '',
      agent: undefined,
      nativeProtocols: [Object],
      pathname: '/api/public/bot/***REMOVED***/getSessions',
      search: '?containmentType=agent'
    },
    _ended: true,
    _ending: true,
    _redirectCount: 0,
    _redirects: [],
    _requestBodyLength: 95,
    _requestBodyBuffers: [ [Object] ],
    _eventsCount: 3,
    _onNativeResponse: [Function (anonymous)],
    _currentRequest: ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: false,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 95,
      _hasBody: true,
      _trailer: '',
      finished: true,
      _headerSent: true,
      _closed: false,
      _header: 'POST /api/public/bot/***REMOVED***/getSessions?containmentType=agent HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjYxMDMsImV4cCI6MTc1NTAyOTcwMywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.z_qzGDDBJSYGrGuH7JbveM7xTmFw4g_I7d4PVeLkJK4\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 95\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: bots.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
      _ended: false,
      res: null,
      aborted: false,
      timeoutCb: [Function: emitRequestTimeout],
      upgradeOrConnect: false,
      parser: [HTTPParser],
      maxHeadersCount: null,
      reusedSocket: true,
      host: 'bots.kore.ai',
      protocol: 'https:',
      _redirectable: [Circular *1],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    _currentUrl: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
    _timeout: null,
    Symbol(shapeMode): true,
    Symbol(kCapture): false
  }
}
[getSessionsMetadata] selfService API call failed: AxiosError: timeout of 30000ms exceeded
    at RedirectableRequest.handleRequestTimeout (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:657:16)
    at RedirectableRequest.emit (node:events:507:28)
    at Timeout.<anonymous> (/Users/kengrafals/workspace/xobcat/node_modules/follow-redirects/index.js:221:12)
    at listOnTimeout (node:internal/timers:608:17)
    at process.processTimers (node:internal/timers:543:7)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at runNextTicks (node:internal/process/task_queues:65:5)
    at listOnTimeout (node:internal/timers:569:9)
    at process.processTimers (node:internal/timers:543:7)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async Promise.allSettled (index 1)
    at async KoreApiService.getSessionsMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:342:23)
    at async SWTService.generateSWTs (/Users/kengrafals/workspace/xobcat/backend/src/services/swtService.ts:214:29)
    at async <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/analysis.ts:92:18) {
  code: 'ECONNABORTED',
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjYxMDMsImV4cCI6MTc1NTAyOTcwMywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.z_qzGDDBJSYGrGuH7JbveM7xTmFw4g_I7d4PVeLkJK4',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '95',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService',
    data: '{"dateFrom":"2025-08-05T19:15:03.104Z","dateTo":"2025-08-12T19:15:03.104Z","skip":0,"limit":50}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> Writable {
    _events: {
      close: undefined,
      error: [Function: handleRequestError],
      prefinish: undefined,
      finish: undefined,
      drain: undefined,
      response: [Function: handleResponse],
      socket: [Array],
      timeout: undefined,
      abort: undefined
    },
    _writableState: WritableState {
      highWaterMark: 65536,
      length: 0,
      corked: 0,
      onwrite: [Function: bound onwrite],
      writelen: 0,
      bufferedIndex: 0,
      pendingcb: 0,
      Symbol(kState): 17580812,
      Symbol(kBufferedValue): null
    },
    _maxListeners: undefined,
    _options: {
      maxRedirects: 21,
      maxBodyLength: Infinity,
      protocol: 'https:',
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=selfService',
      method: 'POST',
      headers: [Object: null prototype],
      agents: [Object],
      auth: undefined,
      family: undefined,
      beforeRedirect: [Function: dispatchBeforeRedirect],
      beforeRedirects: [Object],
      hostname: 'bots.kore.ai',
      port: '',
      agent: undefined,
      nativeProtocols: [Object],
      pathname: '/api/public/bot/***REMOVED***/getSessions',
      search: '?containmentType=selfService'
    },
    _ended: true,
    _ending: true,
    _redirectCount: 0,
    _redirects: [],
    _requestBodyLength: 95,
    _requestBodyBuffers: [ [Object] ],
    _eventsCount: 3,
    _onNativeResponse: [Function (anonymous)],
    _currentRequest: ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: false,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 95,
      _hasBody: true,
      _trailer: '',
      finished: true,
      _headerSent: true,
      _closed: false,
      _header: 'POST /api/public/bot/***REMOVED***/getSessions?containmentType=selfService HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjYxMDMsImV4cCI6MTc1NTAyOTcwMywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.z_qzGDDBJSYGrGuH7JbveM7xTmFw4g_I7d4PVeLkJK4\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 95\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: bots.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=selfService',
      _ended: false,
      res: null,
      aborted: false,
      timeoutCb: [Function: emitRequestTimeout],
      upgradeOrConnect: false,
      parser: [HTTPParser],
      maxHeadersCount: null,
      reusedSocket: false,
      host: 'bots.kore.ai',
      protocol: 'https:',
      _redirectable: [Circular *1],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    _currentUrl: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService',
    _timeout: null,
    Symbol(shapeMode): true,
    Symbol(kCapture): false
  }
}
[getSessionsMetadata] dropOff API call failed: AxiosError: timeout of 30000ms exceeded
    at RedirectableRequest.handleRequestTimeout (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:657:16)
    at RedirectableRequest.emit (node:events:507:28)
    at Timeout.<anonymous> (/Users/kengrafals/workspace/xobcat/node_modules/follow-redirects/index.js:221:12)
    at listOnTimeout (node:internal/timers:608:17)
    at process.processTimers (node:internal/timers:543:7)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at runNextTicks (node:internal/process/task_queues:65:5)
    at listOnTimeout (node:internal/timers:569:9)
    at process.processTimers (node:internal/timers:543:7)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async Promise.allSettled (index 2)
    at async KoreApiService.getSessionsMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:342:23)
    at async SWTService.generateSWTs (/Users/kengrafals/workspace/xobcat/backend/src/services/swtService.ts:214:29)
    at async <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/analysis.ts:92:18) {
  code: 'ECONNABORTED',
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjYxMDMsImV4cCI6MTc1NTAyOTcwMywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.z_qzGDDBJSYGrGuH7JbveM7xTmFw4g_I7d4PVeLkJK4',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '95',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff',
    data: '{"dateFrom":"2025-08-05T19:15:03.104Z","dateTo":"2025-08-12T19:15:03.104Z","skip":0,"limit":50}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> Writable {
    _events: {
      close: undefined,
      error: [Function: handleRequestError],
      prefinish: undefined,
      finish: undefined,
      drain: undefined,
      response: [Function: handleResponse],
      socket: [Array],
      timeout: undefined,
      abort: undefined
    },
    _writableState: WritableState {
      highWaterMark: 65536,
      length: 0,
      corked: 0,
      onwrite: [Function: bound onwrite],
      writelen: 0,
      bufferedIndex: 0,
      pendingcb: 0,
      Symbol(kState): 17580812,
      Symbol(kBufferedValue): null
    },
    _maxListeners: undefined,
    _options: {
      maxRedirects: 21,
      maxBodyLength: Infinity,
      protocol: 'https:',
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff',
      method: 'POST',
      headers: [Object: null prototype],
      agents: [Object],
      auth: undefined,
      family: undefined,
      beforeRedirect: [Function: dispatchBeforeRedirect],
      beforeRedirects: [Object],
      hostname: 'bots.kore.ai',
      port: '',
      agent: undefined,
      nativeProtocols: [Object],
      pathname: '/api/public/bot/***REMOVED***/getSessions',
      search: '?containmentType=dropOff'
    },
    _ended: true,
    _ending: true,
    _redirectCount: 0,
    _redirects: [],
    _requestBodyLength: 95,
    _requestBodyBuffers: [ [Object] ],
    _eventsCount: 3,
    _onNativeResponse: [Function (anonymous)],
    _currentRequest: ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: false,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 95,
      _hasBody: true,
      _trailer: '',
      finished: true,
      _headerSent: true,
      _closed: false,
      _header: 'POST /api/public/bot/***REMOVED***/getSessions?containmentType=dropOff HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjYxMDMsImV4cCI6MTc1NTAyOTcwMywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.z_qzGDDBJSYGrGuH7JbveM7xTmFw4g_I7d4PVeLkJK4\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 95\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: bots.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff',
      _ended: false,
      res: null,
      aborted: false,
      timeoutCb: [Function: emitRequestTimeout],
      upgradeOrConnect: false,
      parser: [HTTPParser],
      maxHeadersCount: null,
      reusedSocket: false,
      host: 'bots.kore.ai',
      protocol: 'https:',
      _redirectable: [Circular *1],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    _currentUrl: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff',
    _timeout: null,
    Symbol(shapeMode): true,
    Symbol(kCapture): false
  }
}
Total session metadata retrieved: 0 (parallel execution)
Retrieved 0 session metadata objects
No sessions found in the specified date range
::1 - - [12/Aug/2025:19:15:33 +0000] "GET /api/analysis/sessions?limit=50 HTTP/1.1" 200 378 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[ParallelAutoAnalyzeService] Parallel analysis 60dd66b0-501f-4d49-9ed7-89bc0467896d completed successfully
[BackgroundJobQueue] Updated job progress to final state: complete
[BackgroundJobQueue] Parallel analysis job 60dd66b0-501f-4d49-9ed7-89bc0467896d-parallel completed successfully
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[Direct API] Fetching real Kore.ai sessions from 2025-08-05T19:15:45.786Z to 2025-08-12T19:15:45.786Z for User Bot st-90549... (limit=50)
Retrieving sessions from 2025-08-05T19:15:45.786Z to 2025-08-12T19:15:45.786Z (limit=50), populateMessages=true...
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T19:15:45.786Z",
  "dateTo": "2025-08-12T19:15:45.786Z",
  "limit": 50
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:15:45.786Z",
  "dateTo": "2025-08-12T19:15:45.786Z",
  "skip": 0,
  "limit": 50
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:15:45.786Z",
  "dateTo": "2025-08-12T19:15:45.786Z",
  "skip": 0,
  "limit": 50
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:15:45.786Z",
  "dateTo": "2025-08-12T19:15:45.786Z",
  "skip": 0,
  "limit": 50
}
[getSessionsMetadata] agent API call failed: AxiosError: timeout of 30000ms exceeded
    at RedirectableRequest.handleRequestTimeout (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:657:16)
    at RedirectableRequest.emit (node:events:507:28)
    at Timeout.<anonymous> (/Users/kengrafals/workspace/xobcat/node_modules/follow-redirects/index.js:221:12)
    at listOnTimeout (node:internal/timers:608:17)
    at process.processTimers (node:internal/timers:543:7)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at runNextTicks (node:internal/process/task_queues:65:5)
    at listOnTimeout (node:internal/timers:569:9)
    at process.processTimers (node:internal/timers:543:7)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async Promise.allSettled (index 0)
    at async KoreApiService.getSessionsMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:342:23)
    at async SWTService.generateSWTs (/Users/kengrafals/workspace/xobcat/backend/src/services/swtService.ts:214:29)
    at async <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/analysis.ts:92:18) {
  code: 'ECONNABORTED',
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjYxMjMsImV4cCI6MTc1NTAyOTcyMywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.e4xH007tMKNL-Yiy5A-fJHA0ew6yD2zDK_iLRQnM4Ak',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '95',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
    data: '{"dateFrom":"2025-08-05T19:15:23.118Z","dateTo":"2025-08-12T19:15:23.118Z","skip":0,"limit":50}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> Writable {
    _events: {
      close: undefined,
      error: [Function: handleRequestError],
      prefinish: undefined,
      finish: undefined,
      drain: undefined,
      response: [Function: handleResponse],
      socket: [Array],
      timeout: undefined,
      abort: undefined
    },
    _writableState: WritableState {
      highWaterMark: 65536,
      length: 0,
      corked: 0,
      onwrite: [Function: bound onwrite],
      writelen: 0,
      bufferedIndex: 0,
      pendingcb: 0,
      Symbol(kState): 17580812,
      Symbol(kBufferedValue): null
    },
    _maxListeners: undefined,
    _options: {
      maxRedirects: 21,
      maxBodyLength: Infinity,
      protocol: 'https:',
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
      method: 'POST',
      headers: [Object: null prototype],
      agents: [Object],
      auth: undefined,
      family: undefined,
      beforeRedirect: [Function: dispatchBeforeRedirect],
      beforeRedirects: [Object],
      hostname: 'bots.kore.ai',
      port: '',
      agent: undefined,
      nativeProtocols: [Object],
      pathname: '/api/public/bot/***REMOVED***/getSessions',
      search: '?containmentType=agent'
    },
    _ended: true,
    _ending: true,
    _redirectCount: 0,
    _redirects: [],
    _requestBodyLength: 95,
    _requestBodyBuffers: [ [Object] ],
    _eventsCount: 3,
    _onNativeResponse: [Function (anonymous)],
    _currentRequest: ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: false,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 95,
      _hasBody: true,
      _trailer: '',
      finished: true,
      _headerSent: true,
      _closed: false,
      _header: 'POST /api/public/bot/***REMOVED***/getSessions?containmentType=agent HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjYxMjMsImV4cCI6MTc1NTAyOTcyMywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.e4xH007tMKNL-Yiy5A-fJHA0ew6yD2zDK_iLRQnM4Ak\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 95\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: bots.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
      _ended: false,
      res: null,
      aborted: false,
      timeoutCb: [Function: emitRequestTimeout],
      upgradeOrConnect: false,
      parser: [HTTPParser],
      maxHeadersCount: null,
      reusedSocket: false,
      host: 'bots.kore.ai',
      protocol: 'https:',
      _redirectable: [Circular *1],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    _currentUrl: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent',
    _timeout: null,
    Symbol(shapeMode): true,
    Symbol(kCapture): false
  }
}
[getSessionsMetadata] selfService API call failed: AxiosError: timeout of 30000ms exceeded
    at RedirectableRequest.handleRequestTimeout (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:657:16)
    at RedirectableRequest.emit (node:events:507:28)
    at Timeout.<anonymous> (/Users/kengrafals/workspace/xobcat/node_modules/follow-redirects/index.js:221:12)
    at listOnTimeout (node:internal/timers:608:17)
    at process.processTimers (node:internal/timers:543:7)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at runNextTicks (node:internal/process/task_queues:65:5)
    at listOnTimeout (node:internal/timers:569:9)
    at process.processTimers (node:internal/timers:543:7)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async Promise.allSettled (index 1)
    at async KoreApiService.getSessionsMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:342:23)
    at async SWTService.generateSWTs (/Users/kengrafals/workspace/xobcat/backend/src/services/swtService.ts:214:29)
    at async <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/analysis.ts:92:18) {
  code: 'ECONNABORTED',
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjYxMjMsImV4cCI6MTc1NTAyOTcyMywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.e4xH007tMKNL-Yiy5A-fJHA0ew6yD2zDK_iLRQnM4Ak',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '95',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService',
    data: '{"dateFrom":"2025-08-05T19:15:23.118Z","dateTo":"2025-08-12T19:15:23.118Z","skip":0,"limit":50}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> Writable {
    _events: {
      close: undefined,
      error: [Function: handleRequestError],
      prefinish: undefined,
      finish: undefined,
      drain: undefined,
      response: [Function: handleResponse],
      socket: [Array],
      timeout: undefined,
      abort: undefined
    },
    _writableState: WritableState {
      highWaterMark: 65536,
      length: 0,
      corked: 0,
      onwrite: [Function: bound onwrite],
      writelen: 0,
      bufferedIndex: 0,
      pendingcb: 0,
      Symbol(kState): 17580812,
      Symbol(kBufferedValue): null
    },
    _maxListeners: undefined,
    _options: {
      maxRedirects: 21,
      maxBodyLength: Infinity,
      protocol: 'https:',
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=selfService',
      method: 'POST',
      headers: [Object: null prototype],
      agents: [Object],
      auth: undefined,
      family: undefined,
      beforeRedirect: [Function: dispatchBeforeRedirect],
      beforeRedirects: [Object],
      hostname: 'bots.kore.ai',
      port: '',
      agent: undefined,
      nativeProtocols: [Object],
      pathname: '/api/public/bot/***REMOVED***/getSessions',
      search: '?containmentType=selfService'
    },
    _ended: true,
    _ending: true,
    _redirectCount: 0,
    _redirects: [],
    _requestBodyLength: 95,
    _requestBodyBuffers: [ [Object] ],
    _eventsCount: 3,
    _onNativeResponse: [Function (anonymous)],
    _currentRequest: ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: false,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 95,
      _hasBody: true,
      _trailer: '',
      finished: true,
      _headerSent: true,
      _closed: false,
      _header: 'POST /api/public/bot/***REMOVED***/getSessions?containmentType=selfService HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjYxMjMsImV4cCI6MTc1NTAyOTcyMywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.e4xH007tMKNL-Yiy5A-fJHA0ew6yD2zDK_iLRQnM4Ak\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 95\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: bots.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=selfService',
      _ended: false,
      res: null,
      aborted: false,
      timeoutCb: [Function: emitRequestTimeout],
      upgradeOrConnect: false,
      parser: [HTTPParser],
      maxHeadersCount: null,
      reusedSocket: false,
      host: 'bots.kore.ai',
      protocol: 'https:',
      _redirectable: [Circular *1],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    _currentUrl: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService',
    _timeout: null,
    Symbol(shapeMode): true,
    Symbol(kCapture): false
  }
}
[getSessionsMetadata] dropOff API call failed: AxiosError: timeout of 30000ms exceeded
    at RedirectableRequest.handleRequestTimeout (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:657:16)
    at RedirectableRequest.emit (node:events:507:28)
    at Timeout.<anonymous> (/Users/kengrafals/workspace/xobcat/node_modules/follow-redirects/index.js:221:12)
    at listOnTimeout (node:internal/timers:608:17)
    at process.processTimers (node:internal/timers:543:7)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async Promise.allSettled (index 2)
    at async KoreApiService.getSessionsMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:342:23)
    at async SWTService.generateSWTs (/Users/kengrafals/workspace/xobcat/backend/src/services/swtService.ts:214:29)
    at async <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/analysis.ts:92:18) {
  code: 'ECONNABORTED',
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjYxMjMsImV4cCI6MTc1NTAyOTcyMywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.e4xH007tMKNL-Yiy5A-fJHA0ew6yD2zDK_iLRQnM4Ak',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '95',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff',
    data: '{"dateFrom":"2025-08-05T19:15:23.118Z","dateTo":"2025-08-12T19:15:23.118Z","skip":0,"limit":50}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> Writable {
    _events: {
      close: undefined,
      error: [Function: handleRequestError],
      prefinish: undefined,
      finish: undefined,
      drain: undefined,
      response: [Function: handleResponse],
      socket: [Array],
      timeout: undefined,
      abort: undefined
    },
    _writableState: WritableState {
      highWaterMark: 65536,
      length: 0,
      corked: 0,
      onwrite: [Function: bound onwrite],
      writelen: 0,
      bufferedIndex: 0,
      pendingcb: 0,
      Symbol(kState): 17580812,
      Symbol(kBufferedValue): null
    },
    _maxListeners: undefined,
    _options: {
      maxRedirects: 21,
      maxBodyLength: Infinity,
      protocol: 'https:',
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff',
      method: 'POST',
      headers: [Object: null prototype],
      agents: [Object],
      auth: undefined,
      family: undefined,
      beforeRedirect: [Function: dispatchBeforeRedirect],
      beforeRedirects: [Object],
      hostname: 'bots.kore.ai',
      port: '',
      agent: undefined,
      nativeProtocols: [Object],
      pathname: '/api/public/bot/***REMOVED***/getSessions',
      search: '?containmentType=dropOff'
    },
    _ended: true,
    _ending: true,
    _redirectCount: 0,
    _redirects: [],
    _requestBodyLength: 95,
    _requestBodyBuffers: [ [Object] ],
    _eventsCount: 3,
    _onNativeResponse: [Function (anonymous)],
    _currentRequest: ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: false,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 95,
      _hasBody: true,
      _trailer: '',
      finished: true,
      _headerSent: true,
      _closed: false,
      _header: 'POST /api/public/bot/***REMOVED***/getSessions?containmentType=dropOff HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjcy0yYTQyOThlYS05NDdjLTVhNDItOTg0Ni02NzBjNjYwZGEwZmQiLCJzdWIiOiJzdC05MDU0OWE2Ny03ZjE5LTUwNzQtYWZjZi0zMTIwZGI1MWEyNmQiLCJpYXQiOjE3NTUwMjYxMjMsImV4cCI6MTc1NTAyOTcyMywiYXVkIjoiaHR0cHM6Ly9ib3RzLmtvcmUuYWkifQ.e4xH007tMKNL-Yiy5A-fJHA0ew6yD2zDK_iLRQnM4Ak\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 95\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: bots.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff',
      _ended: false,
      res: null,
      aborted: false,
      timeoutCb: [Function: emitRequestTimeout],
      upgradeOrConnect: false,
      parser: [HTTPParser],
      maxHeadersCount: null,
      reusedSocket: false,
      host: 'bots.kore.ai',
      protocol: 'https:',
      _redirectable: [Circular *1],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    _currentUrl: 'https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff',
    _timeout: null,
    Symbol(shapeMode): true,
    Symbol(kCapture): false
  }
}
Total session metadata retrieved: 0 (parallel execution)
Retrieved 0 session metadata objects
No sessions found in the specified date range
::1 - - [12/Aug/2025:19:15:53 +0000] "GET /api/analysis/sessions?limit=50 HTTP/1.1" 200 378 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 50 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b92c7b110c33d698aed68',
  '689b92c504e17fb1eb577692',
  '689b92adb95843b7901e8552'
]
[fetchContainmentTypeMetadata] API Response: 50 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b92bd025fed00986517d3',
  '689b92aafca75d828212b25e',
  '689b929f3360bd076e1bca9e'
]
[fetchContainmentTypeMetadata] API Response: 50 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b8eecd0ca50f0ddbd2066',
  '689b8e8632b94a1c3f22df7b',
  '689b8e8232b94a1c3f22dee9'
]
[getSessionsMetadata] agent API call succeeded with 50 sessions
[getSessionsMetadata] selfService API call succeeded with 50 sessions
[getSessionsMetadata] dropOff API call succeeded with 50 sessions
Total session metadata retrieved: 150 (parallel execution)
Retrieved 150 session metadata objects
Creating 150 SWTs from metadata (no messages)
Created 150 SWT objects from metadata
Populating messages for all sessions (legacy behavior)
Populating messages for 150 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 150 sessions from 2025-08-12T17:51:13.722Z to 2025-08-12T19:15:41.910Z at 2025-08-12T19:15:53.993Z
ğŸš€ [ConcurrentBatch] Split 150 sessions into 8 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/8] Starting: 20 sessions
[Batch 2/8] Starting: 20 sessions
[Batch 3/8] Starting: 20 sessions
[Batch 4/8] Starting: 20 sessions
[Batch 5/8] Starting: 20 sessions
[Batch 6/8] Starting: 20 sessions
[Batch 7/8] Starting: 20 sessions
[Batch 8/8] Starting: 10 sessions
[Batch 3/8] Completed in 274ms: 248 messages retrieved (1/8 done)
[Batch 1/8] Completed in 307ms: 220 messages retrieved (2/8 done)
[Batch 2/8] Completed in 329ms: 260 messages retrieved (3/8 done)
[Batch 4/8] Completed in 407ms: 253 messages retrieved (4/8 done)
[Batch 8/8] Completed in 422ms: 106 messages retrieved (5/8 done)
[Batch 6/8] Completed in 453ms: 173 messages retrieved (6/8 done)
[Batch 7/8] Completed in 640ms: 286 messages retrieved (7/8 done)
[Batch 5/8] Completed in 668ms: 493 messages retrieved (8/8 done)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 669ms (0.67s)
â±ï¸  Batch Processing: 669ms (0.67s)
ğŸ“¦ Total batches: 8 (max 10 concurrent)
âœ… Successful batches: 8/8
ğŸ’¬ Total messages: 2039
ğŸ“ˆ Avg time per batch: 84ms
ğŸš€ Time per session: 4ms
ğŸ’ª Performance: 224.2 sessions/second
=======================================================

Retrieved 2039 messages for 150 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
Populated messages for 150 SWT objects
Generated 150 SWT objects in 8891ms using layered architecture
::1 - - [12/Aug/2025:19:15:54 +0000] "GET /api/analysis/sessions?limit=50 HTTP/1.1" 200 977698 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[Direct API] Fetching real Kore.ai sessions from 2025-08-05T19:15:54.695Z to 2025-08-12T19:15:54.695Z for User Bot st-90549... (limit=50)
Retrieving sessions from 2025-08-05T19:15:54.695Z to 2025-08-12T19:15:54.695Z (limit=50), populateMessages=true...
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T19:15:54.695Z",
  "dateTo": "2025-08-12T19:15:54.695Z",
  "limit": 50
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:15:54.695Z",
  "dateTo": "2025-08-12T19:15:54.695Z",
  "skip": 0,
  "limit": 50
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:15:54.695Z",
  "dateTo": "2025-08-12T19:15:54.695Z",
  "skip": 0,
  "limit": 50
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:15:54.695Z",
  "dateTo": "2025-08-12T19:15:54.695Z",
  "skip": 0,
  "limit": 50
}
[fetchContainmentTypeMetadata] API Response: 50 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b92e90cef90d20307d762',
  '689b92c7b110c33d698aed68',
  '689b92adb95843b7901e8552'
]
[fetchContainmentTypeMetadata] API Response: 50 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b8eecd0ca50f0ddbd2066',
  '689b8e8632b94a1c3f22df7b',
  '689b8e8232b94a1c3f22dee9'
]
[fetchContainmentTypeMetadata] API Response: 50 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b92c504e17fb1eb577692',
  '689b92bd025fed00986517d3',
  '689b92abb1f082150b58eafd'
]
[getSessionsMetadata] agent API call succeeded with 50 sessions
[getSessionsMetadata] selfService API call succeeded with 50 sessions
[getSessionsMetadata] dropOff API call succeeded with 50 sessions
Total session metadata retrieved: 150 (parallel execution)
Retrieved 150 session metadata objects
Creating 150 SWTs from metadata (no messages)
Created 150 SWT objects from metadata
Populating messages for all sessions (legacy behavior)
Populating messages for 150 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 150 sessions from 2025-08-12T17:51:13.722Z to 2025-08-12T19:15:54.354Z at 2025-08-12T19:16:11.880Z
ğŸš€ [ConcurrentBatch] Split 150 sessions into 8 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/8] Starting: 20 sessions
[Batch 2/8] Starting: 20 sessions
[Batch 3/8] Starting: 20 sessions
[Batch 4/8] Starting: 20 sessions
[Batch 5/8] Starting: 20 sessions
[Batch 6/8] Starting: 20 sessions
[Batch 7/8] Starting: 20 sessions
[Batch 8/8] Starting: 10 sessions
[Batch 1/8] Completed in 208ms: 231 messages retrieved (1/8 done)
[Batch 3/8] Completed in 244ms: 288 messages retrieved (2/8 done)
[Batch 2/8] Completed in 277ms: 247 messages retrieved (3/8 done)
[Batch 6/8] Completed in 445ms: 173 messages retrieved (4/8 done)
[Batch 8/8] Completed in 470ms: 106 messages retrieved (5/8 done)
[Batch 4/8] Completed in 473ms: 250 messages retrieved (6/8 done)
[Batch 7/8] Completed in 573ms: 286 messages retrieved (7/8 done)
[Batch 5/8] Completed in 616ms: 481 messages retrieved (8/8 done)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 616ms (0.62s)
â±ï¸  Batch Processing: 616ms (0.62s)
ğŸ“¦ Total batches: 8 (max 10 concurrent)
âœ… Successful batches: 8/8
ğŸ’¬ Total messages: 2062
ğŸ“ˆ Avg time per batch: 77ms
ğŸš€ Time per session: 4ms
ğŸ’ª Performance: 243.5 sessions/second
=======================================================

Retrieved 2062 messages for 150 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
Populated messages for 150 SWT objects
Generated 150 SWT objects in 17809ms using layered architecture
::1 - - [12/Aug/2025:19:16:12 +0000] "GET /api/analysis/sessions?limit=50 HTTP/1.1" 200 985958 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸš€ [ParallelAutoAnalyzeRoute] Starting parallel analysis for bot ***REMOVED*** with real credentials
ğŸš€ [ParallelAutoAnalyzeService] Starting parallel analysis da6f8ac9-81c7-4930-9006-fe3945f779c0 with bot ***REMOVED***
ğŸš€ [ParallelAutoAnalyzeService] Using credentials: real
ğŸš€ [ParallelAutoAnalyzeRoute] Parallel analysis started: da6f8ac9-81c7-4930-9006-fe3945f779c0
::1 - - [12/Aug/2025:19:16:48 +0000] "POST /api/analysis/auto-analyze/parallel/start HTTP/1.1" 200 214 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:16:48 +0000] "GET /api/analysis/auto-analyze/parallel/progress/da6f8ac9-81c7-4930-9006-fe3945f779c0 HTTP/1.1" 200 542 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:16:48 +0000] "GET /api/analysis/auto-analyze/parallel/progress/da6f8ac9-81c7-4930-9006-fe3945f779c0 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[BackgroundJobQueue] Starting job processing after delay for job da6f8ac9-81c7-4930-9006-fe3945f779c0-parallel
[BackgroundJobQueue] Starting processing for job da6f8ac9-81c7-4930-9006-fe3945f779c0-parallel, phase: sampling
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing parallel analysis job da6f8ac9-81c7-4930-9006-fe3945f779c0-parallel
[BackgroundJobQueue] Processing parallel analysis for bot ***REMOVED***
[BackgroundJobQueue] Using existing ParallelAutoAnalyzeService instance for bot ***REMOVED***
[BackgroundJobQueue] Session recreated for da6f8ac9-81c7-4930-9006-fe3945f779c0
[ParallelAutoAnalyzeService] Running parallel analysis for da6f8ac9-81c7-4930-9006-fe3945f779c0
[ParallelAutoAnalyzeService] Phase 0: Starting session sampling for da6f8ac9-81c7-4930-9006-fe3945f779c0

ğŸ• ============ SESSION SAMPLING STARTED ============
ğŸ• [SessionSampling] Starting session sampling at 2025-08-12T19:16:49.054Z
ğŸ” [SessionDiscovery] Starting window 1/4: Initial 3-hour window
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
::1 - - [12/Aug/2025:19:16:50 +0000] "GET /api/analysis/auto-analyze/parallel/progress/da6f8ac9-81c7-4930-9006-fe3945f779c0 HTTP/1.1" 200 719 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:16:52 +0000] "GET /api/analysis/auto-analyze/parallel/progress/da6f8ac9-81c7-4930-9006-fe3945f779c0 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 139 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6a14dd27c3112087cd',
  '68922a22ef03d8ad2ec7b4ba',
  '68922a1278c1fe09a079719c'
]
::1 - - [12/Aug/2025:19:16:54 +0000] "GET /api/analysis/auto-analyze/parallel/progress/da6f8ac9-81c7-4930-9006-fe3945f779c0 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 80 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a1287849680ad9fe59e',
  '689229f9583056c6108e38fb',
  '68922914f8bee7ba6c3e67b8'
]
[fetchContainmentTypeMetadata] API Response: 1338 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6d14dd27c31120888b',
  '68922a62e3804084741191d5',
  '68922a523a3160d25de144c8'
]
[getSessionsMetadata] agent API call succeeded with 1338 sessions
[getSessionsMetadata] selfService API call succeeded with 80 sessions
[getSessionsMetadata] dropOff API call succeeded with 139 sessions
Total session metadata retrieved: 1557 (parallel execution)
Creating 1557 SWTs from metadata (no messages)
Created 1557 SWT objects from metadata
âœ… [SessionDiscovery] Window 1 completed in 5981ms: found 1557 new sessions (total: 1557)
â±ï¸  TIMING: Window 1 took 5981ms (5.98s)
ğŸ¯ [SessionDiscovery] Target reached! Found 1557 sessions in 5981ms
ğŸ² [SessionSampling] Random sampling from 1557 sessions to 100 sessions

ğŸ“¬ ============ MESSAGE RETRIEVAL STARTED ============
ğŸ“¬ [MessageRetrieval] Starting message retrieval for 100 sampled sessions at 2025-08-12T19:16:55.037Z
Using new lazy loading approach to populate messages for 100 sampled sessions
Populating messages for 100 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 100 sessions from 2025-08-05T13:00:42.239Z to 2025-08-05T15:57:54.402Z at 2025-08-12T19:16:55.037Z
ğŸš€ [ConcurrentBatch] Split 100 sessions into 5 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/5] Starting: 20 sessions
[Batch 2/5] Starting: 20 sessions
[Batch 3/5] Starting: 20 sessions
[Batch 4/5] Starting: 20 sessions
[Batch 5/5] Starting: 20 sessions
[Batch 1/5] Completed in 374ms: 248 messages retrieved (1/5 done)
ğŸ“Š [BatchProgress] Reporting batch 1/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 40/100 sessions (Batch 2/5)
[Batch 2/5] Completed in 431ms: 256 messages retrieved (2/5 done)
ğŸ“Š [BatchProgress] Reporting batch 2/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 60/100 sessions (Batch 3/5)
[Batch 3/5] Completed in 436ms: 271 messages retrieved (3/5 done)
ğŸ“Š [BatchProgress] Reporting batch 3/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 80/100 sessions (Batch 4/5)
[Batch 5/5] Completed in 517ms: 198 messages retrieved (4/5 done)
ğŸ“Š [BatchProgress] Reporting batch 4/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 100/100 sessions (Batch 5/5)
[Batch 4/5] Completed in 626ms: 271 messages retrieved (5/5 done)
ğŸ“Š [BatchProgress] Reporting batch 5/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 100/100 sessions (Batch 6/5)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 627ms (0.63s)
â±ï¸  Batch Processing: 627ms (0.63s)
ğŸ“¦ Total batches: 5 (max 10 concurrent)
âœ… Successful batches: 5/5
ğŸ’¬ Total messages: 1244
ğŸ“ˆ Avg time per batch: 125ms
ğŸš€ Time per session: 6ms
ğŸ’ª Performance: 159.5 sessions/second
=======================================================

Retrieved 1244 messages for 100 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
Populated messages for 100 SWT objects
Successfully populated messages for 100 sessions using lazy loading
Applying final filtering to 100 sessions with populated messages
Final result: 99 sessions passed filtering with populated messages

ğŸ‰ ============ SESSION SAMPLING COMPLETED ============
â±ï¸  TOTAL TIME: 6617ms (6.62s)
â±ï¸  Session Discovery: 5982ms (5.98s) - 90.4% of total
â±ï¸  Message Retrieval: 634ms (0.63s) - 9.6% of total
â±ï¸  Performance: 15.0 sessions/second
ğŸ¯ Final result: 99 sessions with messages retrieved
====================================================

[StrategicDiscoveryService] Starting discovery phase with 99 total sessions
[StrategicDiscoveryService] Discovery config: {
  targetPercentage: 15,
  minSessions: 9,
  maxSessions: 14,
  diversityStrategy: {
    sessionLengths: [ 'short', 'medium', 'long' ],
    containmentTypes: [ 'agent', 'selfService', 'dropOff' ],
    timeDistribution: 'spread'
  }
}
[StrategicDiscoveryService] Selecting 14 diverse sessions from 99 total
[StrategicDiscoveryService] Session diversity groups: { short: 29, medium: 68, long: 2, early: 33, middle: 33, late: 33 }
[StrategicDiscoveryService] Selected sessions by length distribution: { short: 3, medium: 9, long: 2 }
[StrategicDiscoveryService] Selected 14 sessions for discovery

ğŸ“¦ ===== BATCH 10 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T19:16:55.672Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 0
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T19:16:55.672Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:16:55.672Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6610,
  existingClassifications: { intents: 0, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.



For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and another intent, classify the intent as the other i...
::1 - - [12/Aug/2025:19:16:56 +0000] "GET /api/analysis/auto-analyze/parallel/progress/da6f8ac9-81c7-4930-9006-fe3945f779c0 HTTP/1.1" 200 932 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:16:58 +0000] "GET /api/analysis/auto-analyze/parallel/progress/da6f8ac9-81c7-4930-9006-fe3945f779c0 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:17:00 +0000] "GET /api/analysis/auto-analyze/parallel/progress/da6f8ac9-81c7-4930-9006-fe3945f779c0 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:17:00.141Z',
  duration: '4469ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1910,
    completion_tokens: 357,
    total_tokens: 2267,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Live Agent', 'Unknown' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-bc5108df-d08e-54e5-a334-ec993b7ebe9f",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-29e9e551-1c66-58f0-bc02-1d532d2b2054",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-dd74491d-613d-5f59-be9d-8d591794e911",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to check on a claim but was transferred to an agent."
    },
    {
      "user_id": "u-94d4f8b3-3495-5387-ab79-e8293c81f7af",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to report back to work and was transferred to an agent."
    },
    {
      "user_id": "u-8c2af863-b4fb-5b9d-a85e-4362f796eb75",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested customer service and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1910,
  completionTokens: 357,
  totalTokens: 2267,
  cost: '$0.000334',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 4469ms (4.47s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2267 ($0.0003)
âš¡ Performance: 507.3 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 4469ms (4.47s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2267

âœ… ===== BATCH 10 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 4469ms (4.47s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2267 ($0.0003)
âš¡ Performance: 1.1 sessions/sec
âš¡ Avg Time Per Session: 893.80ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 1 complete: 4 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 2, reasons: 1, locations: 1, total: 4 }

ğŸ“¦ ===== BATCH 11 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T19:17:00.142Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 2
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T19:17:00.142Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:17:00.142Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 11212,
  existingClassifications: { intents: 2, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Age...
::1 - - [12/Aug/2025:19:17:02 +0000] "GET /api/analysis/auto-analyze/parallel/progress/da6f8ac9-81c7-4930-9006-fe3945f779c0 HTTP/1.1" 200 949 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:17:04 +0000] "GET /api/analysis/auto-analyze/parallel/progress/da6f8ac9-81c7-4930-9006-fe3945f779c0 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:17:04.857Z',
  duration: '4715ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 3088,
    completion_tokens: 372,
    total_tokens: 3460,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Unknown' ],
  transferCount: 3,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-186c7475-cf74-55e3-be6c-33cdc053498a",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User attempted to track leave requests but did not have the request number and did not receive any active requests, ending the session without transfer."
    },
    {
      "user_id": "u-70df6947-8a23-59d9-92f7-ca2a1de0e8f0",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to open a new leave request and needed assistance, resulting in transfer to a live agent."
    },
    {
      "user_id": "u-28e16169-8a69-5c7c-b536-1fd7ed509d44",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User inquired about FMLA renewal status but did not have the correct leave request details and ended the session without transfer."
    },
    {
      "user_id": "u-fbbe12b4-aff4-50b5-8484-f7d91b7539da",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and then transferred to a live agent after failed attempts to get assistance."
    },
    {
      "user_id": "u-f92aba57-9fe0-54c1-98e4-a4fcfc8570de",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative, resulting in transfer to a live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 3088,
  completionTokens: 372,
  totalTokens: 3460,
  cost: '$0.000458',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 4715ms (4.71s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 3460 ($0.0005)
âš¡ Performance: 733.8 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 4716ms (4.72s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 3460

âœ… ===== BATCH 11 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 4716ms (4.72s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 3460 ($0.0005)
âš¡ Performance: 1.1 sessions/sec
âš¡ Avg Time Per Session: 943.20ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 2 complete: 0 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 2, reasons: 1, locations: 1, total: 4 }

ğŸ“¦ ===== BATCH 12 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T19:17:04.858Z
ğŸ“Š Sessions in Batch: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 2
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 4
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T19:17:04.858Z
ğŸ“Š Sessions to Analyze: 4

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:17:04.859Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7358,
  existingClassifications: { intents: 2, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Age...
::1 - - [12/Aug/2025:19:17:06 +0000] "GET /api/analysis/auto-analyze/parallel/progress/da6f8ac9-81c7-4930-9006-fe3945f779c0 HTTP/1.1" 200 949 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:17:07.007Z',
  duration: '2148ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2076,
    completion_tokens: 280,
    total_tokens: 2356,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown', 'Live Agent' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-835f682f-4486-595e-823a-42c3a1676d5a",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was unable to provide necessary information and was transferred to a live agent."
    },
    {
      "user_id": "u-186c7475-cf74-55e3-be6c-33cdc053498a",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User did not have the leave request number and the session was closed without transfer."
    },
    {
      "user_id": "u-3a248122-b3cb-54ce-b71d-55576f476ddc",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative and was transferred to an agent."
    },
    {
      "user_id": "u-8a131781-1db2-5c90-bbb4-e03254ce16ce",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to take FMLA day and was transferred to a live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2076,
  completionTokens: 280,
  totalTokens: 2356,
  cost: '$0.000320',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2150ms (2.15s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2356 ($0.0003)
âš¡ Performance: 1095.8 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 4
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2150ms (2.15s)
ğŸ“Š Regular Sessions Processed: 4
ğŸ’° Regular Tokens Used: 2356

âœ… ===== BATCH 12 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2150ms (2.15s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Total Tokens: 2356 ($0.0003)
âš¡ Performance: 1.9 sessions/sec
âš¡ Avg Time Per Session: 537.50ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 3 complete: 0 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 2, reasons: 1, locations: 1, total: 4 }
[StrategicDiscoveryService] Discovery phase complete: {
  totalProcessed: 14,
  uniqueIntents: 2,
  uniqueReasons: 1,
  uniqueLocations: 1,
  discoveryRate: 0.26666666666666666
}

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T19:17:07.008Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms
[ParallelProcessingOrchestrator] Configuration for 86 sessions:
  Design: 8 streams Ã— 4 sessions = 32 per round
  Optimal: 8 streams Ã— 4 sessions = 32 per round
  Estimated Rounds: 3
[ParallelAutoAnalyzeService] Using parallel config: {
  streamCount: 8,
  sessionsPerStream: 4,
  maxSessionsPerLLMCall: 50,
  syncFrequency: 'after_each_round',
  retryAttempts: 3,
  debugLogging: false
}

ğŸš€ ============ PARALLEL PROCESSING STARTED ============
â±ï¸  Start Time: 2025-08-12T19:17:07.008Z
ğŸ“Š Total Sessions: 86

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T19:17:07.008Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms

âš™ï¸  ============ PARALLEL CONFIGURATION ============
â±ï¸  Config Time: 0ms
ğŸ”§ Stream Count: 8
ğŸ“¦ Sessions Per Stream: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per API Call: 50
ğŸ¯ Debug Logging: false

ğŸ”„ ============ ROUND 1/3 STARTED ============
â±ï¸  Round 1 Start: 2025-08-12T19:17:07.008Z
ğŸ“Š Sessions Remaining: 86
[ParallelProcessingOrchestrator] Distributed 32 sessions across 8 streams: [
  'Stream 1: 4 sessions',
  'Stream 2: 4 sessions',
  'Stream 3: 4 sessions',
  'Stream 4: 4 sessions',
  'Stream 5: 4 sessions',
  'Stream 6: 4 sessions',
  'Stream 7: 4 sessions',
  'Stream 8: 4 sessions'
]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 8

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 8 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T19:17:07.008Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:17:07.008Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 827
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6327
   â€¢ Avg Per Session: 207 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6327
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 1ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6327
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:17:07.009Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 2
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:17:07.009Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6524,
  existingClassifications: { intents: 2, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Age...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T19:17:07.009Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:17:07.009Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 1052
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6552
   â€¢ Avg Per Session: 263 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6552
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6552
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:17:07.009Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 2
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:17:07.009Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7540,
  existingClassifications: { intents: 2, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Age...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T19:17:07.009Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:17:07.009Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 663
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6163
   â€¢ Avg Per Session: 166 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6163
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6163
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:17:07.009Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 2
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:17:07.009Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5760,
  existingClassifications: { intents: 2, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Age...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T19:17:07.009Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:17:07.009Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 909
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6409
   â€¢ Avg Per Session: 227 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6409
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6409
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:17:07.009Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 2
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:17:07.010Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6906,
  existingClassifications: { intents: 2, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Age...

ğŸŒŠ ===== STREAM 5 PROCESSING START =====
â±ï¸  Stream 5 Start: 2025-08-12T19:17:07.010Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:17:07.010Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 620
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6120
   â€¢ Avg Per Session: 155 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6120
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 5) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6120
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 5: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:17:07.010Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 2
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:17:07.010Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5586,
  existingClassifications: { intents: 2, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Age...

ğŸŒŠ ===== STREAM 6 PROCESSING START =====
â±ï¸  Stream 6 Start: 2025-08-12T19:17:07.010Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:17:07.010Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 715
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6215
   â€¢ Avg Per Session: 179 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6215
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 6) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6215
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 6: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:17:07.010Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 2
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:17:07.010Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6027,
  existingClassifications: { intents: 2, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Age...

ğŸŒŠ ===== STREAM 7 PROCESSING START =====
â±ï¸  Stream 7 Start: 2025-08-12T19:17:07.010Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:17:07.010Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 603
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6103
   â€¢ Avg Per Session: 151 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6103
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 7) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6103
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 7: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:17:07.010Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 2
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:17:07.010Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5495,
  existingClassifications: { intents: 2, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Age...

ğŸŒŠ ===== STREAM 8 PROCESSING START =====
â±ï¸  Stream 8 Start: 2025-08-12T19:17:07.010Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:17:07.010Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 693
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6193
   â€¢ Avg Per Session: 173 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6193
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 8) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6193
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 8: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:17:07.010Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 2
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:17:07.010Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5905,
  existingClassifications: { intents: 2, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Age...
::1 - - [12/Aug/2025:19:17:08 +0000] "GET /api/analysis/auto-analyze/parallel/progress/da6f8ac9-81c7-4930-9006-fe3945f779c0 HTTP/1.1" 200 1726 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:17:08.950Z',
  duration: '1941ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1867,
    completion_tokens: 276,
    total_tokens: 2143,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status', 'Unknown' ],
  transferCount: 2,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-8c581208-2d7b-5b35-a435-b5d125726ec8",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User attempted to file a claim but did not provide claim details, session ended without transfer."
    },
    {
      "user_id": "u-92c16bcd-606b-5f1a-b39f-4c280233729b",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent, session transferred to live agent."
    },
    {
      "user_id": "u-5dbbc253-d0bd-5b69-9e53-6a0b0a57b2a3",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent, session transferred to live agent."
    },
    {
      "user_id": "u-7a5f8683-9112-55ef-882f-377bc6d93131",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User inquired about leave approval and paperwork status, session handled without transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1867,
  completionTokens: 276,
  totalTokens: 2143,
  cost: '$0.000297',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1942ms (1.94s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2143 ($0.0003)
âš¡ Performance: 1103.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1867
   â€¢ Completion Tokens: 276
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 1 Single Batch Time: 1943ms (1.94s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 1944ms (1.94s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2143 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.1 sessions/sec
âš¡ Avg Time Per Session: 486.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:17:09.140Z',
  duration: '2130ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1722,
    completion_tokens: 284,
    total_tokens: 2006,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status', 'Unknown' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-0d586a81-11da-53f7-baef-cfdf592af947",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted claim status and was transferred to a live agent."
    },
    {
      "user_id": "u-39668043-0249-553e-bbc4-1d3de2fb8766",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-3ccd4175-c809-5d5a-84fb-c35b8a629042",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User inquired about claim status and was transferred to an agent."
    },
    {
      "user_id": "u-6514d456-0aa6-52d6-a8a4-984b3508cbe0",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1722,
  completionTokens: 284,
  totalTokens: 2006,
  cost: '$0.000286',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2130ms (2.13s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2006 ($0.0003)
âš¡ Performance: 941.8 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1722
   â€¢ Completion Tokens: 284
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 6 Single Batch Time: 2131ms (2.13s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 6 PROCESSING COMPLETE =====
â±ï¸  Stream 6 Total Time: 2131ms (2.13s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2006 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.9 sessions/sec
âš¡ Avg Time Per Session: 532.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:17:09.321Z',
  duration: '2311ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1961,
    completion_tokens: 291,
    total_tokens: 2252,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Unknown' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-4bb9c235-cc2e-5f6a-9229-fd1ceeb15fae",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative and was transferred to an agent."
    },
    {
      "user_id": "u-aeb8d386-64f2-56d8-ab42-c6a78d5be396",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User attempted to get help with entry time but did not complete the process, session was closed by the bot."
    },
    {
      "user_id": "u-597cd38d-9abe-543f-af99-c67e046da7f3",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an operator and was transferred to an agent."
    },
    {
      "user_id": "u-501630f1-3930-586e-b31c-d6e9967a1410",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User expressed the need to speak to a representative and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1961,
  completionTokens: 291,
  totalTokens: 2252,
  cost: '$0.000313',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2313ms (2.31s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2252 ($0.0003)
âš¡ Performance: 973.6 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1961
   â€¢ Completion Tokens: 291
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 4 Single Batch Time: 2313ms (2.31s)

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 2313ms (2.31s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2252 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.7 sessions/sec
âš¡ Avg Time Per Session: 578.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:17:09.870Z',
  duration: '2860ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1627,
    completion_tokens: 287,
    total_tokens: 1914,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Unknown', 'Claim Status' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-173dd7ee-4bae-5495-b390-c95776cb4a17",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative about a fax number for the doctor's office and was transferred."
    },
    {
      "user_id": "u-51260be0-0ce7-5ce9-ae63-af25a29cf9ff",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User was silent and did not provide input; session was closed after no response."
    },
    {
      "user_id": "u-0c1f7ce5-4a93-566a-853a-2fe2fa90e691",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative; session was transferred."
    },
    {
      "user_id": "u-0a6bbfb1-0571-53ef-9440-ca1378f316d8",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to put in a new claim and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1627,
  completionTokens: 287,
  totalTokens: 1914,
  cost: '$0.000277',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2860ms (2.86s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1914 ($0.0003)
âš¡ Performance: 669.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1627
   â€¢ Completion Tokens: 287
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 5 Single Batch Time: 2860ms (2.86s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 5 PROCESSING COMPLETE =====
â±ï¸  Stream 5 Total Time: 2860ms (2.86s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1914 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.4 sessions/sec
âš¡ Avg Time Per Session: 715.00ms
::1 - - [12/Aug/2025:19:17:10 +0000] "GET /api/analysis/auto-analyze/parallel/progress/da6f8ac9-81c7-4930-9006-fe3945f779c0 HTTP/1.1" 200 1734 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:17:12 +0000] "GET /api/analysis/auto-analyze/parallel/progress/da6f8ac9-81c7-4930-9006-fe3945f779c0 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:17:12.319Z',
  duration: '5309ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1714,
    completion_tokens: 179,
    total_tokens: 1893,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-c0208bf2-552f-5b95-8ad8-0f67590c3b4c",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-fdab4773-5ddf-5c2a-a807-fcf3509f0d86",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-d1f176df-8f2a-52d8-b5dd-f58cf28c344d",
      "notes": "User wanted to change FMLA status, was transferred."
    },
    {
      "user_id": "u-1316d0b4-050e-5fb9-b390-cfa145c13f6f",
      "notes": "User wanted to take time off work, was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1714,
  completionTokens: 179,
  totalTokens: 1893,
  cost: '$0.000243',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 5310ms (5.31s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1893 ($0.0002)
âš¡ Performance: 356.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1714
   â€¢ Completion Tokens: 179
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-c0208bf2-552f-5b95-8ad8-0f67590c3b4c: Invalid general_intent, u-c0208bf2-552f-5b95-8ad8-0f67590c3b4c: Invalid session_outcome, u-fdab4773-5ddf-5c2a-a807-fcf3509f0d86: Invalid general_intent, u-fdab4773-5ddf-5c2a-a807-fcf3509f0d86: Invalid session_outcome, u-d1f176df-8f2a-52d8-b5dd-f58cf28c344d: Invalid general_intent, u-d1f176df-8f2a-52d8-b5dd-f58cf28c344d: Invalid session_outcome, u-1316d0b4-050e-5fb9-b390-cfa145c13f6f: Invalid general_intent, u-1316d0b4-050e-5fb9-b390-cfa145c13f6f: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 8 Single Batch Time: 5310ms (5.31s)

âœ… ===== STREAM 8 PROCESSING COMPLETE =====
â±ï¸  Stream 8 Total Time: 5310ms (5.31s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1893 ($0.0002)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.8 sessions/sec
âš¡ Avg Time Per Session: 1327.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:17:12.623Z',
  duration: '5614ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2100,
    completion_tokens: 265,
    total_tokens: 2365,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown', 'FMLA' ],
  transferCount: 2,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-2ae89bc0-ca86-5950-b4b3-80f461c8683c",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "Session involved a complex, unclear conversation with no transfer to a live agent."
    },
    {
      "user_id": "u-049a5e9b-8d8f-50ab-a63b-86d462912714",
      "general_intent": "FMLA",
      "session_outcome": "Contained",
      "notes": "User successfully submitted a leave request and ended the session without transfer."
    },
    {
      "user_id": "u-08c5bccb-7de8-5e54-b217-f49abbdecf18",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative, resulting in transfer to an agent."
    },
    {
      "user_id": "u-efaa7bfe-9d0d-59fe-ae98-d3928d99678d",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent, leading to transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2100,
  completionTokens: 265,
  totalTokens: 2365,
  cost: '$0.000316',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 5614ms (5.61s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2365 ($0.0003)
âš¡ Performance: 421.3 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2100
   â€¢ Completion Tokens: 265
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 2 Single Batch Time: 5615ms (5.62s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 5615ms (5.62s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2365 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.7 sessions/sec
âš¡ Avg Time Per Session: 1403.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:17:12.785Z',
  duration: '5776ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1660,
    completion_tokens: 283,
    total_tokens: 1943,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Claim Status' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-94424495-ab40-52b4-acaa-b38698ed04f7",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent and was transferred."
    },
    {
      "user_id": "u-66057b94-270b-5b34-8fb5-a90cb850df82",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent and was transferred."
    },
    {
      "user_id": "u-2dd1a0a5-f940-55f6-a8ef-9aed2395052e",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent and was transferred."
    },
    {
      "user_id": "u-fbabfec9-232a-5a4f-938f-fd868bc3db55",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to start a new claim and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1660,
  completionTokens: 283,
  totalTokens: 1943,
  cost: '$0.000279',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 5776ms (5.78s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1943 ($0.0003)
âš¡ Performance: 336.4 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1660
   â€¢ Completion Tokens: 283
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 3 Single Batch Time: 5777ms (5.78s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 5777ms (5.78s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1943 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.7 sessions/sec
âš¡ Avg Time Per Session: 1444.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:17:12.856Z',
  duration: '5846ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1592,
    completion_tokens: 288,
    total_tokens: 1880,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status', 'Unknown' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-afe49426-bc8f-59cb-8f7d-41caafb7e4dc",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to start a new claim and was transferred to an agent."
    },
    {
      "user_id": "u-43403a36-cf3d-5230-9411-77f188912aed",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted customer service and was transferred to an agent."
    },
    {
      "user_id": "u-bbe5e080-66b9-528b-afab-0f75bdbe8119",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to start a claim and was transferred to an agent."
    },
    {
      "user_id": "u-08c528dc-cefd-56e6-92ff-e30a53bc2ac0",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak to an agency and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1592,
  completionTokens: 288,
  totalTokens: 1880,
  cost: '$0.000274',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 5846ms (5.85s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1880 ($0.0003)
âš¡ Performance: 321.6 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1592
   â€¢ Completion Tokens: 288
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 7 Single Batch Time: 5846ms (5.85s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 7 PROCESSING COMPLETE =====
â±ï¸  Stream 7 Total Time: 5846ms (5.85s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1880 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.7 sessions/sec
âš¡ Avg Time Per Session: 1461.50ms
[ParallelProcessingOrchestrator] Parallel processing complete: 8/8 streams succeeded
â±ï¸  Parallel Processing Time: 5849ms (5.85s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 8 streams
[ParallelProcessingOrchestrator] Synchronization complete: 2 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 2
ğŸ“Š Total Classifications: 6

âœ… ============ ROUND 1 COMPLETED ============
â±ï¸  Round 1 Total Time: 5849ms (5.85s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 54
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 5849ms (100.0%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ”„ ============ ROUND 2/3 STARTED ============
â±ï¸  Round 2 Start: 2025-08-12T19:17:12.857Z
ğŸ“Š Sessions Remaining: 54
[ParallelProcessingOrchestrator] Distributed 32 sessions across 8 streams: [
  'Stream 1: 4 sessions',
  'Stream 2: 4 sessions',
  'Stream 3: 4 sessions',
  'Stream 4: 4 sessions',
  'Stream 5: 4 sessions',
  'Stream 6: 4 sessions',
  'Stream 7: 4 sessions',
  'Stream 8: 4 sessions'
]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 8

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 8 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T19:17:12.857Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:17:12.857Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 771
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6271
   â€¢ Avg Per Session: 193 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6271
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6271
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:17:12.858Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:17:12.858Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6250,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, FMLA, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eli...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T19:17:12.858Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:17:12.858Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 862
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6362
   â€¢ Avg Per Session: 216 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6362
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6362
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:17:12.858Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:17:12.859Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6672,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, FMLA, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eli...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T19:17:12.859Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:17:12.859Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 785
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6285
   â€¢ Avg Per Session: 196 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6285
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6285
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:17:12.859Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:17:12.859Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6347,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, FMLA, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eli...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T19:17:12.859Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:17:12.859Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 782
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6282
   â€¢ Avg Per Session: 196 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6282
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6282
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:17:12.859Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:17:12.859Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6350,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, FMLA, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eli...

ğŸŒŠ ===== STREAM 5 PROCESSING START =====
â±ï¸  Stream 5 Start: 2025-08-12T19:17:12.859Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:17:12.859Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 1096
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6596
   â€¢ Avg Per Session: 274 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6596
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0011
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 5) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6596
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0011

âš¡ Stream 5: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:17:12.859Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:17:12.859Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7720,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, FMLA, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eli...

ğŸŒŠ ===== STREAM 6 PROCESSING START =====
â±ï¸  Stream 6 Start: 2025-08-12T19:17:12.859Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:17:12.859Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 645
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6145
   â€¢ Avg Per Session: 161 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6145
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 6) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6145
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 6: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:17:12.859Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:17:12.859Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5699,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, FMLA, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eli...

ğŸŒŠ ===== STREAM 7 PROCESSING START =====
â±ï¸  Stream 7 Start: 2025-08-12T19:17:12.860Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:17:12.860Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 716
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6216
   â€¢ Avg Per Session: 179 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6216
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 7) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6216
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 7: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:17:12.860Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:17:12.860Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6018,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, FMLA, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eli...

ğŸŒŠ ===== STREAM 8 PROCESSING START =====
â±ï¸  Stream 8 Start: 2025-08-12T19:17:12.860Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:17:12.860Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 1103
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6603
   â€¢ Avg Per Session: 276 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6603
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0011
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 8) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6603
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0011

âš¡ Stream 8: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:17:12.860Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:17:12.860Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7824,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, FMLA, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eli...
::1 - - [12/Aug/2025:19:17:14 +0000] "GET /api/analysis/auto-analyze/parallel/progress/da6f8ac9-81c7-4930-9006-fe3945f779c0 HTTP/1.1" 200 1726 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:17:14.470Z',
  duration: '1611ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2169,
    completion_tokens: 199,
    total_tokens: 2368,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-d58a7bc9-38e8-5cfb-8fd6-33ea0500a492",
      "notes": "User wanted to speak with an agent, and session was transferred to a live agent."
    },
    {
      "user_id": "u-12ddc522-bd83-515d-ab38-faa7376b4cec",
      "notes": "User reported a time entry issue, but ultimately requested to speak with an agent, and session was transferred."
    },
    {
      "user_id": "u-d314c8e3-23f4-554e-bd17-f310596a3d8f",
      "notes": "User was silent and did not respond, session was transferred to an agent."
    },
    {
      "user_id": "u-c5f4effd-a060-575e-ae65-f16db89d966c",
      "notes": "User asked about FMLA and then requested to speak with a representative, session was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2169,
  completionTokens: 199,
  totalTokens: 2368,
  cost: '$0.000296',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1612ms (1.61s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2368 ($0.0003)
âš¡ Performance: 1469.0 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2169
   â€¢ Completion Tokens: 199
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-d58a7bc9-38e8-5cfb-8fd6-33ea0500a492: Invalid general_intent, u-d58a7bc9-38e8-5cfb-8fd6-33ea0500a492: Invalid session_outcome, u-12ddc522-bd83-515d-ab38-faa7376b4cec: Invalid general_intent, u-12ddc522-bd83-515d-ab38-faa7376b4cec: Invalid session_outcome, u-d314c8e3-23f4-554e-bd17-f310596a3d8f: Invalid general_intent, u-d314c8e3-23f4-554e-bd17-f310596a3d8f: Invalid session_outcome, u-c5f4effd-a060-575e-ae65-f16db89d966c: Invalid general_intent, u-c5f4effd-a060-575e-ae65-f16db89d966c: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 5 Single Batch Time: 1612ms (1.61s)

âœ… ===== STREAM 5 PROCESSING COMPLETE =====
â±ï¸  Stream 5 Total Time: 1612ms (1.61s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2368 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.5 sessions/sec
âš¡ Avg Time Per Session: 403.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:17:14.527Z',
  duration: '1668ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1813,
    completion_tokens: 236,
    total_tokens: 2049,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status', 'FMLA' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-80775f06-3d6e-5e31-9ba3-ebc35988dc37",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-65bb5052-b57b-5de2-a7b1-79b9146ea36b",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-45d4e4e2-23d8-5c36-b487-1a8c3c0efb02",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-24f3ff3a-8a6f-5074-a75e-d91e6f5a288a",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": ""
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1813,
  completionTokens: 236,
  totalTokens: 2049,
  cost: '$0.000276',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1669ms (1.67s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2049 ($0.0003)
âš¡ Performance: 1227.7 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1813
   â€¢ Completion Tokens: 236
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-80775f06-3d6e-5e31-9ba3-ebc35988dc37: Invalid notes, u-65bb5052-b57b-5de2-a7b1-79b9146ea36b: Invalid notes, u-45d4e4e2-23d8-5c36-b487-1a8c3c0efb02: Invalid notes, u-24f3ff3a-8a6f-5074-a75e-d91e6f5a288a: Invalid notes'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 4 Single Batch Time: 1670ms (1.67s)

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 1670ms (1.67s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2049 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.4 sessions/sec
âš¡ Avg Time Per Session: 417.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:17:14.990Z',
  duration: '2131ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1648,
    completion_tokens: 289,
    total_tokens: 1937,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Claim Status' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-30bd2e47-aa56-58ae-b944-26ce79512c42",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-74d21e4c-4e47-5ab6-93ff-72d6a9b2be50",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to start a new claim and was transferred to an agent."
    },
    {
      "user_id": "u-a69ff94f-4fb6-54bb-a9b2-c98939975c78",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-e5b99f58-033f-599e-902a-9f42f5350365",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1648,
  completionTokens: 289,
  totalTokens: 1937,
  cost: '$0.000280',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2131ms (2.13s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1937 ($0.0003)
âš¡ Performance: 909.0 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1648
   â€¢ Completion Tokens: 289
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 6 Single Batch Time: 2132ms (2.13s)

âœ… ===== STREAM 6 PROCESSING COMPLETE =====
â±ï¸  Stream 6 Total Time: 2132ms (2.13s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1937 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.9 sessions/sec
âš¡ Avg Time Per Session: 533.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:17:14.991Z',
  duration: '2132ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1813,
    completion_tokens: 280,
    total_tokens: 2093,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'FMLA' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-69880613-bf26-562f-93a9-60671a6a1dd4",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent and was transferred."
    },
    {
      "user_id": "u-9dc7db2f-870e-5a36-a78d-087eb72dd1cf",
      "general_intent": "FMLA",
      "session_outcome": "Contained",
      "notes": "User provided leave request details and was not transferred to an agent."
    },
    {
      "user_id": "u-523c5516-be06-55ab-8c30-2781977461eb",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and then requested to speak to an agent, resulting in transfer."
    },
    {
      "user_id": "u-120a1de7-3044-5c0f-aad2-3c65fca807b9",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1813,
  completionTokens: 280,
  totalTokens: 2093,
  cost: '$0.000293',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2132ms (2.13s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2093 ($0.0003)
âš¡ Performance: 981.7 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1813
   â€¢ Completion Tokens: 280
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 3 Single Batch Time: 2132ms (2.13s)

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 2132ms (2.13s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2093 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.9 sessions/sec
âš¡ Avg Time Per Session: 533.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:17:14.993Z',
  duration: '2133ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1731,
    completion_tokens: 291,
    total_tokens: 2022,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'FMLA' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-42c7b397-fd47-5241-8b19-49fab7008a25",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-2798cfd1-6f23-511f-921b-6359bd24c142",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-edce82b0-63d9-5594-9d64-a43bdf6421cf",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-c9381be1-95b8-5f14-97f1-d0ba7dd8d769",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1731,
  completionTokens: 291,
  totalTokens: 2022,
  cost: '$0.000290',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2134ms (2.13s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2022 ($0.0003)
âš¡ Performance: 947.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1731
   â€¢ Completion Tokens: 291
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 7 Single Batch Time: 2134ms (2.13s)

âœ… ===== STREAM 7 PROCESSING COMPLETE =====
â±ï¸  Stream 7 Total Time: 2134ms (2.13s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2022 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.9 sessions/sec
âš¡ Avg Time Per Session: 533.50ms
::1 - - [12/Aug/2025:19:17:16 +0000] "GET /api/analysis/auto-analyze/parallel/progress/da6f8ac9-81c7-4930-9006-fe3945f779c0 HTTP/1.1" 200 1736 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:17:17.729Z',
  duration: '4870ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1886,
    completion_tokens: 228,
    total_tokens: 2114,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'FMLA' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-c4596db2-d6cb-5d62-9d92-b1e68daaa4e4",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-ad8a401d-f819-50e4-b0de-933caf504220",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-9b912fb5-60d7-5e4c-9aa2-dd41b68711ea",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-56c0eb44-a6fd-5067-a3b3-000c2abc14f0",
      "general_intent": "FMLA",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": ""
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1886,
  completionTokens: 228,
  totalTokens: 2114,
  cost: '$0.000280',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 4871ms (4.87s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2114 ($0.0003)
âš¡ Performance: 434.0 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1886
   â€¢ Completion Tokens: 228
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-c4596db2-d6cb-5d62-9d92-b1e68daaa4e4: Invalid notes, u-ad8a401d-f819-50e4-b0de-933caf504220: Invalid notes, u-9b912fb5-60d7-5e4c-9aa2-dd41b68711ea: Invalid notes, u-56c0eb44-a6fd-5067-a3b3-000c2abc14f0: Invalid notes'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 2 Single Batch Time: 4872ms (4.87s)

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 4872ms (4.87s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2114 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.8 sessions/sec
âš¡ Avg Time Per Session: 1218.00ms
::1 - - [12/Aug/2025:19:17:18 +0000] "GET /api/analysis/auto-analyze/parallel/progress/da6f8ac9-81c7-4930-9006-fe3945f779c0 HTTP/1.1" 200 1738 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:17:18.079Z',
  duration: '5219ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2191,
    completion_tokens: 229,
    total_tokens: 2420,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Unknown' ],
  transferCount: 2,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-64b74bcb-cd04-56df-94bd-e8e3a63fb50f",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-be6907b2-ff40-55dc-9a97-8fd80421407b",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User was attempting to check time and submit leave request details, completed successfully without transfer."
    },
    {
      "user_id": "u-a13f2641-d017-5638-8f4e-2c93a5305855",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-84baa148-35fa-5529-9a4b-da648e66b650",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User was reporting time for leave, completed successfully without transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2191,
  completionTokens: 229,
  totalTokens: 2420,
  cost: '$0.000311',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 5220ms (5.22s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2420 ($0.0003)
âš¡ Performance: 463.6 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2191
   â€¢ Completion Tokens: 229
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-64b74bcb-cd04-56df-94bd-e8e3a63fb50f: Invalid notes, u-a13f2641-d017-5638-8f4e-2c93a5305855: Invalid notes'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 8 Single Batch Time: 5220ms (5.22s)

âœ… ===== STREAM 8 PROCESSING COMPLETE =====
â±ï¸  Stream 8 Total Time: 5220ms (5.22s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2420 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.8 sessions/sec
âš¡ Avg Time Per Session: 1305.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:17:19.156Z',
  duration: '6298ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1776,
    completion_tokens: 300,
    total_tokens: 2076,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'FMLA' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-b9ec360d-34fe-591c-a76d-4d890dd29073",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with a customer representative and was transferred to an agent."
    },
    {
      "user_id": "u-485e8776-7cf5-550a-a5fa-e44e1535cf40",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with someone in customer service and was transferred to an agent."
    },
    {
      "user_id": "u-d38e1cfe-1404-533b-b2b9-ea12af6e54ae",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked about follow-up and was transferred to an agent after unclear responses."
    },
    {
      "user_id": "u-94237b4f-646a-53e0-ac7b-cfa024a304e6",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User mentioned customer service and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1776,
  completionTokens: 300,
  totalTokens: 2076,
  cost: '$0.000298',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 6300ms (6.30s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2076 ($0.0003)
âš¡ Performance: 329.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1776
   â€¢ Completion Tokens: 300
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 1 Single Batch Time: 6300ms (6.30s)

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 6300ms (6.30s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2076 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.6 sessions/sec
âš¡ Avg Time Per Session: 1575.00ms
[ParallelProcessingOrchestrator] Parallel processing complete: 8/8 streams succeeded
â±ï¸  Parallel Processing Time: 6300ms (6.30s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 8 streams
[ParallelProcessingOrchestrator] Synchronization complete: 0 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 0
ğŸ“Š Total Classifications: 6

âœ… ============ ROUND 2 COMPLETED ============
â±ï¸  Round 2 Total Time: 6300ms (6.30s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 22
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 6300ms (100.0%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ”„ ============ ROUND 3/3 STARTED ============
â±ï¸  Round 3 Start: 2025-08-12T19:17:19.157Z
ğŸ“Š Sessions Remaining: 22
[ParallelProcessingOrchestrator] Distributed 22 sessions across 6 streams: [
  'Stream 1: 4 sessions',
  'Stream 2: 4 sessions',
  'Stream 3: 4 sessions',
  'Stream 4: 4 sessions',
  'Stream 5: 4 sessions',
  'Stream 6: 2 sessions'
]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 6

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 6 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T19:17:19.158Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:17:19.158Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 801
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6301
   â€¢ Avg Per Session: 200 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6301
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6301
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:17:19.158Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:17:19.158Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6429,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, FMLA, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eli...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T19:17:19.158Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:17:19.158Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 659
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6159
   â€¢ Avg Per Session: 165 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6159
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 1ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6159
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:17:19.159Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:17:19.159Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5751,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, FMLA, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eli...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T19:17:19.159Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:17:19.159Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 700
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6200
   â€¢ Avg Per Session: 175 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6200
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6200
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:17:19.160Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:17:19.160Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6007,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, FMLA, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eli...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T19:17:19.160Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:17:19.160Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 754
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6254
   â€¢ Avg Per Session: 189 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6254
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6254
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:17:19.160Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:17:19.160Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6217,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, FMLA, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eli...

ğŸŒŠ ===== STREAM 5 PROCESSING START =====
â±ï¸  Stream 5 Start: 2025-08-12T19:17:19.160Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:17:19.160Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 755
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6255
   â€¢ Avg Per Session: 189 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6255
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 1ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 5) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6255
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 5: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:17:19.161Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:17:19.161Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6211,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, FMLA, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eli...

ğŸŒŠ ===== STREAM 6 PROCESSING START =====
â±ï¸  Stream 6 Start: 2025-08-12T19:17:19.161Z
ğŸ“Š Sessions Assigned: 2
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:17:19.161Z
ğŸ“Š Sessions to Estimate: 2
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 2
   â€¢ Session Tokens: 348
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 5848
   â€¢ Avg Per Session: 174 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 5848
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0009
ğŸ“Š Recommended Batch Size: 2

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 6) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 5848
ğŸ“¦ Recommended Batch Size: 2
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0009

âš¡ Stream 6: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:17:19.161Z
ğŸ“Š Sessions to Analyze: 2
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:17:19.161Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 2,
  apiKey: 'sk-proj-...',
  promptLength: 4682,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, FMLA, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eli...
::1 - - [12/Aug/2025:19:17:20 +0000] "GET /api/analysis/auto-analyze/parallel/progress/da6f8ac9-81c7-4930-9006-fe3945f779c0 HTTP/1.1" 200 1536 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:17:21.198Z',
  duration: '2038ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1743,
    completion_tokens: 290,
    total_tokens: 2033,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'FMLA', 'Claim Status' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-394c78c7-6b40-5225-b6be-c02cf2a34dde",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent and was transferred to help with leave questions."
    },
    {
      "user_id": "u-bd119e77-c6c7-51ab-9c96-3e442946edc5",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User did not provide input and session was closed by the bot."
    },
    {
      "user_id": "u-9ec4bf15-44b1-5eb2-8075-303b8065f4c0",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested new leave, and was transferred to an agent for assistance."
    },
    {
      "user_id": "u-ef34d35c-d377-5eda-92fb-51b2b59adb80",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User needed assistance with amending leave hours and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1743,
  completionTokens: 290,
  totalTokens: 2033,
  cost: '$0.000290',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2039ms (2.04s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2033 ($0.0003)
âš¡ Performance: 997.1 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1743
   â€¢ Completion Tokens: 290
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 3 Single Batch Time: 2039ms (2.04s)

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 2040ms (2.04s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2033 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.0 sessions/sec
âš¡ Avg Time Per Session: 510.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:17:21.243Z',
  duration: '2084ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1661,
    completion_tokens: 291,
    total_tokens: 1952,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'FMLA', 'Claim Status', 'Unknown' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-2252b935-35cf-58e2-86f9-ff59850e3ca6",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent and was transferred."
    },
    {
      "user_id": "u-29555d49-006e-5a3c-b98d-269e178f6f26",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked about a payment and was transferred to an agent."
    },
    {
      "user_id": "u-014636f8-2374-5f0e-803c-d53dd3acc3b5",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested customer service and was transferred to an agent."
    },
    {
      "user_id": "u-07174fb4-94cd-5a84-8a3d-ebf5ea37049a",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to talk to a representative and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1661,
  completionTokens: 291,
  totalTokens: 1952,
  cost: '$0.000282',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2085ms (2.08s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1952 ($0.0003)
âš¡ Performance: 936.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1661
   â€¢ Completion Tokens: 291
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 2 Single Batch Time: 2085ms (2.08s)

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 2086ms (2.09s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1952 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.9 sessions/sec
âš¡ Avg Time Per Session: 521.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:17:21.944Z',
  duration: '2783ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1372,
    completion_tokens: 151,
    total_tokens: 1523,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 2,
  intentsFound: [ 'FMLA', 'Claim Status' ],
  transferCount: 2,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-12974d99-8a76-5378-876d-2b2bf940bd29",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak to a representative and was transferred to an agent."
    },
    {
      "user_id": "u-5f17c02b-e486-52bb-af15-815d7fa7f584",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to start a new claim and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1372,
  completionTokens: 151,
  totalTokens: 1523,
  cost: '$0.000198',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2784ms (2.78s)
ğŸ“Š Sessions Returned: 2
ğŸ’° Tokens Used: 1523 ($0.0002)
âš¡ Performance: 547.1 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1372
   â€¢ Completion Tokens: 151
[SessionValidationService] Validating batch response: 2 input sessions, 2 response sessions
[SessionValidationService] Validation successful: all 2 sessions processed
[SessionValidationService] Validating batch response: 2 input sessions, 2 response sessions
[SessionValidationService] Validation successful: all 2 sessions processed
â±ï¸  Stream 6 Single Batch Time: 2785ms (2.79s)

âœ… ===== STREAM 6 PROCESSING COMPLETE =====
â±ï¸  Stream 6 Total Time: 2785ms (2.79s)
ğŸ“Š Sessions Processed: 2/2
ğŸ’° Tokens Used: 1523 ($0.0002)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.7 sessions/sec
âš¡ Avg Time Per Session: 1392.50ms
::1 - - [12/Aug/2025:19:17:22 +0000] "GET /api/analysis/auto-analyze/parallel/progress/da6f8ac9-81c7-4930-9006-fe3945f779c0 HTTP/1.1" 200 1542 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:17:22.254Z',
  duration: '3094ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1780,
    completion_tokens: 214,
    total_tokens: 1994,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'FMLA', 'Time Entry', 'Claim Status' ],
  transferCount: 2,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-1f535134-5316-5dd9-9186-3d8b68fe2c4d",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-18c41c8d-d820-5ec9-aa61-42518ff12695",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-529428c1-ba0f-5668-851e-4bbabb4e411d",
      "general_intent": "Time Entry",
      "session_outcome": "Contained",
      "drop_off_location": ""
    },
    {
      "user_id": "u-0e506d1d-eb51-5ac9-a38b-cbb2b20dfa6e",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "drop_off_location": ""
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1780,
  completionTokens: 214,
  totalTokens: 1994,
  cost: '$0.000264',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 3095ms (3.10s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1994 ($0.0003)
âš¡ Performance: 644.3 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1780
   â€¢ Completion Tokens: 214
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-1f535134-5316-5dd9-9186-3d8b68fe2c4d: Invalid notes, u-18c41c8d-d820-5ec9-aa61-42518ff12695: Invalid notes, u-529428c1-ba0f-5668-851e-4bbabb4e411d: Invalid notes, u-0e506d1d-eb51-5ac9-a38b-cbb2b20dfa6e: Invalid notes'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 4 Single Batch Time: 3095ms (3.10s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 3095ms (3.10s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1994 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.3 sessions/sec
âš¡ Avg Time Per Session: 773.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:17:23.775Z',
  duration: '4617ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1843,
    completion_tokens: 278,
    total_tokens: 2121,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'FMLA', 'Claim Status' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-33e7897c-f6ea-5d48-a59f-c46a99943b4b",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative and was transferred to an agent."
    },
    {
      "user_id": "u-aba17c40-bb89-5531-ad5b-49fb28260d8b",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User provided claim status information without transfer."
    },
    {
      "user_id": "u-a63a46b4-4da2-518a-bfda-c47060d8db8e",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent and was transferred."
    },
    {
      "user_id": "u-9afba1ca-16fe-5a3b-8420-8ec43c41e8f2",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1843,
  completionTokens: 278,
  totalTokens: 2121,
  cost: '$0.000295',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 4617ms (4.62s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2121 ($0.0003)
âš¡ Performance: 459.4 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1843
   â€¢ Completion Tokens: 278
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 1 Single Batch Time: 4618ms (4.62s)

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 4618ms (4.62s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2121 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.9 sessions/sec
âš¡ Avg Time Per Session: 1154.50ms
::1 - - [12/Aug/2025:19:17:24 +0000] "GET /api/analysis/auto-analyze/parallel/progress/da6f8ac9-81c7-4930-9006-fe3945f779c0 HTTP/1.1" 200 1546 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:17:24.289Z',
  duration: '5128ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1778,
    completion_tokens: 278,
    total_tokens: 2056,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Claim Status' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-dc895526-27bb-57a0-8403-e3a590888451",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent and was transferred."
    },
    {
      "user_id": "u-2416d9de-9b9f-5d91-8287-9c14683c896b",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent and was transferred."
    },
    {
      "user_id": "u-206b528e-c6be-5b7a-a4d4-d36634db21ea",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent and was transferred."
    },
    {
      "user_id": "u-7441f4e3-e645-536a-aef0-88d273ef34fa",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User inquired about claim status and was handled by the bot."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1778,
  completionTokens: 278,
  totalTokens: 2056,
  cost: '$0.000289',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 5129ms (5.13s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2056 ($0.0003)
âš¡ Performance: 400.9 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1778
   â€¢ Completion Tokens: 278
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 5 Single Batch Time: 5129ms (5.13s)

âœ… ===== STREAM 5 PROCESSING COMPLETE =====
â±ï¸  Stream 5 Total Time: 5130ms (5.13s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2056 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.8 sessions/sec
âš¡ Avg Time Per Session: 1282.50ms
[ParallelProcessingOrchestrator] Parallel processing complete: 6/6 streams succeeded
â±ï¸  Parallel Processing Time: 5133ms (5.13s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 6 streams
[ParallelProcessingOrchestrator] Synchronization complete: 1 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 1
ğŸ“Š Total Classifications: 7

âœ… ============ ROUND 3 COMPLETED ============
â±ï¸  Round 3 Total Time: 5134ms (5.13s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 0
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 5133ms (100.0%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ‰ ============ PARALLEL PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 17283ms (17.28s)
ğŸ“Š Sessions Processed: 86/86
ğŸ”„ Total Rounds: 3
ğŸŒŠ Stream Results: 22
ğŸ’° Token Usage: 45154 tokens ($0.0062)
ğŸ“ˆ Stream Utilization: 100.0%
ğŸ¯ Performance: 5.0 sessions/second
âš¡ Avg Time Per Session: 200.97ms

ğŸ“Š Stream Performance Breakdown:
   Stream 1: 4 sessions in 1944ms (1102.4 tokens/sec)
   Stream 2: 4 sessions in 5615ms (421.2 tokens/sec)
   Stream 3: 4 sessions in 5777ms (336.3 tokens/sec)
   Stream 4: 4 sessions in 2313ms (973.6 tokens/sec)
   Stream 5: 4 sessions in 2860ms (669.2 tokens/sec)
   Stream 6: 4 sessions in 2131ms (941.3 tokens/sec)
   Stream 7: 4 sessions in 5846ms (321.6 tokens/sec)
   Stream 8: 4 sessions in 5310ms (356.5 tokens/sec)
   Stream 1: 4 sessions in 6300ms (329.5 tokens/sec)
   Stream 2: 4 sessions in 4872ms (433.9 tokens/sec)
   Stream 3: 4 sessions in 2132ms (981.7 tokens/sec)
   Stream 4: 4 sessions in 1670ms (1226.9 tokens/sec)
   Stream 5: 4 sessions in 1612ms (1469.0 tokens/sec)
   Stream 6: 4 sessions in 2132ms (908.5 tokens/sec)
   Stream 7: 4 sessions in 2134ms (947.5 tokens/sec)
   Stream 8: 4 sessions in 5220ms (463.6 tokens/sec)
   Stream 1: 4 sessions in 4618ms (459.3 tokens/sec)
   Stream 2: 4 sessions in 2086ms (935.8 tokens/sec)
   Stream 3: 4 sessions in 2040ms (996.6 tokens/sec)
   Stream 4: 4 sessions in 3095ms (644.3 tokens/sec)
   Stream 5: 4 sessions in 5130ms (400.8 tokens/sec)
   Stream 6: 2 sessions in 2785ms (546.9 tokens/sec)
[ConflictResolutionService] Starting conflict resolution for 100 sessions
[ConflictResolutionService] Found classifications: { intents: 5, reasons: 1, locations: 1 }
[ConflictResolutionService] Calling LLM for conflict resolution with model gpt-4.1-nano
ğŸ”§ Conflict Resolution Prompt Preview: You are reviewing classifications from parallel analysis streams. Identify any semantic duplicates and choose the canonical version for each group.

**Instructions:**
1. Look for classifications that refer to the same concept but use different wording
2. For each group of duplicates, choose the most...
[ConflictResolutionService] LLM call failed: Error: Invalid conflict resolution response format
    at ConflictResolutionService.callLLMForConflictResolution (/Users/kengrafals/workspace/xobcat/backend/src/services/conflictResolutionService.ts:294:15)
    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)
    at async ConflictResolutionService.resolveConflicts (/Users/kengrafals/workspace/xobcat/backend/src/services/conflictResolutionService.ts:128:28)
    at async ParallelAutoAnalyzeService.runConflictResolutionPhase (/Users/kengrafals/workspace/xobcat/backend/src/services/parallelAutoAnalyzeService.ts:450:38)
    at async ParallelAutoAnalyzeService.runParallelAnalysis (/Users/kengrafals/workspace/xobcat/backend/src/services/parallelAutoAnalyzeService.ts:273:32)
    at async BackgroundJobQueue.processParallelAnalysis (/Users/kengrafals/workspace/xobcat/backend/src/services/backgroundJobQueue.ts:469:7)
    at async BackgroundJobQueue.processJob (/Users/kengrafals/workspace/xobcat/backend/src/services/backgroundJobQueue.ts:149:9)
    at async Timeout._onTimeout (/Users/kengrafals/workspace/xobcat/backend/src/services/backgroundJobQueue.ts:116:9)
[ParallelAutoAnalyzeService] Analysis da6f8ac9-81c7-4930-9006-fe3945f779c0 failed: Error: Conflict resolution failed: Error: Invalid conflict resolution response format
    at ConflictResolutionService.callLLMForConflictResolution (/Users/kengrafals/workspace/xobcat/backend/src/services/conflictResolutionService.ts:334:13)
    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)
    at async ConflictResolutionService.resolveConflicts (/Users/kengrafals/workspace/xobcat/backend/src/services/conflictResolutionService.ts:128:28)
    at async ParallelAutoAnalyzeService.runConflictResolutionPhase (/Users/kengrafals/workspace/xobcat/backend/src/services/parallelAutoAnalyzeService.ts:450:38)
    at async ParallelAutoAnalyzeService.runParallelAnalysis (/Users/kengrafals/workspace/xobcat/backend/src/services/parallelAutoAnalyzeService.ts:273:32)
    at async BackgroundJobQueue.processParallelAnalysis (/Users/kengrafals/workspace/xobcat/backend/src/services/backgroundJobQueue.ts:469:7)
    at async BackgroundJobQueue.processJob (/Users/kengrafals/workspace/xobcat/backend/src/services/backgroundJobQueue.ts:149:9)
    at async Timeout._onTimeout (/Users/kengrafals/workspace/xobcat/backend/src/services/backgroundJobQueue.ts:116:9)
[BackgroundJobQueue] Updated job progress to final state: error
[BackgroundJobQueue] Parallel analysis job da6f8ac9-81c7-4930-9006-fe3945f779c0-parallel completed successfully
::1 - - [12/Aug/2025:19:17:26 +0000] "GET /api/analysis/auto-analyze/parallel/progress/da6f8ac9-81c7-4930-9006-fe3945f779c0 HTTP/1.1" 200 1670 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
3:19:21 PM [tsx] change in ./src/services/conflictResolutionService.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
3:19:32 PM [tsx] change in ./src/services/conflictResolutionService.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T19:19:01.679Z",
  "dateTo": "2025-08-12T19:20:01.679Z",
  "skip": 0,
  "limit": 1
}
[fetchContainmentTypeMetadata] API Response: 1 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [ '689b93bd44ce186ba541d6ea' ]
[getSessionsMetadataForConnectionTest] Single API call succeeded with 1 sessions
::1 - - [12/Aug/2025:19:20:04 +0000] "GET /api/kore/test HTTP/1.1" 200 851 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[Direct API] Fetching real Kore.ai sessions from 2025-08-05T19:20:05.294Z to 2025-08-12T19:20:05.294Z for User Bot st-90549... (limit=50)
Retrieving sessions from 2025-08-05T19:20:05.294Z to 2025-08-12T19:20:05.294Z (limit=50), populateMessages=true...
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T19:20:05.294Z",
  "dateTo": "2025-08-12T19:20:05.294Z",
  "limit": 50
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:20:05.294Z",
  "dateTo": "2025-08-12T19:20:05.294Z",
  "skip": 0,
  "limit": 50
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:20:05.294Z",
  "dateTo": "2025-08-12T19:20:05.294Z",
  "skip": 0,
  "limit": 50
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:20:05.294Z",
  "dateTo": "2025-08-12T19:20:05.294Z",
  "skip": 0,
  "limit": 50
}
::1 - - [12/Aug/2025:19:20:05 +0000] "GET /api/analysis/sessions?limit=50 HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 50 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b93beb1f082150b591b26',
  '689b93bd44ce186ba541d6ea',
  '689b939b144f8feea1854a2d'
]
[fetchContainmentTypeMetadata] API Response: 50 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b8fe43d161a676159eb16',
  '689b8f933360bd076e1b4ea3',
  '689b8f19995362de8df4b528'
]
[fetchContainmentTypeMetadata] API Response: 50 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b93e23f6da016cf8818e4',
  '689b93dfcc9c7f5ad06c1ab4',
  '689b93d009b0d5860d00ef24'
]
[getSessionsMetadata] agent API call succeeded with 50 sessions
[getSessionsMetadata] selfService API call succeeded with 50 sessions
[getSessionsMetadata] dropOff API call succeeded with 50 sessions
Total session metadata retrieved: 150 (parallel execution)
Retrieved 150 session metadata objects
Creating 150 SWTs from metadata (no messages)
Created 150 SWT objects from metadata
Populating messages for all sessions (legacy behavior)
Populating messages for 150 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 150 sessions from 2025-08-12T17:59:03.292Z to 2025-08-12T19:20:04.273Z at 2025-08-12T19:20:10.297Z
ğŸš€ [ConcurrentBatch] Split 150 sessions into 8 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/8] Starting: 20 sessions
[Batch 2/8] Starting: 20 sessions
[Batch 3/8] Starting: 20 sessions
[Batch 4/8] Starting: 20 sessions
[Batch 5/8] Starting: 20 sessions
[Batch 6/8] Starting: 20 sessions
[Batch 7/8] Starting: 20 sessions
[Batch 8/8] Starting: 10 sessions
[Batch 1/8] Completed in 254ms: 219 messages retrieved (1/8 done)
[Batch 2/8] Completed in 256ms: 213 messages retrieved (2/8 done)
[Batch 3/8] Completed in 262ms: 224 messages retrieved (3/8 done)
[Batch 8/8] Completed in 479ms: 92 messages retrieved (4/8 done)
[Batch 4/8] Completed in 508ms: 264 messages retrieved (5/8 done)
[Batch 6/8] Completed in 514ms: 181 messages retrieved (6/8 done)
[Batch 7/8] Completed in 597ms: 283 messages retrieved (7/8 done)
[Batch 5/8] Completed in 656ms: 491 messages retrieved (8/8 done)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 657ms (0.66s)
â±ï¸  Batch Processing: 657ms (0.66s)
ğŸ“¦ Total batches: 8 (max 10 concurrent)
âœ… Successful batches: 8/8
ğŸ’¬ Total messages: 1967
ğŸ“ˆ Avg time per batch: 82ms
ğŸš€ Time per session: 4ms
ğŸ’ª Performance: 228.3 sessions/second
=======================================================

Retrieved 1967 messages for 150 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
Populated messages for 150 SWT objects
Generated 150 SWT objects in 5679ms using layered architecture
ğŸš€ [ParallelAutoAnalyzeRoute] Starting parallel analysis for bot ***REMOVED*** with real credentials
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
ğŸ­ ServiceFactory: Creating OpenAI service (type: real)
ğŸš€ [ParallelAutoAnalyzeService] Starting parallel analysis 84ca25b1-6c7f-46d4-aacb-4a97af62e445 with bot ***REMOVED***
ğŸš€ [ParallelAutoAnalyzeService] Using credentials: real
ğŸš€ [ParallelAutoAnalyzeRoute] Parallel analysis started: 84ca25b1-6c7f-46d4-aacb-4a97af62e445
::1 - - [12/Aug/2025:19:20:23 +0000] "POST /api/analysis/auto-analyze/parallel/start HTTP/1.1" 200 214 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:20:23 +0000] "GET /api/analysis/auto-analyze/parallel/progress/84ca25b1-6c7f-46d4-aacb-4a97af62e445 HTTP/1.1" 200 541 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:20:23 +0000] "GET /api/analysis/auto-analyze/parallel/progress/84ca25b1-6c7f-46d4-aacb-4a97af62e445 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[BackgroundJobQueue] Starting job processing after delay for job 84ca25b1-6c7f-46d4-aacb-4a97af62e445-parallel
[BackgroundJobQueue] Starting processing for job 84ca25b1-6c7f-46d4-aacb-4a97af62e445-parallel, phase: sampling
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing parallel analysis job 84ca25b1-6c7f-46d4-aacb-4a97af62e445-parallel
[BackgroundJobQueue] Processing parallel analysis for bot ***REMOVED***
[BackgroundJobQueue] Using existing ParallelAutoAnalyzeService instance for bot ***REMOVED***
[BackgroundJobQueue] Session recreated for 84ca25b1-6c7f-46d4-aacb-4a97af62e445
[ParallelAutoAnalyzeService] Running parallel analysis for 84ca25b1-6c7f-46d4-aacb-4a97af62e445
[ParallelAutoAnalyzeService] Phase 0: Starting session sampling for 84ca25b1-6c7f-46d4-aacb-4a97af62e445

ğŸ• ============ SESSION SAMPLING STARTED ============
ğŸ• [SessionSampling] Starting session sampling at 2025-08-12T19:20:24.846Z
ğŸ” [SessionDiscovery] Starting window 1/4: Initial 3-hour window
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
::1 - - [12/Aug/2025:19:20:25 +0000] "GET /api/analysis/auto-analyze/parallel/progress/84ca25b1-6c7f-46d4-aacb-4a97af62e445 HTTP/1.1" 200 717 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 80 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a1287849680ad9fe59e',
  '689229f9583056c6108e38fb',
  '68922914f8bee7ba6c3e67b8'
]
[fetchContainmentTypeMetadata] API Response: 139 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6a14dd27c3112087cd',
  '68922a22ef03d8ad2ec7b4ba',
  '68922a1278c1fe09a079719c'
]
::1 - - [12/Aug/2025:19:20:27 +0000] "GET /api/analysis/auto-analyze/parallel/progress/84ca25b1-6c7f-46d4-aacb-4a97af62e445 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 1338 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6d14dd27c31120888b',
  '68922a62e3804084741191d5',
  '68922a523a3160d25de144c8'
]
[getSessionsMetadata] agent API call succeeded with 1338 sessions
[getSessionsMetadata] selfService API call succeeded with 80 sessions
[getSessionsMetadata] dropOff API call succeeded with 139 sessions
Total session metadata retrieved: 1557 (parallel execution)
Creating 1557 SWTs from metadata (no messages)
Created 1557 SWT objects from metadata
âœ… [SessionDiscovery] Window 1 completed in 4712ms: found 1557 new sessions (total: 1557)
â±ï¸  TIMING: Window 1 took 4712ms (4.71s)
ğŸ¯ [SessionDiscovery] Target reached! Found 1557 sessions in 4713ms
ğŸ² [SessionSampling] Random sampling from 1557 sessions to 10 sessions

ğŸ“¬ ============ MESSAGE RETRIEVAL STARTED ============
ğŸ“¬ [MessageRetrieval] Starting message retrieval for 10 sampled sessions at 2025-08-12T19:20:29.560Z
Using new lazy loading approach to populate messages for 10 sampled sessions
Populating messages for 10 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 10 sessions from 2025-08-05T13:11:42.889Z to 2025-08-05T15:54:11.210Z at 2025-08-12T19:20:29.560Z
ğŸ”„ [KoreAPI] Using single API call for 10 sessions (â‰¤20)
âœ… [KoreAPI] Single call completed in 330ms: 181 messages
Retrieved 181 messages for 10 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
Populated messages for 10 SWT objects
Successfully populated messages for 10 sessions using lazy loading
Applying final filtering to 10 sessions with populated messages
Final result: 10 sessions passed filtering with populated messages

ğŸ‰ ============ SESSION SAMPLING COMPLETED ============
â±ï¸  TOTAL TIME: 5045ms (5.04s)
â±ï¸  Session Discovery: 4713ms (4.71s) - 93.4% of total
â±ï¸  Message Retrieval: 331ms (0.33s) - 6.6% of total
â±ï¸  Performance: 2.0 sessions/second
ğŸ¯ Final result: 10 sessions with messages retrieved
====================================================

[StrategicDiscoveryService] Starting discovery phase with 10 total sessions
[StrategicDiscoveryService] Discovery config: {
  targetPercentage: 15,
  minSessions: 5,
  maxSessions: 5,
  diversityStrategy: {
    sessionLengths: [ 'short', 'medium', 'long' ],
    containmentTypes: [ 'agent', 'selfService', 'dropOff' ],
    timeDistribution: 'spread'
  }
}
[StrategicDiscoveryService] Selecting 5 diverse sessions from 10 total
[StrategicDiscoveryService] Session diversity groups: { short: 2, medium: 8, early: 3, middle: 3, late: 4 }
[StrategicDiscoveryService] Selected sessions by length distribution: { short: 1, medium: 4, long: 0 }
[StrategicDiscoveryService] Selected 5 sessions for discovery

ğŸ“¦ ===== BATCH 1 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T19:20:29.893Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 0
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T19:20:29.894Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:20:29.896Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7887,
  existingClassifications: { intents: 0, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.



For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and another intent, classify the intent as the other i...
::1 - - [12/Aug/2025:19:20:29 +0000] "GET /api/analysis/auto-analyze/parallel/progress/84ca25b1-6c7f-46d4-aacb-4a97af62e445 HTTP/1.1" 200 830 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:20:31 +0000] "GET /api/analysis/auto-analyze/parallel/progress/84ca25b1-6c7f-46d4-aacb-4a97af62e445 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:20:33.254Z',
  duration: '3357ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2221,
    completion_tokens: 235,
    total_tokens: 2456,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-8b58df25-6e61-5116-9358-477e9c3e9cfa",
      "notes": "Session involved a transfer to a live agent for claim assistance."
    },
    {
      "user_id": "u-2ae89bc0-ca86-5950-b4b3-80f461c8683c",
      "notes": "Session involved a language barrier and incomplete information, ending with session closure."
    },
    {
      "user_id": "u-7d25027f-e704-5b5d-91fe-66c4601a94ca",
      "notes": "Session involved a transfer to a live agent after user input."
    },
    {
      "user_id": "u-28c453c4-6fb8-5cf9-a0e2-cb63f14b7c56",
      "notes": "Session successfully handled a claim report and ended without transfer."
    },
    {
      "user_id": "u-aa4f9d21-4206-569e-9c1b-b1319442f57a",
      "notes": "Session involved a transfer to a live agent after user requested to cancel a leave request."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2221,
  completionTokens: 235,
  totalTokens: 2456,
  cost: '$0.000316',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 3360ms (3.36s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2456 ($0.0003)
âš¡ Performance: 731.0 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 3360ms (3.36s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2456

âœ… ===== BATCH 1 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 3361ms (3.36s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2456 ($0.0003)
âš¡ Performance: 1.5 sessions/sec
âš¡ Avg Time Per Session: 672.20ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 1 complete: 1 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 1, reasons: 0, locations: 0, total: 1 }
[StrategicDiscoveryService] Discovery phase complete: {
  totalProcessed: 5,
  uniqueIntents: 1,
  uniqueReasons: 0,
  uniqueLocations: 0,
  discoveryRate: 0.06666666666666667
}

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T19:20:33.255Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms
[ParallelProcessingOrchestrator] Configuration for 5 sessions:
  Design: 8 streams Ã— 4 sessions = 32 per round
  Optimal: 2 streams Ã— 3 sessions = 6 per round
  Estimated Rounds: 1
[ParallelAutoAnalyzeService] Using parallel config: {
  streamCount: 2,
  sessionsPerStream: 3,
  maxSessionsPerLLMCall: 50,
  syncFrequency: 'after_each_round',
  retryAttempts: 3,
  debugLogging: false
}

ğŸš€ ============ PARALLEL PROCESSING STARTED ============
â±ï¸  Start Time: 2025-08-12T19:20:33.274Z
ğŸ“Š Total Sessions: 5

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T19:20:33.274Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms

âš™ï¸  ============ PARALLEL CONFIGURATION ============
â±ï¸  Config Time: 0ms
ğŸ”§ Stream Count: 2
ğŸ“¦ Sessions Per Stream: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per API Call: 50
ğŸ¯ Debug Logging: false

ğŸ”„ ============ ROUND 1/1 STARTED ============
â±ï¸  Round 1 Start: 2025-08-12T19:20:33.274Z
ğŸ“Š Sessions Remaining: 5
[ParallelProcessingOrchestrator] Distributed 5 sessions across 2 streams: [ 'Stream 1: 3 sessions', 'Stream 2: 2 sessions' ]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 2

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 2 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T19:20:33.275Z
ğŸ“Š Sessions Assigned: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:20:33.275Z
ğŸ“Š Sessions to Estimate: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 3
   â€¢ Session Tokens: 842
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6342
   â€¢ Avg Per Session: 281 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6342
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 3

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6342
ğŸ“¦ Recommended Batch Size: 3
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:20:33.276Z
ğŸ“Š Sessions to Analyze: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 1
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:20:33.276Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 3,
  apiKey: 'sk-proj-...',
  promptLength: 6614,
  existingClassifications: { intents: 1, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Unknown

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and a...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T19:20:33.276Z
ğŸ“Š Sessions Assigned: 2
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:20:33.276Z
ğŸ“Š Sessions to Estimate: 2
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 2
   â€¢ Session Tokens: 694
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6194
   â€¢ Avg Per Session: 347 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6194
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 2

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6194
ğŸ“¦ Recommended Batch Size: 2
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:20:33.276Z
ğŸ“Š Sessions to Analyze: 2
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 1
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:20:33.276Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 2,
  apiKey: 'sk-proj-...',
  promptLength: 6103,
  existingClassifications: { intents: 1, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Unknown

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and a...
::1 - - [12/Aug/2025:19:20:33 +0000] "GET /api/analysis/auto-analyze/parallel/progress/84ca25b1-6c7f-46d4-aacb-4a97af62e445 HTTP/1.1" 200 1054 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:20:35.278Z',
  duration: '2002ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1868,
    completion_tokens: 153,
    total_tokens: 2021,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 3,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-b9fdf33d-ffa8-5c34-9bea-981aceea8caa",
      "notes": "User attempted to submit a time entry but was transferred to an agent after requesting to speak with a person."
    },
    {
      "user_id": "u-431f2503-0f11-50ed-b6bd-3bf4462321ff",
      "notes": "User requested to speak to an agent, and the session was transferred to a live agent."
    },
    {
      "user_id": "u-39668043-0249-553e-bbc4-1d3de2fb8766",
      "notes": "User requested to speak to an agent, and the session was transferred to a live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1868,
  completionTokens: 153,
  totalTokens: 2021,
  cost: '$0.000248',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2003ms (2.00s)
ğŸ“Š Sessions Returned: 3
ğŸ’° Tokens Used: 2021 ($0.0002)
âš¡ Performance: 1009.0 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1868
   â€¢ Completion Tokens: 153
[SessionValidationService] Validating batch response: 3 input sessions, 3 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-b9fdf33d-ffa8-5c34-9bea-981aceea8caa: Invalid general_intent, u-b9fdf33d-ffa8-5c34-9bea-981aceea8caa: Invalid session_outcome, u-431f2503-0f11-50ed-b6bd-3bf4462321ff: Invalid general_intent, u-431f2503-0f11-50ed-b6bd-3bf4462321ff: Invalid session_outcome, u-39668043-0249-553e-bbc4-1d3de2fb8766: Invalid general_intent, u-39668043-0249-553e-bbc4-1d3de2fb8766: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 3 input sessions, 3 response sessions
[SessionValidationService] Validation successful: all 3 sessions processed
â±ï¸  Stream 1 Single Batch Time: 2006ms (2.01s)

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 2006ms (2.01s)
ğŸ“Š Sessions Processed: 3/3
ğŸ’° Tokens Used: 2021 ($0.0002)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.5 sessions/sec
âš¡ Avg Time Per Session: 668.67ms
::1 - - [12/Aug/2025:19:20:35 +0000] "GET /api/analysis/auto-analyze/parallel/progress/84ca25b1-6c7f-46d4-aacb-4a97af62e445 HTTP/1.1" 200 1056 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:20:37.624Z',
  duration: '4348ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1744,
    completion_tokens: 157,
    total_tokens: 1901,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 2,
  intentsFound: [ 'Live Agent', 'Unknown' ],
  transferCount: 1,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-01fe2ea4-45b7-524a-8cf3-cb006ee0a1a9",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred to an agent."
    },
    {
      "user_id": "u-b3dc217a-2fd1-5f0e-bb10-33c8049ef2e9",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User interacted with the bot to verify account details and submit a time entry, then requested to speak with a representative, but was transferred at the end."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1744,
  completionTokens: 157,
  totalTokens: 1901,
  cost: '$0.000237',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 4348ms (4.35s)
ğŸ“Š Sessions Returned: 2
ğŸ’° Tokens Used: 1901 ($0.0002)
âš¡ Performance: 437.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1744
   â€¢ Completion Tokens: 157
[SessionValidationService] Validating batch response: 2 input sessions, 2 response sessions
[SessionValidationService] Validation successful: all 2 sessions processed
[SessionValidationService] Validating batch response: 2 input sessions, 2 response sessions
[SessionValidationService] Validation successful: all 2 sessions processed
â±ï¸  Stream 2 Single Batch Time: 4349ms (4.35s)
[StreamProcessingService] Discovered 3 new classifications: { intents: 1, reasons: 1, locations: 1 }

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 4349ms (4.35s)
ğŸ“Š Sessions Processed: 2/2
ğŸ’° Tokens Used: 1901 ($0.0002)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.5 sessions/sec
âš¡ Avg Time Per Session: 2174.50ms
[ParallelProcessingOrchestrator] Parallel processing complete: 2/2 streams succeeded
â±ï¸  Parallel Processing Time: 4351ms (4.35s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 2 streams
[ParallelProcessingOrchestrator] Synchronization complete: 3 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 3
ğŸ“Š Total Classifications: 4

âœ… ============ ROUND 1 COMPLETED ============
â±ï¸  Round 1 Total Time: 4351ms (4.35s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 0
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 4351ms (100.0%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ‰ ============ PARALLEL PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 4351ms (4.35s)
ğŸ“Š Sessions Processed: 5/5
ğŸ”„ Total Rounds: 1
ğŸŒŠ Stream Results: 2
ğŸ’° Token Usage: 3922 tokens ($0.0005)
ğŸ“ˆ Stream Utilization: 100.0%
ğŸ¯ Performance: 1.1 sessions/second
âš¡ Avg Time Per Session: 870.20ms

ğŸ“Š Stream Performance Breakdown:
   Stream 1: 3 sessions in 2006ms (1007.5 tokens/sec)
   Stream 2: 2 sessions in 4349ms (437.1 tokens/sec)
[ConflictResolutionService] Starting conflict resolution for 10 sessions
[ConflictResolutionService] Found classifications: { intents: 2, reasons: 1, locations: 1 }
[ConflictResolutionService] No conflicts detected, skipping resolution
[ParallelAutoAnalyzeService] Using real analysis summary service
::1 - - [12/Aug/2025:19:20:37 +0000] "GET /api/analysis/auto-analyze/parallel/progress/84ca25b1-6c7f-46d4-aacb-4a97af62e445 HTTP/1.1" 200 1151 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:20:39 +0000] "GET /api/analysis/auto-analyze/parallel/progress/84ca25b1-6c7f-46d4-aacb-4a97af62e445 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:20:41 +0000] "GET /api/analysis/auto-analyze/parallel/progress/84ca25b1-6c7f-46d4-aacb-4a97af62e445 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:20:43 +0000] "GET /api/analysis/auto-analyze/parallel/progress/84ca25b1-6c7f-46d4-aacb-4a97af62e445 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:20:45 +0000] "GET /api/analysis/auto-analyze/parallel/progress/84ca25b1-6c7f-46d4-aacb-4a97af62e445 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:20:47 +0000] "GET /api/analysis/auto-analyze/parallel/progress/84ca25b1-6c7f-46d4-aacb-4a97af62e445 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:20:49 +0000] "GET /api/analysis/auto-analyze/parallel/progress/84ca25b1-6c7f-46d4-aacb-4a97af62e445 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[ParallelAutoAnalyzeService] Parallel analysis 84ca25b1-6c7f-46d4-aacb-4a97af62e445 completed successfully
[BackgroundJobQueue] Updated job progress to final state: complete
[BackgroundJobQueue] Parallel analysis job 84ca25b1-6c7f-46d4-aacb-4a97af62e445-parallel completed successfully
::1 - - [12/Aug/2025:19:20:51 +0000] "GET /api/analysis/auto-analyze/parallel/progress/84ca25b1-6c7f-46d4-aacb-4a97af62e445 HTTP/1.1" 200 1175 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:20:51 +0000] "GET /api/analysis/auto-analyze/parallel/results/84ca25b1-6c7f-46d4-aacb-4a97af62e445 HTTP/1.1" 200 93720 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T19:21:47.308Z",
  "dateTo": "2025-08-12T19:22:47.308Z",
  "skip": 0,
  "limit": 1
}
[fetchContainmentTypeMetadata] API Response: 1 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [ '689b945c1fa10dad3ea3fb62' ]
[getSessionsMetadataForConnectionTest] Single API call succeeded with 1 sessions
::1 - - [12/Aug/2025:19:22:50 +0000] "GET /api/kore/test HTTP/1.1" 200 851 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[Direct API] Fetching real Kore.ai sessions from 2025-08-05T19:22:50.911Z to 2025-08-12T19:22:50.911Z for User Bot st-90549... (limit=50)
Retrieving sessions from 2025-08-05T19:22:50.911Z to 2025-08-12T19:22:50.911Z (limit=50), populateMessages=true...
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T19:22:50.911Z",
  "dateTo": "2025-08-12T19:22:50.911Z",
  "limit": 50
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:22:50.911Z",
  "dateTo": "2025-08-12T19:22:50.911Z",
  "skip": 0,
  "limit": 50
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:22:50.911Z",
  "dateTo": "2025-08-12T19:22:50.911Z",
  "skip": 0,
  "limit": 50
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:22:50.911Z",
  "dateTo": "2025-08-12T19:22:50.911Z",
  "skip": 0,
  "limit": 50
}
::1 - - [12/Aug/2025:19:22:51 +0000] "GET /api/analysis/sessions?limit=50 HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 50 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b9484f54cdbf3def705e1',
  '689b9484618775e3b37cd19c',
  '689b9482025fed0098656087'
]
[fetchContainmentTypeMetadata] API Response: 50 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b9466b95843b7901ecde4',
  '689b945c1fa10dad3ea3fb62',
  '689b945544ce186ba541f1fc'
]
[fetchContainmentTypeMetadata] API Response: 50 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b8fe7144f8feea184ac65',
  '689b8fe43d161a676159eb16',
  '689b8f933360bd076e1b4ea3'
]
[getSessionsMetadata] agent API call succeeded with 50 sessions
[getSessionsMetadata] selfService API call succeeded with 50 sessions
[getSessionsMetadata] dropOff API call succeeded with 50 sessions
Total session metadata retrieved: 150 (parallel execution)
Retrieved 150 session metadata objects
Creating 150 SWTs from metadata (no messages)
Created 150 SWT objects from metadata
Populating messages for all sessions (legacy behavior)
Populating messages for 150 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 150 sessions from 2025-08-12T17:59:42.789Z to 2025-08-12T19:22:49.686Z at 2025-08-12T19:23:05.788Z
ğŸš€ [ConcurrentBatch] Split 150 sessions into 8 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/8] Starting: 20 sessions
[Batch 2/8] Starting: 20 sessions
[Batch 3/8] Starting: 20 sessions
[Batch 4/8] Starting: 20 sessions
[Batch 5/8] Starting: 20 sessions
[Batch 6/8] Starting: 20 sessions
[Batch 7/8] Starting: 20 sessions
[Batch 8/8] Starting: 10 sessions
[Batch 3/8] Completed in 259ms: 144 messages retrieved (1/8 done)
[Batch 2/8] Completed in 291ms: 236 messages retrieved (2/8 done)
[Batch 1/8] Completed in 429ms: 200 messages retrieved (3/8 done)
[Batch 8/8] Completed in 466ms: 76 messages retrieved (4/8 done)
[Batch 4/8] Completed in 624ms: 290 messages retrieved (5/8 done)
[Batch 6/8] Completed in 630ms: 199 messages retrieved (6/8 done)
[Batch 7/8] Completed in 644ms: 276 messages retrieved (7/8 done)
[Batch 5/8] Completed in 680ms: 382 messages retrieved (8/8 done)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 680ms (0.68s)
â±ï¸  Batch Processing: 680ms (0.68s)
ğŸ“¦ Total batches: 8 (max 10 concurrent)
âœ… Successful batches: 8/8
ğŸ’¬ Total messages: 1803
ğŸ“ˆ Avg time per batch: 85ms
ğŸš€ Time per session: 5ms
ğŸ’ª Performance: 220.6 sessions/second
=======================================================

Retrieved 1803 messages for 150 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
Populated messages for 150 SWT objects
Generated 150 SWT objects in 15565ms using layered architecture
ğŸš€ [ParallelAutoAnalyzeRoute] Starting parallel analysis for bot ***REMOVED*** with real credentials
ğŸš€ [ParallelAutoAnalyzeService] Starting parallel analysis b3926172-8317-4b7f-880a-49131acc1649 with bot ***REMOVED***
ğŸš€ [ParallelAutoAnalyzeService] Using credentials: real
ğŸš€ [ParallelAutoAnalyzeRoute] Parallel analysis started: b3926172-8317-4b7f-880a-49131acc1649
::1 - - [12/Aug/2025:19:23:09 +0000] "POST /api/analysis/auto-analyze/parallel/start HTTP/1.1" 200 214 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:23:09 +0000] "GET /api/analysis/auto-analyze/parallel/progress/b3926172-8317-4b7f-880a-49131acc1649 HTTP/1.1" 200 542 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:23:09 +0000] "GET /api/analysis/auto-analyze/parallel/progress/b3926172-8317-4b7f-880a-49131acc1649 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[BackgroundJobQueue] Starting job processing after delay for job b3926172-8317-4b7f-880a-49131acc1649-parallel
[BackgroundJobQueue] Starting processing for job b3926172-8317-4b7f-880a-49131acc1649-parallel, phase: sampling
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing parallel analysis job b3926172-8317-4b7f-880a-49131acc1649-parallel
[BackgroundJobQueue] Processing parallel analysis for bot ***REMOVED***
[BackgroundJobQueue] Using existing ParallelAutoAnalyzeService instance for bot ***REMOVED***
[BackgroundJobQueue] Session recreated for b3926172-8317-4b7f-880a-49131acc1649
[ParallelAutoAnalyzeService] Running parallel analysis for b3926172-8317-4b7f-880a-49131acc1649
[ParallelAutoAnalyzeService] Phase 0: Starting session sampling for b3926172-8317-4b7f-880a-49131acc1649

ğŸ• ============ SESSION SAMPLING STARTED ============
ğŸ• [SessionSampling] Starting session sampling at 2025-08-12T19:23:10.683Z
ğŸ” [SessionDiscovery] Starting window 1/4: Initial 3-hour window
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
::1 - - [12/Aug/2025:19:23:11 +0000] "GET /api/analysis/auto-analyze/parallel/progress/b3926172-8317-4b7f-880a-49131acc1649 HTTP/1.1" 200 719 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 80 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a1287849680ad9fe59e',
  '689229f9583056c6108e38fb',
  '68922914f8bee7ba6c3e67b8'
]
[fetchContainmentTypeMetadata] API Response: 139 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6a14dd27c3112087cd',
  '68922a22ef03d8ad2ec7b4ba',
  '68922a1278c1fe09a079719c'
]
::1 - - [12/Aug/2025:19:23:13 +0000] "GET /api/analysis/auto-analyze/parallel/progress/b3926172-8317-4b7f-880a-49131acc1649 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 1338 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6d14dd27c31120888b',
  '68922a62e3804084741191d5',
  '68922a523a3160d25de144c8'
]
[getSessionsMetadata] agent API call succeeded with 1338 sessions
[getSessionsMetadata] selfService API call succeeded with 80 sessions
[getSessionsMetadata] dropOff API call succeeded with 139 sessions
Total session metadata retrieved: 1557 (parallel execution)
Creating 1557 SWTs from metadata (no messages)
Created 1557 SWT objects from metadata
âœ… [SessionDiscovery] Window 1 completed in 3768ms: found 1557 new sessions (total: 1557)
â±ï¸  TIMING: Window 1 took 3768ms (3.77s)
ğŸ¯ [SessionDiscovery] Target reached! Found 1557 sessions in 3769ms
ğŸ² [SessionSampling] Random sampling from 1557 sessions to 100 sessions

ğŸ“¬ ============ MESSAGE RETRIEVAL STARTED ============
ğŸ“¬ [MessageRetrieval] Starting message retrieval for 100 sampled sessions at 2025-08-12T19:23:14.455Z
Using new lazy loading approach to populate messages for 100 sampled sessions
Populating messages for 100 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 100 sessions from 2025-08-05T13:01:34.009Z to 2025-08-05T15:59:42.366Z at 2025-08-12T19:23:14.455Z
ğŸš€ [ConcurrentBatch] Split 100 sessions into 5 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/5] Starting: 20 sessions
[Batch 2/5] Starting: 20 sessions
[Batch 3/5] Starting: 20 sessions
[Batch 4/5] Starting: 20 sessions
[Batch 5/5] Starting: 20 sessions
[Batch 3/5] Completed in 328ms: 239 messages retrieved (1/5 done)
ğŸ“Š [BatchProgress] Reporting batch 1/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 40/100 sessions (Batch 2/5)
[Batch 2/5] Completed in 344ms: 230 messages retrieved (2/5 done)
ğŸ“Š [BatchProgress] Reporting batch 2/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 60/100 sessions (Batch 3/5)
[Batch 1/5] Completed in 347ms: 248 messages retrieved (3/5 done)
ğŸ“Š [BatchProgress] Reporting batch 3/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 80/100 sessions (Batch 4/5)
[Batch 5/5] Completed in 663ms: 285 messages retrieved (4/5 done)
ğŸ“Š [BatchProgress] Reporting batch 4/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 100/100 sessions (Batch 5/5)
[Batch 4/5] Completed in 689ms: 288 messages retrieved (5/5 done)
ğŸ“Š [BatchProgress] Reporting batch 5/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 100/100 sessions (Batch 6/5)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 689ms (0.69s)
â±ï¸  Batch Processing: 689ms (0.69s)
ğŸ“¦ Total batches: 5 (max 10 concurrent)
âœ… Successful batches: 5/5
ğŸ’¬ Total messages: 1290
ğŸ“ˆ Avg time per batch: 138ms
ğŸš€ Time per session: 7ms
ğŸ’ª Performance: 145.1 sessions/second
=======================================================

Retrieved 1290 messages for 100 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
Populated messages for 100 SWT objects
Successfully populated messages for 100 sessions using lazy loading
Applying final filtering to 100 sessions with populated messages
Final result: 100 sessions passed filtering with populated messages

ğŸ‰ ============ SESSION SAMPLING COMPLETED ============
â±ï¸  TOTAL TIME: 4468ms (4.47s)
â±ï¸  Session Discovery: 3769ms (3.77s) - 84.4% of total
â±ï¸  Message Retrieval: 696ms (0.70s) - 15.6% of total
â±ï¸  Performance: 22.4 sessions/second
ğŸ¯ Final result: 100 sessions with messages retrieved
====================================================

[StrategicDiscoveryService] Starting discovery phase with 100 total sessions
[StrategicDiscoveryService] Discovery config: {
  targetPercentage: 15,
  minSessions: 10,
  maxSessions: 15,
  diversityStrategy: {
    sessionLengths: [ 'short', 'medium', 'long' ],
    containmentTypes: [ 'agent', 'selfService', 'dropOff' ],
    timeDistribution: 'spread'
  }
}
[StrategicDiscoveryService] Selecting 15 diverse sessions from 100 total
[StrategicDiscoveryService] Session diversity groups: { short: 28, medium: 72, early: 33, middle: 33, late: 34 }
[StrategicDiscoveryService] Selected sessions by length distribution: { short: 8, medium: 7, long: 0 }
[StrategicDiscoveryService] Selected 15 sessions for discovery

ğŸ“¦ ===== BATCH 2 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T19:23:15.153Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 0
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T19:23:15.153Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:23:15.153Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6118,
  existingClassifications: { intents: 0, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.



For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and another intent, classify the intent as the other i...
::1 - - [12/Aug/2025:19:23:15 +0000] "GET /api/analysis/auto-analyze/parallel/progress/b3926172-8317-4b7f-880a-49131acc1649 HTTP/1.1" 200 934 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:23:17 +0000] "GET /api/analysis/auto-analyze/parallel/progress/b3926172-8317-4b7f-880a-49131acc1649 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:23:18.217Z',
  duration: '3064ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1777,
    completion_tokens: 354,
    total_tokens: 2131,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Claim Status', 'Unknown', 'Live Agent' ],
  transferCount: 4,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-3dbb6657-abe1-5583-8594-0f5600a00c0f",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to file a claim and was transferred to a live agent."
    },
    {
      "user_id": "u-01e6783a-3d62-5fb0-a980-64d59fe1546b",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User was silent and did not respond, session ended without transfer."
    },
    {
      "user_id": "u-df1ed592-2472-5bfd-beab-b279a1403022",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred to an agent."
    },
    {
      "user_id": "u-1d2f507d-38f1-5af1-993f-4c7dfa700268",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User reported employee number not in system and was transferred to a live agent."
    },
    {
      "user_id": "u-569381e4-050c-50c9-beac-9da84fddbf50",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to talk to a representative and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1777,
  completionTokens: 354,
  totalTokens: 2131,
  cost: '$0.000319',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 3065ms (3.06s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2131 ($0.0003)
âš¡ Performance: 695.3 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 3065ms (3.06s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2131

âœ… ===== BATCH 2 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 3065ms (3.06s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2131 ($0.0003)
âš¡ Performance: 1.6 sessions/sec
âš¡ Avg Time Per Session: 613.00ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 1 complete: 5 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 3, reasons: 1, locations: 1, total: 5 }

ğŸ“¦ ===== BATCH 3 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T19:23:18.218Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T19:23:18.219Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:23:18.219Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6448,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibili...
::1 - - [12/Aug/2025:19:23:19 +0000] "GET /api/analysis/auto-analyze/parallel/progress/b3926172-8317-4b7f-880a-49131acc1649 HTTP/1.1" 200 951 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:23:21.476Z',
  duration: '3257ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1841,
    completion_tokens: 371,
    total_tokens: 2212,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Live Agent', 'Unknown' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-1f70672b-27b4-5f71-becd-2b39429dd2c4",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred to an agent."
    },
    {
      "user_id": "u-55b21da4-61c2-56ac-9009-4dc87baab206",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred to an agent."
    },
    {
      "user_id": "u-d030a2df-e919-5ea7-83af-4365c45ec757",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and did not respond, leading to transfer to an agent."
    },
    {
      "user_id": "u-b2c85c77-c45b-5b21-9f25-96c909eef0ee",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred to an agent."
    },
    {
      "user_id": "u-ddbef90b-b3b1-5b45-93ce-12d5cd913c43",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and did not respond, leading to transfer to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1841,
  completionTokens: 371,
  totalTokens: 2212,
  cost: '$0.000333',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 3258ms (3.26s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2212 ($0.0003)
âš¡ Performance: 678.9 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 3258ms (3.26s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2212

âœ… ===== BATCH 3 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 3260ms (3.26s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2212 ($0.0003)
âš¡ Performance: 1.5 sessions/sec
âš¡ Avg Time Per Session: 652.00ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 2 complete: 0 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 3, reasons: 1, locations: 1, total: 5 }

ğŸ“¦ ===== BATCH 4 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T19:23:21.478Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T19:23:21.478Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:23:21.479Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6542,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibili...
::1 - - [12/Aug/2025:19:23:21 +0000] "GET /api/analysis/auto-analyze/parallel/progress/b3926172-8317-4b7f-880a-49131acc1649 HTTP/1.1" 200 951 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:23:23 +0000] "GET /api/analysis/auto-analyze/parallel/progress/b3926172-8317-4b7f-880a-49131acc1649 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:23:24.039Z',
  duration: '2560ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1881,
    completion_tokens: 363,
    total_tokens: 2244,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Live Agent', 'Claim Status', 'Unknown' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-7f31517c-a1a2-5760-8971-aa385a1defdf",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-dc7be4e0-0db9-5110-9c8e-567a2ac69f81",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User checked claim status and was transferred to an agent."
    },
    {
      "user_id": "u-4c9d959f-5e83-54c8-9fe2-3bf1e7ede932",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User checked FMLA status and was transferred to an agent."
    },
    {
      "user_id": "u-2be80988-5360-5c39-9a99-d3b6b05b8012",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User inquired about receiving paperwork and was transferred."
    },
    {
      "user_id": "u-10a7bce5-126d-59ee-a2cd-a8330a11dbb9",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User mentioned FMLA papers and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1881,
  completionTokens: 363,
  totalTokens: 2244,
  cost: '$0.000333',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2562ms (2.56s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2244 ($0.0003)
âš¡ Performance: 875.9 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2562ms (2.56s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2244

âœ… ===== BATCH 4 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2562ms (2.56s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2244 ($0.0003)
âš¡ Performance: 2.0 sessions/sec
âš¡ Avg Time Per Session: 512.40ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 3 complete: 0 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 3, reasons: 1, locations: 1, total: 5 }
[StrategicDiscoveryService] Discovery phase complete: {
  totalProcessed: 15,
  uniqueIntents: 3,
  uniqueReasons: 1,
  uniqueLocations: 1,
  discoveryRate: 0.3333333333333333
}

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T19:23:24.041Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms
[ParallelProcessingOrchestrator] Configuration for 85 sessions:
  Design: 8 streams Ã— 4 sessions = 32 per round
  Optimal: 8 streams Ã— 4 sessions = 32 per round
  Estimated Rounds: 3
[ParallelAutoAnalyzeService] Using parallel config: {
  streamCount: 8,
  sessionsPerStream: 4,
  maxSessionsPerLLMCall: 50,
  syncFrequency: 'after_each_round',
  retryAttempts: 3,
  debugLogging: false
}

ğŸš€ ============ PARALLEL PROCESSING STARTED ============
â±ï¸  Start Time: 2025-08-12T19:23:24.041Z
ğŸ“Š Total Sessions: 85

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T19:23:24.041Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms

âš™ï¸  ============ PARALLEL CONFIGURATION ============
â±ï¸  Config Time: 0ms
ğŸ”§ Stream Count: 8
ğŸ“¦ Sessions Per Stream: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per API Call: 50
ğŸ¯ Debug Logging: false

ğŸ”„ ============ ROUND 1/3 STARTED ============
â±ï¸  Round 1 Start: 2025-08-12T19:23:24.041Z
ğŸ“Š Sessions Remaining: 85
[ParallelProcessingOrchestrator] Distributed 32 sessions across 8 streams: [
  'Stream 1: 4 sessions',
  'Stream 2: 4 sessions',
  'Stream 3: 4 sessions',
  'Stream 4: 4 sessions',
  'Stream 5: 4 sessions',
  'Stream 6: 4 sessions',
  'Stream 7: 4 sessions',
  'Stream 8: 4 sessions'
]
â±ï¸  Session Distribution Time: 1ms
ğŸŒŠ Active Streams: 8

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 8 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T19:23:24.042Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:23:24.042Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 680
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6180
   â€¢ Avg Per Session: 170 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6180
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6180
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:23:24.042Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:23:24.043Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5836,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibili...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T19:23:24.043Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:23:24.043Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 736
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6236
   â€¢ Avg Per Session: 184 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6236
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6236
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:23:24.043Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:23:24.043Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6129,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibili...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T19:23:24.043Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:23:24.043Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 744
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6244
   â€¢ Avg Per Session: 186 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6244
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 1ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6244
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:23:24.044Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:23:24.044Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6163,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibili...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T19:23:24.044Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:23:24.044Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 1165
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6665
   â€¢ Avg Per Session: 291 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6665
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0011
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6665
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0011

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:23:24.044Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:23:24.044Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 8113,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibili...

ğŸŒŠ ===== STREAM 5 PROCESSING START =====
â±ï¸  Stream 5 Start: 2025-08-12T19:23:24.045Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:23:24.045Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 820
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6320
   â€¢ Avg Per Session: 205 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6320
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 5) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6320
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 5: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:23:24.045Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:23:24.045Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6542,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibili...

ğŸŒŠ ===== STREAM 6 PROCESSING START =====
â±ï¸  Stream 6 Start: 2025-08-12T19:23:24.045Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:23:24.045Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 849
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6349
   â€¢ Avg Per Session: 212 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6349
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 6) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6349
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 6: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:23:24.046Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:23:24.046Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6560,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibili...

ğŸŒŠ ===== STREAM 7 PROCESSING START =====
â±ï¸  Stream 7 Start: 2025-08-12T19:23:24.046Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:23:24.046Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 856
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6356
   â€¢ Avg Per Session: 214 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6356
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 7) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6356
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 7: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:23:24.046Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:23:24.047Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6667,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibili...

ğŸŒŠ ===== STREAM 8 PROCESSING START =====
â±ï¸  Stream 8 Start: 2025-08-12T19:23:24.047Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:23:24.047Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 737
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6237
   â€¢ Avg Per Session: 184 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6237
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 8) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6237
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 8: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:23:24.047Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:23:24.047Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6113,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibili...
::1 - - [12/Aug/2025:19:23:25 +0000] "GET /api/analysis/auto-analyze/parallel/progress/b3926172-8317-4b7f-880a-49131acc1649 HTTP/1.1" 200 1727 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:23:25.988Z',
  duration: '1941ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1881,
    completion_tokens: 267,
    total_tokens: 2148,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status', 'Unknown' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-c533b587-05ca-558a-a54e-821c84d37ca3",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User provided claim-related information and completed the process without transfer."
    },
    {
      "user_id": "u-ad8a401d-f819-50e4-b0de-933caf504220",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent, resulting in transfer."
    },
    {
      "user_id": "u-9c4d4fc0-3ff9-5f97-b069-04c5dd79f598",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent, resulting in transfer."
    },
    {
      "user_id": "u-42db6904-dd9e-5d72-a727-832839b6353d",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to open a new leave request, resulting in transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1881,
  completionTokens: 267,
  totalTokens: 2148,
  cost: '$0.000295',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1943ms (1.94s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2148 ($0.0003)
âš¡ Performance: 1105.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1881
   â€¢ Completion Tokens: 267
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 7 Single Batch Time: 1943ms (1.94s)

âœ… ===== STREAM 7 PROCESSING COMPLETE =====
â±ï¸  Stream 7 Total Time: 1943ms (1.94s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2148 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.1 sessions/sec
âš¡ Avg Time Per Session: 485.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:23:26.022Z',
  duration: '1979ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1686,
    completion_tokens: 300,
    total_tokens: 1986,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-be6580e8-5d15-52ca-ae47-6a2aec3f1d3a",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an operator and was transferred to an agent."
    },
    {
      "user_id": "u-10eeb355-4b7d-51b6-9847-c980a61a2a1c",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked to speak with someone about FMLA and was transferred to an agent."
    },
    {
      "user_id": "u-1a472c94-cb86-5877-a495-728a6ba47b6b",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested an agent and was transferred."
    },
    {
      "user_id": "u-4c7a0fee-83a3-5e4d-8164-eb40f2d97190",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked to speak with a representative and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1686,
  completionTokens: 300,
  totalTokens: 1986,
  cost: '$0.000289',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1981ms (1.98s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1986 ($0.0003)
âš¡ Performance: 1002.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1686
   â€¢ Completion Tokens: 300
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 1 Single Batch Time: 1981ms (1.98s)

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 1981ms (1.98s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1986 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.0 sessions/sec
âš¡ Avg Time Per Session: 495.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:23:26.111Z',
  duration: '2066ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1860,
    completion_tokens: 268,
    total_tokens: 2128,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Unknown' ],
  transferCount: 2,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-55ffa683-dc43-5cee-9d80-d257ce282bb4",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an operator and was transferred to a live agent."
    },
    {
      "user_id": "u-b21c8307-121c-55db-81ca-f72ebd160b91",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a customer service representative and was transferred to a live agent."
    },
    {
      "user_id": "u-14c8cfd1-d015-565c-9e58-083ac59e1f09",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User attempted to apply for maternity leave but was transferred after failing to provide required information."
    },
    {
      "user_id": "u-25bde93a-b323-528e-9528-1c834a8f84ef",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User reported return to work; session was handled by bot without transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1860,
  completionTokens: 268,
  totalTokens: 2128,
  cost: '$0.000293',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2067ms (2.07s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2128 ($0.0003)
âš¡ Performance: 1029.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1860
   â€¢ Completion Tokens: 268
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 5 Single Batch Time: 2067ms (2.07s)

âœ… ===== STREAM 5 PROCESSING COMPLETE =====
â±ï¸  Stream 5 Total Time: 2067ms (2.07s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2128 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.9 sessions/sec
âš¡ Avg Time Per Session: 516.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:23:26.267Z',
  duration: '2224ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1755,
    completion_tokens: 284,
    total_tokens: 2039,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Claim Status', 'Unknown' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-a9ffd182-223c-50c6-84ba-2bf86cac602e",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a support agent and was transferred."
    },
    {
      "user_id": "u-196643d5-dde0-5df7-91e7-7ec73532dbf1",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User inquired about claim status, provided details, and requested email resend, but was not transferred."
    },
    {
      "user_id": "u-7558688c-044b-5f1a-9a77-b8f83d3f2a43",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a new leave request and was transferred to an agent."
    },
    {
      "user_id": "u-12974d99-8a76-5378-876d-2b2bf940bd29",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1755,
  completionTokens: 284,
  totalTokens: 2039,
  cost: '$0.000289',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2224ms (2.22s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2039 ($0.0003)
âš¡ Performance: 916.8 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1755
   â€¢ Completion Tokens: 284
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 2 Single Batch Time: 2224ms (2.22s)

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 2224ms (2.22s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2039 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.8 sessions/sec
âš¡ Avg Time Per Session: 556.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:23:26.273Z',
  duration: '2226ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1751,
    completion_tokens: 220,
    total_tokens: 1971,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status' ],
  transferCount: 2,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-ae29009c-1f31-5ba9-a772-96521d888438",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-9b4cffc2-18b7-5ec8-b37c-edfbf3c8e7bb",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": ""
    },
    {
      "user_id": "u-c550432a-eada-51de-a5e6-2b0f5a49ad19",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": ""
    },
    {
      "user_id": "u-ba29892b-2ed3-5535-9112-33a3c6c5bcc0",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1751,
  completionTokens: 220,
  totalTokens: 1971,
  cost: '$0.000263',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2226ms (2.23s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1971 ($0.0003)
âš¡ Performance: 885.4 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1751
   â€¢ Completion Tokens: 220
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-ae29009c-1f31-5ba9-a772-96521d888438: Invalid notes, u-9b4cffc2-18b7-5ec8-b37c-edfbf3c8e7bb: Invalid notes, u-c550432a-eada-51de-a5e6-2b0f5a49ad19: Invalid notes, u-ba29892b-2ed3-5535-9112-33a3c6c5bcc0: Invalid notes'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 8 Single Batch Time: 2226ms (2.23s)

âœ… ===== STREAM 8 PROCESSING COMPLETE =====
â±ï¸  Stream 8 Total Time: 2226ms (2.23s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1971 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.8 sessions/sec
âš¡ Avg Time Per Session: 556.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:23:26.294Z',
  duration: '2250ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2305,
    completion_tokens: 295,
    total_tokens: 2600,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown', 'Claim Status' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-a2b9fb85-ee85-5d95-a1c6-e0ba63ad1ce8",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was unable to communicate their request and was transferred to a live agent."
    },
    {
      "user_id": "u-e6c1f64a-5cf0-5b6d-9018-ef76e4dabc28",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User successfully reported delivery details and confirmed submission, session handled by bot."
    },
    {
      "user_id": "u-37c52d0b-4fc7-56f5-9b66-9e1639da7e94",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and unable to communicate, transferred to a live agent."
    },
    {
      "user_id": "u-a5c1ffcf-7e67-5d31-99c0-8904b49fa3ef",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to sign up for FMLA, transferred to a live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2305,
  completionTokens: 295,
  totalTokens: 2600,
  cost: '$0.000349',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2250ms (2.25s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2600 ($0.0003)
âš¡ Performance: 1155.6 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2305
   â€¢ Completion Tokens: 295
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 4 Single Batch Time: 2250ms (2.25s)

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 2250ms (2.25s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2600 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.8 sessions/sec
âš¡ Avg Time Per Session: 562.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:23:26.306Z',
  duration: '2260ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1813,
    completion_tokens: 303,
    total_tokens: 2116,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status', 'Live Agent' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-60931903-9817-5849-bec8-d2a9cf2bc122",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User inquired about payment issues related to FMLA and requested to speak with a customer service agent."
    },
    {
      "user_id": "u-d7b1c72b-d6c3-574d-a618-4bc825bee545",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked to extend leave and requested to speak with a customer service agent."
    },
    {
      "user_id": "u-d01b5bfb-bd93-5eba-8581-c5e09b515a8a",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative; session transferred to live agent."
    },
    {
      "user_id": "u-a49460c5-e602-5aaa-a1c7-85b353d8a084",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User indicated desire to speak with a representative; session transferred to live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1813,
  completionTokens: 303,
  totalTokens: 2116,
  cost: '$0.000303',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2260ms (2.26s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2116 ($0.0003)
âš¡ Performance: 936.3 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1813
   â€¢ Completion Tokens: 303
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 6 Single Batch Time: 2260ms (2.26s)

âœ… ===== STREAM 6 PROCESSING COMPLETE =====
â±ï¸  Stream 6 Total Time: 2261ms (2.26s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2116 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.8 sessions/sec
âš¡ Avg Time Per Session: 565.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:23:26.754Z',
  duration: '2710ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1774,
    completion_tokens: 284,
    total_tokens: 2058,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Claim Status', 'Unknown' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-86ef7ec2-8e90-5530-9e8b-e66c412ddd9d",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent and was transferred."
    },
    {
      "user_id": "u-979f5376-5c34-59e4-a576-6c89d72b5e22",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent after checking leave approval status."
    },
    {
      "user_id": "u-1e9379ca-e8a4-5766-be48-8fa5ed45cb1b",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to start a new lease, transferred to an agent."
    },
    {
      "user_id": "u-1dd19dc4-dc07-5d8d-94c9-00073d90ae6a",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User ended the call without further input."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1774,
  completionTokens: 284,
  totalTokens: 2058,
  cost: '$0.000291',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2710ms (2.71s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2058 ($0.0003)
âš¡ Performance: 759.4 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1774
   â€¢ Completion Tokens: 284
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 3 Single Batch Time: 2710ms (2.71s)

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 2712ms (2.71s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2058 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.5 sessions/sec
âš¡ Avg Time Per Session: 678.00ms
[ParallelProcessingOrchestrator] Parallel processing complete: 8/8 streams succeeded
â±ï¸  Parallel Processing Time: 2713ms (2.71s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 8 streams
[ParallelProcessingOrchestrator] Synchronization complete: 0 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 0
ğŸ“Š Total Classifications: 5

âœ… ============ ROUND 1 COMPLETED ============
â±ï¸  Round 1 Total Time: 2714ms (2.71s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 53
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 1ms (0.0%)
   â€¢ Parallel Processing: 2713ms (100.0%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ”„ ============ ROUND 2/3 STARTED ============
â±ï¸  Round 2 Start: 2025-08-12T19:23:26.755Z
ğŸ“Š Sessions Remaining: 53
[ParallelProcessingOrchestrator] Distributed 32 sessions across 8 streams: [
  'Stream 1: 4 sessions',
  'Stream 2: 4 sessions',
  'Stream 3: 4 sessions',
  'Stream 4: 4 sessions',
  'Stream 5: 4 sessions',
  'Stream 6: 4 sessions',
  'Stream 7: 4 sessions',
  'Stream 8: 4 sessions'
]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 8

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 8 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T19:23:26.756Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:23:26.756Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 730
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6230
   â€¢ Avg Per Session: 183 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6230
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6230
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:23:26.756Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:23:26.756Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6100,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibili...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T19:23:26.756Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:23:26.756Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 867
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6367
   â€¢ Avg Per Session: 217 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6367
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6367
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:23:26.756Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:23:26.757Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6724,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibili...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T19:23:26.757Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:23:26.757Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 737
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6237
   â€¢ Avg Per Session: 184 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6237
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6237
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:23:26.757Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:23:26.757Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6131,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibili...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T19:23:26.757Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:23:26.757Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 897
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6397
   â€¢ Avg Per Session: 224 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6397
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6397
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:23:26.757Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:23:26.757Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6864,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibili...

ğŸŒŠ ===== STREAM 5 PROCESSING START =====
â±ï¸  Stream 5 Start: 2025-08-12T19:23:26.757Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:23:26.757Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 628
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6128
   â€¢ Avg Per Session: 157 tokens
   â€¢ Estimation Time: 1ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6128
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 1ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 5) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6128
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 5: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:23:26.758Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:23:26.758Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5702,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibili...

ğŸŒŠ ===== STREAM 6 PROCESSING START =====
â±ï¸  Stream 6 Start: 2025-08-12T19:23:26.758Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:23:26.758Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 986
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6486
   â€¢ Avg Per Session: 247 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6486
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 6) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6486
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 6: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:23:26.758Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:23:26.758Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7325,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibili...

ğŸŒŠ ===== STREAM 7 PROCESSING START =====
â±ï¸  Stream 7 Start: 2025-08-12T19:23:26.758Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:23:26.758Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 1237
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6737
   â€¢ Avg Per Session: 309 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6737
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0011
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 7) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6737
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0011

âš¡ Stream 7: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:23:26.759Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:23:26.759Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 8424,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibili...

ğŸŒŠ ===== STREAM 8 PROCESSING START =====
â±ï¸  Stream 8 Start: 2025-08-12T19:23:26.759Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:23:26.759Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 723
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6223
   â€¢ Avg Per Session: 181 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6223
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 8) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6223
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 8: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:23:26.759Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 3
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:23:26.759Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6020,
  existingClassifications: { intents: 3, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibili...
::1 - - [12/Aug/2025:19:23:27 +0000] "GET /api/analysis/auto-analyze/parallel/progress/b3926172-8317-4b7f-880a-49131acc1649 HTTP/1.1" 200 1727 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:23:28.079Z',
  duration: '1320ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1716,
    completion_tokens: 187,
    total_tokens: 1903,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-8002d234-87cb-56f3-91ad-8981d480c298",
      "notes": "User requested to speak with an agent, session transferred to a representative."
    },
    {
      "user_id": "u-f8572f7f-e301-558c-908b-4e91c1ac4d2a",
      "notes": "User requested to speak with an agent, session transferred to a representative."
    },
    {
      "user_id": "u-f005d34d-0b98-5f50-a1df-dc436f9296fe",
      "notes": "User requested to speak with an agent, session transferred to a representative."
    },
    {
      "user_id": "u-d031be8c-7e25-5a63-a373-6b85ce30d87f",
      "notes": "User requested to speak with an agent, session transferred to a representative."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1716,
  completionTokens: 187,
  totalTokens: 1903,
  cost: '$0.000246',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1321ms (1.32s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1903 ($0.0002)
âš¡ Performance: 1440.6 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1716
   â€¢ Completion Tokens: 187
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-8002d234-87cb-56f3-91ad-8981d480c298: Invalid general_intent, u-8002d234-87cb-56f3-91ad-8981d480c298: Invalid session_outcome, u-f8572f7f-e301-558c-908b-4e91c1ac4d2a: Invalid general_intent, u-f8572f7f-e301-558c-908b-4e91c1ac4d2a: Invalid session_outcome, u-f005d34d-0b98-5f50-a1df-dc436f9296fe: Invalid general_intent, u-f005d34d-0b98-5f50-a1df-dc436f9296fe: Invalid session_outcome, u-d031be8c-7e25-5a63-a373-6b85ce30d87f: Invalid general_intent, u-d031be8c-7e25-5a63-a373-6b85ce30d87f: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 8 Single Batch Time: 1322ms (1.32s)

âœ… ===== STREAM 8 PROCESSING COMPLETE =====
â±ï¸  Stream 8 Total Time: 1322ms (1.32s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1903 ($0.0002)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 3.0 sessions/sec
âš¡ Avg Time Per Session: 330.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:23:28.187Z',
  duration: '1429ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2054,
    completion_tokens: 211,
    total_tokens: 2265,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status' ],
  transferCount: 2,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-dd74491d-613d-5f59-be9d-8d591794e911",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-0feb3096-81dc-5733-8645-c521b8f33555",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-edaa6a4a-21bc-5754-ae12-69fd09dff62c",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": ""
    },
    {
      "user_id": "u-7cbb0316-ad60-547a-9939-55528a811bcd",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": ""
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2054,
  completionTokens: 211,
  totalTokens: 2265,
  cost: '$0.000290',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1429ms (1.43s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2265 ($0.0003)
âš¡ Performance: 1585.0 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2054
   â€¢ Completion Tokens: 211
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-dd74491d-613d-5f59-be9d-8d591794e911: Invalid notes, u-0feb3096-81dc-5733-8645-c521b8f33555: Invalid notes, u-edaa6a4a-21bc-5754-ae12-69fd09dff62c: Invalid notes, u-7cbb0316-ad60-547a-9939-55528a811bcd: Invalid notes'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 6 Single Batch Time: 1430ms (1.43s)

âœ… ===== STREAM 6 PROCESSING COMPLETE =====
â±ï¸  Stream 6 Total Time: 1430ms (1.43s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2265 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.8 sessions/sec
âš¡ Avg Time Per Session: 357.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:23:28.305Z',
  duration: '1548ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1758,
    completion_tokens: 232,
    total_tokens: 1990,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status', 'Question about documentation', 'Unknown' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-6c60e9e7-88e2-57fd-b457-498c2674395d",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-338a5293-c1ca-58b5-af83-a91fe5fd8cc5",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-f32bd3fa-012e-536f-984e-cbda5d20bafb",
      "general_intent": "Question about documentation",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-7b39e258-4207-509b-8b0c-0c232f8c0e74",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1758,
  completionTokens: 232,
  totalTokens: 1990,
  cost: '$0.000269',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1548ms (1.55s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1990 ($0.0003)
âš¡ Performance: 1285.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1758
   â€¢ Completion Tokens: 232
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-6c60e9e7-88e2-57fd-b457-498c2674395d: Invalid notes, u-338a5293-c1ca-58b5-af83-a91fe5fd8cc5: Invalid notes, u-f32bd3fa-012e-536f-984e-cbda5d20bafb: Invalid notes, u-7b39e258-4207-509b-8b0c-0c232f8c0e74: Invalid notes'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 3 Single Batch Time: 1548ms (1.55s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 1548ms (1.55s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1990 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.6 sessions/sec
âš¡ Avg Time Per Session: 387.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:23:28.348Z',
  duration: '1591ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1923,
    completion_tokens: 232,
    total_tokens: 2155,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown', 'Claim Status', 'Live Agent' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-eabfa4b8-7c39-5b9f-85d9-3f298bb7a1b0",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-74a54679-6d9a-5e07-9255-9e9c28bc73b0",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-fbf2fc87-2f31-543f-92f1-15eeb781ae5a",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": ""
    },
    {
      "user_id": "u-42c7b397-fd47-5241-8b19-49fab7008a25",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1923,
  completionTokens: 232,
  totalTokens: 2155,
  cost: '$0.000285',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1592ms (1.59s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2155 ($0.0003)
âš¡ Performance: 1353.6 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1923
   â€¢ Completion Tokens: 232
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-eabfa4b8-7c39-5b9f-85d9-3f298bb7a1b0: Invalid notes, u-74a54679-6d9a-5e07-9255-9e9c28bc73b0: Invalid notes, u-fbf2fc87-2f31-543f-92f1-15eeb781ae5a: Invalid notes, u-42c7b397-fd47-5241-8b19-49fab7008a25: Invalid notes'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 2 Single Batch Time: 1593ms (1.59s)

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 1593ms (1.59s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2155 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.5 sessions/sec
âš¡ Avg Time Per Session: 398.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:23:28.407Z',
  duration: '1650ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1944,
    completion_tokens: 277,
    total_tokens: 2221,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Claim Status' ],
  transferCount: 2,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-99a340aa-10a8-599c-96fd-16a02fc3deaa",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak to someone about payment and was transferred to an agent."
    },
    {
      "user_id": "u-efb861cd-edf8-530d-875e-4a8ad29dfa62",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User inquired about time entry and successfully submitted an absence without transfer."
    },
    {
      "user_id": "u-56240e27-5173-55ca-b793-dcf1fa93d0a0",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak to a representative and was transferred to an agent."
    },
    {
      "user_id": "u-bff9b471-e4d6-5ea0-a3ab-ccc9779cafc8",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User asked about claim status and received information without transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1944,
  completionTokens: 277,
  totalTokens: 2221,
  cost: '$0.000305',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1650ms (1.65s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2221 ($0.0003)
âš¡ Performance: 1346.1 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1944
   â€¢ Completion Tokens: 277
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 4 Single Batch Time: 1650ms (1.65s)

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 1650ms (1.65s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2221 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.4 sessions/sec
âš¡ Avg Time Per Session: 412.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:23:28.519Z',
  duration: '1761ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1676,
    completion_tokens: 289,
    total_tokens: 1965,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Time Entry', 'Unknown' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-29e9e551-1c66-58f0-bc02-1d532d2b2054",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-aa696394-6d32-5d4b-ac3e-028fba03c5e4",
      "general_intent": "Time Entry",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested help with time correction and was transferred to an agent."
    },
    {
      "user_id": "u-145a5bbe-469d-5081-9e93-5d34b4016577",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User wanted to report time but the session ended without transfer or resolution."
    },
    {
      "user_id": "u-0f1a86ea-f601-5d0a-848c-14c4aa8856ec",
      "general_intent": "Time Entry",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to provide claim details but was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1676,
  completionTokens: 289,
  totalTokens: 1965,
  cost: '$0.000283',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1761ms (1.76s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1965 ($0.0003)
âš¡ Performance: 1115.8 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1676
   â€¢ Completion Tokens: 289
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 5 Single Batch Time: 1761ms (1.76s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 5 PROCESSING COMPLETE =====
â±ï¸  Stream 5 Total Time: 1762ms (1.76s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1965 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.3 sessions/sec
âš¡ Avg Time Per Session: 440.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:23:28.571Z',
  duration: '1812ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2368,
    completion_tokens: 276,
    total_tokens: 2644,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown', 'Live Agent' ],
  transferCount: 2,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-c5f4effd-a060-575e-ae65-f16db89d966c",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User inquired about applying for FMLA and was transferred to a live agent."
    },
    {
      "user_id": "u-cb792bc9-d17e-57b5-84c5-608db02ec598",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested time entry assistance, was transferred to a live agent after initial bot interaction."
    },
    {
      "user_id": "u-523a05a6-26af-5150-8a7d-d66f97ab3cac",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative, was transferred to a live agent."
    },
    {
      "user_id": "u-5f720b1c-5d2b-5d94-a34c-cbe2eacdbb3d",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User reported time off and submitted a time entry, session was handled by bot."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2368,
  completionTokens: 276,
  totalTokens: 2644,
  cost: '$0.000347',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1812ms (1.81s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2644 ($0.0003)
âš¡ Performance: 1459.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2368
   â€¢ Completion Tokens: 276
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 7 Single Batch Time: 1812ms (1.81s)

âœ… ===== STREAM 7 PROCESSING COMPLETE =====
â±ï¸  Stream 7 Total Time: 1813ms (1.81s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2644 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.2 sessions/sec
âš¡ Avg Time Per Session: 453.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:23:29.052Z',
  duration: '2296ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1761,
    completion_tokens: 292,
    total_tokens: 2053,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown', 'Live Agent' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-5ce6d9b0-a2af-5e4a-a118-61e09c93bf1e",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User provided leave request number and return to work date, session handled by bot."
    },
    {
      "user_id": "u-1a5fa2fc-4f30-5d3f-a49e-e023dfc0c23a",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent, session transferred to live agent."
    },
    {
      "user_id": "u-da2337c3-3b15-5458-a0b6-7584e4726c07",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent, session transferred to live agent."
    },
    {
      "user_id": "u-98f165c6-00ce-531f-b76e-b85c0a90d696",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent, session transferred to live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1761,
  completionTokens: 292,
  totalTokens: 2053,
  cost: '$0.000293',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2297ms (2.30s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2053 ($0.0003)
âš¡ Performance: 893.8 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1761
   â€¢ Completion Tokens: 292
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 1 Single Batch Time: 2297ms (2.30s)

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 2298ms (2.30s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2053 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.7 sessions/sec
âš¡ Avg Time Per Session: 574.50ms
[ParallelProcessingOrchestrator] Parallel processing complete: 8/8 streams succeeded
â±ï¸  Parallel Processing Time: 2299ms (2.30s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 8 streams
[ParallelProcessingOrchestrator] Synchronization complete: 2 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 2
ğŸ“Š Total Classifications: 7

âœ… ============ ROUND 2 COMPLETED ============
â±ï¸  Round 2 Total Time: 2299ms (2.30s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 21
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 2299ms (100.0%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ”„ ============ ROUND 3/3 STARTED ============
â±ï¸  Round 3 Start: 2025-08-12T19:23:29.054Z
ğŸ“Š Sessions Remaining: 21
[ParallelProcessingOrchestrator] Distributed 21 sessions across 6 streams: [
  'Stream 1: 4 sessions',
  'Stream 2: 4 sessions',
  'Stream 3: 4 sessions',
  'Stream 4: 4 sessions',
  'Stream 5: 4 sessions',
  'Stream 6: 1 sessions'
]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 6

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 6 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T19:23:29.054Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:23:29.055Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 696
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6196
   â€¢ Avg Per Session: 174 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6196
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6196
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:23:29.055Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:23:29.055Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5958,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Question about documentation, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examp...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T19:23:29.056Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:23:29.056Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 734
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6234
   â€¢ Avg Per Session: 184 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6234
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6234
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:23:29.056Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:23:29.056Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6208,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Question about documentation, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examp...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T19:23:29.056Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:23:29.056Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 980
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6480
   â€¢ Avg Per Session: 245 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6480
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6480
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:23:29.056Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:23:29.057Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7333,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Question about documentation, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examp...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T19:23:29.058Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:23:29.058Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 890
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6390
   â€¢ Avg Per Session: 223 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6390
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6390
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:23:29.058Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:23:29.058Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6884,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Question about documentation, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examp...

ğŸŒŠ ===== STREAM 5 PROCESSING START =====
â±ï¸  Stream 5 Start: 2025-08-12T19:23:29.059Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:23:29.059Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 861
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6361
   â€¢ Avg Per Session: 215 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6361
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 5) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6361
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 5: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:23:29.059Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:23:29.059Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6787,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Question about documentation, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examp...

ğŸŒŠ ===== STREAM 6 PROCESSING START =====
â±ï¸  Stream 6 Start: 2025-08-12T19:23:29.059Z
ğŸ“Š Sessions Assigned: 1
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:23:29.059Z
ğŸ“Š Sessions to Estimate: 1
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 1
   â€¢ Session Tokens: 208
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 5708
   â€¢ Avg Per Session: 208 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 5708
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0009
ğŸ“Š Recommended Batch Size: 1

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 1ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 6) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 5708
ğŸ“¦ Recommended Batch Size: 1
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0009

âš¡ Stream 6: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:23:29.060Z
ğŸ“Š Sessions to Analyze: 1
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:23:29.060Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 1,
  apiKey: 'sk-proj-...',
  promptLength: 4252,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Live Agent, Question about documentation, Time Entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examp...
::1 - - [12/Aug/2025:19:23:29 +0000] "GET /api/analysis/auto-analyze/parallel/progress/b3926172-8317-4b7f-880a-49131acc1649 HTTP/1.1" 200 1537 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:23:30.168Z',
  duration: '1108ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1245,
    completion_tokens: 82,
    total_tokens: 1327,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 1,
  intentsFound: [ 'Unknown' ],
  transferCount: 1,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-20f2f80a-a362-598d-aa52-b88c12f6bd5f",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was trying to get information about time notification and was transferred to an agent for license requests."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1245,
  completionTokens: 82,
  totalTokens: 1327,
  cost: '$0.000157',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1109ms (1.11s)
ğŸ“Š Sessions Returned: 1
ğŸ’° Tokens Used: 1327 ($0.0002)
âš¡ Performance: 1196.6 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1245
   â€¢ Completion Tokens: 82
[SessionValidationService] Validating batch response: 1 input sessions, 1 response sessions
[SessionValidationService] Validation successful: all 1 sessions processed
[SessionValidationService] Validating batch response: 1 input sessions, 1 response sessions
[SessionValidationService] Validation successful: all 1 sessions processed
â±ï¸  Stream 6 Single Batch Time: 1109ms (1.11s)

âœ… ===== STREAM 6 PROCESSING COMPLETE =====
â±ï¸  Stream 6 Total Time: 1110ms (1.11s)
ğŸ“Š Sessions Processed: 1/1
ğŸ’° Tokens Used: 1327 ($0.0002)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.9 sessions/sec
âš¡ Avg Time Per Session: 1110.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:23:30.412Z',
  duration: '1353ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1964,
    completion_tokens: 195,
    total_tokens: 2159,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-937af4f5-a2c0-55da-ba54-cf3b10fbd668",
      "notes": "User requested to speak with an agent and was transferred to a live agent."
    },
    {
      "user_id": "u-fb03cc4b-00eb-569f-b079-aab2ee118a52",
      "notes": "User attempted to get assistance but was unable to provide required information and was transferred to an agent."
    },
    {
      "user_id": "u-da6c1bf5-1871-5140-9e9a-f717e7daf3de",
      "notes": "User was silent and did not respond; session was transferred to an agent after inactivity."
    },
    {
      "user_id": "u-d7c8ac85-9565-521f-bf5e-03b91b7855ce",
      "notes": "User requested to speak with an agent and was transferred to a live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1964,
  completionTokens: 195,
  totalTokens: 2159,
  cost: '$0.000274',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1354ms (1.35s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2159 ($0.0003)
âš¡ Performance: 1594.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1964
   â€¢ Completion Tokens: 195
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-937af4f5-a2c0-55da-ba54-cf3b10fbd668: Invalid general_intent, u-937af4f5-a2c0-55da-ba54-cf3b10fbd668: Invalid session_outcome, u-fb03cc4b-00eb-569f-b079-aab2ee118a52: Invalid general_intent, u-fb03cc4b-00eb-569f-b079-aab2ee118a52: Invalid session_outcome, u-da6c1bf5-1871-5140-9e9a-f717e7daf3de: Invalid general_intent, u-da6c1bf5-1871-5140-9e9a-f717e7daf3de: Invalid session_outcome, u-d7c8ac85-9565-521f-bf5e-03b91b7855ce: Invalid general_intent, u-d7c8ac85-9565-521f-bf5e-03b91b7855ce: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 4 Single Batch Time: 1355ms (1.35s)

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 1355ms (1.35s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2159 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 3.0 sessions/sec
âš¡ Avg Time Per Session: 338.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:23:31.008Z',
  duration: '1950ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2117,
    completion_tokens: 310,
    total_tokens: 2427,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Time Entry', 'Claim Status' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-4bb9c235-cc2e-5f6a-9229-fd1ceeb15fae",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative, leading to a transfer to a live agent."
    },
    {
      "user_id": "u-0afcbb17-d319-5547-a823-7022e4105f1b",
      "general_intent": "Time Entry",
      "session_outcome": "Contained",
      "notes": "User attempted to report a return to work date but was unable due to account status, then requested to speak to an agent, resulting in a transfer."
    },
    {
      "user_id": "u-b7285ff0-28cf-5734-b852-0bacfd1a5b8d",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User provided detailed leave request information and was transferred to an agent after difficulty with input."
    },
    {
      "user_id": "u-750a888c-e36b-5b23-a506-5be6e1e0f3ea",
      "general_intent": "Time Entry",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to log time entry but was transferred to an agent after input issues."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2117,
  completionTokens: 310,
  totalTokens: 2427,
  cost: '$0.000336',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1952ms (1.95s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2427 ($0.0003)
âš¡ Performance: 1243.3 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2117
   â€¢ Completion Tokens: 310
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 3 Single Batch Time: 1953ms (1.95s)

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 1953ms (1.95s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2427 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.0 sessions/sec
âš¡ Avg Time Per Session: 488.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:23:31.009Z',
  duration: '1953ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1775,
    completion_tokens: 282,
    total_tokens: 2057,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Time Entry', 'Claim Status' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-4af7996d-0660-59dd-ad61-a1800ccebadb",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred."
    },
    {
      "user_id": "u-f422c254-18d9-56bf-bd30-1dc329091c59",
      "general_intent": "Time Entry",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to request a medical leave and was transferred to an agent."
    },
    {
      "user_id": "u-1137c6ea-842f-5554-b23e-8cdaba5ad337",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-103fd236-2f59-54e8-afdb-36cf1eeb4182",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to start a new claim and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1775,
  completionTokens: 282,
  totalTokens: 2057,
  cost: '$0.000290',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1953ms (1.95s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2057 ($0.0003)
âš¡ Performance: 1053.3 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1775
   â€¢ Completion Tokens: 282
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 2 Single Batch Time: 1953ms (1.95s)

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 1953ms (1.95s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2057 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.0 sessions/sec
âš¡ Avg Time Per Session: 488.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:23:31.304Z',
  duration: '2245ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1933,
    completion_tokens: 298,
    total_tokens: 2231,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Question about documentation', 'Claim Status' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-f2fc7c7c-781f-5775-8f5d-2bca7af049cc",
      "general_intent": "Question about documentation",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to renew FMLA and was transferred to a representative."
    },
    {
      "user_id": "u-6c28d079-1d8c-5503-b65e-6d15144db25c",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User's claim was denied and was transferred to a representative."
    },
    {
      "user_id": "u-1009edee-7332-5105-ad2f-1561bb207ea1",
      "general_intent": "Question about documentation",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent regarding returning a call."
    },
    {
      "user_id": "u-e517b678-55f8-5dbf-bb59-f0076e5d406d",
      "general_intent": "Question about documentation",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and then transferred to an agent after multiple prompts."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1933,
  completionTokens: 298,
  totalTokens: 2231,
  cost: '$0.000313',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2246ms (2.25s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2231 ($0.0003)
âš¡ Performance: 993.3 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1933
   â€¢ Completion Tokens: 298
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 5 Single Batch Time: 2246ms (2.25s)

âœ… ===== STREAM 5 PROCESSING COMPLETE =====
â±ï¸  Stream 5 Total Time: 2246ms (2.25s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2231 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.8 sessions/sec
âš¡ Avg Time Per Session: 561.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:23:31.529Z',
  duration: '2473ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1716,
    completion_tokens: 304,
    total_tokens: 2020,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status', 'Live Agent', 'FMLA' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-8921d8e3-285c-5008-a087-9cb991c7462e",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to file a claim and was transferred to an agent."
    },
    {
      "user_id": "u-9f7874b4-ee73-5d0a-b430-9e90bf6a589f",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to a representative and was transferred to an agent."
    },
    {
      "user_id": "u-807279b9-54f4-56e0-a0cc-b7c312e4bdbd",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked about setting up FMLA and was transferred to an agent."
    },
    {
      "user_id": "u-938b8a49-9c64-5bdb-b056-748f697a41ee",
      "general_intent": "FMLA",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent about FMLA and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1716,
  completionTokens: 304,
  totalTokens: 2020,
  cost: '$0.000293',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2475ms (2.48s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2020 ($0.0003)
âš¡ Performance: 816.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1716
   â€¢ Completion Tokens: 304
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 1 Single Batch Time: 2475ms (2.48s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 2477ms (2.48s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2020 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.6 sessions/sec
âš¡ Avg Time Per Session: 619.25ms
[ParallelProcessingOrchestrator] Parallel processing complete: 6/6 streams succeeded
â±ï¸  Parallel Processing Time: 2477ms (2.48s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 6 streams
[ParallelProcessingOrchestrator] Synchronization complete: 1 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 1
ğŸ“Š Total Classifications: 8

âœ… ============ ROUND 3 COMPLETED ============
â±ï¸  Round 3 Total Time: 2477ms (2.48s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 0
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 2477ms (100.0%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ‰ ============ PARALLEL PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 7490ms (7.49s)
ğŸ“Š Sessions Processed: 85/85
ğŸ”„ Total Rounds: 3
ğŸŒŠ Stream Results: 22
ğŸ’° Token Usage: 46463 tokens ($0.0064)
ğŸ“ˆ Stream Utilization: 100.0%
ğŸ¯ Performance: 11.3 sessions/second
âš¡ Avg Time Per Session: 88.12ms

ğŸ“Š Stream Performance Breakdown:
   Stream 1: 4 sessions in 1981ms (1002.5 tokens/sec)
   Stream 2: 4 sessions in 2224ms (916.8 tokens/sec)
   Stream 3: 4 sessions in 2712ms (758.8 tokens/sec)
   Stream 4: 4 sessions in 2250ms (1155.6 tokens/sec)
   Stream 5: 4 sessions in 2067ms (1029.5 tokens/sec)
   Stream 6: 4 sessions in 2261ms (935.9 tokens/sec)
   Stream 7: 4 sessions in 1943ms (1105.5 tokens/sec)
   Stream 8: 4 sessions in 2226ms (885.4 tokens/sec)
   Stream 1: 4 sessions in 2298ms (893.4 tokens/sec)
   Stream 2: 4 sessions in 1593ms (1352.8 tokens/sec)
   Stream 3: 4 sessions in 1548ms (1285.5 tokens/sec)
   Stream 4: 4 sessions in 1650ms (1346.1 tokens/sec)
   Stream 5: 4 sessions in 1762ms (1115.2 tokens/sec)
   Stream 6: 4 sessions in 1430ms (1583.9 tokens/sec)
   Stream 7: 4 sessions in 1813ms (1458.4 tokens/sec)
   Stream 8: 4 sessions in 1322ms (1439.5 tokens/sec)
   Stream 1: 4 sessions in 2477ms (815.5 tokens/sec)
   Stream 2: 4 sessions in 1953ms (1053.3 tokens/sec)
   Stream 3: 4 sessions in 1953ms (1242.7 tokens/sec)
   Stream 4: 4 sessions in 1355ms (1593.4 tokens/sec)
   Stream 5: 4 sessions in 2246ms (993.3 tokens/sec)
   Stream 6: 1 sessions in 1110ms (1195.5 tokens/sec)
[ConflictResolutionService] Starting conflict resolution for 100 sessions
[ConflictResolutionService] Found classifications: { intents: 6, reasons: 1, locations: 1 }
[ConflictResolutionService] Calling LLM for conflict resolution with model gpt-4.1-nano
ğŸ”§ Conflict Resolution Prompt Preview: You are reviewing classifications from parallel analysis streams. Identify any semantic duplicates and choose the canonical version for each group.

**Instructions:**
1. Look for classifications that refer to the same concept but use different wording
2. For each group of duplicates, choose the most...
::1 - - [12/Aug/2025:19:23:31 +0000] "GET /api/analysis/auto-analyze/parallel/progress/b3926172-8317-4b7f-880a-49131acc1649 HTTP/1.1" 200 1581 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[ConflictResolution] LLM response: {
  "generalIntents": [
    {
      "canonical": "Claim Status Inquiry",
      "aliases": [
        "Claim Status"
      ]
    },
    {
      "canonical": "FMLA Inquiry",
      "aliases": [
        "FMLA"
      ]
    },
    {
      "canonical": "Live Agent Transfer",
      "aliases": [
        "Live Agent"
      ]
    },
    {
      "canonical": "Documentation Question",
      "aliases": [
        "Question about documentation"
      ]
    },
    {
      "canonical": "Time Entry Issue",
      "aliases": [
        "Time Entry"
      ]
    },
    {
      "canonical": "Unknown Issue",
      "aliases": [
        "Unknown"
      ]
    }
  ],
  "transferReasons": [
    {
      "canonical": "Live Agent Request",
      "aliases": [
        "Live Agent Request"
      ]
    }
  ],
  "dropOffLocations": [
    {
      "canonical": "Help Offer Prompt",
      "aliases": [
        "Help Offer Prompt"
      ]
    }
  ]
}
[ConflictResolutionService] LLM conflict resolution complete: { intents: 6, reasons: 1, locations: 1, tokens: 741, cost: 0.0001089 }
ğŸ”§ Conflict Resolution Response: {
  "generalIntents": [
    {
      "canonical": "Claim Status Inquiry",
      "aliases": [
        "Claim Status"
      ]
    },
    {
      "canonical": "FMLA Inquiry",
      "aliases": [
        "FMLA"
      ]
    },
    {
      "canonical": "Live Agent Transfer",
      "aliases": [
        "Live Agent"
      ]
    },
    {
      "canonical": "Documentation Question",
      "aliases": [
        "Question about documentation"
      ]
    },
    {
      "canonical": "Time Entry Issue",
      "aliases": [
        "Time Entry"
      ]
    },
    {
      "canonical": "Unknown Issue",
      "aliases": [
        "Unknown"
      ]
    }
  ],
  "transferReasons": [
    {
      "canonical": "Live Agent Request",
      "aliases": [
        "Live Agent Request"
      ]
    }
  ],
  "dropOffLocations": [
    {
      "canonical": "Help Offer Prompt",
      "aliases": [
        "Help Offer Prompt"
      ]
    }
  ]
}
[ConflictResolutionService] Applying resolutions to 100 sessions
[ConflictResolutionService] Applied 100 classification mappings across 100 sessions
[ConflictResolutionService] Identified 0 potential conflict groups
[ConflictResolutionService] Conflict resolution complete in 2084ms: { conflictsFound: 0, conflictsResolved: 8, canonicalMappings: 8 }
[ParallelAutoAnalyzeService] Using real analysis summary service
::1 - - [12/Aug/2025:19:23:33 +0000] "GET /api/analysis/auto-analyze/parallel/progress/b3926172-8317-4b7f-880a-49131acc1649 HTTP/1.1" 200 1655 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:23:35 +0000] "GET /api/analysis/auto-analyze/parallel/progress/b3926172-8317-4b7f-880a-49131acc1649 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:23:37 +0000] "GET /api/analysis/auto-analyze/parallel/progress/b3926172-8317-4b7f-880a-49131acc1649 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:23:39 +0000] "GET /api/analysis/auto-analyze/parallel/progress/b3926172-8317-4b7f-880a-49131acc1649 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:23:41 +0000] "GET /api/analysis/auto-analyze/parallel/progress/b3926172-8317-4b7f-880a-49131acc1649 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:23:43 +0000] "GET /api/analysis/auto-analyze/parallel/progress/b3926172-8317-4b7f-880a-49131acc1649 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:23:45 +0000] "GET /api/analysis/auto-analyze/parallel/progress/b3926172-8317-4b7f-880a-49131acc1649 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:23:47 +0000] "GET /api/analysis/auto-analyze/parallel/progress/b3926172-8317-4b7f-880a-49131acc1649 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:23:49 +0000] "GET /api/analysis/auto-analyze/parallel/progress/b3926172-8317-4b7f-880a-49131acc1649 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:23:51 +0000] "GET /api/analysis/auto-analyze/parallel/progress/b3926172-8317-4b7f-880a-49131acc1649 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:23:53 +0000] "GET /api/analysis/auto-analyze/parallel/progress/b3926172-8317-4b7f-880a-49131acc1649 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[ParallelAutoAnalyzeService] Parallel analysis b3926172-8317-4b7f-880a-49131acc1649 completed successfully
[BackgroundJobQueue] Updated job progress to final state: complete
[BackgroundJobQueue] Parallel analysis job b3926172-8317-4b7f-880a-49131acc1649-parallel completed successfully
::1 - - [12/Aug/2025:19:23:55 +0000] "GET /api/analysis/auto-analyze/parallel/progress/b3926172-8317-4b7f-880a-49131acc1649 HTTP/1.1" 200 1679 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:23:55 +0000] "GET /api/analysis/auto-analyze/parallel/results/b3926172-8317-4b7f-880a-49131acc1649 HTTP/1.1" 200 699853 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
3:27:39 PM [tsx] change in ./src/services/parallelAutoAnalyzeService.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T19:28:57.737Z",
  "dateTo": "2025-08-12T19:29:57.737Z",
  "skip": 0,
  "limit": 1
}
::1 - - [12/Aug/2025:19:30:02 +0000] "GET /api/kore/test HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 1 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [ '689b9618618775e3b37d12e2' ]
[getSessionsMetadataForConnectionTest] Single API call succeeded with 1 sessions
3:30:49 PM [tsx] change in ./src/services/parallelAutoAnalyzeService.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T19:31:49.147Z",
  "dateTo": "2025-08-12T19:32:49.147Z",
  "skip": 0,
  "limit": 1
}
[fetchContainmentTypeMetadata] API Response: 1 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [ '689b96c032b94a1c3f243589' ]
[getSessionsMetadataForConnectionTest] Single API call succeeded with 1 sessions
::1 - - [12/Aug/2025:19:32:52 +0000] "GET /api/kore/test HTTP/1.1" 200 851 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[Direct API] Fetching real Kore.ai sessions from 2025-08-05T19:32:53.060Z to 2025-08-12T19:32:53.060Z for User Bot st-90549... (limit=50)
Retrieving sessions from 2025-08-05T19:32:53.060Z to 2025-08-12T19:32:53.060Z (limit=50), populateMessages=true...
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T19:32:53.060Z",
  "dateTo": "2025-08-12T19:32:53.060Z",
  "limit": 50
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:32:53.060Z",
  "dateTo": "2025-08-12T19:32:53.060Z",
  "skip": 0,
  "limit": 50
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:32:53.060Z",
  "dateTo": "2025-08-12T19:32:53.060Z",
  "skip": 0,
  "limit": 50
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:32:53.060Z",
  "dateTo": "2025-08-12T19:32:53.060Z",
  "skip": 0,
  "limit": 50
}
::1 - - [12/Aug/2025:19:32:53 +0000] "GET /api/analysis/sessions?limit=50 HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[Direct API] Fetching real Kore.ai sessions from 2025-08-05T19:32:53.485Z to 2025-08-12T19:32:53.485Z for User Bot st-90549... (limit=50)
Retrieving sessions from 2025-08-05T19:32:53.485Z to 2025-08-12T19:32:53.485Z (limit=50), populateMessages=true...
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T19:32:53.485Z",
  "dateTo": "2025-08-12T19:32:53.485Z",
  "limit": 50
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:32:53.485Z",
  "dateTo": "2025-08-12T19:32:53.485Z",
  "skip": 0,
  "limit": 50
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:32:53.485Z",
  "dateTo": "2025-08-12T19:32:53.485Z",
  "skip": 0,
  "limit": 50
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:32:53.485Z",
  "dateTo": "2025-08-12T19:32:53.485Z",
  "skip": 0,
  "limit": 50
}
::1 - - [12/Aug/2025:19:32:53 +0000] "GET /api/analysis/sessions?limit=50 HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 50 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b96c032b94a1c3f243589',
  '689b96bcb1294642859ce88f',
  '689b96b8886ba2d0d250880c'
]
[fetchContainmentTypeMetadata] API Response: 50 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b92fdbf7ccd3cf0fce989',
  '689b9284618775e3b37c7f05',
  '689b9239e6e30b33f5c3a8aa'
]
[fetchContainmentTypeMetadata] API Response: 50 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b96e220c795e6ba1e314a',
  '689b96d704e268eb7c1db5c0',
  '689b96d5cc9c7f5ad06c967b'
]
[fetchContainmentTypeMetadata] API Response: 50 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b92fdbf7ccd3cf0fce989',
  '689b9284618775e3b37c7f05',
  '689b9239e6e30b33f5c3a8aa'
]
[getSessionsMetadata] agent API call succeeded with 50 sessions
[getSessionsMetadata] selfService API call succeeded with 50 sessions
[getSessionsMetadata] dropOff API call succeeded with 50 sessions
Total session metadata retrieved: 150 (parallel execution)
Retrieved 150 session metadata objects
Creating 150 SWTs from metadata (no messages)
Created 150 SWT objects from metadata
Populating messages for all sessions (legacy behavior)
Populating messages for 150 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 150 sessions from 2025-08-12T18:22:17.564Z to 2025-08-12T19:32:53.568Z at 2025-08-12T19:33:06.003Z
ğŸš€ [ConcurrentBatch] Split 150 sessions into 8 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/8] Starting: 20 sessions
[Batch 2/8] Starting: 20 sessions
[Batch 3/8] Starting: 20 sessions
[Batch 4/8] Starting: 20 sessions
[Batch 5/8] Starting: 20 sessions
[Batch 6/8] Starting: 20 sessions
[Batch 7/8] Starting: 20 sessions
[Batch 8/8] Starting: 10 sessions
[Batch 3/8] Completed in 235ms: 161 messages retrieved (1/8 done)
[Batch 2/8] Completed in 258ms: 177 messages retrieved (2/8 done)
[Batch 1/8] Completed in 272ms: 199 messages retrieved (3/8 done)
[Batch 6/8] Completed in 478ms: 186 messages retrieved (4/8 done)
[Batch 8/8] Completed in 503ms: 157 messages retrieved (5/8 done)
[Batch 4/8] Completed in 530ms: 315 messages retrieved (6/8 done)
[fetchContainmentTypeMetadata] API Response: 50 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b96c032b94a1c3f243589',
  '689b96bcb1294642859ce88f',
  '689b96b8886ba2d0d250880c'
]
[Batch 7/8] Completed in 589ms: 199 messages retrieved (7/8 done)
[fetchContainmentTypeMetadata] API Response: 50 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b96e220c795e6ba1e314a',
  '689b96d704e268eb7c1db5c0',
  '689b96d5cc9c7f5ad06c967b'
]
[getSessionsMetadata] agent API call succeeded with 50 sessions
[getSessionsMetadata] selfService API call succeeded with 50 sessions
[getSessionsMetadata] dropOff API call succeeded with 50 sessions
Total session metadata retrieved: 150 (parallel execution)
Retrieved 150 session metadata objects
Creating 150 SWTs from metadata (no messages)
Created 150 SWT objects from metadata
Populating messages for all sessions (legacy behavior)
Populating messages for 150 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 150 sessions from 2025-08-12T18:22:17.564Z to 2025-08-12T19:32:50.408Z at 2025-08-12T19:33:06.639Z
ğŸš€ [ConcurrentBatch] Split 150 sessions into 8 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/8] Starting: 20 sessions
[Batch 2/8] Starting: 20 sessions
[Batch 3/8] Starting: 20 sessions
[Batch 4/8] Starting: 20 sessions
[Batch 5/8] Starting: 20 sessions
[Batch 6/8] Starting: 20 sessions
[Batch 7/8] Starting: 20 sessions
[Batch 8/8] Starting: 10 sessions
[Batch 5/8] Completed in 663ms: 513 messages retrieved (8/8 done)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 663ms (0.66s)
â±ï¸  Batch Processing: 663ms (0.66s)
ğŸ“¦ Total batches: 8 (max 10 concurrent)
âœ… Successful batches: 8/8
ğŸ’¬ Total messages: 1907
ğŸ“ˆ Avg time per batch: 83ms
ğŸš€ Time per session: 4ms
ğŸ’ª Performance: 226.2 sessions/second
=======================================================

Retrieved 1907 messages for 150 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
Populated messages for 150 SWT objects
Generated 150 SWT objects in 13204ms using layered architecture
[Batch 2/8] Completed in 168ms: 177 messages retrieved (1/8 done)
[Batch 7/8] Completed in 183ms: 199 messages retrieved (2/8 done)
[Batch 8/8] Completed in 187ms: 157 messages retrieved (3/8 done)
[Batch 6/8] Completed in 190ms: 186 messages retrieved (4/8 done)
[Batch 4/8] Completed in 221ms: 315 messages retrieved (5/8 done)
[Batch 3/8] Completed in 262ms: 156 messages retrieved (6/8 done)
[Batch 1/8] Completed in 264ms: 199 messages retrieved (7/8 done)
[Batch 5/8] Completed in 323ms: 513 messages retrieved (8/8 done)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 323ms (0.32s)
â±ï¸  Batch Processing: 323ms (0.32s)
ğŸ“¦ Total batches: 8 (max 10 concurrent)
âœ… Successful batches: 8/8
ğŸ’¬ Total messages: 1902
ğŸ“ˆ Avg time per batch: 40ms
ğŸš€ Time per session: 2ms
ğŸ’ª Performance: 464.4 sessions/second
=======================================================

Retrieved 1902 messages for 150 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
Populated messages for 150 SWT objects
Generated 150 SWT objects in 13909ms using layered architecture
ğŸš€ [ParallelAutoAnalyzeRoute] Starting parallel analysis for bot ***REMOVED*** with real credentials
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
ğŸ­ ServiceFactory: Creating OpenAI service (type: real)
ğŸš€ [ParallelAutoAnalyzeService] Starting parallel analysis f36a45f7-cfe8-4f7d-bc51-24034306b040 with bot ***REMOVED***
ğŸš€ [ParallelAutoAnalyzeService] Using credentials: real
ğŸš€ [ParallelAutoAnalyzeRoute] Parallel analysis started: f36a45f7-cfe8-4f7d-bc51-24034306b040
::1 - - [12/Aug/2025:19:33:11 +0000] "POST /api/analysis/auto-analyze/parallel/start HTTP/1.1" 200 214 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:33:11 +0000] "GET /api/analysis/auto-analyze/parallel/progress/f36a45f7-cfe8-4f7d-bc51-24034306b040 HTTP/1.1" 200 541 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:33:11 +0000] "GET /api/analysis/auto-analyze/parallel/progress/f36a45f7-cfe8-4f7d-bc51-24034306b040 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[BackgroundJobQueue] Starting job processing after delay for job f36a45f7-cfe8-4f7d-bc51-24034306b040-parallel
[BackgroundJobQueue] Starting processing for job f36a45f7-cfe8-4f7d-bc51-24034306b040-parallel, phase: sampling
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing parallel analysis job f36a45f7-cfe8-4f7d-bc51-24034306b040-parallel
[BackgroundJobQueue] Processing parallel analysis for bot ***REMOVED***
[BackgroundJobQueue] Using existing ParallelAutoAnalyzeService instance for bot ***REMOVED***
[BackgroundJobQueue] Session recreated for f36a45f7-cfe8-4f7d-bc51-24034306b040
[ParallelAutoAnalyzeService] Running parallel analysis for f36a45f7-cfe8-4f7d-bc51-24034306b040
[ParallelAutoAnalyzeService] Phase 0: Starting session sampling for f36a45f7-cfe8-4f7d-bc51-24034306b040

ğŸ• ============ SESSION SAMPLING STARTED ============
ğŸ• [SessionSampling] Starting session sampling at 2025-08-12T19:33:12.473Z
ğŸ” [SessionDiscovery] Starting window 1/4: Initial 3-hour window
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
::1 - - [12/Aug/2025:19:33:13 +0000] "GET /api/analysis/auto-analyze/parallel/progress/f36a45f7-cfe8-4f7d-bc51-24034306b040 HTTP/1.1" 200 717 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:33:15 +0000] "GET /api/analysis/auto-analyze/parallel/progress/f36a45f7-cfe8-4f7d-bc51-24034306b040 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 80 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a1287849680ad9fe59e',
  '689229f9583056c6108e38fb',
  '68922914f8bee7ba6c3e67b8'
]
[fetchContainmentTypeMetadata] API Response: 139 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6a14dd27c3112087cd',
  '68922a22ef03d8ad2ec7b4ba',
  '68922a1278c1fe09a079719c'
]
::1 - - [12/Aug/2025:19:33:17 +0000] "GET /api/analysis/auto-analyze/parallel/progress/f36a45f7-cfe8-4f7d-bc51-24034306b040 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 1338 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6d14dd27c31120888b',
  '68922a62e3804084741191d5',
  '68922a523a3160d25de144c8'
]
[getSessionsMetadata] agent API call succeeded with 1338 sessions
[getSessionsMetadata] selfService API call succeeded with 80 sessions
[getSessionsMetadata] dropOff API call succeeded with 139 sessions
Total session metadata retrieved: 1557 (parallel execution)
Creating 1557 SWTs from metadata (no messages)
Created 1557 SWT objects from metadata
âœ… [SessionDiscovery] Window 1 completed in 7016ms: found 1557 new sessions (total: 1557)
â±ï¸  TIMING: Window 1 took 7016ms (7.02s)
ğŸ¯ [SessionDiscovery] Target reached! Found 1557 sessions in 7016ms
ğŸ² [SessionSampling] Random sampling from 1557 sessions to 10 sessions

ğŸ“¬ ============ MESSAGE RETRIEVAL STARTED ============
ğŸ“¬ [MessageRetrieval] Starting message retrieval for 10 sampled sessions at 2025-08-12T19:33:19.490Z
Using new lazy loading approach to populate messages for 10 sampled sessions
Populating messages for 10 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 10 sessions from 2025-08-05T13:06:05.472Z to 2025-08-05T15:54:48.069Z at 2025-08-12T19:33:19.491Z
ğŸ”„ [KoreAPI] Using single API call for 10 sessions (â‰¤20)
::1 - - [12/Aug/2025:19:33:19 +0000] "GET /api/analysis/auto-analyze/parallel/progress/f36a45f7-cfe8-4f7d-bc51-24034306b040 HTTP/1.1" 200 737 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… [KoreAPI] Single call completed in 188ms: 98 messages
Retrieved 98 messages for 10 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
Populated messages for 10 SWT objects
Successfully populated messages for 10 sessions using lazy loading
Applying final filtering to 10 sessions with populated messages
Final result: 10 sessions passed filtering with populated messages

ğŸ‰ ============ SESSION SAMPLING COMPLETED ============
â±ï¸  TOTAL TIME: 7207ms (7.21s)
â±ï¸  Session Discovery: 7016ms (7.02s) - 97.3% of total
â±ï¸  Message Retrieval: 190ms (0.19s) - 2.6% of total
â±ï¸  Performance: 1.4 sessions/second
ğŸ¯ Final result: 10 sessions with messages retrieved
====================================================

[StrategicDiscoveryService] Starting discovery phase with 10 total sessions
[StrategicDiscoveryService] Discovery config: {
  targetPercentage: 15,
  minSessions: 5,
  maxSessions: 5,
  diversityStrategy: {
    sessionLengths: [ 'short', 'medium', 'long' ],
    containmentTypes: [ 'agent', 'selfService', 'dropOff' ],
    timeDistribution: 'spread'
  }
}
[StrategicDiscoveryService] Selecting 5 diverse sessions from 10 total
[StrategicDiscoveryService] Session diversity groups: { short: 6, medium: 4, early: 3, middle: 3, late: 4 }
[StrategicDiscoveryService] Selected sessions by length distribution: { short: 3, medium: 2, long: 0 }
[StrategicDiscoveryService] Selected 5 sessions for discovery

ğŸ“¦ ===== BATCH 1 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T19:33:19.681Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 0
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T19:33:19.681Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:33:19.683Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6201,
  existingClassifications: { intents: 0, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.



For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and another intent, classify the intent as the other i...
::1 - - [12/Aug/2025:19:33:21 +0000] "GET /api/analysis/auto-analyze/parallel/progress/f36a45f7-cfe8-4f7d-bc51-24034306b040 HTTP/1.1" 200 830 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:33:22.864Z',
  duration: '3181ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1804,
    completion_tokens: 359,
    total_tokens: 2163,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [
    'Unknown',
    'Claim status',
    'New claim',
    'Starting a claim',
    'Time entry'
  ],
  transferCount: 4,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-29555d49-006e-5a3c-b98d-269e178f6f26",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "Session ended with the bot closing the conversation due to no user input."
    },
    {
      "user_id": "u-f2866308-bb39-5ede-97ab-3e7cd60e0abf",
      "general_intent": "Claim status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested claim status and was transferred to a live agent for further assistance."
    },
    {
      "user_id": "u-29aeefce-9f22-5329-82de-f7d9053f628b",
      "general_intent": "New claim",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to start a new claim and was transferred to a live agent."
    },
    {
      "user_id": "u-19472037-1001-52e3-83f7-0ea9c51fb9b5",
      "general_intent": "Starting a claim",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to start a new claim and was transferred to a live agent."
    },
    {
      "user_id": "u-dd7bee24-c2ce-51b0-9026-827edeae6fc1",
      "general_intent": "Time entry",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User inquired about time entry and was transferred to a live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1804,
  completionTokens: 359,
  totalTokens: 2163,
  cost: '$0.000324',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 3183ms (3.18s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2163 ($0.0003)
âš¡ Performance: 679.5 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 3183ms (3.18s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2163

âœ… ===== BATCH 1 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 3183ms (3.18s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2163 ($0.0003)
âš¡ Performance: 1.6 sessions/sec
âš¡ Avg Time Per Session: 636.60ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 1 complete: 7 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 5, reasons: 1, locations: 1, total: 7 }
[StrategicDiscoveryService] Discovery phase complete: {
  totalProcessed: 5,
  uniqueIntents: 5,
  uniqueReasons: 1,
  uniqueLocations: 1,
  discoveryRate: 0.4666666666666667
}

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T19:33:22.865Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms
[ParallelProcessingOrchestrator] Configuration for 5 sessions:
  Design: 8 streams Ã— 4 sessions = 32 per round
  Optimal: 2 streams Ã— 3 sessions = 6 per round
  Estimated Rounds: 1
[ParallelAutoAnalyzeService] Using parallel config: {
  streamCount: 2,
  sessionsPerStream: 3,
  maxSessionsPerLLMCall: 50,
  syncFrequency: 'after_each_round',
  retryAttempts: 3,
  debugLogging: false
}

ğŸš€ ============ PARALLEL PROCESSING STARTED ============
â±ï¸  Start Time: 2025-08-12T19:33:22.871Z
ğŸ“Š Total Sessions: 5

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T19:33:22.872Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms

âš™ï¸  ============ PARALLEL CONFIGURATION ============
â±ï¸  Config Time: 0ms
ğŸ”§ Stream Count: 2
ğŸ“¦ Sessions Per Stream: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per API Call: 50
ğŸ¯ Debug Logging: false

ğŸ”„ ============ ROUND 1/1 STARTED ============
â±ï¸  Round 1 Start: 2025-08-12T19:33:22.872Z
ğŸ“Š Sessions Remaining: 5
[ParallelProcessingOrchestrator] Distributed 5 sessions across 2 streams: [ 'Stream 1: 3 sessions', 'Stream 2: 2 sessions' ]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 2

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 2 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T19:33:22.872Z
ğŸ“Š Sessions Assigned: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:33:22.872Z
ğŸ“Š Sessions to Estimate: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 3
   â€¢ Session Tokens: 510
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6010
   â€¢ Avg Per Session: 170 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6010
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 3

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6010
ğŸ“¦ Recommended Batch Size: 3
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:33:22.873Z
ğŸ“Š Sessions to Analyze: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:33:22.873Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 3,
  apiKey: 'sk-proj-...',
  promptLength: 5295,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim status, New claim, Starting a claim, Time entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim S...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T19:33:22.873Z
ğŸ“Š Sessions Assigned: 2
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:33:22.873Z
ğŸ“Š Sessions to Estimate: 2
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 2
   â€¢ Session Tokens: 317
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 5817
   â€¢ Avg Per Session: 159 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 5817
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0009
ğŸ“Š Recommended Batch Size: 2

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 5817
ğŸ“¦ Recommended Batch Size: 2
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0009

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:33:22.873Z
ğŸ“Š Sessions to Analyze: 2
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:33:22.873Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 2,
  apiKey: 'sk-proj-...',
  promptLength: 4564,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim status, New claim, Starting a claim, Time entry, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim S...
::1 - - [12/Aug/2025:19:33:23 +0000] "GET /api/analysis/auto-analyze/parallel/progress/f36a45f7-cfe8-4f7d-bc51-24034306b040 HTTP/1.1" 200 844 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:33:24.064Z',
  duration: '1191ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1341,
    completion_tokens: 144,
    total_tokens: 1485,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 2,
  intentsFound: [ 'Live Agent', 'Unknown' ],
  transferCount: 1,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-098734a7-5f97-51c9-af5b-e4a8a6759ef1",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-9291b3b7-c61a-5387-82f1-045ab9e7a258",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User did not provide any input and the session was closed by the bot."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1341,
  completionTokens: 144,
  totalTokens: 1485,
  cost: '$0.000192',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1192ms (1.19s)
ğŸ“Š Sessions Returned: 2
ğŸ’° Tokens Used: 1485 ($0.0002)
âš¡ Performance: 1245.8 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1341
   â€¢ Completion Tokens: 144
[SessionValidationService] Validating batch response: 2 input sessions, 2 response sessions
[SessionValidationService] Validation successful: all 2 sessions processed
[SessionValidationService] Validating batch response: 2 input sessions, 2 response sessions
[SessionValidationService] Validation successful: all 2 sessions processed
â±ï¸  Stream 2 Single Batch Time: 1194ms (1.19s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 1194ms (1.19s)
ğŸ“Š Sessions Processed: 2/2
ğŸ’° Tokens Used: 1485 ($0.0002)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.7 sessions/sec
âš¡ Avg Time Per Session: 597.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:33:24.573Z',
  duration: '1700ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1548,
    completion_tokens: 209,
    total_tokens: 1757,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 3,
  intentsFound: [ 'Live Agent', 'Unknown', 'Starting a claim' ],
  transferCount: 2,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-7faada7a-4cee-5f40-b53b-be0790cc7364",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent, session was transferred."
    },
    {
      "user_id": "u-47411b87-d71e-5227-acf0-5bf91b640d69",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User was silent and did not respond, session ended without transfer."
    },
    {
      "user_id": "u-583c7f73-871c-58a0-a8c6-c5d8f2647356",
      "general_intent": "Starting a claim",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested FMLA paperwork and to speak to customer service, session was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1548,
  completionTokens: 209,
  totalTokens: 1757,
  cost: '$0.000238',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1701ms (1.70s)
ğŸ“Š Sessions Returned: 3
ğŸ’° Tokens Used: 1757 ($0.0002)
âš¡ Performance: 1032.9 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1548
   â€¢ Completion Tokens: 209
[SessionValidationService] Validating batch response: 3 input sessions, 3 response sessions
[SessionValidationService] Validation successful: all 3 sessions processed
[SessionValidationService] Validating batch response: 3 input sessions, 3 response sessions
[SessionValidationService] Validation successful: all 3 sessions processed
â±ï¸  Stream 1 Single Batch Time: 1702ms (1.70s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 1702ms (1.70s)
ğŸ“Š Sessions Processed: 3/3
ğŸ’° Tokens Used: 1757 ($0.0002)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.8 sessions/sec
âš¡ Avg Time Per Session: 567.33ms
[ParallelProcessingOrchestrator] Parallel processing complete: 2/2 streams succeeded
â±ï¸  Parallel Processing Time: 1702ms (1.70s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 2 streams
[ParallelProcessingOrchestrator] Synchronization complete: 1 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 1
ğŸ“Š Total Classifications: 8

âœ… ============ ROUND 1 COMPLETED ============
â±ï¸  Round 1 Total Time: 1703ms (1.70s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 0
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 1702ms (99.9%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ‰ ============ PARALLEL PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 1704ms (1.70s)
ğŸ“Š Sessions Processed: 5/5
ğŸ”„ Total Rounds: 1
ğŸŒŠ Stream Results: 2
ğŸ’° Token Usage: 3242 tokens ($0.0004)
ğŸ“ˆ Stream Utilization: 100.0%
ğŸ¯ Performance: 2.9 sessions/second
âš¡ Avg Time Per Session: 340.80ms

ğŸ“Š Stream Performance Breakdown:
   Stream 1: 3 sessions in 1702ms (1032.3 tokens/sec)
   Stream 2: 2 sessions in 1194ms (1243.7 tokens/sec)
[ConflictResolutionService] Starting conflict resolution for 10 sessions
[ConflictResolutionService] Found classifications: { intents: 6, reasons: 1, locations: 1 }
[ConflictResolutionService] Calling LLM for conflict resolution with model gpt-4.1-nano
ğŸ”§ Conflict Resolution Prompt Preview: You are reviewing classifications from parallel analysis streams. Identify any semantic duplicates and choose the canonical version for each group.

**Instructions:**
1. Look for classifications that refer to the same concept but use different wording
2. For each group of duplicates, choose the most...
::1 - - [12/Aug/2025:19:33:25 +0000] "GET /api/analysis/auto-analyze/parallel/progress/f36a45f7-cfe8-4f7d-bc51-24034306b040 HTTP/1.1" 200 863 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[ConflictResolution] LLM response: {
  "generalIntents": [
    {
      "canonical": "Claim Status Inquiry",
      "aliases": [
        "Claim status",
        "Claim Inquiry"
      ]
    },
    {
      "canonical": "Live Agent Transfer",
      "aliases": [
        "Live Agent",
        "Transfer to Human"
      ]
    },
    {
      "canonical": "New Claim Initiation",
      "aliases": [
        "New claim",
        "Starting a claim"
      ]
    },
    {
      "canonical": "Time Entry Assistance",
      "aliases": [
        "Time entry"
      ]
    },
    {
      "canonical": "Unknown Intent",
      "aliases": [
        "Unknown"
      ]
    }
  ],
  "transferReasons": [
    {
      "canonical": "Live Agent Request",
      "aliases": [
        "Live Agent Request"
      ]
    }
  ],
  "dropOffLocations": [
    {
      "canonical": "Help Offer Prompt",
      "aliases": [
        "Help Offer Prompt"
      ]
    }
  ]
}
[ConflictResolutionService] LLM conflict resolution complete: { intents: 5, reasons: 1, locations: 1, tokens: 738, cost: 0.000108 }
ğŸ”§ Conflict Resolution Response: {
  "generalIntents": [
    {
      "canonical": "Claim Status Inquiry",
      "aliases": [
        "Claim status",
        "Claim Inquiry"
      ]
    },
    {
      "canonical": "Live Agent Transfer",
      "aliases": [
        "Live Agent",
        "Transfer to Human"
      ]
    },
    {
      "canonical": "New Claim Initiation",
      "aliases": [
        "New claim",
        "Starting a claim"
      ]
    },
    {
      "canonical": "Time Entry Assistance",
      "aliases": [
        "Time entry"
      ]
    },
    {
      "canonical": "Unknown Intent",
      "aliases": [
        "Unknown"
      ]
    }
  ],
  "transferReasons": [
    {
      "canonical": "Live Agent Request",
      "aliases": [
        "Live Agent Request"
      ]
    }
  ],
  "dropOffLocations": [
    {
      "canonical": "Help Offer Prompt",
      "aliases": [
        "Help Offer Prompt"
      ]
    }
  ]
}
[ConflictResolutionService] Applying resolutions to 10 sessions
[ConflictResolutionService] Applied 10 classification mappings across 10 sessions
[ConflictResolutionService] Identified 1 potential conflict groups
[ConflictResolutionService] Conflict resolution complete in 1596ms: { conflictsFound: 1, conflictsResolved: 7, canonicalMappings: 10 }
[ParallelAutoAnalyzeService] Using real analysis summary service
::1 - - [12/Aug/2025:19:33:27 +0000] "GET /api/analysis/auto-analyze/parallel/progress/f36a45f7-cfe8-4f7d-bc51-24034306b040 HTTP/1.1" 200 938 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:33:29 +0000] "GET /api/analysis/auto-analyze/parallel/progress/f36a45f7-cfe8-4f7d-bc51-24034306b040 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:33:31 +0000] "GET /api/analysis/auto-analyze/parallel/progress/f36a45f7-cfe8-4f7d-bc51-24034306b040 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:33:33 +0000] "GET /api/analysis/auto-analyze/parallel/progress/f36a45f7-cfe8-4f7d-bc51-24034306b040 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:33:35 +0000] "GET /api/analysis/auto-analyze/parallel/progress/f36a45f7-cfe8-4f7d-bc51-24034306b040 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:33:37 +0000] "GET /api/analysis/auto-analyze/parallel/progress/f36a45f7-cfe8-4f7d-bc51-24034306b040 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[ParallelAutoAnalyzeService] Parallel analysis f36a45f7-cfe8-4f7d-bc51-24034306b040 completed successfully
[BackgroundJobQueue] Updated job progress to final state: complete
[BackgroundJobQueue] Parallel analysis job f36a45f7-cfe8-4f7d-bc51-24034306b040-parallel completed successfully
::1 - - [12/Aug/2025:19:33:39 +0000] "GET /api/analysis/auto-analyze/parallel/progress/f36a45f7-cfe8-4f7d-bc51-24034306b040 HTTP/1.1" 200 974 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:33:39 +0000] "GET /api/analysis/auto-analyze/parallel/results/f36a45f7-cfe8-4f7d-bc51-24034306b040 HTTP/1.1" 200 61769 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T19:33:30.633Z",
  "dateTo": "2025-08-12T19:34:30.633Z",
  "skip": 0,
  "limit": 1
}
[fetchContainmentTypeMetadata] API Response: 1 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [ '689b9725144f8feea185d4fe' ]
[getSessionsMetadataForConnectionTest] Single API call succeeded with 1 sessions
::1 - - [12/Aug/2025:19:34:33 +0000] "GET /api/kore/test HTTP/1.1" 200 851 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[Direct API] Fetching real Kore.ai sessions from 2025-08-05T19:34:34.097Z to 2025-08-12T19:34:34.097Z for User Bot st-90549... (limit=50)
Retrieving sessions from 2025-08-05T19:34:34.097Z to 2025-08-12T19:34:34.097Z (limit=50), populateMessages=true...
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T19:34:34.097Z",
  "dateTo": "2025-08-12T19:34:34.097Z",
  "limit": 50
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:34:34.097Z",
  "dateTo": "2025-08-12T19:34:34.097Z",
  "skip": 0,
  "limit": 50
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:34:34.097Z",
  "dateTo": "2025-08-12T19:34:34.097Z",
  "skip": 0,
  "limit": 50
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:34:34.097Z",
  "dateTo": "2025-08-12T19:34:34.097Z",
  "skip": 0,
  "limit": 50
}
::1 - - [12/Aug/2025:19:34:34 +0000] "GET /api/analysis/sessions?limit=50 HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 50 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b92fdbf7ccd3cf0fce989',
  '689b9284618775e3b37c7f05',
  '689b9239e6e30b33f5c3a8aa'
]
[fetchContainmentTypeMetadata] API Response: 50 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b97480a261bd4437a1b49',
  '689b9745946228cfd4531e64',
  '689b9742144f8feea185d92a'
]
[fetchContainmentTypeMetadata] API Response: 50 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b97375f04b9bca7ba14d6',
  '689b971c0a261bd4437a1601',
  '689b97138b529fd4fab5cad7'
]
[getSessionsMetadata] agent API call succeeded with 50 sessions
[getSessionsMetadata] selfService API call succeeded with 50 sessions
[getSessionsMetadata] dropOff API call succeeded with 50 sessions
Total session metadata retrieved: 150 (parallel execution)
Retrieved 150 session metadata objects
Creating 150 SWTs from metadata (no messages)
Created 150 SWT objects from metadata
Populating messages for all sessions (legacy behavior)
Populating messages for 150 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 150 sessions from 2025-08-12T18:22:17.564Z to 2025-08-12T19:34:32.836Z at 2025-08-12T19:34:37.375Z
ğŸš€ [ConcurrentBatch] Split 150 sessions into 8 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/8] Starting: 20 sessions
[Batch 2/8] Starting: 20 sessions
[Batch 3/8] Starting: 20 sessions
[Batch 4/8] Starting: 20 sessions
[Batch 5/8] Starting: 20 sessions
[Batch 6/8] Starting: 20 sessions
[Batch 7/8] Starting: 20 sessions
[Batch 8/8] Starting: 10 sessions
[Batch 3/8] Completed in 256ms: 148 messages retrieved (1/8 done)
[Batch 2/8] Completed in 263ms: 211 messages retrieved (2/8 done)
[Batch 1/8] Completed in 275ms: 190 messages retrieved (3/8 done)
[Batch 6/8] Completed in 419ms: 186 messages retrieved (4/8 done)
[Batch 7/8] Completed in 426ms: 199 messages retrieved (5/8 done)
[Batch 8/8] Completed in 432ms: 157 messages retrieved (6/8 done)
[Batch 4/8] Completed in 453ms: 255 messages retrieved (7/8 done)
[Batch 5/8] Completed in 560ms: 501 messages retrieved (8/8 done)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 560ms (0.56s)
â±ï¸  Batch Processing: 560ms (0.56s)
ğŸ“¦ Total batches: 8 (max 10 concurrent)
âœ… Successful batches: 8/8
ğŸ’¬ Total messages: 1847
ğŸ“ˆ Avg time per batch: 70ms
ğŸš€ Time per session: 4ms
ğŸ’ª Performance: 267.9 sessions/second
=======================================================

Retrieved 1847 messages for 150 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
Populated messages for 150 SWT objects
Generated 150 SWT objects in 3849ms using layered architecture
ğŸš€ [ParallelAutoAnalyzeRoute] Starting parallel analysis for bot ***REMOVED*** with real credentials
ğŸš€ [ParallelAutoAnalyzeService] Starting parallel analysis 957b9e43-d060-4d9f-b7e9-29b1710f203a with bot ***REMOVED***
ğŸš€ [ParallelAutoAnalyzeService] Using credentials: real
ğŸš€ [ParallelAutoAnalyzeRoute] Parallel analysis started: 957b9e43-d060-4d9f-b7e9-29b1710f203a
::1 - - [12/Aug/2025:19:34:53 +0000] "POST /api/analysis/auto-analyze/parallel/start HTTP/1.1" 200 214 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:34:53 +0000] "GET /api/analysis/auto-analyze/parallel/progress/957b9e43-d060-4d9f-b7e9-29b1710f203a HTTP/1.1" 200 542 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:34:53 +0000] "GET /api/analysis/auto-analyze/parallel/progress/957b9e43-d060-4d9f-b7e9-29b1710f203a HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[BackgroundJobQueue] Starting job processing after delay for job 957b9e43-d060-4d9f-b7e9-29b1710f203a-parallel
[BackgroundJobQueue] Starting processing for job 957b9e43-d060-4d9f-b7e9-29b1710f203a-parallel, phase: sampling
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing parallel analysis job 957b9e43-d060-4d9f-b7e9-29b1710f203a-parallel
[BackgroundJobQueue] Processing parallel analysis for bot ***REMOVED***
[BackgroundJobQueue] Using existing ParallelAutoAnalyzeService instance for bot ***REMOVED***
[BackgroundJobQueue] Session recreated for 957b9e43-d060-4d9f-b7e9-29b1710f203a
[ParallelAutoAnalyzeService] Running parallel analysis for 957b9e43-d060-4d9f-b7e9-29b1710f203a
[ParallelAutoAnalyzeService] Phase 0: Starting session sampling for 957b9e43-d060-4d9f-b7e9-29b1710f203a

ğŸ• ============ SESSION SAMPLING STARTED ============
ğŸ• [SessionSampling] Starting session sampling at 2025-08-12T19:34:54.014Z
ğŸ” [SessionDiscovery] Starting window 1/4: Initial 3-hour window
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
::1 - - [12/Aug/2025:19:34:55 +0000] "GET /api/analysis/auto-analyze/parallel/progress/957b9e43-d060-4d9f-b7e9-29b1710f203a HTTP/1.1" 200 719 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 80 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a1287849680ad9fe59e',
  '689229f9583056c6108e38fb',
  '68922914f8bee7ba6c3e67b8'
]
::1 - - [12/Aug/2025:19:34:57 +0000] "GET /api/analysis/auto-analyze/parallel/progress/957b9e43-d060-4d9f-b7e9-29b1710f203a HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 1338 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6d14dd27c31120888b',
  '68922a62e3804084741191d5',
  '68922a523a3160d25de144c8'
]
[fetchContainmentTypeMetadata] API Response: 139 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6a14dd27c3112087cd',
  '68922a22ef03d8ad2ec7b4ba',
  '68922a1278c1fe09a079719c'
]
[getSessionsMetadata] agent API call succeeded with 1338 sessions
[getSessionsMetadata] selfService API call succeeded with 80 sessions
[getSessionsMetadata] dropOff API call succeeded with 139 sessions
Total session metadata retrieved: 1557 (parallel execution)
Creating 1557 SWTs from metadata (no messages)
Created 1557 SWT objects from metadata
âœ… [SessionDiscovery] Window 1 completed in 4284ms: found 1557 new sessions (total: 1557)
â±ï¸  TIMING: Window 1 took 4284ms (4.28s)
ğŸ¯ [SessionDiscovery] Target reached! Found 1557 sessions in 4284ms
ğŸ² [SessionSampling] Random sampling from 1557 sessions to 100 sessions

ğŸ“¬ ============ MESSAGE RETRIEVAL STARTED ============
ğŸ“¬ [MessageRetrieval] Starting message retrieval for 100 sampled sessions at 2025-08-12T19:34:58.300Z
Using new lazy loading approach to populate messages for 100 sampled sessions
Populating messages for 100 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 100 sessions from 2025-08-05T13:02:41.192Z to 2025-08-05T15:59:32.792Z at 2025-08-12T19:34:58.301Z
ğŸš€ [ConcurrentBatch] Split 100 sessions into 5 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/5] Starting: 20 sessions
[Batch 2/5] Starting: 20 sessions
[Batch 3/5] Starting: 20 sessions
[Batch 4/5] Starting: 20 sessions
[Batch 5/5] Starting: 20 sessions
[Batch 2/5] Completed in 342ms: 272 messages retrieved (1/5 done)
ğŸ“Š [BatchProgress] Reporting batch 1/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 40/100 sessions (Batch 2/5)
[Batch 3/5] Completed in 410ms: 238 messages retrieved (2/5 done)
ğŸ“Š [BatchProgress] Reporting batch 2/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 60/100 sessions (Batch 3/5)
[Batch 1/5] Completed in 423ms: 268 messages retrieved (3/5 done)
ğŸ“Š [BatchProgress] Reporting batch 3/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 80/100 sessions (Batch 4/5)
[Batch 5/5] Completed in 527ms: 261 messages retrieved (4/5 done)
ğŸ“Š [BatchProgress] Reporting batch 4/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 100/100 sessions (Batch 5/5)
[Batch 4/5] Completed in 619ms: 259 messages retrieved (5/5 done)
ğŸ“Š [BatchProgress] Reporting batch 5/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 100/100 sessions (Batch 6/5)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 620ms (0.62s)
â±ï¸  Batch Processing: 620ms (0.62s)
ğŸ“¦ Total batches: 5 (max 10 concurrent)
âœ… Successful batches: 5/5
ğŸ’¬ Total messages: 1298
ğŸ“ˆ Avg time per batch: 124ms
ğŸš€ Time per session: 6ms
ğŸ’ª Performance: 161.3 sessions/second
=======================================================

Retrieved 1298 messages for 100 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
Populated messages for 100 SWT objects
Successfully populated messages for 100 sessions using lazy loading
Applying final filtering to 100 sessions with populated messages
Final result: 100 sessions passed filtering with populated messages

ğŸ‰ ============ SESSION SAMPLING COMPLETED ============
â±ï¸  TOTAL TIME: 4921ms (4.92s)
â±ï¸  Session Discovery: 4284ms (4.28s) - 87.1% of total
â±ï¸  Message Retrieval: 635ms (0.64s) - 12.9% of total
â±ï¸  Performance: 20.3 sessions/second
ğŸ¯ Final result: 100 sessions with messages retrieved
====================================================

[StrategicDiscoveryService] Starting discovery phase with 100 total sessions
[StrategicDiscoveryService] Discovery config: {
  targetPercentage: 15,
  minSessions: 10,
  maxSessions: 15,
  diversityStrategy: {
    sessionLengths: [ 'short', 'medium', 'long' ],
    containmentTypes: [ 'agent', 'selfService', 'dropOff' ],
    timeDistribution: 'spread'
  }
}
[StrategicDiscoveryService] Selecting 15 diverse sessions from 100 total
[StrategicDiscoveryService] Session diversity groups: { short: 22, medium: 78, early: 33, middle: 33, late: 34 }
[StrategicDiscoveryService] Selected sessions by length distribution: { short: 5, medium: 10, long: 0 }
[StrategicDiscoveryService] Selected 15 sessions for discovery

ğŸ“¦ ===== BATCH 2 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T19:34:58.936Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 0
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T19:34:58.936Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:34:58.936Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 5954,
  existingClassifications: { intents: 0, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.



For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and another intent, classify the intent as the other i...
::1 - - [12/Aug/2025:19:34:59 +0000] "GET /api/analysis/auto-analyze/parallel/progress/957b9e43-d060-4d9f-b7e9-29b1710f203a HTTP/1.1" 200 934 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:35:01 +0000] "GET /api/analysis/auto-analyze/parallel/progress/957b9e43-d060-4d9f-b7e9-29b1710f203a HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:35:01.578Z',
  duration: '2641ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1740,
    completion_tokens: 360,
    total_tokens: 2100,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Unknown', 'Portal Access', 'Live Agent', 'Leave Request' ],
  transferCount: 4,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-0be9b316-460b-5ac5-ad32-9b39063b0e8a",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "Session ended without user input, session was closed by bot."
    },
    {
      "user_id": "u-d66ee204-2e12-5781-8885-7f0af13f0631",
      "general_intent": "Portal Access",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested help with logging in, session was transferred to a live agent."
    },
    {
      "user_id": "u-5051df9a-0b19-5d48-a270-0c5e4d966302",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and did not respond, session was transferred to a live agent."
    },
    {
      "user_id": "u-8cc6d7c3-adb3-5ad5-95b0-5236c8135292",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent, session was transferred."
    },
    {
      "user_id": "u-730f41fa-a16e-5a27-bd66-2854187f089b",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested leave for a family member, session was transferred to a live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1740,
  completionTokens: 360,
  totalTokens: 2100,
  cost: '$0.000318',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 2643ms (2.64s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2100 ($0.0003)
âš¡ Performance: 794.6 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 2643ms (2.64s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2100

âœ… ===== BATCH 2 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 2643ms (2.64s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2100 ($0.0003)
âš¡ Performance: 1.9 sessions/sec
âš¡ Avg Time Per Session: 528.60ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 1 complete: 6 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 4, reasons: 1, locations: 1, total: 6 }

ğŸ“¦ ===== BATCH 3 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T19:35:01.580Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T19:35:01.580Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:35:01.580Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 8052,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Leave Request, Live Agent, Portal Access, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Bill...
::1 - - [12/Aug/2025:19:35:03 +0000] "GET /api/analysis/auto-analyze/parallel/progress/957b9e43-d060-4d9f-b7e9-29b1710f203a HTTP/1.1" 200 936 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:35:03.326Z',
  duration: '1746ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2265,
    completion_tokens: 282,
    total_tokens: 2547,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Unknown' ],
  transferCount: 5,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-a41e2e37-e2a1-5445-a774-37a5b928ba0d",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-d2c766a4-4198-5bdb-90eb-b69d0d5ffc1f",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-aeb8d386-64f2-56d8-ab42-c6a78d5be396",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-18243561-78b8-5e0c-a0d7-a913d0c5f1fb",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-a955fadb-d98e-56da-9959-be09cc851ddc",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2265,
  completionTokens: 282,
  totalTokens: 2547,
  cost: '$0.000339',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 1747ms (1.75s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2547 ($0.0003)
âš¡ Performance: 1457.9 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 1747ms (1.75s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2547

âœ… ===== BATCH 3 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 1747ms (1.75s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2547 ($0.0003)
âš¡ Performance: 2.9 sessions/sec
âš¡ Avg Time Per Session: 349.40ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 2 complete: 0 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 4, reasons: 1, locations: 1, total: 6 }

ğŸ“¦ ===== BATCH 4 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T19:35:03.327Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T19:35:03.327Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:35:03.328Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7300,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Leave Request, Live Agent, Portal Access, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Bill...
::1 - - [12/Aug/2025:19:35:05 +0000] "GET /api/analysis/auto-analyze/parallel/progress/957b9e43-d060-4d9f-b7e9-29b1710f203a HTTP/1.1" 200 936 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:35:07 +0000] "GET /api/analysis/auto-analyze/parallel/progress/957b9e43-d060-4d9f-b7e9-29b1710f203a HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:35:07.795Z',
  duration: '4467ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2081,
    completion_tokens: 347,
    total_tokens: 2428,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Live Agent', 'Unknown' ],
  transferCount: 4,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-f3ee8894-fed2-5271-bbce-2d85282bc015",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent, leading to transfer."
    },
    {
      "user_id": "u-d1f176df-8f2a-52d8-b5dd-f58cf28c344d",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to change FMLA status, transferred to live agent."
    },
    {
      "user_id": "u-81641625-86ad-5ba0-a837-b98a3ef90af5",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and transferred after no input."
    },
    {
      "user_id": "u-dae579d0-d327-5f2f-b379-c05e5f622e03",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User discussed FMLA denial and reapplication, then transferred."
    },
    {
      "user_id": "u-11140dec-4046-56e0-b3e7-5a33152a1b76",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User attempted to return to work but session ended due to no input."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2081,
  completionTokens: 347,
  totalTokens: 2428,
  cost: '$0.000347',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 4468ms (4.47s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2428 ($0.0003)
âš¡ Performance: 543.4 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 4468ms (4.47s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2428

âœ… ===== BATCH 4 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 4469ms (4.47s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2428 ($0.0003)
âš¡ Performance: 1.1 sessions/sec
âš¡ Avg Time Per Session: 893.80ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 3 complete: 0 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 4, reasons: 1, locations: 1, total: 6 }
[StrategicDiscoveryService] Discovery phase complete: {
  totalProcessed: 15,
  uniqueIntents: 4,
  uniqueReasons: 1,
  uniqueLocations: 1,
  discoveryRate: 0.4
}

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T19:35:07.796Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms
[ParallelProcessingOrchestrator] Configuration for 85 sessions:
  Design: 8 streams Ã— 4 sessions = 32 per round
  Optimal: 8 streams Ã— 4 sessions = 32 per round
  Estimated Rounds: 3
[ParallelAutoAnalyzeService] Using parallel config: {
  streamCount: 8,
  sessionsPerStream: 4,
  maxSessionsPerLLMCall: 50,
  syncFrequency: 'after_each_round',
  retryAttempts: 3,
  debugLogging: false
}

ğŸš€ ============ PARALLEL PROCESSING STARTED ============
â±ï¸  Start Time: 2025-08-12T19:35:07.797Z
ğŸ“Š Total Sessions: 85

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T19:35:07.797Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms

âš™ï¸  ============ PARALLEL CONFIGURATION ============
â±ï¸  Config Time: 0ms
ğŸ”§ Stream Count: 8
ğŸ“¦ Sessions Per Stream: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per API Call: 50
ğŸ¯ Debug Logging: false

ğŸ”„ ============ ROUND 1/3 STARTED ============
â±ï¸  Round 1 Start: 2025-08-12T19:35:07.797Z
ğŸ“Š Sessions Remaining: 85
[ParallelProcessingOrchestrator] Distributed 32 sessions across 8 streams: [
  'Stream 1: 4 sessions',
  'Stream 2: 4 sessions',
  'Stream 3: 4 sessions',
  'Stream 4: 4 sessions',
  'Stream 5: 4 sessions',
  'Stream 6: 4 sessions',
  'Stream 7: 4 sessions',
  'Stream 8: 4 sessions'
]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 8

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 8 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T19:35:07.798Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:35:07.798Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 703
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6203
   â€¢ Avg Per Session: 176 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6203
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6203
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:35:07.798Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:35:07.799Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5949,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Leave Request, Live Agent, Portal Access, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Bill...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T19:35:07.799Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:35:07.799Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 997
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6497
   â€¢ Avg Per Session: 249 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6497
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6497
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:35:07.799Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:35:07.799Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7389,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Leave Request, Live Agent, Portal Access, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Bill...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T19:35:07.799Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:35:07.799Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 840
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6340
   â€¢ Avg Per Session: 210 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6340
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6340
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:35:07.800Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:35:07.800Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6624,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Leave Request, Live Agent, Portal Access, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Bill...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T19:35:07.800Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:35:07.800Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 728
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6228
   â€¢ Avg Per Session: 182 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6228
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6228
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:35:07.800Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:35:07.800Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6085,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Leave Request, Live Agent, Portal Access, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Bill...

ğŸŒŠ ===== STREAM 5 PROCESSING START =====
â±ï¸  Stream 5 Start: 2025-08-12T19:35:07.801Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:35:07.801Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 1032
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6532
   â€¢ Avg Per Session: 258 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6532
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 5) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6532
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 5: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:35:07.801Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:35:07.801Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7467,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Leave Request, Live Agent, Portal Access, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Bill...

ğŸŒŠ ===== STREAM 6 PROCESSING START =====
â±ï¸  Stream 6 Start: 2025-08-12T19:35:07.801Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:35:07.801Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 735
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6235
   â€¢ Avg Per Session: 184 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6235
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 6) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6235
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 6: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:35:07.801Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:35:07.801Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6155,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Leave Request, Live Agent, Portal Access, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Bill...

ğŸŒŠ ===== STREAM 7 PROCESSING START =====
â±ï¸  Stream 7 Start: 2025-08-12T19:35:07.802Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:35:07.802Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 1066
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6566
   â€¢ Avg Per Session: 267 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6566
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0011
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 7) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6566
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0011

âš¡ Stream 7: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:35:07.802Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:35:07.802Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7733,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Leave Request, Live Agent, Portal Access, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Bill...

ğŸŒŠ ===== STREAM 8 PROCESSING START =====
â±ï¸  Stream 8 Start: 2025-08-12T19:35:07.802Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:35:07.802Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 894
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6394
   â€¢ Avg Per Session: 224 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6394
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 8) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6394
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 8: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:35:07.802Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 4
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:35:07.802Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6854,
  existingClassifications: { intents: 4, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Leave Request, Live Agent, Portal Access, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Bill...
::1 - - [12/Aug/2025:19:35:09 +0000] "GET /api/analysis/auto-analyze/parallel/progress/957b9e43-d060-4d9f-b7e9-29b1710f203a HTTP/1.1" 200 933 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:35:09.344Z',
  duration: '1543ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1751,
    completion_tokens: 210,
    total_tokens: 1961,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-de5a6c4d-ff89-5e1a-834b-3a1e29b987b7",
      "notes": "User wanted to speak with an agent about FMLA leave, session was transferred to an agent."
    },
    {
      "user_id": "u-4e5aa05c-2163-5359-912b-ad826a074166",
      "notes": "User wanted to open a new leave request, session was transferred to an agent."
    },
    {
      "user_id": "u-3a6ccfa3-eea8-5408-bde6-830b4c6e21d3",
      "notes": "User wanted to speak with an agent about a letter, session was transferred to an agent."
    },
    {
      "user_id": "u-3b4b1bcb-2ae5-5f9b-8b87-5a02617afa03",
      "notes": "User wanted to report an absence, session was not transferred, handled by bot."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1751,
  completionTokens: 210,
  totalTokens: 1961,
  cost: '$0.000259',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1545ms (1.54s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1961 ($0.0003)
âš¡ Performance: 1269.3 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1751
   â€¢ Completion Tokens: 210
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-de5a6c4d-ff89-5e1a-834b-3a1e29b987b7: Invalid general_intent, u-de5a6c4d-ff89-5e1a-834b-3a1e29b987b7: Invalid session_outcome, u-4e5aa05c-2163-5359-912b-ad826a074166: Invalid general_intent, u-4e5aa05c-2163-5359-912b-ad826a074166: Invalid session_outcome, u-3a6ccfa3-eea8-5408-bde6-830b4c6e21d3: Invalid general_intent, u-3a6ccfa3-eea8-5408-bde6-830b4c6e21d3: Invalid session_outcome, u-3b4b1bcb-2ae5-5f9b-8b87-5a02617afa03: Invalid general_intent, u-3b4b1bcb-2ae5-5f9b-8b87-5a02617afa03: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 4 Single Batch Time: 1547ms (1.55s)

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 1547ms (1.55s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1961 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.6 sessions/sec
âš¡ Avg Time Per Session: 386.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:35:09.576Z',
  duration: '1774ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2195,
    completion_tokens: 232,
    total_tokens: 2427,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Leave Request' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-1e9379ca-e8a4-5766-be48-8fa5ed45cb1b",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-49174b80-649e-55ce-9546-4b9090c2d49c",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-5e597e44-e5b4-5492-9e80-68557a8d1c00",
      "general_intent": "Leave Request",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": ""
    },
    {
      "user_id": "u-dc7be4e0-0db9-5110-9c8e-567a2ac69f81",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2195,
  completionTokens: 232,
  totalTokens: 2427,
  cost: '$0.000312',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1775ms (1.77s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2427 ($0.0003)
âš¡ Performance: 1367.3 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2195
   â€¢ Completion Tokens: 232
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-1e9379ca-e8a4-5766-be48-8fa5ed45cb1b: Invalid notes, u-49174b80-649e-55ce-9546-4b9090c2d49c: Invalid notes, u-5e597e44-e5b4-5492-9e80-68557a8d1c00: Invalid notes, u-dc7be4e0-0db9-5110-9c8e-567a2ac69f81: Invalid notes'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 7 Single Batch Time: 1775ms (1.77s)

âœ… ===== STREAM 7 PROCESSING COMPLETE =====
â±ï¸  Stream 7 Total Time: 1775ms (1.77s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2427 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.3 sessions/sec
âš¡ Avg Time Per Session: 443.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:35:09.585Z',
  duration: '1786ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2077,
    completion_tokens: 287,
    total_tokens: 2364,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Leave Request', 'Claim Status', 'Live Agent' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-a9ba3dc6-b0ca-5f71-aebc-9f8db9e1c2ff",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was unable to provide required information and was transferred to a live agent."
    },
    {
      "user_id": "u-7a7f5dcd-41b4-50a1-b7c5-a060fff33502",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested paperwork for doctor, but was transferred to an agent for further assistance."
    },
    {
      "user_id": "u-ba606245-0a91-5b78-a542-df50d486bbd6",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User verified account details and received claim information without transfer."
    },
    {
      "user_id": "u-fc12d457-0eea-53e3-9fdc-29ef3d240195",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2077,
  completionTokens: 287,
  totalTokens: 2364,
  cost: '$0.000322',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1786ms (1.79s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2364 ($0.0003)
âš¡ Performance: 1323.6 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2077
   â€¢ Completion Tokens: 287
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 2 Single Batch Time: 1786ms (1.79s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 1786ms (1.79s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2364 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.2 sessions/sec
âš¡ Avg Time Per Session: 446.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:35:09.632Z',
  duration: '1833ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1700,
    completion_tokens: 293,
    total_tokens: 1993,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Leave Request' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-4099f1f8-2992-5913-b3ef-9ad332635954",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an operator and was transferred to an agent."
    },
    {
      "user_id": "u-f7125f43-6db1-5649-8098-0321adb64865",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-4359e8f2-8f8a-552e-9079-0c92b96c0a2b",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent in Spanish and was transferred."
    },
    {
      "user_id": "u-658c97ec-4558-58dd-b360-671da6c71d81",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User indicated intent to open a new leave request and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1700,
  completionTokens: 293,
  totalTokens: 1993,
  cost: '$0.000287',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1834ms (1.83s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1993 ($0.0003)
âš¡ Performance: 1086.7 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1700
   â€¢ Completion Tokens: 293
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 1 Single Batch Time: 1835ms (1.83s)

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 1835ms (1.83s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1993 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.2 sessions/sec
âš¡ Avg Time Per Session: 458.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:35:09.709Z',
  duration: '1908ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2084,
    completion_tokens: 292,
    total_tokens: 2376,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown', 'Claim Status' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-5763f95e-728b-5cdb-bd8c-82d4f4310898",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak to a representative but did not provide input, leading to transfer."
    },
    {
      "user_id": "u-a56d9452-9d50-59e8-a174-14885c44a01a",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak to a representative but did not provide input, leading to transfer."
    },
    {
      "user_id": "u-df15511d-d651-53ff-b863-cf89b66b7d23",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak to a representative but did not provide input, leading to transfer."
    },
    {
      "user_id": "u-84baa148-35fa-5529-9a4b-da648e66b650",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User provided claim details and completed the time entry process without transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2084,
  completionTokens: 292,
  totalTokens: 2376,
  cost: '$0.000325',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1909ms (1.91s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2376 ($0.0003)
âš¡ Performance: 1244.6 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2084
   â€¢ Completion Tokens: 292
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 5 Single Batch Time: 1909ms (1.91s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 5 PROCESSING COMPLETE =====
â±ï¸  Stream 5 Total Time: 1909ms (1.91s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2376 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.1 sessions/sec
âš¡ Avg Time Per Session: 477.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:35:10.160Z',
  duration: '2358ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1766,
    completion_tokens: 274,
    total_tokens: 2040,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Unknown', 'Claim Status' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-431f2503-0f11-50ed-b6bd-3bf4462321ff",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent and was transferred."
    },
    {
      "user_id": "u-9e7555f0-e014-5921-a47f-45e5af817ca2",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User attempted to update claim information but the session was closed without transfer."
    },
    {
      "user_id": "u-e4f3fb70-9c89-5975-a53c-06b10acb25c2",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an operator and was transferred."
    },
    {
      "user_id": "u-c525cd72-038a-5c84-88d4-9b53da0d92ee",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an operator and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1766,
  completionTokens: 274,
  totalTokens: 2040,
  cost: '$0.000286',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2359ms (2.36s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2040 ($0.0003)
âš¡ Performance: 864.8 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1766
   â€¢ Completion Tokens: 274
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 6 Single Batch Time: 2359ms (2.36s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 6 PROCESSING COMPLETE =====
â±ï¸  Stream 6 Total Time: 2359ms (2.36s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2040 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.7 sessions/sec
âš¡ Avg Time Per Session: 589.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:35:10.286Z',
  duration: '2483ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1946,
    completion_tokens: 198,
    total_tokens: 2144,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-428c0f1a-7211-5d29-8abd-2f04a9910ca5",
      "notes": "User requested to speak with an agent and was transferred to a live agent."
    },
    {
      "user_id": "u-32ab19e7-ce34-548d-8c64-7f859460d05c",
      "notes": "User inquired about claim status but was not transferred to an agent."
    },
    {
      "user_id": "u-2588c2f2-4f73-5dc5-b050-5357579be561",
      "notes": "User requested to speak to someone about FMLA and was transferred to a live agent."
    },
    {
      "user_id": "u-5ade6956-a044-5439-aa1a-7d38b3d680d7",
      "notes": "User attempted to report an absence, but session was transferred to an agent after multiple input issues."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1946,
  completionTokens: 198,
  totalTokens: 2144,
  cost: '$0.000274',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2484ms (2.48s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2144 ($0.0003)
âš¡ Performance: 863.1 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1946
   â€¢ Completion Tokens: 198
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-428c0f1a-7211-5d29-8abd-2f04a9910ca5: Invalid general_intent, u-428c0f1a-7211-5d29-8abd-2f04a9910ca5: Invalid session_outcome, u-32ab19e7-ce34-548d-8c64-7f859460d05c: Invalid general_intent, u-32ab19e7-ce34-548d-8c64-7f859460d05c: Invalid session_outcome, u-2588c2f2-4f73-5dc5-b050-5357579be561: Invalid general_intent, u-2588c2f2-4f73-5dc5-b050-5357579be561: Invalid session_outcome, u-5ade6956-a044-5439-aa1a-7d38b3d680d7: Invalid general_intent, u-5ade6956-a044-5439-aa1a-7d38b3d680d7: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 8 Single Batch Time: 2484ms (2.48s)

âœ… ===== STREAM 8 PROCESSING COMPLETE =====
â±ï¸  Stream 8 Total Time: 2484ms (2.48s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2144 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.6 sessions/sec
âš¡ Avg Time Per Session: 621.00ms
::1 - - [12/Aug/2025:19:35:11 +0000] "GET /api/analysis/auto-analyze/parallel/progress/957b9e43-d060-4d9f-b7e9-29b1710f203a HTTP/1.1" 200 933 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:35:12.720Z',
  duration: '4920ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1881,
    completion_tokens: 203,
    total_tokens: 2084,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status', 'Unknown' ],
  transferCount: 1,
  containedCount: 3
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-3ccd4175-c809-5d5a-84fb-c35b8a629042",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-72800432-86f7-53fe-8009-b95e58afa385",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": ""
    },
    {
      "user_id": "u-15956a83-8711-5b0c-b766-187dbee7dbe6",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": ""
    },
    {
      "user_id": "u-7f68f736-86f2-5048-b80e-199077af032b",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": ""
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1881,
  completionTokens: 203,
  totalTokens: 2084,
  cost: '$0.000269',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 4921ms (4.92s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2084 ($0.0003)
âš¡ Performance: 423.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1881
   â€¢ Completion Tokens: 203
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-3ccd4175-c809-5d5a-84fb-c35b8a629042: Invalid notes, u-72800432-86f7-53fe-8009-b95e58afa385: Invalid notes, u-15956a83-8711-5b0c-b766-187dbee7dbe6: Invalid notes, u-7f68f736-86f2-5048-b80e-199077af032b: Invalid notes'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 3 Single Batch Time: 4921ms (4.92s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 4922ms (4.92s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2084 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 0.8 sessions/sec
âš¡ Avg Time Per Session: 1230.50ms
[ParallelProcessingOrchestrator] Parallel processing complete: 8/8 streams succeeded
â±ï¸  Parallel Processing Time: 4925ms (4.92s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 8 streams
[ParallelProcessingOrchestrator] Synchronization complete: 1 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 1
ğŸ“Š Total Classifications: 7

âœ… ============ ROUND 1 COMPLETED ============
â±ï¸  Round 1 Total Time: 4925ms (4.92s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 53
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 4925ms (100.0%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ”„ ============ ROUND 2/3 STARTED ============
â±ï¸  Round 2 Start: 2025-08-12T19:35:12.722Z
ğŸ“Š Sessions Remaining: 53
[ParallelProcessingOrchestrator] Distributed 32 sessions across 8 streams: [
  'Stream 1: 4 sessions',
  'Stream 2: 4 sessions',
  'Stream 3: 4 sessions',
  'Stream 4: 4 sessions',
  'Stream 5: 4 sessions',
  'Stream 6: 4 sessions',
  'Stream 7: 4 sessions',
  'Stream 8: 4 sessions'
]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 8

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 8 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T19:35:12.722Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:35:12.722Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 844
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6344
   â€¢ Avg Per Session: 211 tokens
   â€¢ Estimation Time: 1ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6344
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 1ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 5ms
ğŸ“Š Estimated Tokens: 6344
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:35:12.728Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:35:12.728Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6611,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Portal Access, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim ...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T19:35:12.728Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:35:12.729Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 719
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6219
   â€¢ Avg Per Session: 180 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6219
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6219
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:35:12.729Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:35:12.729Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6094,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Portal Access, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim ...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T19:35:12.729Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:35:12.729Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 722
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6222
   â€¢ Avg Per Session: 181 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6222
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 1ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6222
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:35:12.730Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:35:12.730Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6086,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Portal Access, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim ...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T19:35:12.730Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:35:12.730Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 751
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6251
   â€¢ Avg Per Session: 188 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6251
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6251
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:35:12.731Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:35:12.731Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6240,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Portal Access, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim ...

ğŸŒŠ ===== STREAM 5 PROCESSING START =====
â±ï¸  Stream 5 Start: 2025-08-12T19:35:12.731Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:35:12.731Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 813
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6313
   â€¢ Avg Per Session: 203 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6313
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 5) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6313
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 5: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:35:12.731Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:35:12.731Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6505,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Portal Access, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim ...

ğŸŒŠ ===== STREAM 6 PROCESSING START =====
â±ï¸  Stream 6 Start: 2025-08-12T19:35:12.731Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:35:12.732Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 692
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6192
   â€¢ Avg Per Session: 173 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6192
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 6) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6192
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 6: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:35:12.732Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:35:12.732Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5917,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Portal Access, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim ...

ğŸŒŠ ===== STREAM 7 PROCESSING START =====
â±ï¸  Stream 7 Start: 2025-08-12T19:35:12.732Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:35:12.732Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 765
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6265
   â€¢ Avg Per Session: 191 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6265
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 7) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6265
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 7: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:35:12.732Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:35:12.732Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6256,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Portal Access, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim ...

ğŸŒŠ ===== STREAM 8 PROCESSING START =====
â±ï¸  Stream 8 Start: 2025-08-12T19:35:12.733Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:35:12.733Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 1104
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6604
   â€¢ Avg Per Session: 276 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6604
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0011
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 8) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6604
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0011

âš¡ Stream 8: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:35:12.733Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 5
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:35:12.733Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7768,
  existingClassifications: { intents: 5, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Leave Request, Live Agent, Portal Access, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim ...
::1 - - [12/Aug/2025:19:35:13 +0000] "GET /api/analysis/auto-analyze/parallel/progress/957b9e43-d060-4d9f-b7e9-29b1710f203a HTTP/1.1" 200 933 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:35:14.035Z',
  duration: '1304ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1790,
    completion_tokens: 186,
    total_tokens: 1976,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-36937887-ab34-593d-819f-76cca9175148",
      "notes": "User requested to start a new claim, session transferred to live agent."
    },
    {
      "user_id": "u-4b6a8044-659e-514b-8a5f-e1df8c73a556",
      "notes": "User requested to start a claim, session transferred to live agent."
    },
    {
      "user_id": "u-28c453c4-6fb8-5cf9-a0e2-cb63f14b7c56",
      "notes": "User provided detailed leave request information, session handled by bot."
    },
    {
      "user_id": "u-f9e44c90-29a4-5f40-bb5b-d33a7cef6027",
      "notes": "User requested to speak with an agent, session transferred to live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1790,
  completionTokens: 186,
  totalTokens: 1976,
  cost: '$0.000253',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1305ms (1.30s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1976 ($0.0003)
âš¡ Performance: 1514.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1790
   â€¢ Completion Tokens: 186
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-36937887-ab34-593d-819f-76cca9175148: Invalid general_intent, u-36937887-ab34-593d-819f-76cca9175148: Invalid session_outcome, u-4b6a8044-659e-514b-8a5f-e1df8c73a556: Invalid general_intent, u-4b6a8044-659e-514b-8a5f-e1df8c73a556: Invalid session_outcome, u-28c453c4-6fb8-5cf9-a0e2-cb63f14b7c56: Invalid general_intent, u-28c453c4-6fb8-5cf9-a0e2-cb63f14b7c56: Invalid session_outcome, u-f9e44c90-29a4-5f40-bb5b-d33a7cef6027: Invalid general_intent, u-f9e44c90-29a4-5f40-bb5b-d33a7cef6027: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 4 Single Batch Time: 1305ms (1.30s)

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 1306ms (1.31s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1976 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 3.1 sessions/sec
âš¡ Avg Time Per Session: 326.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:35:14.359Z',
  duration: '1630ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1756,
    completion_tokens: 233,
    total_tokens: 1989,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Claim Status', 'Leave Request', 'Unknown' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-65b59bc5-3059-5817-b6dc-3d4362c5a4fd",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-ddbef90b-b3b1-5b45-93ce-12d5cd913c43",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-420d1e6c-1011-5ebb-b1bf-6e7d6b14b04e",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-7416f61f-ba01-56e6-820a-d48ce07c9837",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1756,
  completionTokens: 233,
  totalTokens: 1989,
  cost: '$0.000269',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1631ms (1.63s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1989 ($0.0003)
âš¡ Performance: 1219.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1756
   â€¢ Completion Tokens: 233
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-65b59bc5-3059-5817-b6dc-3d4362c5a4fd: Invalid notes, u-ddbef90b-b3b1-5b45-93ce-12d5cd913c43: Invalid notes, u-420d1e6c-1011-5ebb-b1bf-6e7d6b14b04e: Invalid notes, u-7416f61f-ba01-56e6-820a-d48ce07c9837: Invalid notes'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 2 Single Batch Time: 1631ms (1.63s)

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 1632ms (1.63s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1989 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.5 sessions/sec
âš¡ Avg Time Per Session: 408.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:35:14.362Z',
  duration: '1632ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1744,
    completion_tokens: 277,
    total_tokens: 2021,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Leave Request', 'Eligibility' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-b8305407-3859-561d-afc9-720b16a842ab",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with a representative about short term disability and FMLA questions."
    },
    {
      "user_id": "u-f18de7cc-fd27-582f-b8b1-f962cee6e935",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a representative, leading to transfer to an agent."
    },
    {
      "user_id": "u-b5f2d64c-ce67-5407-b677-6b63a861731f",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked to speak with a representative, resulting in transfer."
    },
    {
      "user_id": "u-84f77b3d-9435-55bf-b853-84bace42a7ed",
      "general_intent": "Eligibility",
      "session_outcome": "Contained",
      "notes": "User inquired about eligibility for leave and workplace accommodation, session was handled by bot."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1744,
  completionTokens: 277,
  totalTokens: 2021,
  cost: '$0.000285',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1632ms (1.63s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2021 ($0.0003)
âš¡ Performance: 1238.4 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1744
   â€¢ Completion Tokens: 277
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 3 Single Batch Time: 1633ms (1.63s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 1634ms (1.63s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2021 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.4 sessions/sec
âš¡ Avg Time Per Session: 408.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:35:14.422Z',
  duration: '1690ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1696,
    completion_tokens: 286,
    total_tokens: 1982,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-f6d675c6-46d1-5f11-935a-dd93de8fe529",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-a4f83c4d-652d-57f9-87ae-37d59be6750f",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-0989ec9a-30d4-552d-94ff-950e54c42f24",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-f0dbca70-303f-5549-96ab-dbd6a24aea48",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1696,
  completionTokens: 286,
  totalTokens: 1982,
  cost: '$0.000284',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1690ms (1.69s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1982 ($0.0003)
âš¡ Performance: 1172.8 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1696
   â€¢ Completion Tokens: 286
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 6 Single Batch Time: 1690ms (1.69s)

âœ… ===== STREAM 6 PROCESSING COMPLETE =====
â±ï¸  Stream 6 Total Time: 1691ms (1.69s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1982 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.4 sessions/sec
âš¡ Avg Time Per Session: 422.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:35:14.595Z',
  duration: '1862ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2144,
    completion_tokens: 280,
    total_tokens: 2424,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Leave Request', 'Live Agent' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-d11f2582-b1ad-532b-abd2-0803e859a455",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to register as a new person and was transferred to an agent."
    },
    {
      "user_id": "u-6489a8f1-6d3d-5dcb-a4bc-88e9a8f69179",
      "general_intent": "Leave Request",
      "session_outcome": "Contained",
      "notes": "User successfully submitted multiple leave requests for absences."
    },
    {
      "user_id": "u-f710b7c2-80b6-5b0f-8237-66eda653bb3e",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent, session transferred."
    },
    {
      "user_id": "u-5d3510d4-0639-5726-af2b-b2b847b7d30b",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent, session transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2144,
  completionTokens: 280,
  totalTokens: 2424,
  cost: '$0.000326',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1863ms (1.86s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2424 ($0.0003)
âš¡ Performance: 1301.1 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2144
   â€¢ Completion Tokens: 280
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 8 Single Batch Time: 1863ms (1.86s)

âœ… ===== STREAM 8 PROCESSING COMPLETE =====
â±ï¸  Stream 8 Total Time: 1863ms (1.86s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2424 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.1 sessions/sec
âš¡ Avg Time Per Session: 465.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:35:14.674Z',
  duration: '1943ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1840,
    completion_tokens: 297,
    total_tokens: 2137,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Leave Request' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-23356305-a712-5f8a-9629-e36fb7473635",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred to an agent."
    },
    {
      "user_id": "u-e2f46c34-0561-50a8-bc40-079368c9f0d3",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred to an agent."
    },
    {
      "user_id": "u-486516ab-3c5c-5694-a9fe-6e098e64b961",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to talk to someone at direct time and was transferred to an agent."
    },
    {
      "user_id": "u-e5a07387-c7ab-5d69-97e0-c06840df7287",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to register for time off and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1840,
  completionTokens: 297,
  totalTokens: 2137,
  cost: '$0.000303',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1944ms (1.94s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2137 ($0.0003)
âš¡ Performance: 1099.3 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1840
   â€¢ Completion Tokens: 297
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 5 Single Batch Time: 1945ms (1.95s)

âœ… ===== STREAM 5 PROCESSING COMPLETE =====
â±ï¸  Stream 5 Total Time: 1945ms (1.95s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2137 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.1 sessions/sec
âš¡ Avg Time Per Session: 486.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:35:14.714Z',
  duration: '1981ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1786,
    completion_tokens: 302,
    total_tokens: 2088,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Leave Request' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-53c66326-9c11-5ffa-9fdd-7f6843ea7590",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to report time entry but was transferred to an agent after initial verification."
    },
    {
      "user_id": "u-e835d9ae-1ea5-584e-83ec-2a68e545743e",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent regarding FMLA papers, resulting in transfer."
    },
    {
      "user_id": "u-cc1c3ba6-3492-54fe-a3c9-58b37f53b305",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a representative, leading to transfer to an agent."
    },
    {
      "user_id": "u-deb45f93-7f30-596a-9c41-04c3a625a222",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked to talk to a representative, resulting in transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1786,
  completionTokens: 302,
  totalTokens: 2088,
  cost: '$0.000299',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1982ms (1.98s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2088 ($0.0003)
âš¡ Performance: 1053.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1786
   â€¢ Completion Tokens: 302
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 7 Single Batch Time: 1982ms (1.98s)

âœ… ===== STREAM 7 PROCESSING COMPLETE =====
â±ï¸  Stream 7 Total Time: 1982ms (1.98s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2088 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.0 sessions/sec
âš¡ Avg Time Per Session: 495.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:35:14.775Z',
  duration: '2047ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1866,
    completion_tokens: 300,
    total_tokens: 2166,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Leave Request', 'Live Agent', 'Unknown', 'FMLA Inquiry' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-43a7da62-4ff0-5861-905b-bb12fdac635f",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to open a new leave request and was transferred to an agent."
    },
    {
      "user_id": "u-230737dd-65d5-5c5a-a1e7-f3da991702b7",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred to an agent."
    },
    {
      "user_id": "u-d4c37501-cfeb-51fd-a168-83fcb58aac9b",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent about correction, but the session was transferred."
    },
    {
      "user_id": "u-cbd873bc-ec94-5099-98b2-7a365b3f8671",
      "general_intent": "FMLA Inquiry",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent about family medical leave and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1866,
  completionTokens: 300,
  totalTokens: 2166,
  cost: '$0.000307',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2047ms (2.05s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2166 ($0.0003)
âš¡ Performance: 1058.1 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1866
   â€¢ Completion Tokens: 300
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 1 Single Batch Time: 2047ms (2.05s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 2053ms (2.05s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2166 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.9 sessions/sec
âš¡ Avg Time Per Session: 513.25ms
[ParallelProcessingOrchestrator] Parallel processing complete: 8/8 streams succeeded
â±ï¸  Parallel Processing Time: 2053ms (2.05s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 8 streams
[ParallelProcessingOrchestrator] Synchronization complete: 2 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 2
ğŸ“Š Total Classifications: 9

âœ… ============ ROUND 2 COMPLETED ============
â±ï¸  Round 2 Total Time: 2053ms (2.05s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 21
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 2053ms (100.0%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ”„ ============ ROUND 3/3 STARTED ============
â±ï¸  Round 3 Start: 2025-08-12T19:35:14.775Z
ğŸ“Š Sessions Remaining: 21
[ParallelProcessingOrchestrator] Distributed 21 sessions across 6 streams: [
  'Stream 1: 4 sessions',
  'Stream 2: 4 sessions',
  'Stream 3: 4 sessions',
  'Stream 4: 4 sessions',
  'Stream 5: 4 sessions',
  'Stream 6: 1 sessions'
]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 6

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 6 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T19:35:14.775Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:35:14.775Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 699
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6199
   â€¢ Avg Per Session: 175 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6199
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6199
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:35:14.776Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:35:14.776Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6028,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Eligibility, FMLA Inquiry, Leave Request, Live Agent, Portal Access, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T19:35:14.776Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:35:14.776Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 764
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6264
   â€¢ Avg Per Session: 191 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6264
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6264
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:35:14.776Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:35:14.776Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6275,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Eligibility, FMLA Inquiry, Leave Request, Live Agent, Portal Access, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T19:35:14.776Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:35:14.776Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 932
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6432
   â€¢ Avg Per Session: 233 tokens
   â€¢ Estimation Time: 1ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6432
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 1ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6432
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:35:14.777Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:35:14.777Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7184,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Eligibility, FMLA Inquiry, Leave Request, Live Agent, Portal Access, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T19:35:14.777Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:35:14.777Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 852
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6352
   â€¢ Avg Per Session: 213 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6352
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6352
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:35:14.777Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:35:14.777Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6682,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Eligibility, FMLA Inquiry, Leave Request, Live Agent, Portal Access, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words...

ğŸŒŠ ===== STREAM 5 PROCESSING START =====
â±ï¸  Stream 5 Start: 2025-08-12T19:35:14.777Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:35:14.777Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 801
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6301
   â€¢ Avg Per Session: 200 tokens
   â€¢ Estimation Time: 1ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6301
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 1ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 5) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6301
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 5: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:35:14.778Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:35:14.778Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6485,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Eligibility, FMLA Inquiry, Leave Request, Live Agent, Portal Access, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words...

ğŸŒŠ ===== STREAM 6 PROCESSING START =====
â±ï¸  Stream 6 Start: 2025-08-12T19:35:14.778Z
ğŸ“Š Sessions Assigned: 1
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:35:14.778Z
ğŸ“Š Sessions to Estimate: 1
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 1
   â€¢ Session Tokens: 183
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 5683
   â€¢ Avg Per Session: 183 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 5683
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0009
ğŸ“Š Recommended Batch Size: 1

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 6) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 5683
ğŸ“¦ Recommended Batch Size: 1
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0009

âš¡ Stream 6: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:35:14.778Z
ğŸ“Š Sessions to Analyze: 1
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:35:14.778Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 1,
  apiKey: 'sk-proj-...',
  promptLength: 4151,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Eligibility, FMLA Inquiry, Leave Request, Live Agent, Portal Access, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words...
::1 - - [12/Aug/2025:19:35:15 +0000] "GET /api/analysis/auto-analyze/parallel/progress/957b9e43-d060-4d9f-b7e9-29b1710f203a HTTP/1.1" 200 933 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:35:15.793Z',
  duration: '1015ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1226,
    completion_tokens: 78,
    total_tokens: 1304,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 1,
  intentsFound: [ 'Live Agent' ],
  transferCount: 1,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-38a82550-24aa-5dd9-a406-fbc91e9e31f2",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1226,
  completionTokens: 78,
  totalTokens: 1304,
  cost: '$0.000154',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1015ms (1.01s)
ğŸ“Š Sessions Returned: 1
ğŸ’° Tokens Used: 1304 ($0.0002)
âš¡ Performance: 1284.7 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1226
   â€¢ Completion Tokens: 78
[SessionValidationService] Validating batch response: 1 input sessions, 1 response sessions
[SessionValidationService] Validation successful: all 1 sessions processed
[SessionValidationService] Validating batch response: 1 input sessions, 1 response sessions
[SessionValidationService] Validation successful: all 1 sessions processed
â±ï¸  Stream 6 Single Batch Time: 1015ms (1.01s)

âœ… ===== STREAM 6 PROCESSING COMPLETE =====
â±ï¸  Stream 6 Total Time: 1015ms (1.01s)
ğŸ“Š Sessions Processed: 1/1
ğŸ’° Tokens Used: 1304 ($0.0002)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.0 sessions/sec
âš¡ Avg Time Per Session: 1015.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:35:16.628Z',
  duration: '1852ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1729,
    completion_tokens: 287,
    total_tokens: 2016,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Leave Request', 'Claim Status', 'FMLA Inquiry' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-de174894-b92c-5397-8adb-996f7479b588",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to get an update on leave dates but was transferred to an agent."
    },
    {
      "user_id": "u-4e8c266a-f614-588a-aa19-05cc03b222b5",
      "general_intent": "Claim Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked for fax number for doctor and was transferred to an agent."
    },
    {
      "user_id": "u-9ba28138-0d8c-5490-b86c-7ce96c4db00f",
      "general_intent": "Leave Request",
      "session_outcome": "Contained",
      "notes": "User did not have a leave request number and was guided to find it in their notification letter."
    },
    {
      "user_id": "u-94424495-ab40-52b4-acaa-b38698ed04f7",
      "general_intent": "FMLA Inquiry",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent about leave status and other FMLA questions."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1729,
  completionTokens: 287,
  totalTokens: 2016,
  cost: '$0.000288',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1853ms (1.85s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2016 ($0.0003)
âš¡ Performance: 1088.0 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1729
   â€¢ Completion Tokens: 287
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 1 Single Batch Time: 1853ms (1.85s)

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 1854ms (1.85s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2016 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.2 sessions/sec
âš¡ Avg Time Per Session: 463.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:35:16.732Z',
  duration: '1956ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1778,
    completion_tokens: 281,
    total_tokens: 2059,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown', 'Leave Request' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-c820d38a-6ba7-5469-9a4a-66272e867d88",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent but did not respond after transfer."
    },
    {
      "user_id": "u-92d2d22d-3ce5-575c-9878-bdb58257403f",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent but did not respond after transfer."
    },
    {
      "user_id": "u-51a058a9-94cc-5250-9cc1-b7d948511450",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent but did not respond after transfer."
    },
    {
      "user_id": "u-ba252b1a-d5ac-5cac-a944-61d57f594109",
      "general_intent": "Leave Request",
      "session_outcome": "Contained",
      "notes": "User wanted to make a short-term disability claim, but the session was handled by the bot."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1778,
  completionTokens: 281,
  totalTokens: 2059,
  cost: '$0.000290',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1956ms (1.96s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2059 ($0.0003)
âš¡ Performance: 1052.7 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1778
   â€¢ Completion Tokens: 281
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 2 Single Batch Time: 1957ms (1.96s)

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 1957ms (1.96s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2059 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.0 sessions/sec
âš¡ Avg Time Per Session: 489.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:35:16.771Z',
  duration: '1994ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2026,
    completion_tokens: 305,
    total_tokens: 2331,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Leave Request', 'FMLA Inquiry', 'Time Entry' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-78eae2bb-2884-5aa5-b541-f5c7697b4425",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was unable to provide leave request number and was transferred to a live agent."
    },
    {
      "user_id": "u-760e597a-1be9-5bb5-944f-02e9d97e3cf2",
      "general_intent": "FMLA Inquiry",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to update FMLA date and was transferred to a live agent after verification."
    },
    {
      "user_id": "u-bc728a28-1362-5cc7-9575-dfe481ce1b73",
      "general_intent": "Time Entry",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User provided leave request and employee number but was transferred to a live agent."
    },
    {
      "user_id": "u-bf046ed7-3537-5766-a333-6fdf4641ccbf",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User checked leave request status and was transferred to a live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2026,
  completionTokens: 305,
  totalTokens: 2331,
  cost: '$0.000325',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1994ms (1.99s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2331 ($0.0003)
âš¡ Performance: 1169.0 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2026
   â€¢ Completion Tokens: 305
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 3 Single Batch Time: 1995ms (2.00s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 1996ms (2.00s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2331 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.0 sessions/sec
âš¡ Avg Time Per Session: 499.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:35:16.778Z',
  duration: '2001ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1898,
    completion_tokens: 294,
    total_tokens: 2192,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Leave Request', 'Claim Status', 'Live Agent' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-09dbf4ee-1d7b-5d36-8af8-bd806e99f551",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak to someone in absent management and was transferred to an agent."
    },
    {
      "user_id": "u-6828969f-1f93-53be-8ed4-e3b5020fe9ac",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User provided claim and personal details, then was asked if they wanted to speak with an agent, but did not proceed to transfer."
    },
    {
      "user_id": "u-0587272a-a594-56a4-8df5-d5a88e75840a",
      "general_intent": "Leave Request",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to request a leave and was transferred to an agent."
    },
    {
      "user_id": "u-4af7996d-0660-59dd-ad61-a1800ccebadb",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1898,
  completionTokens: 294,
  totalTokens: 2192,
  cost: '$0.000307',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2001ms (2.00s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2192 ($0.0003)
âš¡ Performance: 1095.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1898
   â€¢ Completion Tokens: 294
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 4 Single Batch Time: 2002ms (2.00s)

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 2002ms (2.00s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2192 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.0 sessions/sec
âš¡ Avg Time Per Session: 500.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:35:16.930Z',
  duration: '2152ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1854,
    completion_tokens: 274,
    total_tokens: 2128,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Leave Request' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-20f78936-0cde-547a-b81e-f7892d0c35bc",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent and was transferred."
    },
    {
      "user_id": "u-b51fc204-776e-545a-ad30-5072293ce17e",
      "general_intent": "Leave Request",
      "session_outcome": "Contained",
      "notes": "User provided leave details and session was handled by bot."
    },
    {
      "user_id": "u-3cdb2c5c-7d2b-5632-9c18-19c0093c9081",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent and was transferred."
    },
    {
      "user_id": "u-900c58b9-6f69-5e13-8b6d-87e091cbd744",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1854,
  completionTokens: 274,
  totalTokens: 2128,
  cost: '$0.000295',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2152ms (2.15s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2128 ($0.0003)
âš¡ Performance: 988.8 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1854
   â€¢ Completion Tokens: 274
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 5 Single Batch Time: 2152ms (2.15s)

âœ… ===== STREAM 5 PROCESSING COMPLETE =====
â±ï¸  Stream 5 Total Time: 2154ms (2.15s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2128 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.9 sessions/sec
âš¡ Avg Time Per Session: 538.50ms
[ParallelProcessingOrchestrator] Parallel processing complete: 6/6 streams succeeded
â±ï¸  Parallel Processing Time: 2156ms (2.16s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 6 streams
[ParallelProcessingOrchestrator] Synchronization complete: 1 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 1
ğŸ“Š Total Classifications: 10

âœ… ============ ROUND 3 COMPLETED ============
â±ï¸  Round 3 Total Time: 2156ms (2.16s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 0
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 2156ms (100.0%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ‰ ============ PARALLEL PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 9135ms (9.13s)
ğŸ“Š Sessions Processed: 85/85
ğŸ”„ Total Rounds: 3
ğŸŒŠ Stream Results: 22
ğŸ’° Token Usage: 46202 tokens ($0.0063)
ğŸ“ˆ Stream Utilization: 100.0%
ğŸ¯ Performance: 9.3 sessions/second
âš¡ Avg Time Per Session: 107.47ms

ğŸ“Š Stream Performance Breakdown:
   Stream 1: 4 sessions in 1835ms (1086.1 tokens/sec)
   Stream 2: 4 sessions in 1786ms (1323.6 tokens/sec)
   Stream 3: 4 sessions in 4922ms (423.4 tokens/sec)
   Stream 4: 4 sessions in 1547ms (1267.6 tokens/sec)
   Stream 5: 4 sessions in 1909ms (1244.6 tokens/sec)
   Stream 6: 4 sessions in 2359ms (864.8 tokens/sec)
   Stream 7: 4 sessions in 1775ms (1367.3 tokens/sec)
   Stream 8: 4 sessions in 2484ms (863.1 tokens/sec)
   Stream 1: 4 sessions in 2053ms (1055.0 tokens/sec)
   Stream 2: 4 sessions in 1632ms (1218.8 tokens/sec)
   Stream 3: 4 sessions in 1634ms (1236.8 tokens/sec)
   Stream 4: 4 sessions in 1306ms (1513.0 tokens/sec)
   Stream 5: 4 sessions in 1945ms (1098.7 tokens/sec)
   Stream 6: 4 sessions in 1691ms (1172.1 tokens/sec)
   Stream 7: 4 sessions in 1982ms (1053.5 tokens/sec)
   Stream 8: 4 sessions in 1863ms (1301.1 tokens/sec)
   Stream 1: 4 sessions in 1854ms (1087.4 tokens/sec)
   Stream 2: 4 sessions in 1957ms (1052.1 tokens/sec)
   Stream 3: 4 sessions in 1996ms (1167.8 tokens/sec)
   Stream 4: 4 sessions in 2002ms (1094.9 tokens/sec)
   Stream 5: 4 sessions in 2154ms (987.9 tokens/sec)
   Stream 6: 1 sessions in 1015ms (1284.7 tokens/sec)
[ConflictResolutionService] Starting conflict resolution for 100 sessions
[ConflictResolutionService] Found classifications: { intents: 8, reasons: 1, locations: 1 }
[ConflictResolutionService] Calling LLM for conflict resolution with model gpt-4.1-nano
ğŸ”§ Conflict Resolution Prompt Preview: You are reviewing classifications from parallel analysis streams. Identify any semantic duplicates and choose the canonical version for each group.

**Instructions:**
1. Look for classifications that refer to the same concept but use different wording
2. For each group of duplicates, choose the most...
::1 - - [12/Aug/2025:19:35:17 +0000] "GET /api/analysis/auto-analyze/parallel/progress/957b9e43-d060-4d9f-b7e9-29b1710f203a HTTP/1.1" 200 965 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[ConflictResolution] LLM response: {
  "generalIntents": [
    {
      "canonical": "Claim Status Inquiry",
      "aliases": [
        "Claim Status",
        "Claim Inquiry"
      ]
    },
    {
      "canonical": "Eligibility Verification",
      "aliases": [
        "Eligibility"
      ]
    },
    {
      "canonical": "FMLA Inquiry",
      "aliases": [
        "FMLA Inquiry"
      ]
    },
    {
      "canonical": "Leave Request Processing",
      "aliases": [
        "Leave Request"
      ]
    },
    {
      "canonical": "Live Agent Support",
      "aliases": [
        "Live Agent"
      ]
    },
    {
      "canonical": "Portal Access Assistance",
      "aliases": [
        "Portal Access"
      ]
    },
    {
      "canonical": "Time Entry Support",
      "aliases": [
        "Time Entry"
      ]
    },
    {
      "canonical": "Unknown Issue",
      "aliases": [
        "Unknown"
      ]
    }
  ],
  "transferReasons": [
    {
      "canonical": "Request for Live Agent Support",
      "aliases": [
        "Live Agent Request"
      ]
    }
  ],
  "dropOffLocations": [
    {
      "canonical": "Help Offer Prompt",
      "aliases": [
        "Help Offer Prompt"
      ]
    }
  ]
}
[ConflictResolutionService] LLM conflict resolution complete: { intents: 8, reasons: 1, locations: 1, tokens: 780, cost: 0.0001212 }
ğŸ”§ Conflict Resolution Response: {
  "generalIntents": [
    {
      "canonical": "Claim Status Inquiry",
      "aliases": [
        "Claim Status",
        "Claim Inquiry"
      ]
    },
    {
      "canonical": "Eligibility Verification",
      "aliases": [
        "Eligibility"
      ]
    },
    {
      "canonical": "FMLA Inquiry",
      "aliases": [
        "FMLA Inquiry"
      ]
    },
    {
      "canonical": "Leave Request Processing",
      "aliases": [
        "Leave Request"
      ]
    },
    {
      "canonical": "Live Agent Support",
      "aliases": [
        "Live Agent"
      ]
    },
    {
      "canonical": "Portal Access Assistance",
      "aliases": [
        "Portal Access"
      ]
    },
    {
      "canonical": "Time Entry Support",
      "aliases": [
        "Time Entry"
      ]
    },
    {
      "canonical": "Unknown Issue",
      "aliases": [
        "Unknown"
      ]
    }
  ],
  "transferReasons": [
    {
      "canonical": "Request for Live Agent Support",
      "aliases": [
        "Live Agent Request"
      ]
    }
  ],
  "dropOffLocations": [
    {
      "canonical": "Help Offer Prompt",
      "aliases": [
        "Help Offer Prompt"
      ]
    }
  ]
}
[ConflictResolutionService] Applying resolutions to 100 sessions
[ConflictResolutionService] Applied 170 classification mappings across 100 sessions
[ConflictResolutionService] Identified 0 potential conflict groups
[ConflictResolutionService] Conflict resolution complete in 1866ms: { conflictsFound: 0, conflictsResolved: 10, canonicalMappings: 11 }
[ParallelAutoAnalyzeService] Using real analysis summary service
::1 - - [12/Aug/2025:19:35:19 +0000] "GET /api/analysis/auto-analyze/parallel/progress/957b9e43-d060-4d9f-b7e9-29b1710f203a HTTP/1.1" 200 1041 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:35:21 +0000] "GET /api/analysis/auto-analyze/parallel/progress/957b9e43-d060-4d9f-b7e9-29b1710f203a HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:35:23 +0000] "GET /api/analysis/auto-analyze/parallel/progress/957b9e43-d060-4d9f-b7e9-29b1710f203a HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:35:25 +0000] "GET /api/analysis/auto-analyze/parallel/progress/957b9e43-d060-4d9f-b7e9-29b1710f203a HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:35:27 +0000] "GET /api/analysis/auto-analyze/parallel/progress/957b9e43-d060-4d9f-b7e9-29b1710f203a HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:35:29 +0000] "GET /api/analysis/auto-analyze/parallel/progress/957b9e43-d060-4d9f-b7e9-29b1710f203a HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:35:31 +0000] "GET /api/analysis/auto-analyze/parallel/progress/957b9e43-d060-4d9f-b7e9-29b1710f203a HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:35:33 +0000] "GET /api/analysis/auto-analyze/parallel/progress/957b9e43-d060-4d9f-b7e9-29b1710f203a HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[ParallelAutoAnalyzeService] Parallel analysis 957b9e43-d060-4d9f-b7e9-29b1710f203a completed successfully
[BackgroundJobQueue] Updated job progress to final state: complete
[BackgroundJobQueue] Parallel analysis job 957b9e43-d060-4d9f-b7e9-29b1710f203a-parallel completed successfully
::1 - - [12/Aug/2025:19:35:35 +0000] "GET /api/analysis/auto-analyze/parallel/progress/957b9e43-d060-4d9f-b7e9-29b1710f203a HTTP/1.1" 200 1065 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:35:35 +0000] "GET /api/analysis/auto-analyze/parallel/results/957b9e43-d060-4d9f-b7e9-29b1710f203a HTTP/1.1" 200 705324 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
3:41:39 PM [tsx] change in ./src/services/parallelProcessingOrchestratorService.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
3:41:49 PM [tsx] change in ./src/services/parallelProcessingOrchestratorService.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
3:41:58 PM [tsx] change in ./src/services/parallelProcessingOrchestratorService.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
3:42:25 PM [tsx] change in ./src/services/parallelProcessingOrchestratorService.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
3:42:45 PM [tsx] change in ./src/services/parallelAutoAnalyzeService.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
3:44:13 PM [tsx] change in ./src/services/parallelProcessingOrchestratorService.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
3:45:42 PM [tsx] change in ./src/services/parallelProcessingOrchestratorService.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T19:47:22.116Z",
  "dateTo": "2025-08-12T19:48:22.116Z",
  "skip": 0,
  "limit": 1
}
[fetchContainmentTypeMetadata] API Response: 1 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [ '689b9a52759df7402553069f' ]
[getSessionsMetadataForConnectionTest] Single API call succeeded with 1 sessions
::1 - - [12/Aug/2025:19:48:26 +0000] "GET /api/kore/test HTTP/1.1" 200 851 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸš€ [ParallelAutoAnalyzeRoute] Starting parallel analysis for bot ***REMOVED*** with real credentials
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
ğŸ­ ServiceFactory: Creating OpenAI service (type: real)
ğŸš€ [ParallelAutoAnalyzeService] Starting parallel analysis 5fd4f872-b46e-462c-a292-cb8e1cf1c075 with bot ***REMOVED***
ğŸš€ [ParallelAutoAnalyzeService] Using credentials: real
ğŸš€ [ParallelAutoAnalyzeRoute] Parallel analysis started: 5fd4f872-b46e-462c-a292-cb8e1cf1c075
::1 - - [12/Aug/2025:19:48:44 +0000] "POST /api/analysis/auto-analyze/parallel/start HTTP/1.1" 200 214 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:48:44 +0000] "GET /api/analysis/auto-analyze/parallel/progress/5fd4f872-b46e-462c-a292-cb8e1cf1c075 HTTP/1.1" 200 541 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:48:44 +0000] "GET /api/analysis/auto-analyze/parallel/progress/5fd4f872-b46e-462c-a292-cb8e1cf1c075 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[BackgroundJobQueue] Starting job processing after delay for job 5fd4f872-b46e-462c-a292-cb8e1cf1c075-parallel
[BackgroundJobQueue] Starting processing for job 5fd4f872-b46e-462c-a292-cb8e1cf1c075-parallel, phase: sampling
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing parallel analysis job 5fd4f872-b46e-462c-a292-cb8e1cf1c075-parallel
[BackgroundJobQueue] Processing parallel analysis for bot ***REMOVED***
[BackgroundJobQueue] Using existing ParallelAutoAnalyzeService instance for bot ***REMOVED***
[BackgroundJobQueue] Session recreated for 5fd4f872-b46e-462c-a292-cb8e1cf1c075
[ParallelAutoAnalyzeService] Running parallel analysis for 5fd4f872-b46e-462c-a292-cb8e1cf1c075
[ParallelAutoAnalyzeService] Phase 0: Starting session sampling for 5fd4f872-b46e-462c-a292-cb8e1cf1c075

ğŸ• ============ SESSION SAMPLING STARTED ============
ğŸ• [SessionSampling] Starting session sampling at 2025-08-12T19:48:45.523Z
ğŸ” [SessionDiscovery] Starting window 1/4: Initial 3-hour window
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
::1 - - [12/Aug/2025:19:48:46 +0000] "GET /api/analysis/auto-analyze/parallel/progress/5fd4f872-b46e-462c-a292-cb8e1cf1c075 HTTP/1.1" 200 717 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:48:48 +0000] "GET /api/analysis/auto-analyze/parallel/progress/5fd4f872-b46e-462c-a292-cb8e1cf1c075 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:48:50 +0000] "GET /api/analysis/auto-analyze/parallel/progress/5fd4f872-b46e-462c-a292-cb8e1cf1c075 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:48:52 +0000] "GET /api/analysis/auto-analyze/parallel/progress/5fd4f872-b46e-462c-a292-cb8e1cf1c075 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 139 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6a14dd27c3112087cd',
  '68922a22ef03d8ad2ec7b4ba',
  '68922a1278c1fe09a079719c'
]
[fetchContainmentTypeMetadata] API Response: 80 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a1287849680ad9fe59e',
  '689229f9583056c6108e38fb',
  '68922914f8bee7ba6c3e67b8'
]
::1 - - [12/Aug/2025:19:48:54 +0000] "GET /api/analysis/auto-analyze/parallel/progress/5fd4f872-b46e-462c-a292-cb8e1cf1c075 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 1338 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6d14dd27c31120888b',
  '68922a62e3804084741191d5',
  '68922a523a3160d25de144c8'
]
[getSessionsMetadata] agent API call succeeded with 1338 sessions
[getSessionsMetadata] selfService API call succeeded with 80 sessions
[getSessionsMetadata] dropOff API call succeeded with 139 sessions
Total session metadata retrieved: 1557 (parallel execution)
Creating 1557 SWTs from metadata (no messages)
Created 1557 SWT objects from metadata
âœ… [SessionDiscovery] Window 1 completed in 9787ms: found 1557 new sessions (total: 1557)
â±ï¸  TIMING: Window 1 took 9787ms (9.79s)
ğŸ¯ [SessionDiscovery] Target reached! Found 1557 sessions in 9788ms
ğŸ² [SessionSampling] Random sampling from 1557 sessions to 10 sessions

ğŸ“¬ ============ MESSAGE RETRIEVAL STARTED ============
ğŸ“¬ [MessageRetrieval] Starting message retrieval for 10 sampled sessions at 2025-08-12T19:48:55.312Z
Using new lazy loading approach to populate messages for 10 sampled sessions
Populating messages for 10 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 10 sessions from 2025-08-05T13:22:53.500Z to 2025-08-05T15:45:50.076Z at 2025-08-12T19:48:55.312Z
ğŸ”„ [KoreAPI] Using single API call for 10 sessions (â‰¤20)
âœ… [KoreAPI] Single call completed in 216ms: 94 messages
Retrieved 94 messages for 10 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
Populated messages for 10 SWT objects
Successfully populated messages for 10 sessions using lazy loading
Applying final filtering to 10 sessions with populated messages
Final result: 9 sessions passed filtering with populated messages

ğŸ‰ ============ SESSION SAMPLING COMPLETED ============
â±ï¸  TOTAL TIME: 10008ms (10.01s)
â±ï¸  Session Discovery: 9788ms (9.79s) - 97.8% of total
â±ï¸  Message Retrieval: 219ms (0.22s) - 2.2% of total
â±ï¸  Performance: 0.9 sessions/second
ğŸ¯ Final result: 9 sessions with messages retrieved
====================================================

[StrategicDiscoveryService] Starting discovery phase with 9 total sessions
[StrategicDiscoveryService] Discovery config: {
  targetPercentage: 15,
  minSessions: 5,
  maxSessions: 5,
  diversityStrategy: {
    sessionLengths: [ 'short', 'medium', 'long' ],
    containmentTypes: [ 'agent', 'selfService', 'dropOff' ],
    timeDistribution: 'spread'
  }
}
[StrategicDiscoveryService] Selecting 5 diverse sessions from 9 total
[StrategicDiscoveryService] Session diversity groups: { short: 4, medium: 5, early: 3, middle: 3, late: 3 }
[StrategicDiscoveryService] Selected sessions by length distribution: { short: 2, medium: 3, long: 0 }
[StrategicDiscoveryService] Selected 5 sessions for discovery

ğŸ“¦ ===== BATCH 1 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T19:48:55.532Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 0
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T19:48:55.533Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:48:55.535Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 6632,
  existingClassifications: { intents: 0, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.



For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and another intent, classify the intent as the other i...
::1 - - [12/Aug/2025:19:48:56 +0000] "GET /api/analysis/auto-analyze/parallel/progress/5fd4f872-b46e-462c-a292-cb8e1cf1c075 HTTP/1.1" 200 828 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:48:58 +0000] "GET /api/analysis/auto-analyze/parallel/progress/5fd4f872-b46e-462c-a292-cb8e1cf1c075 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:48:59.588Z',
  duration: '4053ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1908,
    completion_tokens: 318,
    total_tokens: 2226,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ 'Live Agent', 'Unknown' ],
  transferCount: 2,
  containedCount: 3
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-8880a06a-07f2-5f67-936e-bac4ce00ae0c",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent and was transferred."
    },
    {
      "user_id": "u-c4596db2-d6cb-5d62-9d92-b1e68daaa4e4",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "Session was closed after the user did not respond to transfer prompts."
    },
    {
      "user_id": "u-2c2aea2d-7c32-5109-9120-58112e7635cb",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent and was transferred."
    },
    {
      "user_id": "u-c4596db2-d6cb-5d62-9d92-b1e68daaa4e4",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "Session was closed after the user did not respond to transfer prompts."
    },
    {
      "user_id": "u-d405271a-3647-5d51-a702-098f1e602b38",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "Session was closed after the user did not respond to transfer prompts."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1908,
  completionTokens: 318,
  totalTokens: 2226,
  cost: '$0.000318',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 4056ms (4.06s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2226 ($0.0003)
âš¡ Performance: 548.8 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 4
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 4056ms (4.06s)
ğŸ“Š Regular Sessions Processed: 4
ğŸ’° Regular Tokens Used: 2226

âœ… ===== BATCH 1 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 4057ms (4.06s)
ğŸ“Š Sessions Processed: 4/5
ğŸ’° Total Tokens: 2226 ($0.0003)
âš¡ Performance: 1.0 sessions/sec
âš¡ Avg Time Per Session: 1014.25ms
â±ï¸  Metadata Processing: 1ms
[StrategicDiscoveryService] Batch 1 complete: 4 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 2, reasons: 1, locations: 1, total: 4 }
[StrategicDiscoveryService] Discovery phase complete: {
  totalProcessed: 4,
  uniqueIntents: 2,
  uniqueReasons: 1,
  uniqueLocations: 1,
  discoveryRate: 0.26666666666666666
}

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T19:48:59.590Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms
[ParallelProcessingOrchestrator] Configuration for 5 sessions:
  Design: 8 streams Ã— 4 sessions = 32 per round
  Optimal: 2 streams Ã— 3 sessions = 6 per round
  Estimated Rounds: 1
[ParallelAutoAnalyzeService] Using parallel config: {
  streamCount: 2,
  sessionsPerStream: 3,
  maxSessionsPerLLMCall: 50,
  syncFrequency: 'after_each_round',
  retryAttempts: 3,
  debugLogging: false
}

ğŸš€ ============ PARALLEL PROCESSING STARTED ============
â±ï¸  Start Time: 2025-08-12T19:48:59.617Z
ğŸ“Š Total Sessions: 5

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T19:48:59.617Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms

âš™ï¸  ============ PARALLEL CONFIGURATION ============
â±ï¸  Config Time: 0ms
ğŸ”§ Stream Count: 2
ğŸ“¦ Sessions Per Stream: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per API Call: 50
ğŸ¯ Debug Logging: false

ğŸ”„ ============ ROUND 1/1 STARTED ============
â±ï¸  Round 1 Start: 2025-08-12T19:48:59.617Z
ğŸ“Š Sessions Remaining: 5
[ParallelProcessingOrchestrator] Distributed 5 sessions across 2 streams: [ 'Stream 1: 3 sessions', 'Stream 2: 2 sessions' ]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 2

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 2 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T19:48:59.618Z
ğŸ“Š Sessions Assigned: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:48:59.618Z
ğŸ“Š Sessions to Estimate: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 3
   â€¢ Session Tokens: 655
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6155
   â€¢ Avg Per Session: 218 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6155
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 3

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6155
ğŸ“¦ Recommended Batch Size: 3
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:48:59.618Z
ğŸ“Š Sessions to Analyze: 3
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 2
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:48:59.618Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 3,
  apiKey: 'sk-proj-...',
  promptLength: 5856,
  existingClassifications: { intents: 2, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Age...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T19:48:59.619Z
ğŸ“Š Sessions Assigned: 2
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:48:59.619Z
ğŸ“Š Sessions to Estimate: 2
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 2
   â€¢ Session Tokens: 366
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 5866
   â€¢ Avg Per Session: 183 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 5866
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0009
ğŸ“Š Recommended Batch Size: 2

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 5866
ğŸ“¦ Recommended Batch Size: 2
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0009

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:48:59.619Z
ğŸ“Š Sessions to Analyze: 2
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 2
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:48:59.619Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 2,
  apiKey: 'sk-proj-...',
  promptLength: 4746,
  existingClassifications: { intents: 2, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Age...
::1 - - [12/Aug/2025:19:49:00 +0000] "GET /api/analysis/auto-analyze/parallel/progress/5fd4f872-b46e-462c-a292-cb8e1cf1c075 HTTP/1.1" 200 843 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:49:01.499Z',
  duration: '1880ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1633,
    completion_tokens: 164,
    total_tokens: 1797,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 3,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-182ffbd2-c02e-509e-8a67-9f5b7f315019",
      "notes": "User inquired about FMLA, medical certification, leave notification packet, and was transferred to a live agent after multiple prompts."
    },
    {
      "user_id": "u-011c79b5-c8d9-5093-96cb-2a6969eaf8ac",
      "notes": "User requested to speak with someone about SMLA and was transferred to a live agent."
    },
    {
      "user_id": "u-02042eba-0448-5b00-9c7e-0b4e7e656088",
      "notes": "User reported claim denial and requested a representative, then was transferred to a live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1633,
  completionTokens: 164,
  totalTokens: 1797,
  cost: '$0.000229',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1882ms (1.88s)
ğŸ“Š Sessions Returned: 3
ğŸ’° Tokens Used: 1797 ($0.0002)
âš¡ Performance: 954.8 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1633
   â€¢ Completion Tokens: 164
[SessionValidationService] Validating batch response: 3 input sessions, 3 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-182ffbd2-c02e-509e-8a67-9f5b7f315019: Invalid general_intent, u-182ffbd2-c02e-509e-8a67-9f5b7f315019: Invalid session_outcome, u-011c79b5-c8d9-5093-96cb-2a6969eaf8ac: Invalid general_intent, u-011c79b5-c8d9-5093-96cb-2a6969eaf8ac: Invalid session_outcome, u-02042eba-0448-5b00-9c7e-0b4e7e656088: Invalid general_intent, u-02042eba-0448-5b00-9c7e-0b4e7e656088: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 3 input sessions, 3 response sessions
[SessionValidationService] Validation successful: all 3 sessions processed
â±ï¸  Stream 1 Single Batch Time: 1883ms (1.88s)

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 1883ms (1.88s)
ğŸ“Š Sessions Processed: 3/3
ğŸ’° Tokens Used: 1797 ($0.0002)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.6 sessions/sec
âš¡ Avg Time Per Session: 627.67ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:49:01.506Z',
  duration: '1887ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1396,
    completion_tokens: 165,
    total_tokens: 1561,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 2,
  intentsFound: [ 'Unknown' ],
  transferCount: 2,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-807279b9-54f4-56e0-a0cc-b7c312e4bdbd",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to set up FMLA and asked about signing up, but was transferred to a live agent."
    },
    {
      "user_id": "u-df1f1f06-e426-5f38-8e5d-35f03f3ec40e",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to claims specialist, session was transferred to a live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1396,
  completionTokens: 165,
  totalTokens: 1561,
  cost: '$0.000206',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1887ms (1.89s)
ğŸ“Š Sessions Returned: 2
ğŸ’° Tokens Used: 1561 ($0.0002)
âš¡ Performance: 827.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1396
   â€¢ Completion Tokens: 165
[SessionValidationService] Validating batch response: 2 input sessions, 2 response sessions
[SessionValidationService] Validation successful: all 2 sessions processed
[SessionValidationService] Validating batch response: 2 input sessions, 2 response sessions
[SessionValidationService] Validation successful: all 2 sessions processed
â±ï¸  Stream 2 Single Batch Time: 1887ms (1.89s)

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 1887ms (1.89s)
ğŸ“Š Sessions Processed: 2/2
ğŸ’° Tokens Used: 1561 ($0.0002)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.1 sessions/sec
âš¡ Avg Time Per Session: 943.50ms
[ParallelProcessingOrchestrator] Parallel processing complete: 2/2 streams succeeded
â±ï¸  Parallel Processing Time: 1889ms (1.89s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 2 streams
[ParallelProcessingOrchestrator] Synchronization complete: 0 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 1ms
ğŸ†• New Classifications: 0
ğŸ“Š Total Classifications: 4

âœ… ============ ROUND 1 COMPLETED ============
â±ï¸  Round 1 Total Time: 1890ms (1.89s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 0
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 1889ms (99.9%)
   â€¢ Synchronization: 1ms (0.1%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ‰ ============ PARALLEL PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 1890ms (1.89s)
ğŸ“Š Sessions Processed: 5/5
ğŸ”„ Total Rounds: 1
ğŸŒŠ Stream Results: 2
ğŸ’° Token Usage: 3358 tokens ($0.0004)
ğŸ“ˆ Stream Utilization: 100.0%
ğŸ¯ Performance: 2.6 sessions/second
âš¡ Avg Time Per Session: 378.00ms

ğŸ“Š Stream Performance Breakdown:
   Stream 1: 3 sessions in 1883ms (954.3 tokens/sec)
   Stream 2: 2 sessions in 1887ms (827.2 tokens/sec)
[ConflictResolutionService] Starting conflict resolution for 9 sessions
[ConflictResolutionService] Found classifications: { intents: 2, reasons: 1, locations: 1 }
[ConflictResolutionService] No conflicts detected, skipping resolution
[ParallelAutoAnalyzeService] Using real analysis summary service
::1 - - [12/Aug/2025:19:49:02 +0000] "GET /api/analysis/auto-analyze/parallel/progress/5fd4f872-b46e-462c-a292-cb8e1cf1c075 HTTP/1.1" 200 947 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:49:04 +0000] "GET /api/analysis/auto-analyze/parallel/progress/5fd4f872-b46e-462c-a292-cb8e1cf1c075 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:49:06 +0000] "GET /api/analysis/auto-analyze/parallel/progress/5fd4f872-b46e-462c-a292-cb8e1cf1c075 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:49:08 +0000] "GET /api/analysis/auto-analyze/parallel/progress/5fd4f872-b46e-462c-a292-cb8e1cf1c075 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:49:10 +0000] "GET /api/analysis/auto-analyze/parallel/progress/5fd4f872-b46e-462c-a292-cb8e1cf1c075 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:49:12 +0000] "GET /api/analysis/auto-analyze/parallel/progress/5fd4f872-b46e-462c-a292-cb8e1cf1c075 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:49:14 +0000] "GET /api/analysis/auto-analyze/parallel/progress/5fd4f872-b46e-462c-a292-cb8e1cf1c075 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:49:16 +0000] "GET /api/analysis/auto-analyze/parallel/progress/5fd4f872-b46e-462c-a292-cb8e1cf1c075 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:49:18 +0000] "GET /api/analysis/auto-analyze/parallel/progress/5fd4f872-b46e-462c-a292-cb8e1cf1c075 HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[ParallelAutoAnalyzeService] Parallel analysis 5fd4f872-b46e-462c-a292-cb8e1cf1c075 completed successfully
[BackgroundJobQueue] Updated job progress to final state: complete
[BackgroundJobQueue] Parallel analysis job 5fd4f872-b46e-462c-a292-cb8e1cf1c075-parallel completed successfully
::1 - - [12/Aug/2025:19:49:20 +0000] "GET /api/analysis/auto-analyze/parallel/progress/5fd4f872-b46e-462c-a292-cb8e1cf1c075 HTTP/1.1" 200 959 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:49:20 +0000] "GET /api/analysis/auto-analyze/parallel/results/5fd4f872-b46e-462c-a292-cb8e1cf1c075 HTTP/1.1" 200 59945 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ­ Detected mock credentials - using mock service configuration
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://mock.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://mock.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T19:52:52.772Z",
  "dateTo": "2025-08-12T19:53:52.772Z",
  "skip": 0,
  "limit": 1
}
[getSessionsMetadataForConnectionTest] Connection test failed: AxiosError: getaddrinfo ENOTFOUND mock.kore.ai
    at AxiosError.AxiosError.from (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/AxiosError.js:92:14)
    at RedirectableRequest.handleRequestError (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:620:25)
    at RedirectableRequest.emit (node:events:519:35)
    at eventHandlers.<computed> (/Users/kengrafals/workspace/xobcat/node_modules/follow-redirects/index.js:49:24)
    at ClientRequest.emit (node:events:507:28)
    at emitErrorEvent (node:_http_client:104:11)
    at TLSSocket.socketErrorListener (node:_http_client:518:5)
    at TLSSocket.emit (node:events:507:28)
    at emitErrorNT (node:internal/streams/destroy:170:8)
    at emitErrorCloseNT (node:internal/streams/destroy:129:3)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async KoreApiService.getSessionsMetadataForConnectionTest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:503:22)
    at async <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/kore.ts:28:29) {
  hostname: 'mock.kore.ai',
  syscall: 'getaddrinfo',
  code: 'ENOTFOUND',
  errno: -3008,
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU1MDI4NDMyLCJleHAiOjE3NTUwMzIwMzIsImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.aJXTtd5w1muEt2nCIwDTdsLM9dRWTYhIoIulQZGKyGs',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '94',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://mock.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
    data: '{"dateFrom":"2025-08-12T19:52:52.772Z","dateTo":"2025-08-12T19:53:52.772Z","skip":0,"limit":1}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> Writable {
    _events: {
      close: undefined,
      error: [Function: handleRequestError],
      prefinish: undefined,
      finish: undefined,
      drain: undefined,
      response: [Function: handleResponse],
      socket: [Array],
      timeout: undefined,
      abort: undefined
    },
    _writableState: WritableState {
      highWaterMark: 65536,
      length: 0,
      corked: 0,
      onwrite: [Function: bound onwrite],
      writelen: 0,
      bufferedIndex: 0,
      pendingcb: 0,
      Symbol(kState): 17580812,
      Symbol(kBufferedValue): null
    },
    _maxListeners: undefined,
    _options: {
      maxRedirects: 21,
      maxBodyLength: Infinity,
      protocol: 'https:',
      path: '/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      method: 'POST',
      headers: [Object: null prototype],
      agents: [Object],
      auth: undefined,
      family: undefined,
      beforeRedirect: [Function: dispatchBeforeRedirect],
      beforeRedirects: [Object],
      hostname: 'mock.kore.ai',
      port: '',
      agent: undefined,
      nativeProtocols: [Object],
      pathname: '/api/public/bot/mock-bot-id/getSessions',
      search: '?containmentType=agent'
    },
    _ended: false,
    _ending: true,
    _redirectCount: 0,
    _redirects: [],
    _requestBodyLength: 94,
    _requestBodyBuffers: [ [Object] ],
    _eventsCount: 3,
    _onNativeResponse: [Function (anonymous)],
    _currentRequest: ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: false,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 94,
      _hasBody: true,
      _trailer: '',
      finished: false,
      _headerSent: true,
      _closed: false,
      _header: 'POST /api/public/bot/mock-bot-id/getSessions?containmentType=agent HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU1MDI4NDMyLCJleHAiOjE3NTUwMzIwMzIsImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.aJXTtd5w1muEt2nCIwDTdsLM9dRWTYhIoIulQZGKyGs\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 94\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: mock.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      _ended: false,
      res: null,
      aborted: false,
      timeoutCb: [Function: emitRequestTimeout],
      upgradeOrConnect: false,
      parser: null,
      maxHeadersCount: null,
      reusedSocket: false,
      host: 'mock.kore.ai',
      protocol: 'https:',
      _redirectable: [Circular *1],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    _currentUrl: 'https://mock.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
    _timeout: null,
    Symbol(shapeMode): true,
    Symbol(kCapture): false
  },
  cause: Error: getaddrinfo ENOTFOUND mock.kore.ai
      at GetAddrInfoReqWrap.onlookupall [as oncomplete] (node:dns:122:26) {
    errno: -3008,
    code: 'ENOTFOUND',
    syscall: 'getaddrinfo',
    hostname: 'mock.kore.ai'
  }
}
Kore.ai API connection test failed: AxiosError: getaddrinfo ENOTFOUND mock.kore.ai
    at AxiosError.AxiosError.from (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/AxiosError.js:92:14)
    at RedirectableRequest.handleRequestError (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/adapters/http.js:620:25)
    at RedirectableRequest.emit (node:events:519:35)
    at eventHandlers.<computed> (/Users/kengrafals/workspace/xobcat/node_modules/follow-redirects/index.js:49:24)
    at ClientRequest.emit (node:events:507:28)
    at emitErrorEvent (node:_http_client:104:11)
    at TLSSocket.socketErrorListener (node:_http_client:518:5)
    at TLSSocket.emit (node:events:507:28)
    at emitErrorNT (node:internal/streams/destroy:170:8)
    at emitErrorCloseNT (node:internal/streams/destroy:129:3)
    at Axios.request (/Users/kengrafals/workspace/xobcat/node_modules/axios/lib/core/Axios.js:45:41)
    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)
    at async KoreApiService.makeRequest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:195:42)
    at async KoreApiService.fetchContainmentTypeMetadata (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:402:22)
    at async KoreApiService.getSessionsMetadataForConnectionTest (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:503:22)
    at async <anonymous> (/Users/kengrafals/workspace/xobcat/backend/src/routes/kore.ts:28:29) {
  hostname: 'mock.kore.ai',
  syscall: 'getaddrinfo',
  code: 'ENOTFOUND',
  errno: -3008,
  config: {
    transitional: {
      silentJSONParsing: true,
      forcedJSONParsing: true,
      clarifyTimeoutError: false
    },
    adapter: [ 'xhr', 'http', 'fetch' ],
    transformRequest: [ [Function: transformRequest] ],
    transformResponse: [ [Function: transformResponse] ],
    timeout: 30000,
    xsrfCookieName: 'XSRF-TOKEN',
    xsrfHeaderName: 'X-XSRF-TOKEN',
    maxContentLength: -1,
    maxBodyLength: -1,
    env: { FormData: [Function [FormData]], Blob: [class Blob] },
    validateStatus: [Function: validateStatus],
    headers: Object [AxiosHeaders] {
      Accept: 'application/json, text/plain, */*',
      'Content-Type': 'application/json',
      auth: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU1MDI4NDMyLCJleHAiOjE3NTUwMzIwMzIsImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.aJXTtd5w1muEt2nCIwDTdsLM9dRWTYhIoIulQZGKyGs',
      'User-Agent': 'axios/1.11.0',
      'Content-Length': '94',
      'Accept-Encoding': 'gzip, compress, deflate, br'
    },
    method: 'post',
    url: 'https://mock.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
    data: '{"dateFrom":"2025-08-12T19:52:52.772Z","dateTo":"2025-08-12T19:53:52.772Z","skip":0,"limit":1}',
    allowAbsoluteUrls: true
  },
  request: <ref *1> Writable {
    _events: {
      close: undefined,
      error: [Function: handleRequestError],
      prefinish: undefined,
      finish: undefined,
      drain: undefined,
      response: [Function: handleResponse],
      socket: [Array],
      timeout: undefined,
      abort: undefined
    },
    _writableState: WritableState {
      highWaterMark: 65536,
      length: 0,
      corked: 0,
      onwrite: [Function: bound onwrite],
      writelen: 0,
      bufferedIndex: 0,
      pendingcb: 0,
      Symbol(kState): 17580812,
      Symbol(kBufferedValue): null
    },
    _maxListeners: undefined,
    _options: {
      maxRedirects: 21,
      maxBodyLength: Infinity,
      protocol: 'https:',
      path: '/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      method: 'POST',
      headers: [Object: null prototype],
      agents: [Object],
      auth: undefined,
      family: undefined,
      beforeRedirect: [Function: dispatchBeforeRedirect],
      beforeRedirects: [Object],
      hostname: 'mock.kore.ai',
      port: '',
      agent: undefined,
      nativeProtocols: [Object],
      pathname: '/api/public/bot/mock-bot-id/getSessions',
      search: '?containmentType=agent'
    },
    _ended: false,
    _ending: true,
    _redirectCount: 0,
    _redirects: [],
    _requestBodyLength: 94,
    _requestBodyBuffers: [ [Object] ],
    _eventsCount: 3,
    _onNativeResponse: [Function (anonymous)],
    _currentRequest: ClientRequest {
      _events: [Object: null prototype],
      _eventsCount: 7,
      _maxListeners: undefined,
      outputData: [],
      outputSize: 0,
      writable: true,
      destroyed: false,
      _last: false,
      chunkedEncoding: false,
      shouldKeepAlive: true,
      maxRequestsOnConnectionReached: false,
      _defaultKeepAlive: true,
      useChunkedEncodingByDefault: true,
      sendDate: false,
      _removedConnection: false,
      _removedContLen: false,
      _removedTE: false,
      strictContentLength: false,
      _contentLength: 94,
      _hasBody: true,
      _trailer: '',
      finished: false,
      _headerSent: true,
      _closed: false,
      _header: 'POST /api/public/bot/mock-bot-id/getSessions?containmentType=agent HTTP/1.1\r\n' +
        'Accept: application/json, text/plain, */*\r\n' +
        'Content-Type: application/json\r\n' +
        'auth: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtb2NrLWNsaWVudC1pZCIsInN1YiI6Im1vY2stYm90LWlkIiwiaWF0IjoxNzU1MDI4NDMyLCJleHAiOjE3NTUwMzIwMzIsImF1ZCI6Imh0dHBzOi8vYm90cy5rb3JlLmFpIn0.aJXTtd5w1muEt2nCIwDTdsLM9dRWTYhIoIulQZGKyGs\r\n' +
        'User-Agent: axios/1.11.0\r\n' +
        'Content-Length: 94\r\n' +
        'Accept-Encoding: gzip, compress, deflate, br\r\n' +
        'Host: mock.kore.ai\r\n' +
        'Connection: keep-alive\r\n' +
        '\r\n',
      _keepAliveTimeout: 0,
      _onPendingData: [Function: nop],
      agent: [Agent],
      socketPath: undefined,
      method: 'POST',
      maxHeaderSize: undefined,
      insecureHTTPParser: undefined,
      joinDuplicateHeaders: undefined,
      path: '/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
      _ended: false,
      res: null,
      aborted: false,
      timeoutCb: [Function: emitRequestTimeout],
      upgradeOrConnect: false,
      parser: null,
      maxHeadersCount: null,
      reusedSocket: false,
      host: 'mock.kore.ai',
      protocol: 'https:',
      _redirectable: [Circular *1],
      Symbol(shapeMode): false,
      Symbol(kCapture): false,
      Symbol(kBytesWritten): 0,
      Symbol(kNeedDrain): false,
      Symbol(corked): 0,
      Symbol(kChunkedBuffer): [],
      Symbol(kChunkedLength): 0,
      Symbol(kSocket): [TLSSocket],
      Symbol(kOutHeaders): [Object: null prototype],
      Symbol(errored): null,
      Symbol(kHighWaterMark): 65536,
      Symbol(kRejectNonStandardBodyWrites): false,
      Symbol(kUniqueHeaders): null
    },
    _currentUrl: 'https://mock.kore.ai/api/public/bot/mock-bot-id/getSessions?containmentType=agent',
    _timeout: null,
    Symbol(shapeMode): true,
    Symbol(kCapture): false
  },
  cause: Error: getaddrinfo ENOTFOUND mock.kore.ai
      at GetAddrInfoReqWrap.onlookupall [as oncomplete] (node:dns:122:26) {
    errno: -3008,
    code: 'ENOTFOUND',
    syscall: 'getaddrinfo',
    hostname: 'mock.kore.ai'
  }
}
::1 - - [12/Aug/2025:19:53:53 +0000] "GET /api/kore/test HTTP/1.1" 500 245 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T19:53:14.601Z",
  "dateTo": "2025-08-12T19:54:14.601Z",
  "skip": 0,
  "limit": 1
}
[fetchContainmentTypeMetadata] API Response: 1 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [ '689b9bb304e17fb1eb58d5f3' ]
[getSessionsMetadataForConnectionTest] Single API call succeeded with 1 sessions
::1 - - [12/Aug/2025:19:54:17 +0000] "GET /api/kore/test HTTP/1.1" 200 851 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
ğŸ­ ServiceFactory: Creating Kore API service (type: real)
ğŸ­ ServiceFactory: NODE_ENV=development, USE_MOCK_SERVICES=undefined
ğŸ­ ServiceFactory: Config: { type: 'real', environment: 'development' }
ğŸ­ ServiceFactory: Has koreConfig: true bot: ***REMOVED***
[Direct API] Fetching real Kore.ai sessions from 2025-08-05T19:54:18.367Z to 2025-08-12T19:54:18.367Z for User Bot st-90549... (limit=50)
Retrieving sessions from 2025-08-05T19:54:18.367Z to 2025-08-12T19:54:18.367Z (limit=50), populateMessages=true...
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T19:54:18.367Z",
  "dateTo": "2025-08-12T19:54:18.367Z",
  "limit": 50
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:54:18.367Z",
  "dateTo": "2025-08-12T19:54:18.367Z",
  "skip": 0,
  "limit": 50
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:54:18.367Z",
  "dateTo": "2025-08-12T19:54:18.367Z",
  "skip": 0,
  "limit": 50
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T19:54:18.367Z",
  "dateTo": "2025-08-12T19:54:18.367Z",
  "skip": 0,
  "limit": 50
}
::1 - - [12/Aug/2025:19:54:18 +0000] "GET /api/analysis/sessions?limit=50 HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
ğŸš€ [ParallelAutoAnalyzeRoute] Starting parallel analysis for bot ***REMOVED*** with real credentials
ğŸš€ [ParallelAutoAnalyzeService] Starting parallel analysis e3384dec-edb5-44ac-bf5a-02d64396ce8c with bot ***REMOVED***
ğŸš€ [ParallelAutoAnalyzeService] Using credentials: real
ğŸš€ [ParallelAutoAnalyzeRoute] Parallel analysis started: e3384dec-edb5-44ac-bf5a-02d64396ce8c
::1 - - [12/Aug/2025:19:54:37 +0000] "POST /api/analysis/auto-analyze/parallel/start HTTP/1.1" 200 214 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:54:37 +0000] "GET /api/analysis/auto-analyze/parallel/progress/e3384dec-edb5-44ac-bf5a-02d64396ce8c HTTP/1.1" 200 542 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:54:37 +0000] "GET /api/analysis/auto-analyze/parallel/progress/e3384dec-edb5-44ac-bf5a-02d64396ce8c HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[BackgroundJobQueue] Starting job processing after delay for job e3384dec-edb5-44ac-bf5a-02d64396ce8c-parallel
[BackgroundJobQueue] Starting processing for job e3384dec-edb5-44ac-bf5a-02d64396ce8c-parallel, phase: sampling
[BackgroundJobQueue] Job credentials available: true
[BackgroundJobQueue] Processing parallel analysis job e3384dec-edb5-44ac-bf5a-02d64396ce8c-parallel
[BackgroundJobQueue] Processing parallel analysis for bot ***REMOVED***
[BackgroundJobQueue] Using existing ParallelAutoAnalyzeService instance for bot ***REMOVED***
[BackgroundJobQueue] Session recreated for e3384dec-edb5-44ac-bf5a-02d64396ce8c
[ParallelAutoAnalyzeService] Running parallel analysis for e3384dec-edb5-44ac-bf5a-02d64396ce8c
[ParallelAutoAnalyzeService] Phase 0: Starting session sampling for e3384dec-edb5-44ac-bf5a-02d64396ce8c

ğŸ• ============ SESSION SAMPLING STARTED ============
ğŸ• [SessionSampling] Starting session sampling at 2025-08-12T19:54:38.063Z
ğŸ” [SessionDiscovery] Starting window 1/4: Initial 3-hour window
[getSessionsMetadata] Called with options: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "limit": 10000
}
[getSessionsMetadata] isMockCredentials: false
[getSessionsMetadata] Starting parallel API calls for 3 containment types
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting selfService session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Making API call for selfService:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=selfService
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
Requesting dropOff session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Making API call for dropOff:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=dropOff
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-05T13:00:00.000Z",
  "dateTo": "2025-08-05T16:00:00.000Z",
  "skip": 0,
  "limit": 10000
}
::1 - - [12/Aug/2025:19:54:39 +0000] "GET /api/analysis/auto-analyze/parallel/progress/e3384dec-edb5-44ac-bf5a-02d64396ce8c HTTP/1.1" 200 719 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:54:41 +0000] "GET /api/analysis/auto-analyze/parallel/progress/e3384dec-edb5-44ac-bf5a-02d64396ce8c HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 80 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a1287849680ad9fe59e',
  '689229f9583056c6108e38fb',
  '68922914f8bee7ba6c3e67b8'
]
[fetchContainmentTypeMetadata] API Response: 139 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6a14dd27c3112087cd',
  '68922a22ef03d8ad2ec7b4ba',
  '68922a1278c1fe09a079719c'
]
::1 - - [12/Aug/2025:19:54:43 +0000] "GET /api/analysis/auto-analyze/parallel/progress/e3384dec-edb5-44ac-bf5a-02d64396ce8c HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[fetchContainmentTypeMetadata] API Response: 50 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b9bdd224c97ecf13bc9b7',
  '689b9bd9f54cdbf3def82781',
  '689b9bb304e17fb1eb58d5f3'
]
[fetchContainmentTypeMetadata] API Response: 1338 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '68922a6d14dd27c31120888b',
  '68922a62e3804084741191d5',
  '68922a523a3160d25de144c8'
]
[getSessionsMetadata] agent API call succeeded with 1338 sessions
[getSessionsMetadata] selfService API call succeeded with 80 sessions
[getSessionsMetadata] dropOff API call succeeded with 139 sessions
Total session metadata retrieved: 1557 (parallel execution)
Creating 1557 SWTs from metadata (no messages)
Created 1557 SWT objects from metadata
âœ… [SessionDiscovery] Window 1 completed in 6344ms: found 1557 new sessions (total: 1557)
â±ï¸  TIMING: Window 1 took 6344ms (6.34s)
ğŸ¯ [SessionDiscovery] Target reached! Found 1557 sessions in 6345ms
ğŸ² [SessionSampling] Random sampling from 1557 sessions to 100 sessions

ğŸ“¬ ============ MESSAGE RETRIEVAL STARTED ============
ğŸ“¬ [MessageRetrieval] Starting message retrieval for 100 sampled sessions at 2025-08-12T19:54:44.409Z
Using new lazy loading approach to populate messages for 100 sampled sessions
Populating messages for 100 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 100 sessions from 2025-08-05T13:00:15.014Z to 2025-08-05T15:59:14.367Z at 2025-08-12T19:54:44.409Z
ğŸš€ [ConcurrentBatch] Split 100 sessions into 5 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/5] Starting: 20 sessions
[Batch 2/5] Starting: 20 sessions
[Batch 3/5] Starting: 20 sessions
[Batch 4/5] Starting: 20 sessions
[Batch 5/5] Starting: 20 sessions
[fetchContainmentTypeMetadata] API Response: 50 selfService sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b9be80cef90d203093b8f',
  '689b9be59dd6aafc5d9a73e0',
  '689b9bdc759df740255339b9'
]
[fetchContainmentTypeMetadata] API Response: 50 dropOff sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [
  '689b976edcfd96eb5e7cdcba',
  '689b9745946228cfd4531e64',
  '689b97195f04b9bca7ba10f1'
]
[getSessionsMetadata] agent API call succeeded with 50 sessions
[getSessionsMetadata] selfService API call succeeded with 50 sessions
[getSessionsMetadata] dropOff API call succeeded with 50 sessions
Total session metadata retrieved: 150 (parallel execution)
Retrieved 150 session metadata objects
Creating 150 SWTs from metadata (no messages)
Created 150 SWT objects from metadata
Populating messages for all sessions (legacy behavior)
Populating messages for 150 sessions

ğŸ“¬ ============ KORE API MESSAGE FETCH STARTED ============
ğŸ“¬ [KoreAPI] Fetching messages for 150 sessions from 2025-08-12T18:45:14.212Z to 2025-08-12T19:54:21.126Z at 2025-08-12T19:54:44.667Z
ğŸš€ [ConcurrentBatch] Split 150 sessions into 8 batches of up to 20 sessions each
ğŸš€ [ConcurrentBatch] Processing with max 10 concurrent API calls
[Batch 1/8] Starting: 20 sessions
[Batch 2/8] Starting: 20 sessions
[Batch 3/8] Starting: 20 sessions
[Batch 4/8] Starting: 20 sessions
[Batch 5/8] Starting: 20 sessions
[Batch 6/8] Starting: 20 sessions
[Batch 7/8] Starting: 20 sessions
[Batch 8/8] Starting: 10 sessions
[Batch 1/5] Completed in 384ms: 295 messages retrieved (1/5 done)
ğŸ“Š [BatchProgress] Reporting batch 1/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 40/100 sessions (Batch 2/5)
[Batch 2/5] Completed in 388ms: 257 messages retrieved (2/5 done)
ğŸ“Š [BatchProgress] Reporting batch 2/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 60/100 sessions (Batch 3/5)
[Batch 4/5] Completed in 400ms: 265 messages retrieved (3/5 done)
ğŸ“Š [BatchProgress] Reporting batch 3/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 80/100 sessions (Batch 4/5)
[Batch 3/5] Completed in 457ms: 286 messages retrieved (4/5 done)
ğŸ“Š [BatchProgress] Reporting batch 4/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 100/100 sessions (Batch 5/5)
[Batch 1/8] Completed in 237ms: 200 messages retrieved (1/8 done)
[Batch 2/8] Completed in 241ms: 218 messages retrieved (2/8 done)
[Batch 5/5] Completed in 619ms: 265 messages retrieved (5/5 done)
ğŸ“Š [BatchProgress] Reporting batch 5/5 completed (20 sessions in this batch)
ğŸ“Š [MessageProgress] Retrieved messages: 100/100 sessions (Batch 6/5)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 622ms (0.62s)
â±ï¸  Batch Processing: 622ms (0.62s)
ğŸ“¦ Total batches: 5 (max 10 concurrent)
âœ… Successful batches: 5/5
ğŸ’¬ Total messages: 1368
ğŸ“ˆ Avg time per batch: 124ms
ğŸš€ Time per session: 6ms
ğŸ’ª Performance: 160.8 sessions/second
=======================================================

Retrieved 1368 messages for 100 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
Populated messages for 100 SWT objects
Successfully populated messages for 100 sessions using lazy loading
Applying final filtering to 100 sessions with populated messages
Final result: 100 sessions passed filtering with populated messages

ğŸ‰ ============ SESSION SAMPLING COMPLETED ============
â±ï¸  TOTAL TIME: 6977ms (6.98s)
â±ï¸  Session Discovery: 6345ms (6.34s) - 90.9% of total
â±ï¸  Message Retrieval: 631ms (0.63s) - 9.0% of total
â±ï¸  Performance: 14.3 sessions/second
ğŸ¯ Final result: 100 sessions with messages retrieved
====================================================

[StrategicDiscoveryService] Starting discovery phase with 100 total sessions
[StrategicDiscoveryService] Discovery config: {
  targetPercentage: 15,
  minSessions: 10,
  maxSessions: 15,
  diversityStrategy: {
    sessionLengths: [ 'short', 'medium', 'long' ],
    containmentTypes: [ 'agent', 'selfService', 'dropOff' ],
    timeDistribution: 'spread'
  }
}
[StrategicDiscoveryService] Selecting 15 diverse sessions from 100 total
[StrategicDiscoveryService] Session diversity groups: { short: 22, medium: 77, long: 1, early: 33, middle: 33, late: 34 }
[StrategicDiscoveryService] Selected sessions by length distribution: { short: 4, medium: 10, long: 1 }
[StrategicDiscoveryService] Selected 15 sessions for discovery

ğŸ“¦ ===== BATCH 2 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T19:54:45.041Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 0
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T19:54:45.041Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:54:45.042Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 8973,
  existingClassifications: { intents: 0, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.



For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and another intent, classify the intent as the other i...
[Batch 3/8] Completed in 424ms: 166 messages retrieved (3/8 done)
::1 - - [12/Aug/2025:19:54:45 +0000] "GET /api/analysis/auto-analyze/parallel/progress/e3384dec-edb5-44ac-bf5a-02d64396ce8c HTTP/1.1" 200 934 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[Batch 8/8] Completed in 450ms: 86 messages retrieved (4/8 done)
[Batch 6/8] Completed in 503ms: 220 messages retrieved (5/8 done)
[Batch 7/8] Completed in 523ms: 195 messages retrieved (6/8 done)
[Batch 4/8] Completed in 582ms: 305 messages retrieved (7/8 done)
[Batch 5/8] Completed in 769ms: 444 messages retrieved (8/8 done)

ğŸ‰ ============ KORE API BATCH PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 769ms (0.77s)
â±ï¸  Batch Processing: 769ms (0.77s)
ğŸ“¦ Total batches: 8 (max 10 concurrent)
âœ… Successful batches: 8/8
ğŸ’¬ Total messages: 1834
ğŸ“ˆ Avg time per batch: 96ms
ğŸš€ Time per session: 5ms
ğŸ’ª Performance: 195.1 sessions/second
=======================================================

Retrieved 1834 messages for 150 sessions
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "{"type":"command","command":"redirect","queueCommand":true,"data":[{"verb":"pause","length":0.2},{"verb":"hangup","headers":{}}]}" (bot)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
ğŸ§¼ SWTService: Filtered out message: "Welcome Task" (user)
Populated messages for 150 SWT objects
Generated 150 SWT objects in 27079ms using layered architecture
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:54:47.011Z',
  duration: '1969ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2490,
    completion_tokens: 259,
    total_tokens: 2749,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-26ccd4e1-65b1-5022-a9f9-164fb96f598a",
      "notes": "User wanted to speak with an agent, session was transferred to a live agent."
    },
    {
      "user_id": "u-146f02b4-8368-5cf2-ad41-a2b92ff866fd",
      "notes": "User checked leave request status, then requested to speak to an agent, session was transferred."
    },
    {
      "user_id": "u-27e558fe-8281-5cdb-98aa-3c207bcfe04b",
      "notes": "User attempted to report time entries, verified details, and submitted entries; later requested to verify last reported dates, session was transferred to an agent."
    },
    {
      "user_id": "u-4ae9b8c5-e32d-5e70-8506-e5284ccb5cbb",
      "notes": "User requested to update time status and asked to speak to an operator; session was transferred to an agent."
    },
    {
      "user_id": "u-09587d3f-004a-501c-a14d-654cd0f61f65",
      "notes": "User expressed desire to speak with an agent, session was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2490,
  completionTokens: 259,
  totalTokens: 2749,
  cost: '$0.000353',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 1971ms (1.97s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2749 ($0.0004)
âš¡ Performance: 1394.7 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 1971ms (1.97s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2749

âœ… ===== BATCH 2 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 1971ms (1.97s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2749 ($0.0004)
âš¡ Performance: 2.5 sessions/sec
âš¡ Avg Time Per Session: 394.20ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 1 complete: 1 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 1, reasons: 0, locations: 0, total: 1 }

ğŸ“¦ ===== BATCH 3 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T19:54:47.012Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 1
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T19:54:47.012Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:54:47.012Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7132,
  existingClassifications: { intents: 1, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Unknown

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and a...
::1 - - [12/Aug/2025:19:54:47 +0000] "GET /api/analysis/auto-analyze/parallel/progress/e3384dec-edb5-44ac-bf5a-02d64396ce8c HTTP/1.1" 200 952 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:54:48.729Z',
  duration: '1717ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2050,
    completion_tokens: 273,
    total_tokens: 2323,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-3cdb2c5c-7d2b-5632-9c18-19c0093c9081",
      "notes": "User requested to speak to a representative and was transferred to an agent, but the session was closed without further input."
    },
    {
      "user_id": "u-25d943ff-d30e-581c-94c5-287ea3452a4d",
      "notes": "User requested leave of absence and was transferred to an agent for assistance."
    },
    {
      "user_id": "u-053d6cba-ed02-5760-978a-6c29d23a00d3",
      "notes": "User attempted to track time, verified account details, and confirmed a time entry, then requested to speak to a representative and was transferred."
    },
    {
      "user_id": "u-2104e004-56c5-5443-a4cf-c035f65902bc",
      "notes": "User requested claim status but the session was incomplete, with no transfer to an agent."
    },
    {
      "user_id": "u-3cdb2c5c-7d2b-5632-9c18-19c0093c9081",
      "notes": "User requested to speak to a representative and was transferred to an agent, but the session was closed without further input."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2050,
  completionTokens: 273,
  totalTokens: 2323,
  cost: '$0.000314',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 1718ms (1.72s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2323 ($0.0003)
âš¡ Performance: 1352.2 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 4
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 1718ms (1.72s)
ğŸ“Š Regular Sessions Processed: 4
ğŸ’° Regular Tokens Used: 2323

âœ… ===== BATCH 3 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 1718ms (1.72s)
ğŸ“Š Sessions Processed: 4/5
ğŸ’° Total Tokens: 2323 ($0.0003)
âš¡ Performance: 2.3 sessions/sec
âš¡ Avg Time Per Session: 429.50ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 2 complete: 0 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 1, reasons: 0, locations: 0, total: 1 }

ğŸ“¦ ===== BATCH 4 PROCESSING START =====
â±ï¸  Batch Start: 2025-08-12T19:54:48.731Z
ğŸ“Š Sessions in Batch: 5
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Existing Classifications:
   â€¢ Intents: 1
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ”„ ===== SESSION SPLITTING =====
â±ï¸  Split Time: 0ms
ğŸ“Š Regular Sessions: 5
ğŸ“Š Oversized Sessions: 0

ğŸš€ ===== PROCESSING REGULAR SESSIONS =====

ğŸ¤– ===== OPENAI SERVICE CALL =====
â±ï¸  OpenAI Call Start: 2025-08-12T19:54:48.731Z
ğŸ“Š Sessions to Analyze: 5

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:54:48.731Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 5,
  apiKey: 'sk-proj-...',
  promptLength: 7237,
  existingClassifications: { intents: 1, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Unknown

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and a...
::1 - - [12/Aug/2025:19:54:49 +0000] "GET /api/analysis/auto-analyze/parallel/progress/e3384dec-edb5-44ac-bf5a-02d64396ce8c HTTP/1.1" 200 952 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:54:50.550Z',
  duration: '1818ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2048,
    completion_tokens: 255,
    total_tokens: 2303,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 5,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-c2a9ef24-49b8-5e96-aef4-bc58d4ac71bf",
      "notes": "User attempted to report FML-related leave but did not provide sufficient details, and then requested to speak with a representative, resulting in a transfer."
    },
    {
      "user_id": "u-f19f7ffd-df70-565e-aa37-841b32386389",
      "notes": "User requested to start a claim, but the session was transferred to an agent without further interaction."
    },
    {
      "user_id": "u-fe00876b-298c-5ee5-bc06-072a4b980dbf",
      "notes": "User demanded a callback and expressed a desire to speak to a human, leading to session closure without transfer."
    },
    {
      "user_id": "u-a955fadb-d98e-56da-9959-be09cc851ddc",
      "notes": "User wanted to speak to an agent; session was transferred after user confirmed."
    },
    {
      "user_id": "u-92fe0dd2-bcb8-5a20-a56a-8ee4a1093b03",
      "notes": "User requested to speak to an agent; session was transferred after user pressed star."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2048,
  completionTokens: 255,
  totalTokens: 2303,
  cost: '$0.000307',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI SERVICE CALL COMPLETE =====
â±ï¸  OpenAI Call Time: 1820ms (1.82s)
ğŸ“Š Sessions Returned: 5
ğŸ’° Tokens Used: 2303 ($0.0003)
âš¡ Performance: 1265.4 tokens/sec

ğŸ”„ ===== SESSION MAPPING COMPLETE =====
â±ï¸  Mapping Time: 0ms
ğŸ“Š Final Session Results: 5
ğŸ“Š Missing Sessions: 0
â±ï¸  Regular Batch Time: 1820ms (1.82s)
ğŸ“Š Regular Sessions Processed: 5
ğŸ’° Regular Tokens Used: 2303

âœ… ===== BATCH 4 PROCESSING COMPLETE =====
â±ï¸  Total Batch Time: 1820ms (1.82s)
ğŸ“Š Sessions Processed: 5/5
ğŸ’° Total Tokens: 2303 ($0.0003)
âš¡ Performance: 2.7 sessions/sec
âš¡ Avg Time Per Session: 364.00ms
â±ï¸  Metadata Processing: 0ms
[StrategicDiscoveryService] Batch 3 complete: 0 new classifications discovered
[StrategicDiscoveryService] Current classifications: { intents: 1, reasons: 0, locations: 0, total: 1 }
[StrategicDiscoveryService] Discovery phase complete: {
  totalProcessed: 14,
  uniqueIntents: 1,
  uniqueReasons: 0,
  uniqueLocations: 0,
  discoveryRate: 0.06666666666666667
}

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T19:54:50.552Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms
[ParallelProcessingOrchestrator] Configuration for 86 sessions:
  Design: 8 streams Ã— 4 sessions = 32 per round
  Optimal: 8 streams Ã— 4 sessions = 32 per round
  Estimated Rounds: 3
[ParallelAutoAnalyzeService] Using parallel config: {
  streamCount: 8,
  sessionsPerStream: 4,
  maxSessionsPerLLMCall: 50,
  syncFrequency: 'after_each_round',
  retryAttempts: 3,
  debugLogging: false
}

ğŸš€ ============ PARALLEL PROCESSING STARTED ============
â±ï¸  Start Time: 2025-08-12T19:54:50.552Z
ğŸ“Š Total Sessions: 86

âš™ï¸  ===== OPTIMAL BATCH CONFIG =====
â±ï¸  Config Start: 2025-08-12T19:54:50.552Z
ğŸ§  Model: gpt-4.1-nano
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== OPTIMAL BATCH CONFIG COMPLETE =====
â±ï¸  Config Time: 0ms
ğŸ“¦ Max Sessions Per Call: 50
ğŸ•°ï¸ Context Window: 1,000,000 tokens
ğŸŒŠ Recommended Streams: 3
â±ï¸  Timing:
   â€¢ Max Sessions Calculation: 0ms

âš™ï¸  ============ PARALLEL CONFIGURATION ============
â±ï¸  Config Time: 0ms
ğŸ”§ Stream Count: 8
ğŸ“¦ Sessions Per Stream: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per API Call: 50
ğŸ¯ Debug Logging: false

ğŸ”„ ============ ROUND 1/3 STARTED ============
â±ï¸  Round 1 Start: 2025-08-12T19:54:50.552Z
ğŸ“Š Sessions Remaining: 86
[ParallelProcessingOrchestrator] Distributed 32 sessions across 8 streams: [
  'Stream 1: 4 sessions',
  'Stream 2: 4 sessions',
  'Stream 3: 4 sessions',
  'Stream 4: 4 sessions',
  'Stream 5: 4 sessions',
  'Stream 6: 4 sessions',
  'Stream 7: 4 sessions',
  'Stream 8: 4 sessions'
]
â±ï¸  Session Distribution Time: 2ms
ğŸŒŠ Active Streams: 8

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 8 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T19:54:50.554Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:54:50.554Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 752
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6252
   â€¢ Avg Per Session: 188 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6252
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6252
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:54:50.554Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 1
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:54:50.555Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6034,
  existingClassifications: { intents: 1, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Unknown

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and a...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T19:54:50.555Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:54:50.555Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 956
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6456
   â€¢ Avg Per Session: 239 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6456
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6456
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:54:50.555Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 1
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:54:50.555Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7015,
  existingClassifications: { intents: 1, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Unknown

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and a...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T19:54:50.555Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:54:50.555Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 664
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6164
   â€¢ Avg Per Session: 166 tokens
   â€¢ Estimation Time: 1ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6164
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 1ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6164
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:54:50.556Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 1
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:54:50.556Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5624,
  existingClassifications: { intents: 1, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Unknown

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and a...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T19:54:50.556Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:54:50.556Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 848
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6348
   â€¢ Avg Per Session: 212 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6348
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6348
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:54:50.556Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 1
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:54:50.557Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6404,
  existingClassifications: { intents: 1, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Unknown

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and a...

ğŸŒŠ ===== STREAM 5 PROCESSING START =====
â±ï¸  Stream 5 Start: 2025-08-12T19:54:50.557Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:54:50.557Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 948
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6448
   â€¢ Avg Per Session: 237 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6448
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 5) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6448
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 5: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:54:50.557Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 1
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:54:50.557Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6995,
  existingClassifications: { intents: 1, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Unknown

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and a...

ğŸŒŠ ===== STREAM 6 PROCESSING START =====
â±ï¸  Stream 6 Start: 2025-08-12T19:54:50.557Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:54:50.557Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 553
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6053
   â€¢ Avg Per Session: 138 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6053
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 6) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6053
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 6: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:54:50.557Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 1
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:54:50.558Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5155,
  existingClassifications: { intents: 1, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Unknown

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and a...

ğŸŒŠ ===== STREAM 7 PROCESSING START =====
â±ï¸  Stream 7 Start: 2025-08-12T19:54:50.558Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:54:50.558Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 659
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6159
   â€¢ Avg Per Session: 165 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6159
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 7) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6159
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 7: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:54:50.558Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 1
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:54:50.558Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 5604,
  existingClassifications: { intents: 1, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Unknown

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and a...

ğŸŒŠ ===== STREAM 8 PROCESSING START =====
â±ï¸  Stream 8 Start: 2025-08-12T19:54:50.558Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:54:50.558Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 911
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6411
   â€¢ Avg Per Session: 228 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6411
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 8) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6411
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 8: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:54:50.558Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 1
   â€¢ Reasons: 0
   â€¢ Locations: 0

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:54:50.559Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6788,
  existingClassifications: { intents: 1, transferReasons: 0, dropOffLocations: 0 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Unknown

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common examples: "Claim Status", "Billing", "Eligibility", "Live Agent", "Provider Enrollment", "Portal Access", "Authorization". If unknown, use "Unknown". If the user's intent was both Live Agent and a...
::1 - - [12/Aug/2025:19:54:51 +0000] "GET /api/analysis/auto-analyze/parallel/progress/e3384dec-edb5-44ac-bf5a-02d64396ce8c HTTP/1.1" 200 949 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:54:51.963Z',
  duration: '1406ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1811,
    completion_tokens: 185,
    total_tokens: 1996,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-d7ce1719-d911-580d-95bd-8dcbef48c380",
      "notes": "User wanted to speak with an agent, session was transferred to a live agent."
    },
    {
      "user_id": "u-52894ed9-0fc9-5ba3-9f58-e82d623917ac",
      "notes": "User wanted to speak with an agent, session was transferred to a live agent."
    },
    {
      "user_id": "u-8a7ffe93-f90d-5b31-af01-c20ca8bb316a",
      "notes": "Session was not transferred, ended due to no input from user."
    },
    {
      "user_id": "u-e6677030-b96d-570c-842f-d7157e0666c3",
      "notes": "User inquired about FMLA, session was transferred to a live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1811,
  completionTokens: 185,
  totalTokens: 1996,
  cost: '$0.000255',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1408ms (1.41s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1996 ($0.0003)
âš¡ Performance: 1417.6 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1811
   â€¢ Completion Tokens: 185
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-d7ce1719-d911-580d-95bd-8dcbef48c380: Invalid general_intent, u-d7ce1719-d911-580d-95bd-8dcbef48c380: Invalid session_outcome, u-52894ed9-0fc9-5ba3-9f58-e82d623917ac: Invalid general_intent, u-52894ed9-0fc9-5ba3-9f58-e82d623917ac: Invalid session_outcome, u-8a7ffe93-f90d-5b31-af01-c20ca8bb316a: Invalid general_intent, u-8a7ffe93-f90d-5b31-af01-c20ca8bb316a: Invalid session_outcome, u-e6677030-b96d-570c-842f-d7157e0666c3: Invalid general_intent, u-e6677030-b96d-570c-842f-d7157e0666c3: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 4 Single Batch Time: 1409ms (1.41s)

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 1409ms (1.41s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1996 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.8 sessions/sec
âš¡ Avg Time Per Session: 352.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:54:52.020Z',
  duration: '1463ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2005,
    completion_tokens: 196,
    total_tokens: 2201,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-69366f69-e835-5f64-8ab3-36292d5b0825",
      "notes": "User wanted to speak with an agent, and the bot transferred the call."
    },
    {
      "user_id": "u-96618d9f-871d-5b97-aa75-a0b14ffa7026",
      "notes": "User wanted to speak with an agent, but the session was closed due to inactivity."
    },
    {
      "user_id": "u-7441f4e3-e645-536a-aef0-88d273ef34fa",
      "notes": "User requested claim status, then was transferred to an agent."
    },
    {
      "user_id": "u-4f8cbef0-bbe8-5814-8ec6-25ec81b95704",
      "notes": "User wanted to enter a date, then was guided through claim and time entry process, and successfully submitted a time entry."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2005,
  completionTokens: 196,
  totalTokens: 2201,
  cost: '$0.000279',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1464ms (1.46s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2201 ($0.0003)
âš¡ Performance: 1503.4 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2005
   â€¢ Completion Tokens: 196
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-69366f69-e835-5f64-8ab3-36292d5b0825: Invalid general_intent, u-69366f69-e835-5f64-8ab3-36292d5b0825: Invalid session_outcome, u-96618d9f-871d-5b97-aa75-a0b14ffa7026: Invalid general_intent, u-96618d9f-871d-5b97-aa75-a0b14ffa7026: Invalid session_outcome, u-7441f4e3-e645-536a-aef0-88d273ef34fa: Invalid general_intent, u-7441f4e3-e645-536a-aef0-88d273ef34fa: Invalid session_outcome, u-4f8cbef0-bbe8-5814-8ec6-25ec81b95704: Invalid general_intent, u-4f8cbef0-bbe8-5814-8ec6-25ec81b95704: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 5 Single Batch Time: 1464ms (1.46s)

âœ… ===== STREAM 5 PROCESSING COMPLETE =====
â±ï¸  Stream 5 Total Time: 1464ms (1.46s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2201 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.7 sessions/sec
âš¡ Avg Time Per Session: 366.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:54:52.063Z',
  duration: '1505ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1535,
    completion_tokens: 197,
    total_tokens: 1732,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-3a020de4-f067-5a2b-9539-76193bde453c",
      "notes": "User requested to file papers for FMLA, session transferred to a live agent."
    },
    {
      "user_id": "u-00e6c2f0-c8f4-533a-bd08-1e5b2dfd253b",
      "notes": "User requested a new leave request, session transferred to a live agent."
    },
    {
      "user_id": "u-6664b9fd-99b2-521a-8f5d-c2fdfdc1589d",
      "notes": "User requested to speak with an agent, session transferred to a live agent."
    },
    {
      "user_id": "u-7034345e-9323-5b95-a776-6e05758dcb41",
      "notes": "User requested to file a new claim, session transferred to a live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1535,
  completionTokens: 197,
  totalTokens: 1732,
  cost: '$0.000232',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1507ms (1.51s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1732 ($0.0002)
âš¡ Performance: 1149.3 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1535
   â€¢ Completion Tokens: 197
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-3a020de4-f067-5a2b-9539-76193bde453c: Invalid general_intent, u-3a020de4-f067-5a2b-9539-76193bde453c: Invalid session_outcome, u-00e6c2f0-c8f4-533a-bd08-1e5b2dfd253b: Invalid general_intent, u-00e6c2f0-c8f4-533a-bd08-1e5b2dfd253b: Invalid session_outcome, u-6664b9fd-99b2-521a-8f5d-c2fdfdc1589d: Invalid general_intent, u-6664b9fd-99b2-521a-8f5d-c2fdfdc1589d: Invalid session_outcome, u-7034345e-9323-5b95-a776-6e05758dcb41: Invalid general_intent, u-7034345e-9323-5b95-a776-6e05758dcb41: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 6 Single Batch Time: 1507ms (1.51s)

âœ… ===== STREAM 6 PROCESSING COMPLETE =====
â±ï¸  Stream 6 Total Time: 1507ms (1.51s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1732 ($0.0002)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.7 sessions/sec
âš¡ Avg Time Per Session: 376.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:54:52.314Z',
  duration: '1756ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1638,
    completion_tokens: 225,
    total_tokens: 1863,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-7a4e5d38-baa0-5c46-8c5d-9049186ebf39",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-ef2429e8-0673-5471-9342-89819834b565",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-0c7c1ca0-36aa-5367-9abd-7ec04ad06d4c",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": ""
    },
    {
      "user_id": "u-10a7bce5-126d-59ee-a2cd-a8330a11dbb9",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1638,
  completionTokens: 225,
  totalTokens: 1863,
  cost: '$0.000254',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1756ms (1.76s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1863 ($0.0003)
âš¡ Performance: 1060.9 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1638
   â€¢ Completion Tokens: 225
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-7a4e5d38-baa0-5c46-8c5d-9049186ebf39: Invalid notes, u-ef2429e8-0673-5471-9342-89819834b565: Invalid notes, u-0c7c1ca0-36aa-5367-9abd-7ec04ad06d4c: Invalid notes, u-10a7bce5-126d-59ee-a2cd-a8330a11dbb9: Invalid notes'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 7 Single Batch Time: 1756ms (1.76s)
[StreamProcessingService] Discovered 2 new classifications: { intents: 0, reasons: 1, locations: 1 }

âœ… ===== STREAM 7 PROCESSING COMPLETE =====
â±ï¸  Stream 7 Total Time: 1756ms (1.76s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1863 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.3 sessions/sec
âš¡ Avg Time Per Session: 439.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:54:52.349Z',
  duration: '1794ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2004,
    completion_tokens: 277,
    total_tokens: 2281,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Claim status', 'Customer service' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-16f01507-1160-5322-aa3c-fb4b3b7413a9",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-372fb377-e092-5a93-8855-6fc3015ae78b",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-32b4f2f0-7c16-539e-896c-c35247eb904a",
      "general_intent": "Claim status",
      "session_outcome": "Contained",
      "transfer_reason": "",
      "drop_off_location": "",
      "notes": "User successfully verified identity and submitted a time entry."
    },
    {
      "user_id": "u-003b28d6-e53e-5f07-8bd8-028ab5ff6107",
      "general_intent": "Customer service",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested customer service and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2004,
  completionTokens: 277,
  totalTokens: 2281,
  cost: '$0.000311',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1795ms (1.79s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2281 ($0.0003)
âš¡ Performance: 1270.8 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2004
   â€¢ Completion Tokens: 277
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 2 Single Batch Time: 1795ms (1.79s)
[StreamProcessingService] Discovered 5 new classifications: { intents: 3, reasons: 1, locations: 1 }

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 1795ms (1.79s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2281 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.2 sessions/sec
âš¡ Avg Time Per Session: 448.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:54:52.373Z',
  duration: '1814ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1936,
    completion_tokens: 268,
    total_tokens: 2204,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown', 'Claim Status', 'Leave Status' ],
  transferCount: 2,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-48148013-f5f9-5bfa-83ec-9fbb17aef450",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent, session was transferred."
    },
    {
      "user_id": "u-8c581208-2d7b-5b35-a435-b5d125726ec8",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User attempted to file a claim but did not provide sufficient information, session was not transferred."
    },
    {
      "user_id": "u-c9419a53-1423-5fee-ab85-08ceb35a0a5b",
      "general_intent": "Leave Status",
      "session_outcome": "Contained",
      "notes": "User provided leave request details and verified information; session was handled by bot."
    },
    {
      "user_id": "u-f49ff565-7e3b-5d8a-afb5-6f2318aa26b7",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent, session was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1936,
  completionTokens: 268,
  totalTokens: 2204,
  cost: '$0.000301',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1815ms (1.81s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2204 ($0.0003)
âš¡ Performance: 1214.3 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1936
   â€¢ Completion Tokens: 268
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 8 Single Batch Time: 1816ms (1.82s)
[StreamProcessingService] Discovered 4 new classifications: { intents: 2, reasons: 1, locations: 1 }

âœ… ===== STREAM 8 PROCESSING COMPLETE =====
â±ï¸  Stream 8 Total Time: 1816ms (1.82s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2204 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.2 sessions/sec
âš¡ Avg Time Per Session: 454.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:54:52.374Z',
  duration: '1818ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1636,
    completion_tokens: 284,
    total_tokens: 1920,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-c583691c-9270-5d1b-83c6-50c148993d35",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-fd998279-49b3-5b54-be54-8547f315b61d",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-ce4bff4d-4eef-542b-bb32-f7f54b775a62",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-84f971b0-b1a3-5cac-9cb4-ee4397ac97ea",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1636,
  completionTokens: 284,
  totalTokens: 1920,
  cost: '$0.000277',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1818ms (1.82s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1920 ($0.0003)
âš¡ Performance: 1056.1 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1636
   â€¢ Completion Tokens: 284
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 3 Single Batch Time: 1818ms (1.82s)
[StreamProcessingService] Discovered 3 new classifications: { intents: 1, reasons: 1, locations: 1 }

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 1820ms (1.82s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1920 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.2 sessions/sec
âš¡ Avg Time Per Session: 455.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:54:52.566Z',
  duration: '2011ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1741,
    completion_tokens: 227,
    total_tokens: 1968,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Unknown' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-b8738305-b5ea-5fff-8edd-3585a31c39f1",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-2aba4862-9b7b-57aa-9d06-6d9a8a912289",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-84fa423f-7077-50f5-8d46-da81fe8bdcc0",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-f6d675c6-46d1-5f11-935a-dd93de8fe529",
      "general_intent": "Unknown",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1741,
  completionTokens: 227,
  totalTokens: 1968,
  cost: '$0.000265',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2013ms (2.01s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 1968 ($0.0003)
âš¡ Performance: 977.6 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1741
   â€¢ Completion Tokens: 227
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-b8738305-b5ea-5fff-8edd-3585a31c39f1: Invalid notes, u-2aba4862-9b7b-57aa-9d06-6d9a8a912289: Invalid notes, u-84fa423f-7077-50f5-8d46-da81fe8bdcc0: Invalid notes, u-f6d675c6-46d1-5f11-935a-dd93de8fe529: Invalid notes'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 1 Single Batch Time: 2014ms (2.01s)
[StreamProcessingService] Discovered 2 new classifications: { intents: 0, reasons: 1, locations: 1 }

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 2014ms (2.01s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 1968 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.0 sessions/sec
âš¡ Avg Time Per Session: 503.50ms
[ParallelProcessingOrchestrator] Parallel processing complete: 8/8 streams succeeded
â±ï¸  Parallel Processing Time: 2014ms (2.01s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 8 streams
[ParallelProcessingOrchestrator] Synchronization complete: 7 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 7
ğŸ“Š Total Classifications: 8
ğŸ” [ConflictResolution] Checking if conflict resolution should run:
   â€¢ Total Classifications: 8
   â€¢ Intents: 6
   â€¢ Reasons: 1
   â€¢ Locations: 1
   â€¢ Should Run: true (threshold: 3)

âš–ï¸ ============ INTER-ROUND CONFLICT RESOLUTION ============
â±ï¸  Starting conflict resolution after round 1
âš ï¸  ConflictResolutionService not available, skipping inter-round resolution

âœ… ============ ROUND 1 COMPLETED ============
â±ï¸  Round 1 Total Time: 2017ms (2.02s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 54
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 2ms (0.1%)
   â€¢ Parallel Processing: 2014ms (99.9%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ”„ ============ ROUND 2/3 STARTED ============
â±ï¸  Round 2 Start: 2025-08-12T19:54:52.569Z
ğŸ“Š Sessions Remaining: 54
[ParallelProcessingOrchestrator] Distributed 32 sessions across 8 streams: [
  'Stream 1: 4 sessions',
  'Stream 2: 4 sessions',
  'Stream 3: 4 sessions',
  'Stream 4: 4 sessions',
  'Stream 5: 4 sessions',
  'Stream 6: 4 sessions',
  'Stream 7: 4 sessions',
  'Stream 8: 4 sessions'
]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 8

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 8 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T19:54:52.570Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:54:52.570Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 1004
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6504
   â€¢ Avg Per Session: 251 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6504
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6504
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:54:52.570Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 6
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:54:52.571Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7365,
  existingClassifications: { intents: 6, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Customer service, Leave Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common e...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T19:54:52.571Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:54:52.571Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 739
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6239
   â€¢ Avg Per Session: 185 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6239
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6239
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:54:52.571Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 6
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:54:52.571Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6161,
  existingClassifications: { intents: 6, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Customer service, Leave Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common e...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T19:54:52.571Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:54:52.571Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 1025
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6525
   â€¢ Avg Per Session: 256 tokens
   â€¢ Estimation Time: 1ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6525
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 1ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6525
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:54:52.572Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 6
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:54:52.572Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7541,
  existingClassifications: { intents: 6, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Customer service, Leave Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common e...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T19:54:52.572Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:54:52.572Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 857
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6357
   â€¢ Avg Per Session: 214 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6357
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6357
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:54:52.573Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 6
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:54:52.573Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6737,
  existingClassifications: { intents: 6, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Customer service, Leave Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common e...

ğŸŒŠ ===== STREAM 5 PROCESSING START =====
â±ï¸  Stream 5 Start: 2025-08-12T19:54:52.573Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:54:52.573Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 919
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6419
   â€¢ Avg Per Session: 230 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6419
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 5) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6419
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 5: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:54:52.573Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 6
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:54:52.573Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7050,
  existingClassifications: { intents: 6, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Customer service, Leave Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common e...

ğŸŒŠ ===== STREAM 6 PROCESSING START =====
â±ï¸  Stream 6 Start: 2025-08-12T19:54:52.573Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:54:52.573Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 830
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6330
   â€¢ Avg Per Session: 208 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6330
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 6) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6330
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 6: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:54:52.574Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 6
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:54:52.574Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6626,
  existingClassifications: { intents: 6, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Customer service, Leave Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common e...

ğŸŒŠ ===== STREAM 7 PROCESSING START =====
â±ï¸  Stream 7 Start: 2025-08-12T19:54:52.574Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:54:52.574Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 719
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6219
   â€¢ Avg Per Session: 180 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6219
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 7) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6219
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 7: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:54:52.574Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 6
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:54:52.574Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6055,
  existingClassifications: { intents: 6, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Customer service, Leave Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common e...

ğŸŒŠ ===== STREAM 8 PROCESSING START =====
â±ï¸  Stream 8 Start: 2025-08-12T19:54:52.574Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:54:52.575Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 868
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6368
   â€¢ Avg Per Session: 217 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6368
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 8) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6368
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 8: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:54:52.575Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 6
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:54:52.575Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6729,
  existingClassifications: { intents: 6, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Customer service, Leave Status, Live Agent, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 words). Common e...
::1 - - [12/Aug/2025:19:54:53 +0000] "GET /api/analysis/auto-analyze/parallel/progress/e3384dec-edb5-44ac-bf5a-02d64396ce8c HTTP/1.1" 200 949 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:54:53.853Z',
  duration: '1281ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2155,
    completion_tokens: 195,
    total_tokens: 2350,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-f79c5c2c-df1e-50fb-a40b-1dd4d866b175",
      "notes": "User wanted to speak with an agent and was transferred to a live agent."
    },
    {
      "user_id": "u-c4b7dfe0-8003-50be-8a2e-9b83743d4f6b",
      "notes": "User expressed intent to discuss claim status and was transferred to an agent."
    },
    {
      "user_id": "u-3402b9ab-217e-57d3-bb57-f8fbef2d23be",
      "notes": "User attempted to stop a claim but was not transferred; session was handled by bot."
    },
    {
      "user_id": "u-c3dd0050-687b-5de4-8dd0-353ad921e383",
      "notes": "User inquired about claim status and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2155,
  completionTokens: 195,
  totalTokens: 2350,
  cost: '$0.000293',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1281ms (1.28s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2350 ($0.0003)
âš¡ Performance: 1834.5 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2155
   â€¢ Completion Tokens: 195
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-f79c5c2c-df1e-50fb-a40b-1dd4d866b175: Invalid general_intent, u-f79c5c2c-df1e-50fb-a40b-1dd4d866b175: Invalid session_outcome, u-c4b7dfe0-8003-50be-8a2e-9b83743d4f6b: Invalid general_intent, u-c4b7dfe0-8003-50be-8a2e-9b83743d4f6b: Invalid session_outcome, u-3402b9ab-217e-57d3-bb57-f8fbef2d23be: Invalid general_intent, u-3402b9ab-217e-57d3-bb57-f8fbef2d23be: Invalid session_outcome, u-c3dd0050-687b-5de4-8dd0-353ad921e383: Invalid general_intent, u-c3dd0050-687b-5de4-8dd0-353ad921e383: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 3 Single Batch Time: 1281ms (1.28s)

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 1282ms (1.28s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2350 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 3.1 sessions/sec
âš¡ Avg Time Per Session: 320.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:54:54.030Z',
  duration: '1457ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1918,
    completion_tokens: 221,
    total_tokens: 2139,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-4f6d8f21-79ad-5b7f-96a6-8ded61b7558c",
      "notes": "User was attempting to inquire about FMLA leave request details but was unable to provide the necessary information, leading to a transfer."
    },
    {
      "user_id": "u-92e19bc8-2dad-5b09-9c6f-2964ef85a0ea",
      "notes": "User expressed interest in customer service and was transferred to an agent due to silence and lack of input."
    },
    {
      "user_id": "u-ce48737c-af8e-58a3-9b09-c677305713a1",
      "notes": "User was silent and then declined to open a new leave request or other options, leading to a transfer."
    },
    {
      "user_id": "u-65de5019-27a8-5788-a16c-833401f7b785",
      "notes": "User asked about FMLA and renewal, but was transferred after the bot couldn't process the request."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1918,
  completionTokens: 221,
  totalTokens: 2139,
  cost: '$0.000280',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1458ms (1.46s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2139 ($0.0003)
âš¡ Performance: 1467.1 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1918
   â€¢ Completion Tokens: 221
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-4f6d8f21-79ad-5b7f-96a6-8ded61b7558c: Invalid general_intent, u-4f6d8f21-79ad-5b7f-96a6-8ded61b7558c: Invalid session_outcome, u-92e19bc8-2dad-5b09-9c6f-2964ef85a0ea: Invalid general_intent, u-92e19bc8-2dad-5b09-9c6f-2964ef85a0ea: Invalid session_outcome, u-ce48737c-af8e-58a3-9b09-c677305713a1: Invalid general_intent, u-ce48737c-af8e-58a3-9b09-c677305713a1: Invalid session_outcome, u-65de5019-27a8-5788-a16c-833401f7b785: Invalid general_intent, u-65de5019-27a8-5788-a16c-833401f7b785: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 4 Single Batch Time: 1459ms (1.46s)

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 1459ms (1.46s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2139 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.7 sessions/sec
âš¡ Avg Time Per Session: 364.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:54:54.108Z',
  duration: '1535ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2000,
    completion_tokens: 214,
    total_tokens: 2214,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-63320aaf-30dd-5cc6-854f-3d7561a28a42",
      "notes": "User wanted to speak with an agent but did not specify the reason, and the session was transferred to an agent."
    },
    {
      "user_id": "u-b55f88d0-ad9e-551e-87d8-d33d98e2e36c",
      "notes": "User wanted to speak with an agent but did not specify the reason, and the session was transferred to an agent."
    },
    {
      "user_id": "u-ab41b38a-0cab-59fb-b5db-fedde61b339b",
      "notes": "User provided leave request details and confirmed submission; session was handled by bot."
    },
    {
      "user_id": "u-64bd9ac5-2e64-5ed1-95da-5a4e112f4b9f",
      "notes": "User wanted to track time off but did not specify details, session was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2000,
  completionTokens: 214,
  totalTokens: 2214,
  cost: '$0.000286',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1536ms (1.54s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2214 ($0.0003)
âš¡ Performance: 1441.4 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2000
   â€¢ Completion Tokens: 214
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-63320aaf-30dd-5cc6-854f-3d7561a28a42: Invalid general_intent, u-63320aaf-30dd-5cc6-854f-3d7561a28a42: Invalid session_outcome, u-b55f88d0-ad9e-551e-87d8-d33d98e2e36c: Invalid general_intent, u-b55f88d0-ad9e-551e-87d8-d33d98e2e36c: Invalid session_outcome, u-ab41b38a-0cab-59fb-b5db-fedde61b339b: Invalid general_intent, u-ab41b38a-0cab-59fb-b5db-fedde61b339b: Invalid session_outcome, u-64bd9ac5-2e64-5ed1-95da-5a4e112f4b9f: Invalid general_intent, u-64bd9ac5-2e64-5ed1-95da-5a4e112f4b9f: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 5 Single Batch Time: 1536ms (1.54s)

âœ… ===== STREAM 5 PROCESSING COMPLETE =====
â±ï¸  Stream 5 Total Time: 1536ms (1.54s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2214 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.6 sessions/sec
âš¡ Avg Time Per Session: 384.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:54:54.210Z',
  duration: '1639ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2084,
    completion_tokens: 283,
    total_tokens: 2367,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Claim Status', 'Leave Status' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-30b3737f-8f3a-5e90-b33a-65fea102bc35",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent and was transferred."
    },
    {
      "user_id": "u-7b049bb1-230d-5659-a88d-3a1d7afe5998",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent and was transferred."
    },
    {
      "user_id": "u-dae579d0-d327-5f2f-b379-c05e5f622e03",
      "general_intent": "Claim Status",
      "session_outcome": "Contained",
      "notes": "User discussed FMLA claim status and initiated a new request, session was handled by bot."
    },
    {
      "user_id": "u-53c03431-0b56-5ef7-83af-592e5c2e5b8d",
      "general_intent": "Leave Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak to a representative and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2084,
  completionTokens: 283,
  totalTokens: 2367,
  cost: '$0.000322',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1641ms (1.64s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2367 ($0.0003)
âš¡ Performance: 1442.4 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2084
   â€¢ Completion Tokens: 283
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 1 Single Batch Time: 1641ms (1.64s)

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 1641ms (1.64s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2367 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.4 sessions/sec
âš¡ Avg Time Per Session: 410.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:54:54.273Z',
  duration: '1699ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1730,
    completion_tokens: 291,
    total_tokens: 2021,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-4adfe2e6-a070-5380-8c9e-abe379209e82",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-0a9699a8-1250-5352-9844-aa2da63aeb95",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-d2c766a4-4198-5bdb-90eb-b69d0d5ffc1f",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-3e6f1bc5-2b7a-5854-81eb-fdc23a96320b",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and did not respond, leading to transfer."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1730,
  completionTokens: 291,
  totalTokens: 2021,
  cost: '$0.000289',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1700ms (1.70s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2021 ($0.0003)
âš¡ Performance: 1188.8 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1730
   â€¢ Completion Tokens: 291
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 7 Single Batch Time: 1700ms (1.70s)

âœ… ===== STREAM 7 PROCESSING COMPLETE =====
â±ï¸  Stream 7 Total Time: 1700ms (1.70s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2021 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.4 sessions/sec
âš¡ Avg Time Per Session: 425.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:54:54.280Z',
  duration: '1709ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1744,
    completion_tokens: 277,
    total_tokens: 2021,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Live Agent', 'Request leave', 'Customer service' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-b5571402-150c-53b7-a5e2-0ddda856ccc1",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent and was transferred."
    },
    {
      "user_id": "u-001fb183-e99e-5054-8235-53b075135c05",
      "general_intent": "Live Agent",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak to an agent and was transferred."
    },
    {
      "user_id": "u-730f41fa-a16e-5a27-bd66-2854187f089b",
      "general_intent": "Request leave",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested leave and was transferred to an agent."
    },
    {
      "user_id": "u-0cd5d775-712e-5c8d-ad14-699b6b220d23",
      "general_intent": "Customer service",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested customer service and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1744,
  completionTokens: 277,
  totalTokens: 2021,
  cost: '$0.000285',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1709ms (1.71s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2021 ($0.0003)
âš¡ Performance: 1182.6 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1744
   â€¢ Completion Tokens: 277
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 2 Single Batch Time: 1709ms (1.71s)
[StreamProcessingService] Discovered 1 new classifications: { intents: 1, reasons: 0, locations: 0 }

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 1709ms (1.71s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2021 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.3 sessions/sec
âš¡ Avg Time Per Session: 427.25ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:54:54.454Z',
  duration: '1880ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1893,
    completion_tokens: 278,
    total_tokens: 2171,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Leave Status' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-57a9feec-0517-5db6-862f-9cb00b46a044",
      "general_intent": "Leave Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent and was transferred."
    },
    {
      "user_id": "u-022eb062-a606-5858-9b4a-b65095d9cd4b",
      "general_intent": "Leave Status",
      "session_outcome": "Contained",
      "notes": "User attempted to get help with time entry but did not complete the session."
    },
    {
      "user_id": "u-f65e063c-a483-5e18-bc0f-10630a25363c",
      "general_intent": "Leave Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to file a new FMLA claim and was transferred to an agent."
    },
    {
      "user_id": "u-4898b204-9214-5313-8558-0f0d865ef097",
      "general_intent": "Leave Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with a representative and was transferred."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1893,
  completionTokens: 278,
  totalTokens: 2171,
  cost: '$0.000300',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1881ms (1.88s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2171 ($0.0003)
âš¡ Performance: 1154.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1893
   â€¢ Completion Tokens: 278
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 6 Single Batch Time: 1881ms (1.88s)

âœ… ===== STREAM 6 PROCESSING COMPLETE =====
â±ï¸  Stream 6 Total Time: 1882ms (1.88s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2171 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.1 sessions/sec
âš¡ Avg Time Per Session: 470.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:54:55.007Z',
  duration: '2432ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1892,
    completion_tokens: 297,
    total_tokens: 2189,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Leave Status' ],
  transferCount: 4,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-0f1a86ea-f601-5d0a-848c-14c4aa8856ec",
      "general_intent": "Leave Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User attempted to access leave entry information but was transferred to an agent."
    },
    {
      "user_id": "u-cbd873bc-ec94-5099-98b2-7a365b3f8671",
      "general_intent": "Leave Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested to speak with an agent about family medical leave and was transferred."
    },
    {
      "user_id": "u-2c92818f-3b8f-5182-9723-ffe8bfc80784",
      "general_intent": "Leave Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User asked about FMLA review and was transferred to an agent."
    },
    {
      "user_id": "u-230dc45d-68d2-5051-a8bf-98573c15967c",
      "general_intent": "Leave Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User requested a representative and was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1892,
  completionTokens: 297,
  totalTokens: 2189,
  cost: '$0.000308',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 2434ms (2.43s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2189 ($0.0003)
âš¡ Performance: 899.3 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1892
   â€¢ Completion Tokens: 297
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 8 Single Batch Time: 2435ms (2.44s)

âœ… ===== STREAM 8 PROCESSING COMPLETE =====
â±ï¸  Stream 8 Total Time: 2436ms (2.44s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2189 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.6 sessions/sec
âš¡ Avg Time Per Session: 609.00ms
[ParallelProcessingOrchestrator] Parallel processing complete: 8/8 streams succeeded
â±ï¸  Parallel Processing Time: 2441ms (2.44s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 8 streams
[ParallelProcessingOrchestrator] Synchronization complete: 1 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 1ms
ğŸ†• New Classifications: 1
ğŸ“Š Total Classifications: 9
ğŸ” [ConflictResolution] Checking if conflict resolution should run:
   â€¢ Total Classifications: 9
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 1
   â€¢ Should Run: true (threshold: 3)

âš–ï¸ ============ INTER-ROUND CONFLICT RESOLUTION ============
â±ï¸  Starting conflict resolution after round 2
âš ï¸  ConflictResolutionService not available, skipping inter-round resolution

âœ… ============ ROUND 2 COMPLETED ============
â±ï¸  Round 2 Total Time: 2443ms (2.44s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 22
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 2441ms (99.9%)
   â€¢ Synchronization: 1ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ”„ ============ ROUND 3/3 STARTED ============
â±ï¸  Round 3 Start: 2025-08-12T19:54:55.012Z
ğŸ“Š Sessions Remaining: 22
[ParallelProcessingOrchestrator] Distributed 22 sessions across 6 streams: [
  'Stream 1: 4 sessions',
  'Stream 2: 4 sessions',
  'Stream 3: 4 sessions',
  'Stream 4: 4 sessions',
  'Stream 5: 4 sessions',
  'Stream 6: 2 sessions'
]
â±ï¸  Session Distribution Time: 0ms
ğŸŒŠ Active Streams: 6

ğŸš€ Starting parallel stream processing...
[ParallelProcessingOrchestrator] Starting 6 streams in parallel

ğŸŒŠ ===== STREAM 1 PROCESSING START =====
â±ï¸  Stream 1 Start: 2025-08-12T19:54:55.012Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:54:55.012Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 926
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6426
   â€¢ Avg Per Session: 232 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6426
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 1) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6426
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 1: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:54:55.013Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:54:55.013Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7069,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Customer service, Leave Status, Live Agent, Request leave, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 w...

ğŸŒŠ ===== STREAM 2 PROCESSING START =====
â±ï¸  Stream 2 Start: 2025-08-12T19:54:55.013Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:54:55.013Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 870
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6370
   â€¢ Avg Per Session: 218 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6370
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 2) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6370
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 2: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:54:55.013Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:54:55.013Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6873,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Customer service, Leave Status, Live Agent, Request leave, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 w...

ğŸŒŠ ===== STREAM 3 PROCESSING START =====
â±ï¸  Stream 3 Start: 2025-08-12T19:54:55.013Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:54:55.013Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 806
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6306
   â€¢ Avg Per Session: 202 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6306
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 1ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 3) =====
â±ï¸  Token Estimation Time: 1ms
ğŸ“Š Estimated Tokens: 6306
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 3: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:54:55.014Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:54:55.014Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6470,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Customer service, Leave Status, Live Agent, Request leave, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 w...

ğŸŒŠ ===== STREAM 4 PROCESSING START =====
â±ï¸  Stream 4 Start: 2025-08-12T19:54:55.014Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:54:55.014Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 872
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6372
   â€¢ Avg Per Session: 218 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6372
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 4) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6372
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 4: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:54:55.014Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:54:55.014Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 6843,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Customer service, Leave Status, Live Agent, Request leave, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 w...

ğŸŒŠ ===== STREAM 5 PROCESSING START =====
â±ï¸  Stream 5 Start: 2025-08-12T19:54:55.014Z
ğŸ“Š Sessions Assigned: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:54:55.014Z
ğŸ“Š Sessions to Estimate: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 4
   â€¢ Session Tokens: 936
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 6436
   â€¢ Avg Per Session: 234 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6436
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010
ğŸ“Š Recommended Batch Size: 4

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 5) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 6436
ğŸ“¦ Recommended Batch Size: 4
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0010

âš¡ Stream 5: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:54:55.014Z
ğŸ“Š Sessions to Analyze: 4
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:54:55.014Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 4,
  apiKey: 'sk-proj-...',
  promptLength: 7114,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Customer service, Leave Status, Live Agent, Request leave, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 w...

ğŸŒŠ ===== STREAM 6 PROCESSING START =====
â±ï¸  Stream 6 Start: 2025-08-12T19:54:55.015Z
ğŸ“Š Sessions Assigned: 2
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Max Sessions Per Call: 50

ğŸ§  ===== TOKEN ESTIMATION =====
â±ï¸  Estimation Start: 2025-08-12T19:54:55.015Z
ğŸ“Š Sessions to Estimate: 2
ğŸ§  Model: gpt-4.1-nano
ğŸ“Š Token Usage Estimation Results:
   â€¢ Sessions Processed: 2
   â€¢ Session Tokens: 362
   â€¢ Reserved Tokens: 5500
   â€¢ Total Tokens: 5862
   â€¢ Avg Per Session: 181 tokens
   â€¢ Estimation Time: 0ms
[TokenManagementService] Model gpt-4.1-nano context window: 1000000 tokens
[TokenManagementService] Max sessions per call for gpt-4.1-nano: 50

âœ… ===== TOKEN ESTIMATION COMPLETE =====
â±ï¸  Total Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 5862
ğŸ“¦ Max Sessions Per Call: 50
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0009
ğŸ“Š Recommended Batch Size: 2

â±ï¸  Timing Breakdown:
   â€¢ Token Usage Calculation: 0ms
   â€¢ Max Sessions Calculation: 0ms
   â€¢ Cost Estimation: 0ms

ğŸ§  ===== TOKEN ESTIMATION (Stream 6) =====
â±ï¸  Token Estimation Time: 0ms
ğŸ“Š Estimated Tokens: 5862
ğŸ“¦ Recommended Batch Size: 2
ğŸ”„ Requires Splitting: false
ğŸ’° Cost Estimate: $0.0009

âš¡ Stream 6: Processing all sessions in single API call

ğŸ¤– ===== OPENAI API CALL =====
â±ï¸  API Call Start: 2025-08-12T19:54:55.015Z
ğŸ“Š Sessions to Analyze: 2
ğŸ§  Model: gpt-4.1-nano
ğŸ”§ Base Classifications:
   â€¢ Intents: 7
   â€¢ Reasons: 1
   â€¢ Locations: 1

ğŸ¤– OpenAI API Request: {
  timestamp: '2025-08-12T19:54:55.015Z',
  model: 'gpt-4.1-nano',
  modelId: 'gpt-4.1-nano',
  sessionCount: 2,
  apiKey: 'sk-proj-...',
  promptLength: 4805,
  existingClassifications: { intents: 7, transferReasons: 1, dropOffLocations: 1 }
}
ğŸ“ Request Prompt Preview: Analyze the following session transcripts and classify each session according to the specified criteria.


Existing General Intent classifications: Claim Status, Claim status, Customer service, Leave Status, Live Agent, Request leave, Unknown
Existing Transfer Reason classifications: Live Agent Request
Existing Drop-Off Location classifications: Help Offer Prompt

For each session, provide the following classifications:

1. **General Intent**: What the user is trying to accomplish (usually 1-2 w...
::1 - - [12/Aug/2025:19:54:55 +0000] "GET /api/analysis/auto-analyze/parallel/progress/e3384dec-edb5-44ac-bf5a-02d64396ce8c HTTP/1.1" 200 949 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:54:56.188Z',
  duration: '1175ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1949,
    completion_tokens: 184,
    total_tokens: 2133,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-23fea8c8-f919-53ad-9881-252b83a664db",
      "notes": "User wanted to troubleshoot login issue and was transferred to an agent."
    },
    {
      "user_id": "u-44a3baeb-5382-50b3-b965-c6b3dacde7bd",
      "notes": "User indicated desire to speak with an agent, session was transferred."
    },
    {
      "user_id": "u-fa5967dd-1fe8-512b-a895-0c3e78d1e37f",
      "notes": "User inquired about claim status and return to work date; session was transferred to an agent."
    },
    {
      "user_id": "u-dc0fc431-39bd-5277-bdc7-d884a570adc3",
      "notes": "User asked about leave request date; session was transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1949,
  completionTokens: 184,
  totalTokens: 2133,
  cost: '$0.000269',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1175ms (1.18s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2133 ($0.0003)
âš¡ Performance: 1815.3 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1949
   â€¢ Completion Tokens: 184
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-23fea8c8-f919-53ad-9881-252b83a664db: Invalid general_intent, u-23fea8c8-f919-53ad-9881-252b83a664db: Invalid session_outcome, u-44a3baeb-5382-50b3-b965-c6b3dacde7bd: Invalid general_intent, u-44a3baeb-5382-50b3-b965-c6b3dacde7bd: Invalid session_outcome, u-fa5967dd-1fe8-512b-a895-0c3e78d1e37f: Invalid general_intent, u-fa5967dd-1fe8-512b-a895-0c3e78d1e37f: Invalid session_outcome, u-dc0fc431-39bd-5277-bdc7-d884a570adc3: Invalid general_intent, u-dc0fc431-39bd-5277-bdc7-d884a570adc3: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 2 Single Batch Time: 1175ms (1.18s)

âœ… ===== STREAM 2 PROCESSING COMPLETE =====
â±ï¸  Stream 2 Total Time: 1175ms (1.18s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2133 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 3.4 sessions/sec
âš¡ Avg Time Per Session: 293.75ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:54:56.251Z',
  duration: '1238ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1993,
    completion_tokens: 201,
    total_tokens: 2194,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-06c9a0d4-c83c-5be3-8717-044b781bcfb8",
      "notes": "User wanted to speak to an agent but the session was transferred to a live agent."
    },
    {
      "user_id": "u-d40b78e2-d258-53b5-b753-22bb8872a0b5",
      "notes": "User wanted assistance with tax-related issue; session was transferred to a live agent."
    },
    {
      "user_id": "u-592305d2-8cc5-55b5-89b2-43898efd573e",
      "notes": "User attempted to inquire about claim information; session was transferred to a live agent."
    },
    {
      "user_id": "u-7bbf81c6-59d1-5db2-a884-fb85583e8e90",
      "notes": "User wanted to track time and open a leave request; session was transferred to a live agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1993,
  completionTokens: 201,
  totalTokens: 2194,
  cost: '$0.000280',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1239ms (1.24s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2194 ($0.0003)
âš¡ Performance: 1770.8 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1993
   â€¢ Completion Tokens: 201
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-06c9a0d4-c83c-5be3-8717-044b781bcfb8: Invalid general_intent, u-06c9a0d4-c83c-5be3-8717-044b781bcfb8: Invalid session_outcome, u-d40b78e2-d258-53b5-b753-22bb8872a0b5: Invalid general_intent, u-d40b78e2-d258-53b5-b753-22bb8872a0b5: Invalid session_outcome, u-592305d2-8cc5-55b5-89b2-43898efd573e: Invalid general_intent, u-592305d2-8cc5-55b5-89b2-43898efd573e: Invalid session_outcome, u-7bbf81c6-59d1-5db2-a884-fb85583e8e90: Invalid general_intent, u-7bbf81c6-59d1-5db2-a884-fb85583e8e90: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 1 Single Batch Time: 1239ms (1.24s)

âœ… ===== STREAM 1 PROCESSING COMPLETE =====
â±ï¸  Stream 1 Total Time: 1240ms (1.24s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2194 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 3.2 sessions/sec
âš¡ Avg Time Per Session: 310.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:54:56.374Z',
  duration: '1359ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1405,
    completion_tokens: 153,
    total_tokens: 1558,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 2,
  intentsFound: [ 'Customer service', 'Leave Status' ],
  transferCount: 2,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-ec9eb289-59b0-5116-8d5b-ab6e89dc4809",
      "general_intent": "Customer service",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent about renewal."
    },
    {
      "user_id": "u-420d1e6c-1011-5ebb-b1bf-6e7d6b14b04e",
      "general_intent": "Leave Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User was silent and then asked to be transferred to assist with leave request."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1405,
  completionTokens: 153,
  totalTokens: 1558,
  cost: '$0.000202',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1359ms (1.36s)
ğŸ“Š Sessions Returned: 2
ğŸ’° Tokens Used: 1558 ($0.0002)
âš¡ Performance: 1146.4 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1405
   â€¢ Completion Tokens: 153
[SessionValidationService] Validating batch response: 2 input sessions, 2 response sessions
[SessionValidationService] Validation successful: all 2 sessions processed
[SessionValidationService] Validating batch response: 2 input sessions, 2 response sessions
[SessionValidationService] Validation successful: all 2 sessions processed
â±ï¸  Stream 6 Single Batch Time: 1360ms (1.36s)

âœ… ===== STREAM 6 PROCESSING COMPLETE =====
â±ï¸  Stream 6 Total Time: 1360ms (1.36s)
ğŸ“Š Sessions Processed: 2/2
ğŸ’° Tokens Used: 1558 ($0.0002)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 1.5 sessions/sec
âš¡ Avg Time Per Session: 680.00ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:54:56.413Z',
  duration: '1399ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1956,
    completion_tokens: 199,
    total_tokens: 2155,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ undefined ],
  transferCount: 0,
  containedCount: 0
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-15cbb12a-7fe1-58b5-9b89-b0e49763998a",
      "notes": "User wanted to speak with an agent, session was transferred to a live agent."
    },
    {
      "user_id": "u-84d44832-4225-58ed-9997-8e3fb9d056a5",
      "notes": "User attempted to check eligibility but was transferred to a live agent after multiple prompts."
    },
    {
      "user_id": "u-55a1e1d4-d19f-5ca3-8658-3ef9f38695f3",
      "notes": "User was silent, no input received, session was transferred to an agent."
    },
    {
      "user_id": "u-b98657b8-ad28-5250-be43-4a1f7122e18a",
      "notes": "User provided detailed information to report time, session was handled by bot and successfully completed."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1956,
  completionTokens: 199,
  totalTokens: 2155,
  cost: '$0.000275',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1401ms (1.40s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2155 ($0.0003)
âš¡ Performance: 1538.2 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1956
   â€¢ Completion Tokens: 199
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-15cbb12a-7fe1-58b5-9b89-b0e49763998a: Invalid general_intent, u-15cbb12a-7fe1-58b5-9b89-b0e49763998a: Invalid session_outcome, u-84d44832-4225-58ed-9997-8e3fb9d056a5: Invalid general_intent, u-84d44832-4225-58ed-9997-8e3fb9d056a5: Invalid session_outcome, u-55a1e1d4-d19f-5ca3-8658-3ef9f38695f3: Invalid general_intent, u-55a1e1d4-d19f-5ca3-8658-3ef9f38695f3: Invalid session_outcome, u-b98657b8-ad28-5250-be43-4a1f7122e18a: Invalid general_intent, u-b98657b8-ad28-5250-be43-4a1f7122e18a: Invalid session_outcome'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 4 Single Batch Time: 1402ms (1.40s)

âœ… ===== STREAM 4 PROCESSING COMPLETE =====
â±ï¸  Stream 4 Total Time: 1402ms (1.40s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2155 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.9 sessions/sec
âš¡ Avg Time Per Session: 350.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:54:56.654Z',
  duration: '1640ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 1821,
    completion_tokens: 292,
    total_tokens: 2113,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Customer service', 'Request leave' ],
  transferCount: 3,
  containedCount: 1
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-47c37255-0e49-5754-a0de-f1dabc352edc",
      "general_intent": "Customer service",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to update on short term disability and was transferred to an agent."
    },
    {
      "user_id": "u-552412b5-9316-5e90-9cbc-0c29bbc77227",
      "general_intent": "Request leave",
      "session_outcome": "Contained",
      "notes": "User attempted to request a leave but did not provide sufficient information, session was closed."
    },
    {
      "user_id": "u-48628c62-9541-5dce-8e96-6cf21c76a1a8",
      "general_intent": "Customer service",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent about documents not received, transferred to an agent."
    },
    {
      "user_id": "u-39668043-0249-553e-bbc4-1d3de2fb8766",
      "general_intent": "Customer service",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt",
      "notes": "User wanted to speak with an agent about documents not received, transferred to an agent."
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 1821,
  completionTokens: 292,
  totalTokens: 2113,
  cost: '$0.000299',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1641ms (1.64s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2113 ($0.0003)
âš¡ Performance: 1287.6 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 1821
   â€¢ Completion Tokens: 292
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 3 Single Batch Time: 1641ms (1.64s)

âœ… ===== STREAM 3 PROCESSING COMPLETE =====
â±ï¸  Stream 3 Total Time: 1642ms (1.64s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2113 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.4 sessions/sec
âš¡ Avg Time Per Session: 410.50ms
âœ… OpenAI API Response: {
  timestamp: '2025-08-12T19:54:56.922Z',
  duration: '1907ms',
  model: 'gpt-4.1-nano-2025-04-14',
  usage: {
    prompt_tokens: 2057,
    completion_tokens: 244,
    total_tokens: 2301,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 0,
      rejected_prediction_tokens: 0
    }
  },
  finishReason: 'stop',
  hasToolCalls: true
}
ğŸ“Š Parsed Analysis Results: {
  sessionsAnalyzed: 4,
  intentsFound: [ 'Request leave', 'Unknown', 'Leave Status' ],
  transferCount: 2,
  containedCount: 2
}
ğŸ“‹ Full Function Arguments: {
  "sessions": [
    {
      "user_id": "u-2c88bfee-7fbf-5580-9a65-a9ee258e2096",
      "general_intent": "Request leave",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    },
    {
      "user_id": "u-fb98553b-688e-55b7-a9a5-8b5a3eb5ab58",
      "general_intent": "Unknown",
      "session_outcome": "Contained",
      "notes": "User did not provide enough input to determine intent, session was closed without transfer."
    },
    {
      "user_id": "u-959fb7af-197e-51d1-8765-3a7a789faba0",
      "general_intent": "Leave Status",
      "session_outcome": "Contained",
      "notes": "User reported a leave request and confirmed details, session was handled by bot."
    },
    {
      "user_id": "u-0027376a-8dd6-5594-97f8-bc6c3a96c6a7",
      "general_intent": "Leave Status",
      "session_outcome": "Transfer",
      "transfer_reason": "Live Agent Request",
      "drop_off_location": "Help Offer Prompt"
    }
  ]
}
ğŸ’° Cost Calculation: {
  promptTokens: 2057,
  completionTokens: 244,
  totalTokens: 2301,
  cost: '$0.000303',
  modelUsedForCost: 'gpt-4.1-nano'
}

âœ… ===== OPENAI API CALL COMPLETE =====
â±ï¸  API Call Time: 1908ms (1.91s)
ğŸ“Š Sessions Returned: 4
ğŸ’° Tokens Used: 2301 ($0.0003)
âš¡ Performance: 1206.0 tokens/sec
ğŸ“ˆ Token Breakdown:
   â€¢ Prompt Tokens: 2057
   â€¢ Completion Tokens: 244
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation issues found: {
  missing: 0,
  errors: 1,
  details: [
    'Malformed sessions: u-2c88bfee-7fbf-5580-9a65-a9ee258e2096: Invalid notes, u-0027376a-8dd6-5594-97f8-bc6c3a96c6a7: Invalid notes'
  ]
}
[SessionValidationService] Validating batch response: 4 input sessions, 4 response sessions
[SessionValidationService] Validation successful: all 4 sessions processed
â±ï¸  Stream 5 Single Batch Time: 1908ms (1.91s)

âœ… ===== STREAM 5 PROCESSING COMPLETE =====
â±ï¸  Stream 5 Total Time: 1908ms (1.91s)
ğŸ“Š Sessions Processed: 4/4
ğŸ’° Tokens Used: 2301 ($0.0003)
ğŸ”„ Retry Attempts: 0
ğŸ¯ Performance: 2.1 sessions/sec
âš¡ Avg Time Per Session: 477.00ms
[ParallelProcessingOrchestrator] Parallel processing complete: 6/6 streams succeeded
â±ï¸  Parallel Processing Time: 1910ms (1.91s)
[ParallelProcessingOrchestrator] Synchronizing classifications from 6 streams
[ParallelProcessingOrchestrator] Synchronization complete: 0 new classifications added

ğŸ”„ ============ CLASSIFICATION SYNCHRONIZATION ============
â±ï¸  Sync Time: 0ms
ğŸ†• New Classifications: 0
ğŸ“Š Total Classifications: 9

âœ… ============ ROUND 3 COMPLETED ============
â±ï¸  Round 3 Total Time: 1911ms (1.91s)
â±ï¸  Session Cleanup Time: 0ms
ğŸ“Š Sessions Remaining: 0
ğŸ¯ Round Breakdown:
   â€¢ Distribution: 0ms (0.0%)
   â€¢ Parallel Processing: 1910ms (99.9%)
   â€¢ Synchronization: 0ms (0.0%)
   â€¢ Cleanup: 0ms (0.0%)

ğŸ‰ ============ PARALLEL PROCESSING COMPLETE ============
â±ï¸  TOTAL TIME: 6371ms (6.37s)
ğŸ“Š Sessions Processed: 86/86
ğŸ”„ Total Rounds: 3
ğŸŒŠ Stream Results: 22
ğŸ’° Token Usage: 46091 tokens ($0.0062)
ğŸ“ˆ Stream Utilization: 100.0%
ğŸ¯ Performance: 13.5 sessions/second
âš¡ Avg Time Per Session: 74.08ms

ğŸ“Š Stream Performance Breakdown:
   Stream 1: 4 sessions in 2014ms (977.2 tokens/sec)
   Stream 2: 4 sessions in 1795ms (1270.8 tokens/sec)
   Stream 3: 4 sessions in 1820ms (1054.9 tokens/sec)
   Stream 4: 4 sessions in 1409ms (1416.6 tokens/sec)
   Stream 5: 4 sessions in 1464ms (1503.4 tokens/sec)
   Stream 6: 4 sessions in 1507ms (1149.3 tokens/sec)
   Stream 7: 4 sessions in 1756ms (1060.9 tokens/sec)
   Stream 8: 4 sessions in 1816ms (1213.7 tokens/sec)
   Stream 1: 4 sessions in 1641ms (1442.4 tokens/sec)
   Stream 2: 4 sessions in 1709ms (1182.6 tokens/sec)
   Stream 3: 4 sessions in 1282ms (1833.1 tokens/sec)
   Stream 4: 4 sessions in 1459ms (1466.1 tokens/sec)
   Stream 5: 4 sessions in 1536ms (1441.4 tokens/sec)
   Stream 6: 4 sessions in 1882ms (1153.6 tokens/sec)
   Stream 7: 4 sessions in 1700ms (1188.8 tokens/sec)
   Stream 8: 4 sessions in 2436ms (898.6 tokens/sec)
   Stream 1: 4 sessions in 1240ms (1769.4 tokens/sec)
   Stream 2: 4 sessions in 1175ms (1815.3 tokens/sec)
   Stream 3: 4 sessions in 1642ms (1286.8 tokens/sec)
   Stream 4: 4 sessions in 1402ms (1537.1 tokens/sec)
   Stream 5: 4 sessions in 1908ms (1206.0 tokens/sec)
   Stream 6: 2 sessions in 1360ms (1145.6 tokens/sec)
[ConflictResolutionService] Starting conflict resolution for 100 sessions
[ConflictResolutionService] Found classifications: { intents: 7, reasons: 1, locations: 1 }
[ConflictResolutionService] Calling LLM for conflict resolution with model gpt-4.1-nano
ğŸ”§ Conflict Resolution Prompt Preview: You are reviewing classifications from parallel analysis streams. Identify any semantic duplicates and choose the canonical version for each group.

**Instructions:**
1. Look for classifications that refer to the same concept but use different wording
2. For each group of duplicates, choose the most...
::1 - - [12/Aug/2025:19:54:57 +0000] "GET /api/analysis/auto-analyze/parallel/progress/e3384dec-edb5-44ac-bf5a-02d64396ce8c HTTP/1.1" 200 970 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[ConflictResolution] LLM response: {
  "generalIntents": [
    {
      "canonical": "Claim Status",
      "aliases": [
        "Claim status"
      ]
    },
    {
      "canonical": "Customer Service",
      "aliases": []
    },
    {
      "canonical": "Leave Request Status",
      "aliases": [
        "Leave Status"
      ]
    },
    {
      "canonical": "Live Agent Transfer",
      "aliases": [
        "Live Agent"
      ]
    },
    {
      "canonical": "Unknown",
      "aliases": []
    }
  ],
  "transferReasons": [
    {
      "canonical": "Live Agent Request",
      "aliases": [
        "Live Agent Request"
      ]
    }
  ],
  "dropOffLocations": [
    {
      "canonical": "Help Offer Prompt",
      "aliases": [
        "Help Offer Prompt"
      ]
    }
  ]
}
[ConflictResolutionService] LLM conflict resolution complete: { intents: 5, reasons: 1, locations: 1, tokens: 725, cost: 0.0001013 }
ğŸ”§ Conflict Resolution Response: {
  "generalIntents": [
    {
      "canonical": "Claim Status",
      "aliases": [
        "Claim status"
      ]
    },
    {
      "canonical": "Customer Service",
      "aliases": []
    },
    {
      "canonical": "Leave Request Status",
      "aliases": [
        "Leave Status"
      ]
    },
    {
      "canonical": "Live Agent Transfer",
      "aliases": [
        "Live Agent"
      ]
    },
    {
      "canonical": "Unknown",
      "aliases": []
    }
  ],
  "transferReasons": [
    {
      "canonical": "Live Agent Request",
      "aliases": [
        "Live Agent Request"
      ]
    }
  ],
  "dropOffLocations": [
    {
      "canonical": "Help Offer Prompt",
      "aliases": [
        "Help Offer Prompt"
      ]
    }
  ]
}
[ConflictResolutionService] Applying resolutions to 100 sessions
[ConflictResolutionService] Applied 28 classification mappings across 100 sessions
[ConflictResolutionService] Identified 1 potential conflict groups
[ConflictResolutionService] Conflict resolution complete in 1192ms: { conflictsFound: 1, conflictsResolved: 7, canonicalMappings: 5 }
[ParallelAutoAnalyzeService] Using real analysis summary service
::1 - - [12/Aug/2025:19:54:59 +0000] "GET /api/analysis/auto-analyze/parallel/progress/e3384dec-edb5-44ac-bf5a-02d64396ce8c HTTP/1.1" 200 1044 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:55:01 +0000] "GET /api/analysis/auto-analyze/parallel/progress/e3384dec-edb5-44ac-bf5a-02d64396ce8c HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:55:03 +0000] "GET /api/analysis/auto-analyze/parallel/progress/e3384dec-edb5-44ac-bf5a-02d64396ce8c HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:55:05 +0000] "GET /api/analysis/auto-analyze/parallel/progress/e3384dec-edb5-44ac-bf5a-02d64396ce8c HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:55:07 +0000] "GET /api/analysis/auto-analyze/parallel/progress/e3384dec-edb5-44ac-bf5a-02d64396ce8c HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:55:09 +0000] "GET /api/analysis/auto-analyze/parallel/progress/e3384dec-edb5-44ac-bf5a-02d64396ce8c HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:55:11 +0000] "GET /api/analysis/auto-analyze/parallel/progress/e3384dec-edb5-44ac-bf5a-02d64396ce8c HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:55:13 +0000] "GET /api/analysis/auto-analyze/parallel/progress/e3384dec-edb5-44ac-bf5a-02d64396ce8c HTTP/1.1" 304 - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[ParallelAutoAnalyzeService] Parallel analysis e3384dec-edb5-44ac-bf5a-02d64396ce8c completed successfully
[BackgroundJobQueue] Updated job progress to final state: complete
[BackgroundJobQueue] Parallel analysis job e3384dec-edb5-44ac-bf5a-02d64396ce8c-parallel completed successfully
::1 - - [12/Aug/2025:19:55:15 +0000] "GET /api/analysis/auto-analyze/parallel/progress/e3384dec-edb5-44ac-bf5a-02d64396ce8c HTTP/1.1" 200 1068 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
::1 - - [12/Aug/2025:19:55:15 +0000] "GET /api/analysis/auto-analyze/parallel/results/e3384dec-edb5-44ac-bf5a-02d64396ce8c HTTP/1.1" 200 727651 "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
4:02:38 PM [tsx] change in ./src/services/parallelAutoAnalyzeService.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
4:03:55 PM [tsx] change in ./src/services/parallelAutoAnalyzeService.ts Restarting...
cğŸš€ XOB CAT Backend API running on port 3001
ğŸ“Š Health check: http://localhost:3001/health
ğŸ”— Frontend URL: http://localhost:3000
ğŸ”— Detected real credentials - clearing mock service environment variable
ğŸ”— Using user-provided Kore.ai credentials: User Bot st-90549...
Testing Kore.ai API connectivity with optimized connection test...
[getSessionsMetadataForConnectionTest] Connection test with limit=1, timeout=10000ms
[getSessionsMetadataForConnectionTest] isMockCredentials: false
[getSessionsMetadataForConnectionTest] Making SINGLE API call for 'agent' containment type
Requesting agent session metadata from URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Making API call for agent:
[fetchContainmentTypeMetadata] URL: https://bots.kore.ai/api/public/bot/***REMOVED***/getSessions?containmentType=agent
[fetchContainmentTypeMetadata] Payload: {
  "dateFrom": "2025-08-12T20:03:34.684Z",
  "dateTo": "2025-08-12T20:04:34.684Z",
  "skip": 0,
  "limit": 1
}
::1 - - [12/Aug/2025:20:04:39 +0000] "GET /api/kore/test HTTP/1.1" - - "http://localhost:3000/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
[getSessionsMetadataForConnectionTest] Connection test failed: Error: Connection test timeout after 10000ms
    at Timeout._onTimeout (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:491:33)
    at listOnTimeout (node:internal/timers:608:17)
    at process.processTimers (node:internal/timers:543:7)
Kore.ai API connection test failed: Error: Connection test timeout after 10000ms
    at Timeout._onTimeout (/Users/kengrafals/workspace/xobcat/backend/src/services/koreApiService.ts:491:33)
    at listOnTimeout (node:internal/timers:608:17)
    at process.processTimers (node:internal/timers:543:7)
[fetchContainmentTypeMetadata] API Response: 1 agent sessions received
[fetchContainmentTypeMetadata] Sample session IDs: [ '689b9e29759df740255398a3' ]
